{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"17iPgIhucZHuF1xiM9eLjeL0S4n3TnthH","timestamp":1668427265957},{"file_id":"17B1TNnNzNJOaFfgIxnoc2J92QtZ_WWSw","timestamp":1668343763028}],"machine_shape":"hm","gpuType":"V100","authorship_tag":"ABX9TyMxAgYSyYDNzWkSey4Y1FIX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"8856e0244c7a4a278c70af17ba222aec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6a2a4ab75ad443d49a3638f29827303b","IPY_MODEL_fa9c69a78a084663bc3f9e30b75d4473","IPY_MODEL_68031e477f7048408260185dbe78d21a"],"layout":"IPY_MODEL_47313e0dff814d9882171837dd562d3f"}},"6a2a4ab75ad443d49a3638f29827303b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69d45bd2ca294752aeb6f38155333c2d","placeholder":"​","style":"IPY_MODEL_6ee00ad75ecf4719b0bc2d286b022fe3","value":"Processing Progress: 100%"}},"fa9c69a78a084663bc3f9e30b75d4473":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5269b2001b3e4652ac45a494d5197855","max":100000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ac22784a5d0c47138b51819090230953","value":100000}},"68031e477f7048408260185dbe78d21a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa329694c0d94a349c1c8ba89693d0e3","placeholder":"​","style":"IPY_MODEL_c38fcff54d36456fa367c8bd07821261","value":" 100000/100000 [10:18&lt;00:00, 37.81it/s]"}},"47313e0dff814d9882171837dd562d3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69d45bd2ca294752aeb6f38155333c2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ee00ad75ecf4719b0bc2d286b022fe3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5269b2001b3e4652ac45a494d5197855":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac22784a5d0c47138b51819090230953":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fa329694c0d94a349c1c8ba89693d0e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c38fcff54d36456fa367c8bd07821261":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"141a8321993d4b6497e945d5cae1f2bd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_06efa173c613478ea3f12997f2a48e14","IPY_MODEL_f943ac4144864c18bae86a600aa5f559","IPY_MODEL_c0e9a183cc954b8c9e3c3db47ef9c611"],"layout":"IPY_MODEL_c41f1b39cff24f72bd0e7b60d5423d83"}},"06efa173c613478ea3f12997f2a48e14":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84ffefbf17b54ef4a4afd3acd43d9486","placeholder":"​","style":"IPY_MODEL_aca99de89b9f4838aa3ce85e706b95d3","value":"Write Progress: "}},"f943ac4144864c18bae86a600aa5f559":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ff69842a1c24792a6cd4f42db45fdcd","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d2786ffbbcd14ca5b0af3bfaa35e2f53","value":1000}},"c0e9a183cc954b8c9e3c3db47ef9c611":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf0eee0cf56c4402a35b2683f5f3ea01","placeholder":"​","style":"IPY_MODEL_f1610f90fd004a38b194ae4859f25426","value":" 1001/? [13:53&lt;00:00,  1.53it/s]"}},"c41f1b39cff24f72bd0e7b60d5423d83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84ffefbf17b54ef4a4afd3acd43d9486":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aca99de89b9f4838aa3ce85e706b95d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4ff69842a1c24792a6cd4f42db45fdcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2786ffbbcd14ca5b0af3bfaa35e2f53":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cf0eee0cf56c4402a35b2683f5f3ea01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1610f90fd004a38b194ae4859f25426":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c44037262314e129fb33e267244034a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f2ea0e5a173a4cf2a87dfc6224aa20c4","IPY_MODEL_f15f430308024941b3bbcbe425aea8a3","IPY_MODEL_da98fa9396fd4bb68214e4e7b2ac4879"],"layout":"IPY_MODEL_689719364ce5494a9df3a158db256f45"}},"f2ea0e5a173a4cf2a87dfc6224aa20c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_885edba6ac9946e58af4d42945fb1ad4","placeholder":"​","style":"IPY_MODEL_ae96cdd390114581a4df661d839d36e1","value":"Processing Progress: 100%"}},"f15f430308024941b3bbcbe425aea8a3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4084c6e9d79e430c8e0bebec6af2a1bc","max":100000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_de61536a2856409b830cf25d7810faa9","value":100000}},"da98fa9396fd4bb68214e4e7b2ac4879":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d5ff26f66184d438d27e5ea907d2143","placeholder":"​","style":"IPY_MODEL_b7f7bfd2f8124c7a8ba9ec009985dbbc","value":" 100000/100000 [10:23&lt;00:00, 168.95it/s]"}},"689719364ce5494a9df3a158db256f45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"885edba6ac9946e58af4d42945fb1ad4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae96cdd390114581a4df661d839d36e1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4084c6e9d79e430c8e0bebec6af2a1bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de61536a2856409b830cf25d7810faa9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8d5ff26f66184d438d27e5ea907d2143":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7f7bfd2f8124c7a8ba9ec009985dbbc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c8eec8906a0b4f7086f3a1cc49a0e391":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ed3e6458d8f4418092700e8d3d227890","IPY_MODEL_68060fb0b5ef4092b09b1d1d3746cc7c","IPY_MODEL_8cc7b11c6e204d36b63ca4b6498c9694"],"layout":"IPY_MODEL_9f17e367d76242398756365022f3bcd5"}},"ed3e6458d8f4418092700e8d3d227890":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_349bf3f1097941c0a2e3ee575a02a18a","placeholder":"​","style":"IPY_MODEL_5e8d0d8ecf4447d793e8f854941688c8","value":"Write Progress: "}},"68060fb0b5ef4092b09b1d1d3746cc7c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_05b8ef0a6a504e95b652703399b846b3","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_80b4e3e1c1df44dbbcbd406f31e62002","value":1000}},"8cc7b11c6e204d36b63ca4b6498c9694":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_980b64206d944b6795bb8f0ced2e3c04","placeholder":"​","style":"IPY_MODEL_f8026818bbb84b608d859f3e60659ad4","value":" 1001/? [09:24&lt;00:00,  5.35s/it]"}},"9f17e367d76242398756365022f3bcd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"349bf3f1097941c0a2e3ee575a02a18a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e8d0d8ecf4447d793e8f854941688c8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05b8ef0a6a504e95b652703399b846b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80b4e3e1c1df44dbbcbd406f31e62002":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"980b64206d944b6795bb8f0ced2e3c04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8026818bbb84b608d859f3e60659ad4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0fc03a616766446c8e1fc181f7ad7e53":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f96e425cf65948e2bec3303250750109","IPY_MODEL_358b61297fbd4d498d83e37bcf1f5020","IPY_MODEL_cdc28a7e756846f8b3a4f1309c7b2c28"],"layout":"IPY_MODEL_670ac2254b58499085469892297a829e"}},"f96e425cf65948e2bec3303250750109":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b21d3a2c4d11440b82f34956ddc42e99","placeholder":"​","style":"IPY_MODEL_a1fb0f22d387494787f5a8b7fe804e97","value":"Processing Progress: 100%"}},"358b61297fbd4d498d83e37bcf1f5020":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e255cc2176b2408fb3db966f0042208f","max":100000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7cdd6c0ae0154f97b383334bebfcccc5","value":100000}},"cdc28a7e756846f8b3a4f1309c7b2c28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7504afd683f485c94db3464d3a6de29","placeholder":"​","style":"IPY_MODEL_ff832b02902447779e919cfd9d00fbdb","value":" 100000/100000 [10:23&lt;00:00, 172.20it/s]"}},"670ac2254b58499085469892297a829e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b21d3a2c4d11440b82f34956ddc42e99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1fb0f22d387494787f5a8b7fe804e97":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e255cc2176b2408fb3db966f0042208f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cdd6c0ae0154f97b383334bebfcccc5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c7504afd683f485c94db3464d3a6de29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff832b02902447779e919cfd9d00fbdb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df9c3d40c4e24aadbf4e27f91c6ef528":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ff03379fd03a48a8b19da5a6c12ed513","IPY_MODEL_c73273b93cb6446d92f77b6c4f8e6164","IPY_MODEL_ba98c5b0d25142c2a25be9ffdce15415"],"layout":"IPY_MODEL_9286935a0dca499d9f8e79dc3c2eaa30"}},"ff03379fd03a48a8b19da5a6c12ed513":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d028e060162141f894b034e1dfb5be14","placeholder":"​","style":"IPY_MODEL_b7631692d1c54528aa8500ea60c40c8a","value":"Write Progress: "}},"c73273b93cb6446d92f77b6c4f8e6164":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_482cde19ffad4bb2bd52aac7aa0aa787","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ee99866a961d4a8e99ec73ad5ab5c343","value":1000}},"ba98c5b0d25142c2a25be9ffdce15415":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a91a784424284f9fa7179533431537d9","placeholder":"​","style":"IPY_MODEL_9d11afeda80845ad903082b0c8be098f","value":" 1001/? [14:36&lt;00:00,  1.26it/s]"}},"9286935a0dca499d9f8e79dc3c2eaa30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d028e060162141f894b034e1dfb5be14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7631692d1c54528aa8500ea60c40c8a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"482cde19ffad4bb2bd52aac7aa0aa787":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee99866a961d4a8e99ec73ad5ab5c343":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a91a784424284f9fa7179533431537d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d11afeda80845ad903082b0c8be098f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f1c2622d28c48e4abedc0432746fb59":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1f94b2d9dfcf4484bbebcfe733ac0c52","IPY_MODEL_ade0fe2ecacc406195f600fb23f5cc11","IPY_MODEL_f260d0ed5bbf43578f0050e66f45ff6d"],"layout":"IPY_MODEL_841684594a2c40e28f5cdb67b09ab276"}},"1f94b2d9dfcf4484bbebcfe733ac0c52":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1affe0f2fa240a180589820485a9f37","placeholder":"​","style":"IPY_MODEL_07b97bf60f754c17aa3d5ddcec013aba","value":"Processing Progress: 100%"}},"ade0fe2ecacc406195f600fb23f5cc11":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_07c0c331706d42239e3354aecd2f4b4e","max":100000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d1ae18b5c9164ce4ac060e384b7f3392","value":100000}},"f260d0ed5bbf43578f0050e66f45ff6d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1da643bcb379450e9e0c6e89e30b6020","placeholder":"​","style":"IPY_MODEL_9fd933f2247b4dd7b7e807672ba78510","value":" 100000/100000 [10:13&lt;00:00, 164.86it/s]"}},"841684594a2c40e28f5cdb67b09ab276":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1affe0f2fa240a180589820485a9f37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07b97bf60f754c17aa3d5ddcec013aba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"07c0c331706d42239e3354aecd2f4b4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1ae18b5c9164ce4ac060e384b7f3392":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1da643bcb379450e9e0c6e89e30b6020":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fd933f2247b4dd7b7e807672ba78510":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30b674c683334dc5a886085bc5da7dd1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_226ef69ded694399ac823b459e889fed","IPY_MODEL_df1d26813baa4a0597b9bdb5af3bd13f","IPY_MODEL_24682bd6941d4aa4b6e07d63ab60545d"],"layout":"IPY_MODEL_51da0ed9171b4ad3a3c765564893863c"}},"226ef69ded694399ac823b459e889fed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04c43fbbb50145018762cc798c2d9f85","placeholder":"​","style":"IPY_MODEL_9081f193c5c1478686b33ac298646938","value":"Write Progress: "}},"df1d26813baa4a0597b9bdb5af3bd13f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b38c92b86ea54e7cb1d2c996bff4801d","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5a32fe5b7d9544fd859b29d8357a7cf6","value":1000}},"24682bd6941d4aa4b6e07d63ab60545d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3d757fa65994b479ce9c3351f931d9c","placeholder":"​","style":"IPY_MODEL_92abb3ee1b5642a0a63b5b0791a45294","value":" 1001/? [02:43&lt;00:00, 35.69it/s]"}},"51da0ed9171b4ad3a3c765564893863c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04c43fbbb50145018762cc798c2d9f85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9081f193c5c1478686b33ac298646938":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b38c92b86ea54e7cb1d2c996bff4801d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a32fe5b7d9544fd859b29d8357a7cf6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d3d757fa65994b479ce9c3351f931d9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92abb3ee1b5642a0a63b5b0791a45294":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5eeb380e3e1146b38f3dd90642344e84":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d181067b4f2a43bb8cdf021c8bf12a73","IPY_MODEL_06e0abef7de14b5d82e64f3a9d24759e","IPY_MODEL_83567640b3ca4a0aa50043dc66738afe"],"layout":"IPY_MODEL_ee49a484649a4314b018d7110f09a204"}},"d181067b4f2a43bb8cdf021c8bf12a73":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dda1984cb671441d9e98b97b7417bf3f","placeholder":"​","style":"IPY_MODEL_7de4ee8644d64df6b0ede1017f51c447","value":"Processing Progress: 100%"}},"06e0abef7de14b5d82e64f3a9d24759e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7070f9ea2e744f4caafb634617e519c9","max":100000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ac5d70712474ece9b2c254794a30e02","value":100000}},"83567640b3ca4a0aa50043dc66738afe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b120872a03ee4d3cb8ea298ec59767d3","placeholder":"​","style":"IPY_MODEL_cc7fa056ca584b0bb9e929fff48e0e33","value":" 100000/100000 [09:59&lt;00:00, 192.61it/s]"}},"ee49a484649a4314b018d7110f09a204":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dda1984cb671441d9e98b97b7417bf3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7de4ee8644d64df6b0ede1017f51c447":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7070f9ea2e744f4caafb634617e519c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ac5d70712474ece9b2c254794a30e02":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b120872a03ee4d3cb8ea298ec59767d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc7fa056ca584b0bb9e929fff48e0e33":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4497b28d9a804c498b3f0ae8d062cfb4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_73033b7c63c7460fbecd9920aeb62bd0","IPY_MODEL_e376350679d24ba49ca3a66aa2daeae7","IPY_MODEL_36bab4f238e141dc94f065d8efdc3e07"],"layout":"IPY_MODEL_3db122836c6442628cdb5b9aa5b80375"}},"73033b7c63c7460fbecd9920aeb62bd0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3bc584cfaec74aec8d9d9e4c1a002d77","placeholder":"​","style":"IPY_MODEL_f9d8525f21c14911911f2799c8d50e0f","value":"Write Progress: "}},"e376350679d24ba49ca3a66aa2daeae7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_82304c5496994199ab0ba4b92f8f048e","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_073cf41004eb4711b9ce77703ffe63fa","value":1000}},"36bab4f238e141dc94f065d8efdc3e07":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_477d788db9394ba7ad2002c0f150006b","placeholder":"​","style":"IPY_MODEL_d247008e92644b55bc6971ba69fc630d","value":" 1001/? [04:38&lt;00:00, 15.24it/s]"}},"3db122836c6442628cdb5b9aa5b80375":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bc584cfaec74aec8d9d9e4c1a002d77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9d8525f21c14911911f2799c8d50e0f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82304c5496994199ab0ba4b92f8f048e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"073cf41004eb4711b9ce77703ffe63fa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"477d788db9394ba7ad2002c0f150006b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d247008e92644b55bc6971ba69fc630d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8898fe84ab1b429e88a5a609b8b270fe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2dd301500e7c4cfea9c25629764caab1","IPY_MODEL_a35f832bc8c44d829dc5f4a4a52d6edf","IPY_MODEL_e8dc90df222f4de3aa5a40b976148069"],"layout":"IPY_MODEL_f7d5fb6fd03e41bf85e2d15cae5d0e4b"}},"2dd301500e7c4cfea9c25629764caab1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ae24993b3344dd6b91e61c4ec915b83","placeholder":"​","style":"IPY_MODEL_fb56d8c8925d4e48b2e849cb6f9ee00d","value":"Processing Progress: 100%"}},"a35f832bc8c44d829dc5f4a4a52d6edf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3352751c1b704215ab1fea989d048e56","max":100000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f3eedf8092a54754bdf664c66241c4c2","value":100000}},"e8dc90df222f4de3aa5a40b976148069":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a746d3da20eb4725ba583a56ac623538","placeholder":"​","style":"IPY_MODEL_e03e828cc24e4d4bad5238a6bb809161","value":" 100000/100000 [10:08&lt;00:00, 182.12it/s]"}},"f7d5fb6fd03e41bf85e2d15cae5d0e4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ae24993b3344dd6b91e61c4ec915b83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb56d8c8925d4e48b2e849cb6f9ee00d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3352751c1b704215ab1fea989d048e56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3eedf8092a54754bdf664c66241c4c2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a746d3da20eb4725ba583a56ac623538":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e03e828cc24e4d4bad5238a6bb809161":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31904fe7b4dd482ba8d3d964452a3424":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_740d72c1b342429db6e3fb0dc4324916","IPY_MODEL_b1055304aa9c4398bfe1e7b04232c82f","IPY_MODEL_1c92b7598d2d45ebbd6c1dd5f0e593f6"],"layout":"IPY_MODEL_097d8e83002b4dbc83ee14a153502f41"}},"740d72c1b342429db6e3fb0dc4324916":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_29ac7667469c464eba98b8c0651d0bdb","placeholder":"​","style":"IPY_MODEL_113e2fb288b34c95a6d034dcd58bf0b9","value":"Write Progress: "}},"b1055304aa9c4398bfe1e7b04232c82f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5efc9d376cab49e393a74dc58bdcfd85","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_65abd516ec2b44bd99aa2f4790143124","value":1000}},"1c92b7598d2d45ebbd6c1dd5f0e593f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e2d66dcd8ee463aaa6fc317d7a80d8a","placeholder":"​","style":"IPY_MODEL_41b42b7ec7774683a24e26f7c7fd8d5a","value":" 1001/? [00:49&lt;00:00, 21.95it/s]"}},"097d8e83002b4dbc83ee14a153502f41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29ac7667469c464eba98b8c0651d0bdb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"113e2fb288b34c95a6d034dcd58bf0b9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5efc9d376cab49e393a74dc58bdcfd85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65abd516ec2b44bd99aa2f4790143124":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8e2d66dcd8ee463aaa6fc317d7a80d8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41b42b7ec7774683a24e26f7c7fd8d5a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e6a2b17f46b4778b2566537b62c20a8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_517e904d47c54eacb943faf2e6bbc8aa","IPY_MODEL_24a2132bfac64fb1b8252c76dab60ba9","IPY_MODEL_d55a967071d8483688041fd5b44f8c0a"],"layout":"IPY_MODEL_3cf3860a67f54773867b88639277e96d"}},"517e904d47c54eacb943faf2e6bbc8aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f50e10500684e0687ce3b9caf035351","placeholder":"​","style":"IPY_MODEL_bd7de79a8fac49de9e0e34cd5fa75810","value":"Processing Progress: 100%"}},"24a2132bfac64fb1b8252c76dab60ba9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb12d7c0ccc14b9f80486805eb4c1091","max":100000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_659523e3dd9a44d7b8c0b221f71e7a4e","value":100000}},"d55a967071d8483688041fd5b44f8c0a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5dec1fea15594c9285bf8970e817b25c","placeholder":"​","style":"IPY_MODEL_1b8e35d3dae840f3a115903a6653cc92","value":" 100000/100000 [10:03&lt;00:00, 173.93it/s]"}},"3cf3860a67f54773867b88639277e96d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f50e10500684e0687ce3b9caf035351":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd7de79a8fac49de9e0e34cd5fa75810":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb12d7c0ccc14b9f80486805eb4c1091":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"659523e3dd9a44d7b8c0b221f71e7a4e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5dec1fea15594c9285bf8970e817b25c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b8e35d3dae840f3a115903a6653cc92":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1b0b3dceb04d41b49ad0a9030ecd87de":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7c7e2f248e5d48319c059d4a216e6547","IPY_MODEL_bb1dddf496144561967823b73e070a39","IPY_MODEL_5a9de94ddc6147239a21cab578d44626"],"layout":"IPY_MODEL_3772e775a84e45f6b069ac81c38d4805"}},"7c7e2f248e5d48319c059d4a216e6547":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7db64f6d3cf44744ae0a0cfba32b6e06","placeholder":"​","style":"IPY_MODEL_fae6a3c4b6094fadae8f0db700595fd4","value":"Write Progress: "}},"bb1dddf496144561967823b73e070a39":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5270f13681e44ac88ca295e2550fac1c","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1ee540a502d042bfbda71adb2eeabfd2","value":1000}},"5a9de94ddc6147239a21cab578d44626":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8716c0d7b0946a2bdc23ceb92616b85","placeholder":"​","style":"IPY_MODEL_7931baa091c24e91af39cb4f33a237bc","value":" 1001/? [00:28&lt;00:00, 23.38it/s]"}},"3772e775a84e45f6b069ac81c38d4805":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7db64f6d3cf44744ae0a0cfba32b6e06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fae6a3c4b6094fadae8f0db700595fd4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5270f13681e44ac88ca295e2550fac1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ee540a502d042bfbda71adb2eeabfd2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e8716c0d7b0946a2bdc23ceb92616b85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7931baa091c24e91af39cb4f33a237bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3eb8b0db1f9644fb9af6fb10f026b1ca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8eb2e0617e4341819fd08002ffd9f26a","IPY_MODEL_402b5f592e864be498742dcf9ce274b9","IPY_MODEL_5e9e9ad0dc4f4d688a5db26726119178"],"layout":"IPY_MODEL_c32a5b09e8c14f6492eb05496dacf5af"}},"8eb2e0617e4341819fd08002ffd9f26a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_548bf7c7ae3f45c2a8e2a912cc6067b8","placeholder":"​","style":"IPY_MODEL_24991884345847668757523dc811c0ed","value":"Processing Progress: 100%"}},"402b5f592e864be498742dcf9ce274b9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e1fcc80a5194995aa0cc57e18e70e2f","max":100000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ea015c3d01784854b5a0f91bb2846340","value":100000}},"5e9e9ad0dc4f4d688a5db26726119178":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_18baafbd13734a65936797ca25b6d375","placeholder":"​","style":"IPY_MODEL_e10996b57f9a4281a8a5cbf622610962","value":" 100000/100000 [10:00&lt;00:00, 187.18it/s]"}},"c32a5b09e8c14f6492eb05496dacf5af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"548bf7c7ae3f45c2a8e2a912cc6067b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24991884345847668757523dc811c0ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e1fcc80a5194995aa0cc57e18e70e2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea015c3d01784854b5a0f91bb2846340":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"18baafbd13734a65936797ca25b6d375":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e10996b57f9a4281a8a5cbf622610962":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7db1d391a762430caab84dc1f222cb7f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9e51f74d10ea4546b1f0db1795cf478d","IPY_MODEL_e9cf3978f0bc47d68c6489dbb6b77444","IPY_MODEL_6e20865484ec449599a46a08e43cd660"],"layout":"IPY_MODEL_27feb45f2f3242659d442318d2d5d430"}},"9e51f74d10ea4546b1f0db1795cf478d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e05f38a8061441fae8e6217ea6edf5f","placeholder":"​","style":"IPY_MODEL_19e88ad6fd45468395391ee3cc7315cd","value":"Write Progress: "}},"e9cf3978f0bc47d68c6489dbb6b77444":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6be20f53a3b942079602f3b397852db0","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_92a8ef75c4c64252a11cb0c7c8ceecdd","value":1000}},"6e20865484ec449599a46a08e43cd660":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_447c83d95ffc4844a9de2b5b990ff32d","placeholder":"​","style":"IPY_MODEL_2fa272c2eeb8471996509d5c3f85bb48","value":" 1001/? [06:35&lt;00:00, 52.12it/s]"}},"27feb45f2f3242659d442318d2d5d430":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e05f38a8061441fae8e6217ea6edf5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19e88ad6fd45468395391ee3cc7315cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6be20f53a3b942079602f3b397852db0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92a8ef75c4c64252a11cb0c7c8ceecdd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"447c83d95ffc4844a9de2b5b990ff32d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fa272c2eeb8471996509d5c3f85bb48":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce4dd1bb215040728744ceb6394211d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ce01f958c64d471490023ce5d030a4b6","IPY_MODEL_5a898b649ecc4802bf8cb868d82d00c3","IPY_MODEL_abadf98563784d53921a059af10c3ba6"],"layout":"IPY_MODEL_7beadfa5d1fa477d84434f26f80c57bb"}},"ce01f958c64d471490023ce5d030a4b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3245ea3e1d024b5e9c69de41a963dc98","placeholder":"​","style":"IPY_MODEL_ff630956dae64d829f9995196dc0071f","value":"Processing Progress: 100%"}},"5a898b649ecc4802bf8cb868d82d00c3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6390e6b786ee46c8baaa65f44a5bcc5d","max":100000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a10ead483edb4af3a411c364b70430c5","value":100000}},"abadf98563784d53921a059af10c3ba6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a98e4dace8df4176951ecafe8f5250f4","placeholder":"​","style":"IPY_MODEL_12d2e96145574682965e611ce8ade2be","value":" 100000/100000 [10:03&lt;00:00, 174.21it/s]"}},"7beadfa5d1fa477d84434f26f80c57bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3245ea3e1d024b5e9c69de41a963dc98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff630956dae64d829f9995196dc0071f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6390e6b786ee46c8baaa65f44a5bcc5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a10ead483edb4af3a411c364b70430c5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a98e4dace8df4176951ecafe8f5250f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12d2e96145574682965e611ce8ade2be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fef99d16fd404251bc464ef81d8d99ca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9d5ea4818d0845bb8a0286f4d2cfba34","IPY_MODEL_4a9a2e78902b4317b040146055fa8ba9","IPY_MODEL_b1e61cbcd0e34c0a9ea9b9d436f2025b"],"layout":"IPY_MODEL_02d922ef867f47a790a320e9bcafa2c5"}},"9d5ea4818d0845bb8a0286f4d2cfba34":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_51aaf42a67b348d6a12fa037f4d4e4a0","placeholder":"​","style":"IPY_MODEL_ba38aa1a7913495085cfc4dc1f74365a","value":"Write Progress: "}},"4a9a2e78902b4317b040146055fa8ba9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_55b1ce84b49f4bca8b18c7b46df6c82d","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c0c3053a14d94883883ad87acff92952","value":1000}},"b1e61cbcd0e34c0a9ea9b9d436f2025b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5fe2e82dbae4b028dc87c78e717525b","placeholder":"​","style":"IPY_MODEL_af7100a6a4f841f487b72c67f9d42a98","value":" 1001/? [02:12&lt;00:00, 55.55it/s]"}},"02d922ef867f47a790a320e9bcafa2c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51aaf42a67b348d6a12fa037f4d4e4a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba38aa1a7913495085cfc4dc1f74365a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"55b1ce84b49f4bca8b18c7b46df6c82d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0c3053a14d94883883ad87acff92952":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c5fe2e82dbae4b028dc87c78e717525b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af7100a6a4f841f487b72c67f9d42a98":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"56ca7045080d43fb88ac1773cd096728":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_159391f2a2964586836614a91afd08ef","IPY_MODEL_c6509b9789624a24ba30ab6f31c77dd9","IPY_MODEL_0ad0e54195564def90dd199c297b89fd"],"layout":"IPY_MODEL_c551e40ea1ea4bc1b930cdbb2b62bab4"}},"159391f2a2964586836614a91afd08ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2909d85fcbc84e14bd8e803bfd2c1552","placeholder":"​","style":"IPY_MODEL_4e976439b3174be095e0a31a6183d4cf","value":"Processing Progress: 100%"}},"c6509b9789624a24ba30ab6f31c77dd9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9dd93efc80984b9b92055e3c9dbba754","max":100000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_48d30ab8d5a0440ea28ae4c9e9940a3f","value":100000}},"0ad0e54195564def90dd199c297b89fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d223be80583c4c36bd1f323aac56038a","placeholder":"​","style":"IPY_MODEL_57f30c610f2b42f48708cf2e9d73e090","value":" 100000/100000 [10:02&lt;00:00, 185.85it/s]"}},"c551e40ea1ea4bc1b930cdbb2b62bab4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2909d85fcbc84e14bd8e803bfd2c1552":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e976439b3174be095e0a31a6183d4cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9dd93efc80984b9b92055e3c9dbba754":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48d30ab8d5a0440ea28ae4c9e9940a3f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d223be80583c4c36bd1f323aac56038a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57f30c610f2b42f48708cf2e9d73e090":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"771faebabf584cb0a336140d828f157a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d3c4ec7ef8634763906946e895cf7e6d","IPY_MODEL_ab94adf8923e42fb8872d45e544303d6","IPY_MODEL_e0dce679842649399d62ed64e378e4f4"],"layout":"IPY_MODEL_3ba3d7a1d2824c7fbcb9fb61683e69ab"}},"d3c4ec7ef8634763906946e895cf7e6d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_976dbfccce5944d9a68923061986fc0e","placeholder":"​","style":"IPY_MODEL_9cc81994c9bf44849476b92fe7b0d213","value":"Write Progress: "}},"ab94adf8923e42fb8872d45e544303d6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_77408a5de91f472bacb5ee51a33093bb","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5d84029f0b2f4b689da27d05a08cd23c","value":1000}},"e0dce679842649399d62ed64e378e4f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb70b21152074190b4686c277a82598b","placeholder":"​","style":"IPY_MODEL_8d2b53184bac4103b50cda8db4667c59","value":" 1001/? [03:11&lt;00:00, 88.09it/s]"}},"3ba3d7a1d2824c7fbcb9fb61683e69ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"976dbfccce5944d9a68923061986fc0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cc81994c9bf44849476b92fe7b0d213":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"77408a5de91f472bacb5ee51a33093bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d84029f0b2f4b689da27d05a08cd23c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bb70b21152074190b4686c277a82598b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d2b53184bac4103b50cda8db4667c59":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b4221863abc44d2fbed2a02245e7f109":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_49e507c187ef4f288a16a86e43a1f5a3","IPY_MODEL_bbb9fc067ff94b429806336d1beb83bc","IPY_MODEL_83487565432c48f788fb431fb5abbb18"],"layout":"IPY_MODEL_d447abbbb8c24b3ab42f9bbe8c441948"}},"49e507c187ef4f288a16a86e43a1f5a3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e171cf83a33643ea81682d39289fba69","placeholder":"​","style":"IPY_MODEL_4291101367b84ff48286e7214880e762","value":"Processing Progress: 100%"}},"bbb9fc067ff94b429806336d1beb83bc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3eaabda6f64b47b187dc498ad8f9d5f2","max":100000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_05a132924d9a43c7a49660cdcf8de327","value":100000}},"83487565432c48f788fb431fb5abbb18":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_29d81c953fd64e54bb68a7754503b859","placeholder":"​","style":"IPY_MODEL_c1e40d08be6e4426aea7257d7b284ed9","value":" 100000/100000 [10:04&lt;00:00, 110.99it/s]"}},"d447abbbb8c24b3ab42f9bbe8c441948":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e171cf83a33643ea81682d39289fba69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4291101367b84ff48286e7214880e762":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3eaabda6f64b47b187dc498ad8f9d5f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05a132924d9a43c7a49660cdcf8de327":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"29d81c953fd64e54bb68a7754503b859":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1e40d08be6e4426aea7257d7b284ed9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24e8c5a5fc17430fbd78653da9ba53d4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_773efd4fc4e7409e8b4fd539fdefe56a","IPY_MODEL_16fd458d2ee9454a9c452c1172a5a86b","IPY_MODEL_21a57124b4004a4caf6f116be6e6691d"],"layout":"IPY_MODEL_3e41b93f74ba4c0eb27af0fc60512989"}},"773efd4fc4e7409e8b4fd539fdefe56a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b74712a797e4bdaac282dcbde21328d","placeholder":"​","style":"IPY_MODEL_2658b8fdf7444526860a86074c576249","value":"Write Progress: "}},"16fd458d2ee9454a9c452c1172a5a86b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9c959d33193464e975d3e919e3a56f1","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_05e75a2009254f02bc8e9d03d300e6bf","value":1000}},"21a57124b4004a4caf6f116be6e6691d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa65f4c255854243974c0b43ff2f9bed","placeholder":"​","style":"IPY_MODEL_4baa8f29b4164786ac2853d2045afb39","value":" 1001/? [05:21&lt;00:00,  1.49s/it]"}},"3e41b93f74ba4c0eb27af0fc60512989":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b74712a797e4bdaac282dcbde21328d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2658b8fdf7444526860a86074c576249":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d9c959d33193464e975d3e919e3a56f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05e75a2009254f02bc8e9d03d300e6bf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aa65f4c255854243974c0b43ff2f9bed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4baa8f29b4164786ac2853d2045afb39":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d7aade26bbb4010910faca1a9ce9c86":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_754ffbc812744efe8eb54741a94b7cc1","IPY_MODEL_35f9f19ca8cb4a2992423f6094b7f8c3","IPY_MODEL_bef28b22c3764b8db40cf1db8d8ceaba"],"layout":"IPY_MODEL_bea006a710154dcbb3de85e499e25353"}},"754ffbc812744efe8eb54741a94b7cc1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3f048830c5742e58e3d505f18c7ced4","placeholder":"​","style":"IPY_MODEL_51e61eb58d814701b673f90ab76cf84a","value":"Processing Progress: 100%"}},"35f9f19ca8cb4a2992423f6094b7f8c3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f337c9c38244408b8c1782c60b5ec1f8","max":100000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_986681cbcefe468784e75efec5c76c8d","value":100000}},"bef28b22c3764b8db40cf1db8d8ceaba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_da527fd6e91c454599ac0434a49e4f89","placeholder":"​","style":"IPY_MODEL_3c23fa4628be4da8ae56e10f607a267c","value":" 100000/100000 [10:05&lt;00:00, 194.03it/s]"}},"bea006a710154dcbb3de85e499e25353":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3f048830c5742e58e3d505f18c7ced4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51e61eb58d814701b673f90ab76cf84a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f337c9c38244408b8c1782c60b5ec1f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"986681cbcefe468784e75efec5c76c8d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"da527fd6e91c454599ac0434a49e4f89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c23fa4628be4da8ae56e10f607a267c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc6412a522444ee7b7a5dd89f092824c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d27b8d9217ac4495bb0fb7d0b0e8c62e","IPY_MODEL_959d1a8fdfdd40eaa2c5d8ae4694144f","IPY_MODEL_30f88682b78a4d149471a1b2c8023d82"],"layout":"IPY_MODEL_77cfa26139864764a71636e39d17b45a"}},"d27b8d9217ac4495bb0fb7d0b0e8c62e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4483016842e246768cb2352b68e268e7","placeholder":"​","style":"IPY_MODEL_b5b333c9ac254d838db7d2d457578af4","value":"Write Progress: "}},"959d1a8fdfdd40eaa2c5d8ae4694144f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_10c2b9e55141456abc1debc2b1538707","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_efaee6030f254d619c939cc2933f247f","value":1000}},"30f88682b78a4d149471a1b2c8023d82":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ec24e1975614ef2b78365d581b93ca2","placeholder":"​","style":"IPY_MODEL_4df9dc2c04904e11b059a5f0de61582e","value":" 1001/? [02:02&lt;00:00, 96.47it/s]"}},"77cfa26139864764a71636e39d17b45a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4483016842e246768cb2352b68e268e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5b333c9ac254d838db7d2d457578af4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"10c2b9e55141456abc1debc2b1538707":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efaee6030f254d619c939cc2933f247f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9ec24e1975614ef2b78365d581b93ca2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4df9dc2c04904e11b059a5f0de61582e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b7a61bef9b84114ac9239ebd140849f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e746c36faea545869359daf258c82185","IPY_MODEL_6d49bec9a491469db4aea6f2b9f1669b","IPY_MODEL_a4e59f9582bc4732b96955a6ae06a598"],"layout":"IPY_MODEL_31d73696bf444b8a8616291125ade4b9"}},"e746c36faea545869359daf258c82185":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b4e3314edd04edea7be5d7ff507a04a","placeholder":"​","style":"IPY_MODEL_673db829be704a4486de1b749e539066","value":"Processing Progress: 100%"}},"6d49bec9a491469db4aea6f2b9f1669b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_de32d7c147dd4daa9975e9ea9215a461","max":100000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ba3439e630eb411e9a93d6b96fdad661","value":100000}},"a4e59f9582bc4732b96955a6ae06a598":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91869cb63804414382d953a30579acd1","placeholder":"​","style":"IPY_MODEL_eee42fd2aa6c4808b8916ee39536991f","value":" 100000/100000 [10:13&lt;00:00, 169.10it/s]"}},"31d73696bf444b8a8616291125ade4b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b4e3314edd04edea7be5d7ff507a04a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"673db829be704a4486de1b749e539066":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de32d7c147dd4daa9975e9ea9215a461":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba3439e630eb411e9a93d6b96fdad661":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"91869cb63804414382d953a30579acd1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eee42fd2aa6c4808b8916ee39536991f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f33575dce314412f880122b9d9656c5e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4a2d9a90e99f41498871826386bb985e","IPY_MODEL_204d1cefcd0b45f9879b892e5f12a109","IPY_MODEL_7c7b3a4abb484676ae3de1b495a8663a"],"layout":"IPY_MODEL_42616641c4db4f219b3e488385ece72f"}},"4a2d9a90e99f41498871826386bb985e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4312d09da4e44816904ba974aa1b4cb5","placeholder":"​","style":"IPY_MODEL_5713115f4fa7447daef785af7513ad89","value":"Write Progress: "}},"204d1cefcd0b45f9879b892e5f12a109":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b318e331eb424bd9824cde45166bfee0","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1840b8e2baff4252bcf73a4e4cfc9cc6","value":1000}},"7c7b3a4abb484676ae3de1b495a8663a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b85416a0512948e1947aaa285d8c98ed","placeholder":"​","style":"IPY_MODEL_7008ac52529349f4b505dac17dbcc8c5","value":" 1001/? [00:13&lt;00:00, 124.07it/s]"}},"42616641c4db4f219b3e488385ece72f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4312d09da4e44816904ba974aa1b4cb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5713115f4fa7447daef785af7513ad89":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b318e331eb424bd9824cde45166bfee0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1840b8e2baff4252bcf73a4e4cfc9cc6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b85416a0512948e1947aaa285d8c98ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7008ac52529349f4b505dac17dbcc8c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce9e7f335bd1460fbfbd2280bb449b7b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b354c35f790b4d789c85ee773ebc9977","IPY_MODEL_f5094ede598c4489bac074018fc232d9","IPY_MODEL_edec6c72dee3443caa03d539fac5a6f0"],"layout":"IPY_MODEL_25d5a4a00f124d3e9fa92fc3de0b342f"}},"b354c35f790b4d789c85ee773ebc9977":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_192a121860df4b019dde57e049088ef8","placeholder":"​","style":"IPY_MODEL_9974a2a7a96e4fb5803e71329de9631e","value":"Processing Progress: 100%"}},"f5094ede598c4489bac074018fc232d9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_15e818e3a50e49fc874bf1c18975f656","max":100000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_771463824c414434ae7808cc4d1c077d","value":100000}},"edec6c72dee3443caa03d539fac5a6f0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b74d255f28694e12ac0d0c72f242f3c0","placeholder":"​","style":"IPY_MODEL_05ae9ae7afb6489c87d6117150fe6946","value":" 100000/100000 [09:59&lt;00:00, 192.16it/s]"}},"25d5a4a00f124d3e9fa92fc3de0b342f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"192a121860df4b019dde57e049088ef8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9974a2a7a96e4fb5803e71329de9631e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"15e818e3a50e49fc874bf1c18975f656":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"771463824c414434ae7808cc4d1c077d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b74d255f28694e12ac0d0c72f242f3c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05ae9ae7afb6489c87d6117150fe6946":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d62c07c4d017435f9937c3dd2331f1bf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_03eaec383d354f919f8a0e7497c6b549","IPY_MODEL_eaa10361934345bca6be567384cf6ffe","IPY_MODEL_ecab84f4a1644eeca40f122c3b45d83a"],"layout":"IPY_MODEL_dcc11692eea44c79a44b46e0b7fce721"}},"03eaec383d354f919f8a0e7497c6b549":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d34ff74f6e947d9b5dc7534048449bc","placeholder":"​","style":"IPY_MODEL_c8b5f8da0e684adbbb35056e8b5a130a","value":"Write Progress: "}},"eaa10361934345bca6be567384cf6ffe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_790d01265c3f4ed78f343aee27351efe","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fea7b165eda2471182ea3058a460540e","value":1000}},"ecab84f4a1644eeca40f122c3b45d83a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd089ab8a4bc458188d2df5ed7061b93","placeholder":"​","style":"IPY_MODEL_39cf634df52b4edbb56af296537931c1","value":" 1001/? [02:45&lt;00:00, 143.08it/s]"}},"dcc11692eea44c79a44b46e0b7fce721":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d34ff74f6e947d9b5dc7534048449bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8b5f8da0e684adbbb35056e8b5a130a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"790d01265c3f4ed78f343aee27351efe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fea7b165eda2471182ea3058a460540e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dd089ab8a4bc458188d2df5ed7061b93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39cf634df52b4edbb56af296537931c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cdf18fedbe8a495cba1fa11a35a3638f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_535ac72b11624f2d933c4adc86072cfd","IPY_MODEL_141dab626bc44438868d4e4bbad43e05","IPY_MODEL_49faadbdfb234bb2930bf0a1fce4c2a1"],"layout":"IPY_MODEL_add888a35c4d45f2a6e4db90ba00d4dc"}},"535ac72b11624f2d933c4adc86072cfd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c28816391d9489d964ca0eb93bf2468","placeholder":"​","style":"IPY_MODEL_ec45024e31f1414eb6eaa52a869efda0","value":"Processing Progress: 100%"}},"141dab626bc44438868d4e4bbad43e05":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f299b79578c24cd09617922e409e8331","max":100000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d0fa0482e7114c7286d73434fec925d8","value":100000}},"49faadbdfb234bb2930bf0a1fce4c2a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9aba61e3d064a2eb373215c63b67243","placeholder":"​","style":"IPY_MODEL_698fe2aa854c42f7bb21deaffdd4ae81","value":" 100000/100000 [10:01&lt;00:00, 184.33it/s]"}},"add888a35c4d45f2a6e4db90ba00d4dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c28816391d9489d964ca0eb93bf2468":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec45024e31f1414eb6eaa52a869efda0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f299b79578c24cd09617922e409e8331":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0fa0482e7114c7286d73434fec925d8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a9aba61e3d064a2eb373215c63b67243":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"698fe2aa854c42f7bb21deaffdd4ae81":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7763e013592c481692c8631e5cb3b757":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_08927959ba6b41cd954e67b6ec527657","IPY_MODEL_5852db60d352431194ac86b01c73a1b4","IPY_MODEL_5c40e55b22804d1dbc6c6138f0e7e14c"],"layout":"IPY_MODEL_08e1c152cb494619b4354a41efe123ca"}},"08927959ba6b41cd954e67b6ec527657":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d58fc2f247b248e98a736e892cbde9e5","placeholder":"​","style":"IPY_MODEL_cfd85b5704e14423a65a0c1ba5db1c16","value":"Write Progress: "}},"5852db60d352431194ac86b01c73a1b4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c232ab16a95f42c8a97a3976a89b2df3","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5aa6a14fbc2f4b029affee3a892ad497","value":1000}},"5c40e55b22804d1dbc6c6138f0e7e14c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1fc5919a497484ca064f2500cb78964","placeholder":"​","style":"IPY_MODEL_27d1f5f0aa15481bb6c53390f1e0b365","value":" 1001/? [03:21&lt;00:00, 69.00it/s]"}},"08e1c152cb494619b4354a41efe123ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d58fc2f247b248e98a736e892cbde9e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfd85b5704e14423a65a0c1ba5db1c16":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c232ab16a95f42c8a97a3976a89b2df3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5aa6a14fbc2f4b029affee3a892ad497":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b1fc5919a497484ca064f2500cb78964":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27d1f5f0aa15481bb6c53390f1e0b365":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34279a8fe16e4e94a91e3fb816484345":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_46b454518eae49b1bd2ee45494e0b6c7","IPY_MODEL_0aad49ce4c8042e39b15fbf04ef47ca8","IPY_MODEL_601e1041f3374aba87f325b9c4ec4812"],"layout":"IPY_MODEL_2d724dd248fb4ab0a1af873b78d3a353"}},"46b454518eae49b1bd2ee45494e0b6c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eabeedc878fa4a0e9a4360b2a5514a76","placeholder":"​","style":"IPY_MODEL_3d89dfd19dfa473ab5f14862c8864706","value":"Processing Progress: 100%"}},"0aad49ce4c8042e39b15fbf04ef47ca8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9993a674c4aa47a4aa2ff2a2d7731f22","max":100000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_24bff944845541e2a107de58f26158ce","value":100000}},"601e1041f3374aba87f325b9c4ec4812":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_74c4d0f8ea18444b80abb0b0ad7c8c99","placeholder":"​","style":"IPY_MODEL_a5f64bf184594b58b5c152b73a9bae56","value":" 100000/100000 [10:00&lt;00:00, 181.67it/s]"}},"2d724dd248fb4ab0a1af873b78d3a353":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eabeedc878fa4a0e9a4360b2a5514a76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d89dfd19dfa473ab5f14862c8864706":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9993a674c4aa47a4aa2ff2a2d7731f22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24bff944845541e2a107de58f26158ce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"74c4d0f8ea18444b80abb0b0ad7c8c99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5f64bf184594b58b5c152b73a9bae56":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5657ce7e40414921a34fc1897fe47ff3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_39076c8dc2fa4282b302f549a1983317","IPY_MODEL_022369ba384a4f50a6adaca52b3e1ddf","IPY_MODEL_ebee06b107f1463198d596136f460715"],"layout":"IPY_MODEL_37f9512c377c425c943d13d4fd4055f5"}},"39076c8dc2fa4282b302f549a1983317":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e74ff1bcaba74b3ea9823aa6c1eedc89","placeholder":"​","style":"IPY_MODEL_004a012697c14103aa8800982030650a","value":"Write Progress: "}},"022369ba384a4f50a6adaca52b3e1ddf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_180a0a7b41234996bbe6b1bc1c272d7d","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_53ceb3c87e754931927976c16a090fba","value":1000}},"ebee06b107f1463198d596136f460715":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1861512ef08c4c6b925b55a0940d4fc7","placeholder":"​","style":"IPY_MODEL_6cd505d1382a4d2a9bd33a9355c34294","value":" 1001/? [02:12&lt;00:00, 12.05it/s]"}},"37f9512c377c425c943d13d4fd4055f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e74ff1bcaba74b3ea9823aa6c1eedc89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"004a012697c14103aa8800982030650a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"180a0a7b41234996bbe6b1bc1c272d7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53ceb3c87e754931927976c16a090fba":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1861512ef08c4c6b925b55a0940d4fc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6cd505d1382a4d2a9bd33a9355c34294":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7ebaadc6b2945f69b17a46e83ac1ae1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b103c4367fd9487aa9071e0c91838d02","IPY_MODEL_0e4def368211419fba181282417920fb","IPY_MODEL_fc0eb78224654e2498f92e536279a496"],"layout":"IPY_MODEL_3089d14a33134f28a95eecd5ef287fac"}},"b103c4367fd9487aa9071e0c91838d02":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6aba5071771d444f93685c94ff75c245","placeholder":"​","style":"IPY_MODEL_bae8a851ca1a4c029d823f8e1babb915","value":"Processing Progress: 100%"}},"0e4def368211419fba181282417920fb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6742d4617f8d4cd2bc11467319ce2a28","max":100000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_62c3c7de7e3d42e788394e4fbfb9580a","value":100000}},"fc0eb78224654e2498f92e536279a496":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_37304c891eb142309c6b387b9da6146e","placeholder":"​","style":"IPY_MODEL_f88539e0fd5e42acb7bb1929322f6513","value":" 100000/100000 [10:08&lt;00:00, 191.27it/s]"}},"3089d14a33134f28a95eecd5ef287fac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6aba5071771d444f93685c94ff75c245":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bae8a851ca1a4c029d823f8e1babb915":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6742d4617f8d4cd2bc11467319ce2a28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62c3c7de7e3d42e788394e4fbfb9580a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"37304c891eb142309c6b387b9da6146e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f88539e0fd5e42acb7bb1929322f6513":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eb00ca4c15b04b6da53ed37b24ec9ece":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_66ebc58fcaa8468ea9232e91096799a3","IPY_MODEL_3fde07030ecc4c7baa3b80ad6056a169","IPY_MODEL_a91d483580ab485398ef793ca3e91299"],"layout":"IPY_MODEL_75e4302f6c814435b1f782252910234c"}},"66ebc58fcaa8468ea9232e91096799a3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_94865dab54a0450382a499dfd0ea1156","placeholder":"​","style":"IPY_MODEL_9c1d30a1ca52427a9c78788e73024d9e","value":"Write Progress: "}},"3fde07030ecc4c7baa3b80ad6056a169":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b83273e88f8400a992a06b4ee77574e","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1c77892c9d0e4e28bd9771b9a9decebb","value":1000}},"a91d483580ab485398ef793ca3e91299":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_65101fb186a944589fa58be452fd51c3","placeholder":"​","style":"IPY_MODEL_c3085b8e71bf4a86924d0c4285bfe80d","value":" 1001/? [00:18&lt;00:00, 122.96it/s]"}},"75e4302f6c814435b1f782252910234c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94865dab54a0450382a499dfd0ea1156":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c1d30a1ca52427a9c78788e73024d9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b83273e88f8400a992a06b4ee77574e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c77892c9d0e4e28bd9771b9a9decebb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"65101fb186a944589fa58be452fd51c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3085b8e71bf4a86924d0c4285bfe80d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0bc7001a1a734188832ca2fba148e9a0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e8c6576ca2f2445ab9a4ab518e31535b","IPY_MODEL_ab9191cb8cae4ef4abc3114e98241459","IPY_MODEL_5cb2d8b8a1674dfd8d12c6e4592f7b26"],"layout":"IPY_MODEL_d6829f3452174f2ea172a4405befb896"}},"e8c6576ca2f2445ab9a4ab518e31535b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ef17d1902ba4082a51dd2c1cec9b5b4","placeholder":"​","style":"IPY_MODEL_6c126918f9304ad2b798543157caf396","value":"Processing Progress: 100%"}},"ab9191cb8cae4ef4abc3114e98241459":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_064ace65ee8a4d579ab6d80f2266fc77","max":100000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_218a41f3d13442c28f59ca2d05e4d721","value":100000}},"5cb2d8b8a1674dfd8d12c6e4592f7b26":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_06e17eb713094b71ba06fd93b4e6743c","placeholder":"​","style":"IPY_MODEL_a00f1c4d0efc43e281a5f63ce37f31a3","value":" 100000/100000 [09:57&lt;00:00, 189.57it/s]"}},"d6829f3452174f2ea172a4405befb896":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ef17d1902ba4082a51dd2c1cec9b5b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c126918f9304ad2b798543157caf396":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"064ace65ee8a4d579ab6d80f2266fc77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"218a41f3d13442c28f59ca2d05e4d721":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"06e17eb713094b71ba06fd93b4e6743c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a00f1c4d0efc43e281a5f63ce37f31a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"45013ac717ae40f78a3bf77771c1a237":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b4a724b796b2455d998074418205d797","IPY_MODEL_d2397b421f834ce9b7556409bc88f5cd","IPY_MODEL_ef4294c797c0459ca95cd0492a70e791"],"layout":"IPY_MODEL_80a42055ec4e40b88b73b5667167bcee"}},"b4a724b796b2455d998074418205d797":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43b933ab79e14558bdc986fb203ef14a","placeholder":"​","style":"IPY_MODEL_db66dbfe60714d4b82925def69533dba","value":"Write Progress: "}},"d2397b421f834ce9b7556409bc88f5cd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_faf3cbb14d8c46a3b5a420398ffda3e7","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cce6aafec7f441149ff16f11454b883b","value":1000}},"ef4294c797c0459ca95cd0492a70e791":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e77108222544d53bee33a47dcffb7cd","placeholder":"​","style":"IPY_MODEL_0306d8beca94492aa2a9111b248eafde","value":" 1001/? [03:26&lt;00:00, 14.60it/s]"}},"80a42055ec4e40b88b73b5667167bcee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43b933ab79e14558bdc986fb203ef14a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db66dbfe60714d4b82925def69533dba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"faf3cbb14d8c46a3b5a420398ffda3e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cce6aafec7f441149ff16f11454b883b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1e77108222544d53bee33a47dcffb7cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0306d8beca94492aa2a9111b248eafde":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9e3e2544df434d47b91ef7c242c4a869":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c767082e1a8c4a20ab75fc5481f907ea","IPY_MODEL_4c3b6e0db4854cffbe9ab799e9d8079c","IPY_MODEL_5e845a1e30594a44b18b3478a784e110"],"layout":"IPY_MODEL_6eab5b0ab49c48ca9c38f82b02db8f4f"}},"c767082e1a8c4a20ab75fc5481f907ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e81491e8a76c45d8a1e5690533dbd32e","placeholder":"​","style":"IPY_MODEL_1e16cbd15aaf41eda727ade5814c37fa","value":"Processing Progress: 100%"}},"4c3b6e0db4854cffbe9ab799e9d8079c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e29a66ba74134f50a7502f674abd3a1b","max":100000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cde68b99a93241e485dee1ea30ac3538","value":100000}},"5e845a1e30594a44b18b3478a784e110":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_239d4b45c65440df957cc9ef64541081","placeholder":"​","style":"IPY_MODEL_3c1edfa58683498a84e7c03f6b07fe1b","value":" 100000/100000 [10:04&lt;00:00, 194.55it/s]"}},"6eab5b0ab49c48ca9c38f82b02db8f4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e81491e8a76c45d8a1e5690533dbd32e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e16cbd15aaf41eda727ade5814c37fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e29a66ba74134f50a7502f674abd3a1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cde68b99a93241e485dee1ea30ac3538":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"239d4b45c65440df957cc9ef64541081":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c1edfa58683498a84e7c03f6b07fe1b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e049623d38394120834caea21e2c97c9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_acd3a6626ced432d836b8993753cb3a0","IPY_MODEL_83d789f3289b4088a26fafd77fddd2ec","IPY_MODEL_bea3112b8f38401aa25c2625596d2db2"],"layout":"IPY_MODEL_d3c35732159e4737a3288a3fd68373c2"}},"acd3a6626ced432d836b8993753cb3a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e38d99767c414099b740c969fcc6c144","placeholder":"​","style":"IPY_MODEL_9b3c9f89d3fc4fa396a54b749926c528","value":"Write Progress:  41%"}},"83d789f3289b4088a26fafd77fddd2ec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_d20daf109d304b658ff7ec745a100959","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c3e149b8faed401083a6fedaa3cecd13","value":414}},"bea3112b8f38401aa25c2625596d2db2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_438be166e67741d6ab32d9fc81d60525","placeholder":"​","style":"IPY_MODEL_2221d92c88e94b51ab9b264e320d76e8","value":" 414/1000 [00:29&lt;01:24,  6.96it/s]"}},"d3c35732159e4737a3288a3fd68373c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e38d99767c414099b740c969fcc6c144":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b3c9f89d3fc4fa396a54b749926c528":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d20daf109d304b658ff7ec745a100959":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3e149b8faed401083a6fedaa3cecd13":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"438be166e67741d6ab32d9fc81d60525":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2221d92c88e94b51ab9b264e320d76e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2133a131407415eb33b757ee8db3bd2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ea492fd4f4c44593a9d1ffdc1ddde69a","IPY_MODEL_19f9c23a0910460393ea1948bcda1519","IPY_MODEL_3fd6f09f4ff24cc6ad62793b52cfad0c"],"layout":"IPY_MODEL_f6bcd01260514406a4d41b54e57e27f0"}},"ea492fd4f4c44593a9d1ffdc1ddde69a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_450525149c6643a5bc22d0c6c550c203","placeholder":"​","style":"IPY_MODEL_a1cb0bcfc9e942a5ae342a41f035edb5","value":"Downloading (…)lve/main/config.json: 100%"}},"19f9c23a0910460393ea1948bcda1519":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_376585bf1cc84e0fa0f1ed748ff9a0ae","max":753,"min":0,"orientation":"horizontal","style":"IPY_MODEL_409b8a5be95544afbd4767b5521417b5","value":753}},"3fd6f09f4ff24cc6ad62793b52cfad0c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e279a96bd2f8407f8fdb5d93cf002b28","placeholder":"​","style":"IPY_MODEL_7c4c6c7432824c92a798c2793c6ad0ac","value":" 753/753 [00:00&lt;00:00, 36.9kB/s]"}},"f6bcd01260514406a4d41b54e57e27f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"450525149c6643a5bc22d0c6c550c203":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1cb0bcfc9e942a5ae342a41f035edb5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"376585bf1cc84e0fa0f1ed748ff9a0ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"409b8a5be95544afbd4767b5521417b5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e279a96bd2f8407f8fdb5d93cf002b28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c4c6c7432824c92a798c2793c6ad0ac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c83dfb8baf44dcaa9bda6332804b02d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c20f15e477b24e7bb0f2b2be0bda95b3","IPY_MODEL_746aea0ab6244c7e8fce4db571940a42","IPY_MODEL_71f0580e6ff8419c808b88226c7a7484"],"layout":"IPY_MODEL_bb175c05113140b6a8c1dd8abf4b0caf"}},"c20f15e477b24e7bb0f2b2be0bda95b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b877b314dbfd48a0adb47a75615a01cc","placeholder":"​","style":"IPY_MODEL_f92bc61e2d444986ab25a5bd949cf13b","value":"Downloading SoLU_6L_v13_final.pth: 100%"}},"746aea0ab6244c7e8fce4db571940a42":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2dcdd3fe77cf4a588fc69cebc3134d21","max":488648585,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d32ecdbfb0c64ca6941ef720bbcf2718","value":488648585}},"71f0580e6ff8419c808b88226c7a7484":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e295973a725049da8bf927c6a021e6bf","placeholder":"​","style":"IPY_MODEL_3565c15bf1614e69a0f5713673d4e842","value":" 489M/489M [00:12&lt;00:00, 40.8MB/s]"}},"bb175c05113140b6a8c1dd8abf4b0caf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b877b314dbfd48a0adb47a75615a01cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f92bc61e2d444986ab25a5bd949cf13b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2dcdd3fe77cf4a588fc69cebc3134d21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d32ecdbfb0c64ca6941ef720bbcf2718":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e295973a725049da8bf927c6a021e6bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3565c15bf1614e69a0f5713673d4e842":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"45f376e0e5024fb288f7f5c5da685d95":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_050db19b1a624da3bf5f26bb8a55efb9","IPY_MODEL_d29c1d33796a4f2fbe3963a32b371cdc","IPY_MODEL_45490509af984970bfa406adb120a1f4"],"layout":"IPY_MODEL_0e0eea5b8b014dbd92bd626d8c617c93"}},"050db19b1a624da3bf5f26bb8a55efb9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ede3fd4cfc914c78ac9585e844107875","placeholder":"​","style":"IPY_MODEL_a94990a9d7bb4f54bd99b39a94148e55","value":"Downloading (…)okenizer_config.json: 100%"}},"d29c1d33796a4f2fbe3963a32b371cdc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8a054f3613840a1beac13ac51300945","max":156,"min":0,"orientation":"horizontal","style":"IPY_MODEL_943b68b2e6b74bba982e49154d91b9b7","value":156}},"45490509af984970bfa406adb120a1f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4f8bc180ccb4611b521b29867eb9936","placeholder":"​","style":"IPY_MODEL_783e09433aa545b2b82e9ad001d5f72e","value":" 156/156 [00:00&lt;00:00, 8.13kB/s]"}},"0e0eea5b8b014dbd92bd626d8c617c93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ede3fd4cfc914c78ac9585e844107875":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a94990a9d7bb4f54bd99b39a94148e55":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8a054f3613840a1beac13ac51300945":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"943b68b2e6b74bba982e49154d91b9b7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b4f8bc180ccb4611b521b29867eb9936":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"783e09433aa545b2b82e9ad001d5f72e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89b1c558c53e4328888428a683312558":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1dbedf20a0d14bbb9f77e49c2bd546a2","IPY_MODEL_69d1b8a86cf44a3997f53bd3982cadb8","IPY_MODEL_78b3bff1d0d94825ae4447087f212316"],"layout":"IPY_MODEL_4afb7ed58dd541ceaa7468fb269b8279"}},"1dbedf20a0d14bbb9f77e49c2bd546a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_86280f5f92a74b07b9e6e71e38850650","placeholder":"​","style":"IPY_MODEL_bd6a8977ee1a45f4a5ce87a7df399d16","value":"Downloading (…)olve/main/vocab.json: 100%"}},"69d1b8a86cf44a3997f53bd3982cadb8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d009e92b0d44f2ca7cb2ee059af2fc4","max":1077392,"min":0,"orientation":"horizontal","style":"IPY_MODEL_67e7e91ae4944fa1961429ef5371335b","value":1077392}},"78b3bff1d0d94825ae4447087f212316":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7ebbfb41ab14e2792898cd8f58304b2","placeholder":"​","style":"IPY_MODEL_caefb5a8ef004726a7682aeb588e6393","value":" 1.08M/1.08M [00:00&lt;00:00, 13.1MB/s]"}},"4afb7ed58dd541ceaa7468fb269b8279":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86280f5f92a74b07b9e6e71e38850650":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd6a8977ee1a45f4a5ce87a7df399d16":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d009e92b0d44f2ca7cb2ee059af2fc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67e7e91ae4944fa1961429ef5371335b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a7ebbfb41ab14e2792898cd8f58304b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"caefb5a8ef004726a7682aeb588e6393":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a16db03c5d74a429df7cf285ee9f700":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3a13632175bd4a108d449a768cceab9f","IPY_MODEL_f1c898313a1b42bb90ad162cbc813084","IPY_MODEL_777ad534914940289998c5a155b2dc88"],"layout":"IPY_MODEL_145d42567db94e94a9245de7099f10bd"}},"3a13632175bd4a108d449a768cceab9f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b42d369b38a74538a6aba084dcb3031d","placeholder":"​","style":"IPY_MODEL_0cb3f7930ef44c7bbd46c7e6308527e0","value":"Downloading (…)olve/main/merges.txt: 100%"}},"f1c898313a1b42bb90ad162cbc813084":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e65e6845924b4dc3a1c7cb1a040429c3","max":456583,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2acdc4a53ce149b9851969f04778b633","value":456583}},"777ad534914940289998c5a155b2dc88":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c555545f03e04859bab7cd3cb9eec308","placeholder":"​","style":"IPY_MODEL_e8ef69eae5fb4309af5d28cb42e1a078","value":" 457k/457k [00:00&lt;00:00, 14.0MB/s]"}},"145d42567db94e94a9245de7099f10bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b42d369b38a74538a6aba084dcb3031d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cb3f7930ef44c7bbd46c7e6308527e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e65e6845924b4dc3a1c7cb1a040429c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2acdc4a53ce149b9851969f04778b633":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c555545f03e04859bab7cd3cb9eec308":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8ef69eae5fb4309af5d28cb42e1a078":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"69263d671baf4b3e995d982c899a5972":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b72a8ad4acf9465fb4c404fe78051d53","IPY_MODEL_4ae47982e91645d0853b7ee5d43de5a2","IPY_MODEL_64c3a8170e8246daa59716aa1075bc24"],"layout":"IPY_MODEL_9e18884f13f5497689697728a0ed04b5"}},"b72a8ad4acf9465fb4c404fe78051d53":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d314e9e83af493b8ef0c3ed7331d7e3","placeholder":"​","style":"IPY_MODEL_5dbd4353123848f485a551274f5c438b","value":"Downloading (…)/main/tokenizer.json: 100%"}},"4ae47982e91645d0853b7ee5d43de5a2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6323fcaa4f3478ea518b8ba135e13b6","max":2113710,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b423f484c15c43e79fbf1ae2d5f72d33","value":2113710}},"64c3a8170e8246daa59716aa1075bc24":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_941728866457433ab5cd12bcd3288df1","placeholder":"​","style":"IPY_MODEL_4a14ed1df7324e7691428fbeab583519","value":" 2.11M/2.11M [00:00&lt;00:00, 12.6MB/s]"}},"9e18884f13f5497689697728a0ed04b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d314e9e83af493b8ef0c3ed7331d7e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5dbd4353123848f485a551274f5c438b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a6323fcaa4f3478ea518b8ba135e13b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b423f484c15c43e79fbf1ae2d5f72d33":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"941728866457433ab5cd12bcd3288df1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a14ed1df7324e7691428fbeab583519":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ef319dcfea743329f8189b3685ccdd6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_269224db473045369710e9f3c11fc5b8","IPY_MODEL_1ef37f4fae714981a45fb9161f313d79","IPY_MODEL_fe74222ae4524fd08c4334b0c947281c"],"layout":"IPY_MODEL_0c537f70757245e99e58fd7dff8964f5"}},"269224db473045369710e9f3c11fc5b8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ae069ce24794d06916d2ca659114996","placeholder":"​","style":"IPY_MODEL_0479a82ba1af4bfb9958d529cf24409c","value":"Downloading (…)cial_tokens_map.json: 100%"}},"1ef37f4fae714981a45fb9161f313d79":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_83cba34231e94d7bb46f19f0b691748b","max":90,"min":0,"orientation":"horizontal","style":"IPY_MODEL_82343591af0840c0890b770608c1fd25","value":90}},"fe74222ae4524fd08c4334b0c947281c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ad267bdb26347e094804805978c5f69","placeholder":"​","style":"IPY_MODEL_8b2cd3fe61944debbd340f04a2a039c5","value":" 90.0/90.0 [00:00&lt;00:00, 3.84kB/s]"}},"0c537f70757245e99e58fd7dff8964f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ae069ce24794d06916d2ca659114996":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0479a82ba1af4bfb9958d529cf24409c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"83cba34231e94d7bb46f19f0b691748b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82343591af0840c0890b770608c1fd25":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3ad267bdb26347e094804805978c5f69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b2cd3fe61944debbd340f04a2a039c5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72b529603fed4ae18b2298cfc401199b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_975cd611e7ae45ca9930df68b70595c5","IPY_MODEL_db0c00cb35d14405a94b748160be4fd3","IPY_MODEL_1850274706824a24aabcb4ec13485f0b"],"layout":"IPY_MODEL_1f8ea22a29b842bca86a786e1963ae11"}},"975cd611e7ae45ca9930df68b70595c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32a3b897a2ee44f79fe7a93a166f0dcd","placeholder":"​","style":"IPY_MODEL_dc14ddfa17b74cdc88f8bcccbd487eb2","value":"Downloading (…)lve/main/config.json: 100%"}},"db0c00cb35d14405a94b748160be4fd3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfa6c53bca3c4cfc8a1735f575e2fe2a","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e2bf5acb274f4bb6a0eee03a048a6192","value":483}},"1850274706824a24aabcb4ec13485f0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc8cc22e485b4d0f81e395ac1a03fe8b","placeholder":"​","style":"IPY_MODEL_b1629157cc7848e69b1258ba0ed17b9c","value":" 483/483 [00:00&lt;00:00, 33.8kB/s]"}},"1f8ea22a29b842bca86a786e1963ae11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32a3b897a2ee44f79fe7a93a166f0dcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc14ddfa17b74cdc88f8bcccbd487eb2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bfa6c53bca3c4cfc8a1735f575e2fe2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2bf5acb274f4bb6a0eee03a048a6192":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fc8cc22e485b4d0f81e395ac1a03fe8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1629157cc7848e69b1258ba0ed17b9c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"faa88ccf7f414e568a66e858a7c6fa06":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4c8eb17eff744201868f0f2e9a174be4","IPY_MODEL_ffa48c1720344cfdaff94cba9ae95d46","IPY_MODEL_ed7fb0d638d04eadbb0ffc7be7a8422f"],"layout":"IPY_MODEL_fc531673c3fd4df9ac69e4b0115815ea"}},"4c8eb17eff744201868f0f2e9a174be4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a2b45d7bbd74b65a8cc6fd88dadd9d7","placeholder":"​","style":"IPY_MODEL_1680efbb95fe45c385289d9da6e684e9","value":"Downloading pytorch_model.bin: 100%"}},"ffa48c1720344cfdaff94cba9ae95d46":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_847131304e3e47fc8cfa30bd4a5874cc","max":267967963,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4958cc68c6b243d3916661596489591f","value":267967963}},"ed7fb0d638d04eadbb0ffc7be7a8422f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b38adc08e3ec4373bd793063bf1c2062","placeholder":"​","style":"IPY_MODEL_291ea9291a0146e5ae443ff82dd27ab7","value":" 268M/268M [00:00&lt;00:00, 293MB/s]"}},"fc531673c3fd4df9ac69e4b0115815ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a2b45d7bbd74b65a8cc6fd88dadd9d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1680efbb95fe45c385289d9da6e684e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"847131304e3e47fc8cfa30bd4a5874cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4958cc68c6b243d3916661596489591f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b38adc08e3ec4373bd793063bf1c2062":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"291ea9291a0146e5ae443ff82dd27ab7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f9a791c3289344bda77f67bcd3bd3790":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_53e17325c8e04222a8425bb33dc4dcc9","IPY_MODEL_6a78882beba74e2f9b97be5ad02106b8","IPY_MODEL_b2ea28edd31343808256636c7fa586e4"],"layout":"IPY_MODEL_ca9ac78747ff46cdaba0aedd9c88c698"}},"53e17325c8e04222a8425bb33dc4dcc9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a38e74d9680455faad43244a0707088","placeholder":"​","style":"IPY_MODEL_07f4eebe7f2e464d9f368d88571de8df","value":"Downloading (…)okenizer_config.json: 100%"}},"6a78882beba74e2f9b97be5ad02106b8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f65ebbe688f46c090933f096edba642","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_77d30c4e85f74e9ea38383cb45d66f65","value":28}},"b2ea28edd31343808256636c7fa586e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6da6f63cc2f14f64a25994160422086b","placeholder":"​","style":"IPY_MODEL_d647fc42d7a142e1a0c68ed5a94c2d21","value":" 28.0/28.0 [00:00&lt;00:00, 1.97kB/s]"}},"ca9ac78747ff46cdaba0aedd9c88c698":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a38e74d9680455faad43244a0707088":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07f4eebe7f2e464d9f368d88571de8df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f65ebbe688f46c090933f096edba642":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77d30c4e85f74e9ea38383cb45d66f65":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6da6f63cc2f14f64a25994160422086b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d647fc42d7a142e1a0c68ed5a94c2d21":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"83ab64412c6f4f3793e4bb37c1cbe5c0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8a044b778cfd433888746badd9e3ebb5","IPY_MODEL_79a3d8dddb2943ca9ddd86f2030f75a5","IPY_MODEL_df1a2123aa28437a91dbbf7b79486ead"],"layout":"IPY_MODEL_be243803ea1e49fc8fc3cf053c13b8dc"}},"8a044b778cfd433888746badd9e3ebb5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_352cacc0aff94873b768d0eaa80c35c9","placeholder":"​","style":"IPY_MODEL_8d43463620f745dfa547c04a997e6750","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"79a3d8dddb2943ca9ddd86f2030f75a5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b31076178616403a8761138fda8d9bd6","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d871f7a813f94e6fbe0aef79654dde64","value":231508}},"df1a2123aa28437a91dbbf7b79486ead":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a62ef003fcb6497492e33352f25b3f75","placeholder":"​","style":"IPY_MODEL_9f679d4a5a754cbabd6b30fae4b7f0e5","value":" 232k/232k [00:00&lt;00:00, 14.6MB/s]"}},"be243803ea1e49fc8fc3cf053c13b8dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"352cacc0aff94873b768d0eaa80c35c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d43463620f745dfa547c04a997e6750":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b31076178616403a8761138fda8d9bd6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d871f7a813f94e6fbe0aef79654dde64":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a62ef003fcb6497492e33352f25b3f75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f679d4a5a754cbabd6b30fae4b7f0e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a5ba76f1313448e8f1543303fefbdc4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ec051eb1e63f4ff7819977a6c32b5855","IPY_MODEL_a704e9e6fe2641f49c1f946ffb367ac6","IPY_MODEL_6320f5b0b5b14f46aa64fb6f66e45714"],"layout":"IPY_MODEL_f724c65f048c42639b840f9c088d8bb4"}},"ec051eb1e63f4ff7819977a6c32b5855":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3a9cd458f244181a6fd5141db7e7967","placeholder":"​","style":"IPY_MODEL_d7ad362c0a6e4fb6949d445275ae353b","value":"Downloading (…)/main/tokenizer.json: 100%"}},"a704e9e6fe2641f49c1f946ffb367ac6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_68125e9891be490484d5644f34562836","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_416a09ab32644cd29a30849fd70a627d","value":466062}},"6320f5b0b5b14f46aa64fb6f66e45714":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78ae821e374a4327ab134d9a7bab6501","placeholder":"​","style":"IPY_MODEL_bb766f1521b34666bc2347d0c25ea5ef","value":" 466k/466k [00:00&lt;00:00, 30.6MB/s]"}},"f724c65f048c42639b840f9c088d8bb4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3a9cd458f244181a6fd5141db7e7967":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7ad362c0a6e4fb6949d445275ae353b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68125e9891be490484d5644f34562836":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"416a09ab32644cd29a30849fd70a627d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"78ae821e374a4327ab134d9a7bab6501":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb766f1521b34666bc2347d0c25ea5ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"j6XXjqb8X22i"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u-V_QpDYLJ36","executionInfo":{"status":"ok","timestamp":1684069227298,"user_tz":-60,"elapsed":9610,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"3cf5de55-7fba-4ad6-ccfb-5b4207b23a62"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mSKv3rGfYox6","executionInfo":{"status":"ok","timestamp":1684069227299,"user_tz":-60,"elapsed":11,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"d255d80a-1814-4d5a-ad06-091454034fbe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun May 14 13:00:19 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    25W / 300W |      0MiB / 16384MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["import os\n","\n","base_path = \"/content/drive/MyDrive/Interpretability\" "],"metadata":{"id":"bBh1_hjcLeZz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install numpy==1.23"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"25PcMHSi2wfl","executionInfo":{"status":"ok","timestamp":1684069227299,"user_tz":-60,"elapsed":7,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"3847b38d-e8e8-41d6-f0e5-040fa12b976d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: numpy==1.23 in /usr/local/lib/python3.10/dist-packages (1.23.0)\n"]}]},{"cell_type":"code","source":["!pip install git+https://github.com/neelnanda-io/TransformerLens"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r5RFUEgxSO-A","executionInfo":{"status":"ok","timestamp":1684069272951,"user_tz":-60,"elapsed":45655,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"0af8f084-de2c-45e6-ce59-2125bcae134b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/neelnanda-io/TransformerLens\n","  Cloning https://github.com/neelnanda-io/TransformerLens to /tmp/pip-req-build-d1p_biov\n","  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/TransformerLens /tmp/pip-req-build-d1p_biov\n","  Resolved https://github.com/neelnanda-io/TransformerLens to commit 49edbec5424081182ef090265e2e6112153deffc\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting datasets>=2.7.1 (from transformer-lens==0.0.0)\n","  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting einops>=0.6.0 (from transformer-lens==0.0.0)\n","  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fancy-einsum>=0.0.3 (from transformer-lens==0.0.0)\n","  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n","Collecting jaxtyping>=0.2.11 (from transformer-lens==0.0.0)\n","  Downloading jaxtyping-0.2.19-py3-none-any.whl (24 kB)\n","Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (1.23.0)\n","Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (1.5.3)\n","Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (13.3.4)\n","Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (2.0.0+cu118)\n","Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (4.65.0)\n","Collecting transformers>=4.25.1 (from transformer-lens==0.0.0)\n","  Downloading transformers-4.29.1-py3-none-any.whl (7.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typeguard<4.0.0,>=3.0.2 (from transformer-lens==0.0.0)\n","  Downloading typeguard-3.0.2-py3-none-any.whl (30 kB)\n","Collecting wandb>=0.13.5 (from transformer-lens==0.0.0)\n","  Downloading wandb-0.15.2-py3-none-any.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (9.0.0)\n","Collecting dill<0.3.7,>=0.3.0 (from datasets>=2.7.1->transformer-lens==0.0.0)\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2.27.1)\n","Collecting xxhash (from datasets>=2.7.1->transformer-lens==0.0.0)\n","  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets>=2.7.1->transformer-lens==0.0.0)\n","  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2023.4.0)\n","Collecting aiohttp (from datasets>=2.7.1->transformer-lens==0.0.0)\n","  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.11.0 (from datasets>=2.7.1->transformer-lens==0.0.0)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (23.1)\n","Collecting responses<0.19 (from datasets>=2.7.1->transformer-lens==0.0.0)\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.10/dist-packages (from jaxtyping>=0.2.11->transformer-lens==0.0.0) (4.5.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2022.7.1)\n","Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.2.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.14.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.12.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10->transformer-lens==0.0.0) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10->transformer-lens==0.0.0) (16.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (2022.10.31)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=4.25.1->transformer-lens==0.0.0)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (8.1.3)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (5.9.5)\n","Collecting sentry-sdk>=1.0.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading sentry_sdk-1.22.2-py2.py3-none-any.whl (203 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.3/203.3 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting pathtools (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting setproctitle (from wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer-lens==0.0.0) (1.16.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (2.0.12)\n","Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0)\n","  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0)\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0 (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0)\n","  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0)\n","  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0)\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=12.6.0->transformer-lens==0.0.0) (0.1.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->transformer-lens==0.0.0) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->transformer-lens==0.0.0) (1.3.0)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0)\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: transformer-lens, pathtools\n","  Building wheel for transformer-lens (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformer-lens: filename=transformer_lens-0.0.0-py3-none-any.whl size=91820 sha256=c122840afc620b1c4cc0fbeb963e696d99e5095ab37e555a87c87cfaaeb8b185\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-fwk0lbjs/wheels/60/65/82/80e3fa068c7037d07b22230004d112265d6da4134423a3b753\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=e73f5d6af8e103dac611bc71a1240955e12dcf58132fd82ad9bdd4ddbc817ef7\n","  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n","Successfully built transformer-lens pathtools\n","Installing collected packages: tokenizers, pathtools, xxhash, typeguard, smmap, setproctitle, sentry-sdk, multidict, frozenlist, fancy-einsum, einops, docker-pycreds, dill, async-timeout, yarl, responses, multiprocess, jaxtyping, huggingface-hub, gitdb, aiosignal, transformers, GitPython, aiohttp, wandb, datasets, transformer-lens\n","Successfully installed GitPython-3.1.31 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 docker-pycreds-0.4.0 einops-0.6.1 fancy-einsum-0.0.3 frozenlist-1.3.3 gitdb-4.0.10 huggingface-hub-0.14.1 jaxtyping-0.2.19 multidict-6.0.4 multiprocess-0.70.14 pathtools-0.1.2 responses-0.18.0 sentry-sdk-1.22.2 setproctitle-1.3.2 smmap-5.0.0 tokenizers-0.13.3 transformer-lens-0.0.0 transformers-4.29.1 typeguard-3.0.2 wandb-0.15.2 xxhash-3.2.0 yarl-1.9.2\n"]}]},{"cell_type":"code","source":["!pip install devtools\n","from devtools import debug"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hM7xgwxBXTCD","executionInfo":{"status":"ok","timestamp":1684069272952,"user_tz":-60,"elapsed":17,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"f099fc90-43c5-491c-db3c-8ee7b910e770"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting devtools\n","  Downloading devtools-0.11.0-py3-none-any.whl (19 kB)\n","Collecting asttokens<3.0.0,>=2.0.0 (from devtools)\n","  Downloading asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n","Collecting executing>=1.1.1 (from devtools)\n","  Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from asttokens<3.0.0,>=2.0.0->devtools) (1.16.0)\n","Installing collected packages: executing, asttokens, devtools\n","Successfully installed asttokens-2.2.1 devtools-0.11.0 executing-1.2.0\n"]}]},{"cell_type":"code","source":["# Import stuff\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import einops\n","import tqdm.notebook as tqdm\n","\n","import random\n","import time\n","\n","# from google.colab import drive\n","from pathlib import Path\n","import pickle\n","import os\n","\n","\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline\n","import plotly.express as px\n","import plotly.graph_objects as go\n","\n","from torch.utils.data import DataLoader\n","\n","from functools import *\n","import pandas as pd\n","import gc\n","import collections\n","import copy\n","\n","# import comet_ml\n","import itertools\n","from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n","import dataclasses\n","import datasets\n","\n","from pprint import pprint"],"metadata":{"id":"q8XmZlmOUtoJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformer_lens.utils import (\n","    gelu_new,\n","    to_numpy,\n","    get_corner,\n","    lm_cross_entropy_loss,\n",")  # Helper functions\n","from transformer_lens.hook_points import (\n","    HookedRootModule,\n","    HookPoint,\n",")  # Hooking utilities\n","from transformer_lens import HookedTransformer, HookedTransformerConfig"],"metadata":{"id":"_DZmDwTSUjwS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\""],"metadata":{"id":"wG5dKXVyVExr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM\n","\n","model_name = \"solu-6l-pile\"\n","layer_ending = \"mlp.hook_mid\"\n","model = HookedTransformer.from_pretrained(model_name).to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":310,"referenced_widgets":["d2133a131407415eb33b757ee8db3bd2","ea492fd4f4c44593a9d1ffdc1ddde69a","19f9c23a0910460393ea1948bcda1519","3fd6f09f4ff24cc6ad62793b52cfad0c","f6bcd01260514406a4d41b54e57e27f0","450525149c6643a5bc22d0c6c550c203","a1cb0bcfc9e942a5ae342a41f035edb5","376585bf1cc84e0fa0f1ed748ff9a0ae","409b8a5be95544afbd4767b5521417b5","e279a96bd2f8407f8fdb5d93cf002b28","7c4c6c7432824c92a798c2793c6ad0ac","5c83dfb8baf44dcaa9bda6332804b02d","c20f15e477b24e7bb0f2b2be0bda95b3","746aea0ab6244c7e8fce4db571940a42","71f0580e6ff8419c808b88226c7a7484","bb175c05113140b6a8c1dd8abf4b0caf","b877b314dbfd48a0adb47a75615a01cc","f92bc61e2d444986ab25a5bd949cf13b","2dcdd3fe77cf4a588fc69cebc3134d21","d32ecdbfb0c64ca6941ef720bbcf2718","e295973a725049da8bf927c6a021e6bf","3565c15bf1614e69a0f5713673d4e842","45f376e0e5024fb288f7f5c5da685d95","050db19b1a624da3bf5f26bb8a55efb9","d29c1d33796a4f2fbe3963a32b371cdc","45490509af984970bfa406adb120a1f4","0e0eea5b8b014dbd92bd626d8c617c93","ede3fd4cfc914c78ac9585e844107875","a94990a9d7bb4f54bd99b39a94148e55","a8a054f3613840a1beac13ac51300945","943b68b2e6b74bba982e49154d91b9b7","b4f8bc180ccb4611b521b29867eb9936","783e09433aa545b2b82e9ad001d5f72e","89b1c558c53e4328888428a683312558","1dbedf20a0d14bbb9f77e49c2bd546a2","69d1b8a86cf44a3997f53bd3982cadb8","78b3bff1d0d94825ae4447087f212316","4afb7ed58dd541ceaa7468fb269b8279","86280f5f92a74b07b9e6e71e38850650","bd6a8977ee1a45f4a5ce87a7df399d16","6d009e92b0d44f2ca7cb2ee059af2fc4","67e7e91ae4944fa1961429ef5371335b","a7ebbfb41ab14e2792898cd8f58304b2","caefb5a8ef004726a7682aeb588e6393","4a16db03c5d74a429df7cf285ee9f700","3a13632175bd4a108d449a768cceab9f","f1c898313a1b42bb90ad162cbc813084","777ad534914940289998c5a155b2dc88","145d42567db94e94a9245de7099f10bd","b42d369b38a74538a6aba084dcb3031d","0cb3f7930ef44c7bbd46c7e6308527e0","e65e6845924b4dc3a1c7cb1a040429c3","2acdc4a53ce149b9851969f04778b633","c555545f03e04859bab7cd3cb9eec308","e8ef69eae5fb4309af5d28cb42e1a078","69263d671baf4b3e995d982c899a5972","b72a8ad4acf9465fb4c404fe78051d53","4ae47982e91645d0853b7ee5d43de5a2","64c3a8170e8246daa59716aa1075bc24","9e18884f13f5497689697728a0ed04b5","8d314e9e83af493b8ef0c3ed7331d7e3","5dbd4353123848f485a551274f5c438b","a6323fcaa4f3478ea518b8ba135e13b6","b423f484c15c43e79fbf1ae2d5f72d33","941728866457433ab5cd12bcd3288df1","4a14ed1df7324e7691428fbeab583519","2ef319dcfea743329f8189b3685ccdd6","269224db473045369710e9f3c11fc5b8","1ef37f4fae714981a45fb9161f313d79","fe74222ae4524fd08c4334b0c947281c","0c537f70757245e99e58fd7dff8964f5","6ae069ce24794d06916d2ca659114996","0479a82ba1af4bfb9958d529cf24409c","83cba34231e94d7bb46f19f0b691748b","82343591af0840c0890b770608c1fd25","3ad267bdb26347e094804805978c5f69","8b2cd3fe61944debbd340f04a2a039c5"]},"id":"W416JfwYVEzx","executionInfo":{"status":"ok","timestamp":1684069312539,"user_tz":-60,"elapsed":33942,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"d9710104-959f-4fa6-ba44-1af992cf1802"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/753 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2133a131407415eb33b757ee8db3bd2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading SoLU_6L_v13_final.pth:   0%|          | 0.00/489M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c83dfb8baf44dcaa9bda6332804b02d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45f376e0e5024fb288f7f5c5da685d95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89b1c558c53e4328888428a683312558"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/457k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a16db03c5d74a429df7cf285ee9f700"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69263d671baf4b3e995d982c899a5972"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ef319dcfea743329f8189b3685ccdd6"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Using pad_token, but it is not set yet.\n","WARNING:root:This model is using final RMS normalization, so the writing weights can't be centered! Skipping\n"]},{"output_type":"stream","name":"stdout","text":["Loaded pretrained model solu-6l-pile into HookedTransformer\n","Moving model to device:  cuda\n"]}]},{"cell_type":"code","source":["# from transformers import AutoModelForCausalLM\n","\n","# model_name = \"gpt2-small\"\n","# layer_ending = \"mlp.hook_post\"\n","# model = HookedTransformer.from_pretrained(model_name).to(device)"],"metadata":{"id":"xUTEAkhKRClO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from transformers import AutoModelForCausalLM\n","\n","# model_name = \"gpt2-xl\"\n","# layer_ending = \"mlp.hook_post\"\n","# model = HookedTransformer.from_pretrained(model_name).to(device)"],"metadata":{"id":"OUwBKu25VLzB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from transformers import AutoModelForCausalLM\n","\n","# model_name = \"pythia-70m\"\n","# layer_ending = \"mlp.hook_post\"\n","# model = HookedTransformer.from_pretrained(model_name).to(device)"],"metadata":{"id":"JDxrBA7Sf1aK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","nltk.download('stopwords')"],"metadata":{"id":"pdT54W_fwTNw","executionInfo":{"status":"ok","timestamp":1684069312540,"user_tz":-60,"elapsed":10,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"59e044ce-3c88-4281-af41-105a8a8a003b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["from transformers import AutoModelForMaskedLM\n","from transformers import AutoTokenizer\n","\n","aug_model_checkpoint = \"distilbert-base-uncased\"\n","aug_model = AutoModelForMaskedLM.from_pretrained(aug_model_checkpoint).to(device)\n","aug_tokenizer = AutoTokenizer.from_pretrained(aug_model_checkpoint)"],"metadata":{"id":"WthFIEKnpf6B","executionInfo":{"status":"ok","timestamp":1684069313011,"user_tz":-60,"elapsed":479,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"colab":{"base_uri":"https://localhost:8080/","height":177,"referenced_widgets":["72b529603fed4ae18b2298cfc401199b","975cd611e7ae45ca9930df68b70595c5","db0c00cb35d14405a94b748160be4fd3","1850274706824a24aabcb4ec13485f0b","1f8ea22a29b842bca86a786e1963ae11","32a3b897a2ee44f79fe7a93a166f0dcd","dc14ddfa17b74cdc88f8bcccbd487eb2","bfa6c53bca3c4cfc8a1735f575e2fe2a","e2bf5acb274f4bb6a0eee03a048a6192","fc8cc22e485b4d0f81e395ac1a03fe8b","b1629157cc7848e69b1258ba0ed17b9c","faa88ccf7f414e568a66e858a7c6fa06","4c8eb17eff744201868f0f2e9a174be4","ffa48c1720344cfdaff94cba9ae95d46","ed7fb0d638d04eadbb0ffc7be7a8422f","fc531673c3fd4df9ac69e4b0115815ea","7a2b45d7bbd74b65a8cc6fd88dadd9d7","1680efbb95fe45c385289d9da6e684e9","847131304e3e47fc8cfa30bd4a5874cc","4958cc68c6b243d3916661596489591f","b38adc08e3ec4373bd793063bf1c2062","291ea9291a0146e5ae443ff82dd27ab7","f9a791c3289344bda77f67bcd3bd3790","53e17325c8e04222a8425bb33dc4dcc9","6a78882beba74e2f9b97be5ad02106b8","b2ea28edd31343808256636c7fa586e4","ca9ac78747ff46cdaba0aedd9c88c698","7a38e74d9680455faad43244a0707088","07f4eebe7f2e464d9f368d88571de8df","5f65ebbe688f46c090933f096edba642","77d30c4e85f74e9ea38383cb45d66f65","6da6f63cc2f14f64a25994160422086b","d647fc42d7a142e1a0c68ed5a94c2d21","83ab64412c6f4f3793e4bb37c1cbe5c0","8a044b778cfd433888746badd9e3ebb5","79a3d8dddb2943ca9ddd86f2030f75a5","df1a2123aa28437a91dbbf7b79486ead","be243803ea1e49fc8fc3cf053c13b8dc","352cacc0aff94873b768d0eaa80c35c9","8d43463620f745dfa547c04a997e6750","b31076178616403a8761138fda8d9bd6","d871f7a813f94e6fbe0aef79654dde64","a62ef003fcb6497492e33352f25b3f75","9f679d4a5a754cbabd6b30fae4b7f0e5","9a5ba76f1313448e8f1543303fefbdc4","ec051eb1e63f4ff7819977a6c32b5855","a704e9e6fe2641f49c1f946ffb367ac6","6320f5b0b5b14f46aa64fb6f66e45714","f724c65f048c42639b840f9c088d8bb4","a3a9cd458f244181a6fd5141db7e7967","d7ad362c0a6e4fb6949d445275ae353b","68125e9891be490484d5644f34562836","416a09ab32644cd29a30849fd70a627d","78ae821e374a4327ab134d9a7bab6501","bb766f1521b34666bc2347d0c25ea5ef"]},"outputId":"81eff647-ecb1-4172-ce6c-1cb71c149602"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72b529603fed4ae18b2298cfc401199b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"faa88ccf7f414e568a66e858a7c6fa06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9a791c3289344bda77f67bcd3bd3790"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83ab64412c6f4f3793e4bb37c1cbe5c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a5ba76f1313448e8f1543303fefbdc4"}},"metadata":{}}]},{"cell_type":"markdown","source":["# Code"],"metadata":{"id":"ox_8QsnsYkIf"}},{"cell_type":"code","source":["import requests\n","import re\n","import json\n","\n","# parser = re.compile(\"<span class='token' style='background-color:rgb\\([0-9]{1,3}, [0-9]{1,3}, [0-9]{1,3}\\)' >\")\n","parser = re.compile('\\{\\\"tokens\\\": ')\n","def get_snippets(model_name, layer, neuron):\n","  \"\"\"Get the max activating dataset examples for a given neuron in a model\"\"\"\n","  base_url = f\"https://neuroscope.io/{model_name}/{layer}/{neuron}.html\"\n","\n","  response = requests.get(base_url)\n","  webpage = response.text\n","  \n","  parts = parser.split(webpage)\n","  snippets = []\n","  for i, part in enumerate(parts):    \n","    if i == 0 or i % 2 != 0:\n","      continue\n","\n","    token_str = part.split(', \"values\": ')[0]\n","\n","    tokens = json.loads(token_str)\n","\n","    snippet = \"\".join(tokens)\n","\n","    snippets.append(snippet)\n","    \n","  if len(snippets) != 20:\n","    raise Exception\n","  return snippets"],"metadata":{"id":"ceSIVvAuAC1S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["snippets = get_snippets(\"solu-6l-pile\", 3, 13)"],"metadata":{"id":"WRzVxS_3hrtv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["act_parser = re.compile('<h4>Max Act: <b>')\n","def get_max_activations(model_name, layer, neuron, n=1):\n","  \"\"\"Get the max activating dataset examples for a given neuron in a model\"\"\"\n","  base_url = f\"https://neuroscope.io/{model_name}/{layer}/{neuron}.html\"\n","\n","  response = requests.get(base_url)\n","  webpage = response.text\n","  \n","  parts = act_parser.split(webpage)\n","  activations = []\n","  for i, part in enumerate(parts):    \n","    if i == 0:\n","      continue\n","\n","    activation = float(part.split('</b>')[0])\n","\n","    activations.append(activation)\n","    if len(activations) >= n:\n","      break\n","    \n","  if len(activations) != min(20, n):\n","    raise Exception\n","  return activations if n > 1 else activations[0]"],"metadata":{"id":"AfU-fnqhTMAT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from string import punctuation\n","\n","class WordTokenizer:\n","  \"\"\"Simple tokenizer for splitting text into words\"\"\"\n","\n","  def __init__(self, split_tokens, stick_tokens):\n","    self.split_tokens = split_tokens\n","    self.stick_tokens = stick_tokens\n","\n","  def __call__(self, text):\n","    return self.tokenize(text)\n","\n","  def is_split(self, char):\n","    \"\"\"Split on any non-alphabet chars unless excluded, and split on any specified chars\"\"\"\n","    return char in self.split_tokens or (not char.isalpha() and char not in stick_tokens)\n","  \n","  def tokenize(self, text):\n","    \"\"\"Tokenize text, preserving all characters\"\"\"\n","    tokens = []\n","    current_token = \"\"\n","    for char in text:\n","      if self.is_split(char):\n","        tokens.append(current_token)\n","        tokens.append(char)\n","        current_token = \"\"\n","        continue\n","      current_token += char\n","    tokens.append(current_token)\n","    tokens = [token for token in tokens if token]\n","    return tokens\n","\n","stick_tokens = {\"'\"}\n","word_tokenizer = WordTokenizer(set(), stick_tokens)"],"metadata":{"id":"W-mtxV3Tv2td"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","\n","import gzip\n","from collections import Counter, defaultdict\n","\n","if False:\n","  file_ids = \"abcdefghijklmnopqrstuvwxyz\"\n","\n","  word_counter = Counter()\n","\n","  tags = [\"NOUN\", \"VERB\", \"ADJ\", \"ADV\", \"PRON\", \"DET\", \"ADP\", \"NUM\", \"CONJ\", \"PRT\", \"X\", \".\", \"END_\", \"START_\"]\n","\n","  tags = [f\"_{tag}\" for tag in tags]\n","\n","  for c in file_ids:\n","    print(f\"Processing {c}\")\n","    c_counter = Counter()\n","\n","    with gzip.open(f\"{base_path}/data/ngrams/googlebooks-eng-all-1gram-20120701-{c}.gz\") as ifh:\n","      for j, line in enumerate(ifh):\n","        if j % 5000000 == 0:\n","          print(f\"{j} complete\")\n","\n","        line = line.decode()\n","        line = line.strip()\n","        text, year, count, book_count = line.split(\"\\t\")\n","\n","        if int(year) < 1950:\n","          continue\n","\n","        if \"_\" in text:\n","          continue\n","\n","        c_counter[text] += int(count)\n","\n","      print(\"Removing rare words\")\n","      min_count = 2000\n","      common_c_counter = Counter()\n","      for i, (word, count) in enumerate(c_counter.most_common()):\n","        if i % 5000000 == 0:\n","          print(f\"{i} complete\")\n","\n","        if count < min_count:\n","          break\n","        common_c_counter[word] += count\n","\n","      word_counter.update(common_c_counter)\n","\n","  print(\"Counting casings\")\n","  word_to_casings = defaultdict(list)\n","  for word, count in word_counter.most_common():\n","    word_norm = word.lower()\n","    word_to_casings[word_norm].append((word, count))\n","\n","  with open(f\"{base_path}/data/ngrams/word_to_casings.json\", \"w\") as ifh:\n","    json.dump(word_to_casings, ifh, ensure_ascii=False)"],"metadata":{"id":"kSwhSZaqB4WK","executionInfo":{"status":"ok","timestamp":1684069313012,"user_tz":-60,"elapsed":7,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2d7bbe2c-80aa-4b1e-ee38-02c50578999d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 15 µs, sys: 0 ns, total: 15 µs\n","Wall time: 20.3 µs\n"]}]},{"cell_type":"code","source":["with open(f\"{base_path}/data/ngrams/word_to_casings.json\") as ifh:\n","  word_to_casings = json.load(ifh)"],"metadata":{"id":"N9MsoHbsI9fy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import copy\n","from nltk.corpus import stopwords\n","from string import punctuation\n","import re\n","from scipy.special import softmax\n","\n","class ContextualAugmenter:\n","  \"\"\"Uses BERT to generate variations on input text by masking words and substituting with most likely predictions\"\"\"\n","\n","  def __init__(self, model, model_tokenizer, word_tokenizer, neuron_model, device=\"cuda:0\"):\n","    self.model = model\n","    self.model_tokenizer = model_tokenizer\n","    self.stops = set(stopwords.words('english'))\n","    self.punctuation_set = set(punctuation)\n","    self.to_strip = \" \" + punctuation\n","    self.word_tokenizer = word_tokenizer\n","    self.device = device\n","\n","  def augment(self, text, max_char_position=None, exclude_stopwords=False, n=5, mask_num=1, important_tokens=None, all_but_important=False, only_important=False, **kwargs):\n","    \"\"\"Generate new texts given an initial text and a masking scheme by auto-regressively predicting each masked token with BERT\"\"\"\n","\n","    if all_but_important and important_tokens is None:\n","      raise ValueError(\"When all_but_important is True you must provide one or more important_tokens\")\n","\n","    if only_important and important_tokens is None:\n","      raise ValueError(\"When only_important is True you must provide one or more important_tokens\")\n","\n","    if only_important and all_but_important:\n","      raise ValueError(\"only_important and all_but_important are not allowed to be True at the same time\")\n","\n","    joiner = \"\"\n","    tokens = self.word_tokenizer(text)\n","    \n","    new_texts = []\n","    positions = []\n","\n","    important_tokens = {token.strip(self.to_strip).lower() for token in important_tokens}\n","\n","    seen_prompts = set()\n","\n","    for i, token in enumerate(tokens):\n","      norm_token = token.strip(self.to_strip).lower()\n","      if not token or word_tokenizer.is_split(token) or (exclude_stopwords and norm_token in self.stops) or (important_tokens is not None and norm_token not in important_tokens):\n","        continue\n","\n","      masked_tokens = copy.deepcopy(tokens)\n","      masked = 0\n","      \n","      if not all_but_important and not only_important:\n","        # Mask mask_num consecutive tokens\n","        masking_index = 0\n","        while masked < mask_num and i + masking_index < len(masked_tokens):\n","          if not word_tokenizer.is_split(masked_tokens[i + masking_index]):\n","            masked_tokens[i + masking_index] = \"[MASK]\"\n","            masked += 1\n","          masking_index += 1\n","\n","      else:\n","        for j, cand_token in enumerate(tokens):\n","          norm_cand_token = cand_token.strip(self.to_strip).lower()\n","          # Basic token checks plus check if the token is important and therefore whether it should be masked\n","          if (not cand_token or word_tokenizer.is_split(cand_token) or \n","              (exclude_stopwords and norm_cand_token in self.stops) or \n","              (norm_cand_token in important_tokens and all_but_important) or \n","              (norm_cand_token not in important_tokens and only_important)):\n","            continue\n","          masked_tokens[j] = \"[MASK]\"\n","          masked += 1\n","        \n","      before = tokens[:i]\n","      before_text = joiner.join(before)\n","      position = len(before_text)\n","\n","      # Don't bother if we're beyond the max activating token, as these tokens have no effect on the activation\n","      if max_char_position is not None and position > max_char_position:\n","        break\n","\n","      start_masked_text = joiner.join(masked_tokens)\n","      masked_matrix = [[copy.deepcopy(start_masked_text) for _ in range(n)] for _ in range(masked + 1)]\n","\n","      for j in range(masked):\n","        masked_texts = masked_matrix[j]\n","        inputs = self.model_tokenizer(masked_texts, padding=True, return_tensors=\"pt\").to(self.device)\n","        token_probs = softmax(self.model(**inputs).logits.cpu().detach().numpy(), axis=-1)\n","        inputs = inputs.to(\"cpu\")\n","\n","        chosen_tokens = set()\n","        \n","        for k in range(n):\n","          # Get the index of the first masked token\n","          mask_token_index = np.argwhere(inputs[\"input_ids\"][k] == self.model_tokenizer.mask_token_id)[0, 0]\n","          mask_token_probs = token_probs[k, mask_token_index, :]\n","          # We negate the array before argsort to get the largest, not the smallest, logits\n","          top_probs = -np.sort(-mask_token_probs).transpose()\n","          top_tokens = np.argsort(-mask_token_probs).transpose()\n","\n","          # Substitute the given token with the best predictions\n","          for l, top_token in enumerate(top_tokens):\n","            next_top_prob = top_probs[l + 1]\n","            candidate_token = self.model_tokenizer.decode(top_token)\n","            if candidate_token in chosen_tokens and next_top_prob > 0.00001:\n","              continue\n","\n","            # Check that the predicted token isn't the same as the token that was already there\n","            normalised_candidate = candidate_token.strip(self.to_strip).lower() if candidate_token not in self.punctuation_set else candidate_token\n","            normalised_token = token.strip(self.to_strip).lower() if token not in self.punctuation_set else token\n","            \n","            if normalised_candidate != normalised_token:\n","              chosen_token = candidate_token\n","              chosen_tokens.add(chosen_token)\n","              break\n","\n","          # BERT uses ## to denote a tokenisation within a word, so we remove it to glue the word back together\n","          masked_matrix[j + 1][k] = masked_texts[k].replace(self.model_tokenizer.mask_token, candidate_token, 1).replace(\" ##\", \"\")\n","\n","      for new_prompt in masked_matrix[-1]:\n","        if new_prompt in seen_prompts:\n","          continue\n","        new_texts.append(new_prompt)\n","        positions.append(position)\n","        seen_prompts.add(new_prompt)\n","\n","      if all_but_important or only_important:\n","        break       \n","    \n","    return new_texts, positions"],"metadata":{"id":"OyHgzc3bmGWJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from ast import Continue\n","import copy\n","from nltk.corpus import stopwords\n","from string import punctuation\n","import re\n","from scipy.special import softmax\n","\n","class FastAugmenter:\n","  \"\"\"Uses word embeddings to generate variations on input text by replacing words with other words with similar embeddings\"\"\"\n","\n","  def __init__(self, model, model_tokenizer, word_tokenizer, neuron_model, device=\"cuda:0\"):\n","    self.model = model\n","    self.model_tokenizer = model_tokenizer\n","    self.stops = set(stopwords.words('english'))\n","    self.punctuation_set = set(punctuation)\n","    self.to_strip = \" \" + punctuation\n","    self.word_tokenizer = word_tokenizer\n","    self.device = device\n","\n","  def augment(self, text, max_char_position=None, exclude_stopwords=False, n=5, important_tokens=None, **kwargs):\n","    joiner = \"\"\n","    tokens = self.word_tokenizer(text)\n","    \n","    new_texts = []\n","    positions = []\n","\n","    important_tokens = {token.strip(self.to_strip).lower() for token in important_tokens}\n","\n","    seen_prompts = set()\n","\n","    # Gather all tokens to be substituted\n","    tokens_to_sub = []\n","\n","    # Mask important tokens   \n","    masked_token_sets = []\n","    masked_texts = []\n","\n","    masked_tokens = []\n","\n","    for i, token in enumerate(tokens):\n","      norm_token = token.strip(self.to_strip).lower() if any(c.isalpha() for c in token) else token\n","\n","      if not token or word_tokenizer.is_split(token) or (exclude_stopwords and norm_token in self.stops) or (important_tokens is not None and norm_token not in important_tokens):\n","        continue\n","      \n","      # If no alphanumeric characters, we'll do a special substitution rather than using BERT\n","      if not any(c.isalpha() for c in token):\n","        continue\n","\n","      before = tokens[:i]\n","      before_text = joiner.join(before)\n","      position = len(before_text)\n","\n","      # Don't bother if we're beyond the max activating token, as these tokens have no effect on the activation\n","      if max_char_position is not None and position > max_char_position:\n","        break\n","\n","      copy_tokens = copy.deepcopy(tokens)\n","      copy_tokens[i] = \"[MASK]\"     \n","      masked_token_sets.append((copy_tokens, position))\n","      masked_texts.append(joiner.join(copy_tokens))\n","\n","      masked_tokens.append(token)\n","\n","    # pprint(masked_texts)\n","    if len(masked_texts) == 0:\n","      return [], []\n","    \n","    inputs = self.model_tokenizer(masked_texts, padding=True, return_tensors=\"pt\").to(self.device)\n","    token_probs = softmax(self.model(**inputs).logits.cpu().detach().numpy(), axis=-1)\n","    inputs = inputs.to(\"cpu\")\n","\n","    chosen_tokens = set()\n","\n","    new_texts = []\n","    positions = []\n","\n","    seen_texts = set()\n","\n","    for i, (masked_token_set, char_position) in enumerate(masked_token_sets):    \n","      mask_token_index = np.argwhere(inputs[\"input_ids\"][i] == self.model_tokenizer.mask_token_id)[0, 0]\n","\n","      mask_token_probs = token_probs[i, mask_token_index, :]\n","\n","      # We negate the array before argsort to get the largest, not the smallest, logits\n","      top_probs = -np.sort(-mask_token_probs).transpose()\n","      top_tokens = np.argsort(-mask_token_probs).transpose()\n","\n","      subbed = 0\n","\n","      # Substitute the given token with the best predictions\n","      for l, (top_token, top_prob) in enumerate(zip(top_tokens, top_probs)):\n","        if top_prob < 0.00001:\n","          break        \n","\n","        candidate_token = self.model_tokenizer.decode(top_token)\n","\n","        # print(candidate_token)\n","\n","        # Check that the predicted token isn't the same as the token that was already there\n","        normalised_candidate = candidate_token.strip(self.to_strip).lower() if candidate_token not in self.punctuation_set else candidate_token\n","        normalised_token = token.strip(self.to_strip).lower() if token not in self.punctuation_set else token\n","        \n","        if normalised_candidate == normalised_token or not any(c.isalpha() for c in candidate_token):\n","          continue\n","\n","        # Get most common casing of the word\n","        most_common_casing = word_to_casings.get(candidate_token, [(candidate_token, 1)])[0][0]\n","\n","        original_token = masked_tokens[i]\n","        # Title case normally has meaning (e.g., start of sentence, in a proper noun, etc.) so follow original token, otherwise use most common\n","        best_casing = candidate_token.title() if original_token.istitle() else most_common_casing\n","\n","        new_token_set = copy.deepcopy(masked_token_set)\n","        # BERT uses ## to denote a tokenisation within a word, so we remove it to glue the word back together\n","        masked_text = joiner.join(new_token_set)\n","        new_text = masked_text.replace(self.model_tokenizer.mask_token, best_casing, 1).replace(\" ##\", \"\")\n","\n","        if new_text in seen_texts:\n","          continue\n","\n","        new_texts.append(new_text)\n","        positions.append(char_position)\n","        subbed += 1\n","\n","        if subbed >= n:\n","          break\n","\n","    return new_texts, positions"],"metadata":{"id":"3tk4LSboQrCg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fast_aug = FastAugmenter(aug_model, aug_tokenizer, word_tokenizer, model)"],"metadata":{"id":"ECYilAPzXO8V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["contextual_aug = ContextualAugmenter(aug_model, aug_tokenizer, word_tokenizer, model)"],"metadata":{"id":"1xJfbbSBftKi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","\n","new_prompts, _ = fast_aug.augment(\"J.C.C. is supported by a grant from the UK Medical Research Council\", important_tokens={\"is\", \"supported\", \"by\", \"a\", \"grant\", \"from\", \"the\", \"UK\", \"Medical\", \"Research\", \"Council\"}, n=10)"],"metadata":{"id":"O42axWSjR6mI","executionInfo":{"status":"ok","timestamp":1684069322718,"user_tz":-60,"elapsed":432,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2c342d14-b765-447a-c394-47ce86f7ba90"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 2.32 s, sys: 170 ms, total: 2.49 s\n","Wall time: 2.56 s\n"]}]},{"cell_type":"code","source":["%%time\n","\n","contextual_aug.augment(\"J.C.C. is supported by a grant from the UK Medical Research Council\", important_tokens={\"is\", \"supported\", \"by\", \"a\", \"grant\", \"from\", \"the\", \"UK\", \"Medical\", \"Research\", \"Council\"}, n=10)"],"metadata":{"id":"abe-d-7Yew-A","executionInfo":{"status":"ok","timestamp":1684069324001,"user_tz":-60,"elapsed":1285,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"979da82c-9420-4612-ae3b-b9494e0f33ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 1.45 s, sys: 324 ms, total: 1.77 s\n","Wall time: 3.27 s\n"]},{"output_type":"execute_result","data":{"text/plain":["(['J.C.C. was supported by a grant from the UK Medical Research Council',\n","  'J.C.C. has supported by a grant from the UK Medical Research Council',\n","  'J.C.C. currently supported by a grant from the UK Medical Research Council',\n","  'J.C.C. were supported by a grant from the UK Medical Research Council',\n","  'J.C.C. are supported by a grant from the UK Medical Research Council',\n","  'J.C.C. , supported by a grant from the UK Medical Research Council',\n","  'J.C.C. research supported by a grant from the UK Medical Research Council',\n","  'J.C.C. - supported by a grant from the UK Medical Research Council',\n","  'J.C.C. ltd supported by a grant from the UK Medical Research Council',\n","  'J.C.C. foundation supported by a grant from the UK Medical Research Council',\n","  'J.C.C. is funded by a grant from the UK Medical Research Council',\n","  'J.C.C. is financed by a grant from the UK Medical Research Council',\n","  'J.C.C. is recognised by a grant from the UK Medical Research Council',\n","  'J.C.C. is backed by a grant from the UK Medical Research Council',\n","  'J.C.C. is promoted by a grant from the UK Medical Research Council',\n","  'J.C.C. is governed by a grant from the UK Medical Research Council',\n","  'J.C.C. is assisted by a grant from the UK Medical Research Council',\n","  'J.C.C. is benefited by a grant from the UK Medical Research Council',\n","  'J.C.C. is sponsored by a grant from the UK Medical Research Council',\n","  'J.C.C. is funding by a grant from the UK Medical Research Council',\n","  'J.C.C. is supported through a grant from the UK Medical Research Council',\n","  'J.C.C. is supported with a grant from the UK Medical Research Council',\n","  'J.C.C. is supported via a grant from the UK Medical Research Council',\n","  'J.C.C. is supported from a grant from the UK Medical Research Council',\n","  'J.C.C. is supported under a grant from the UK Medical Research Council',\n","  'J.C.C. is supported in a grant from the UK Medical Research Council',\n","  'J.C.C. is supported on a grant from the UK Medical Research Council',\n","  'J.C.C. is supported using a grant from the UK Medical Research Council',\n","  'J.C.C. is supported at a grant from the UK Medical Research Council',\n","  'J.C.C. is supported against a grant from the UK Medical Research Council',\n","  'J.C.C. is supported by research grant from the UK Medical Research Council',\n","  'J.C.C. is supported by annual grant from the UK Medical Research Council',\n","  'J.C.C. is supported by an grant from the UK Medical Research Council',\n","  'J.C.C. is supported by grant grant from the UK Medical Research Council',\n","  'J.C.C. is supported by strategic grant from the UK Medical Research Council',\n","  'J.C.C. is supported by matching grant from the UK Medical Research Council',\n","  'J.C.C. is supported by direct grant from the UK Medical Research Council',\n","  'J.C.C. is supported by funding grant from the UK Medical Research Council',\n","  'J.C.C. is supported by substantial grant from the UK Medical Research Council',\n","  'J.C.C. is supported by seed grant from the UK Medical Research Council',\n","  'J.C.C. is supported by a donation from the UK Medical Research Council',\n","  'J.C.C. is supported by a fellowship from the UK Medical Research Council',\n","  'J.C.C. is supported by a scholarship from the UK Medical Research Council',\n","  'J.C.C. is supported by a funding from the UK Medical Research Council',\n","  'J.C.C. is supported by a consortium from the UK Medical Research Council',\n","  'J.C.C. is supported by a grants from the UK Medical Research Council',\n","  'J.C.C. is supported by a team from the UK Medical Research Council',\n","  'J.C.C. is supported by a contribution from the UK Medical Research Council',\n","  'J.C.C. is supported by a loan from the UK Medical Research Council',\n","  'J.C.C. is supported by a sponsorship from the UK Medical Research Council',\n","  'J.C.C. is supported by a grant by the UK Medical Research Council',\n","  'J.C.C. is supported by a grant of the UK Medical Research Council',\n","  'J.C.C. is supported by a grant through the UK Medical Research Council',\n","  'J.C.C. is supported by a grant via the UK Medical Research Council',\n","  'J.C.C. is supported by a grant with the UK Medical Research Council',\n","  'J.C.C. is supported by a grant to the UK Medical Research Council',\n","  'J.C.C. is supported by a grant at the UK Medical Research Council',\n","  'J.C.C. is supported by a grant in the UK Medical Research Council',\n","  'J.C.C. is supported by a grant for the UK Medical Research Council',\n","  'J.C.C. is supported by a grant under the UK Medical Research Council',\n","  'J.C.C. is supported by a grant from royal UK Medical Research Council',\n","  'J.C.C. is supported by a grant from : UK Medical Research Council',\n","  'J.C.C. is supported by a grant from a UK Medical Research Council',\n","  'J.C.C. is supported by a grant from nhs UK Medical Research Council',\n","  'J.C.C. is supported by a grant from central UK Medical Research Council',\n","  'J.C.C. is supported by a grant from independent UK Medical Research Council',\n","  'J.C.C. is supported by a grant from statistics UK Medical Research Council',\n","  'J.C.C. is supported by a grant from all UK Medical Research Council',\n","  'J.C.C. is supported by a grant from prestigious UK Medical Research Council',\n","  'J.C.C. is supported by a grant from national UK Medical Research Council',\n","  'J.C.C. is supported by a grant from the australian Medical Research Council',\n","  'J.C.C. is supported by a grant from the national Medical Research Council',\n","  'J.C.C. is supported by a grant from the indian Medical Research Council',\n","  'J.C.C. is supported by a grant from the canadian Medical Research Council',\n","  'J.C.C. is supported by a grant from the british Medical Research Council',\n","  'J.C.C. is supported by a grant from the american Medical Research Council',\n","  'J.C.C. is supported by a grant from the european Medical Research Council',\n","  'J.C.C. is supported by a grant from the ontario Medical Research Council',\n","  'J.C.C. is supported by a grant from the victorian Medical Research Council',\n","  'J.C.C. is supported by a grant from the international Medical Research Council',\n","  'J.C.C. is supported by a grant from the UK agricultural Research Council',\n","  'J.C.C. is supported by a grant from the UK humanities Research Council',\n","  'J.C.C. is supported by a grant from the UK transport Research Council',\n","  'J.C.C. is supported by a grant from the UK educational Research Council',\n","  'J.C.C. is supported by a grant from the UK antarctic Research Council',\n","  'J.C.C. is supported by a grant from the UK cancer Research Council',\n","  'J.C.C. is supported by a grant from the UK social Research Council',\n","  'J.C.C. is supported by a grant from the UK economic Research Council',\n","  'J.C.C. is supported by a grant from the UK industrial Research Council',\n","  'J.C.C. is supported by a grant from the UK defence Research Council',\n","  'J.C.C. is supported by a grant from the UK Medical technology Council',\n","  'J.C.C. is supported by a grant from the UK Medical standards Council',\n","  'J.C.C. is supported by a grant from the UK Medical science Council',\n","  'J.C.C. is supported by a grant from the UK Medical education Council',\n","  'J.C.C. is supported by a grant from the UK Medical innovation Council',\n","  'J.C.C. is supported by a grant from the UK Medical quality Council',\n","  'J.C.C. is supported by a grant from the UK Medical cannabis Council',\n","  'J.C.C. is supported by a grant from the UK Medical advisory Council',\n","  'J.C.C. is supported by a grant from the UK Medical accreditation Council',\n","  'J.C.C. is supported by a grant from the UK Medical ethics Council',\n","  'J.C.C. is supported by a grant from the UK Medical Research foundation',\n","  'J.C.C. is supported by a grant from the UK Medical Research .',\n","  'J.C.C. is supported by a grant from the UK Medical Research institute',\n","  'J.C.C. is supported by a grant from the UK Medical Research fund',\n","  'J.C.C. is supported by a grant from the UK Medical Research trust',\n","  'J.C.C. is supported by a grant from the UK Medical Research association',\n","  'J.C.C. is supported by a grant from the UK Medical Research organisation',\n","  'J.C.C. is supported by a grant from the UK Medical Research centre',\n","  'J.C.C. is supported by a grant from the UK Medical Research society',\n","  'J.C.C. is supported by a grant from the UK Medical Research ;'],\n"," [7,\n","  7,\n","  7,\n","  7,\n","  7,\n","  7,\n","  7,\n","  7,\n","  7,\n","  7,\n","  10,\n","  10,\n","  10,\n","  10,\n","  10,\n","  10,\n","  10,\n","  10,\n","  10,\n","  10,\n","  20,\n","  20,\n","  20,\n","  20,\n","  20,\n","  20,\n","  20,\n","  20,\n","  20,\n","  20,\n","  23,\n","  23,\n","  23,\n","  23,\n","  23,\n","  23,\n","  23,\n","  23,\n","  23,\n","  23,\n","  25,\n","  25,\n","  25,\n","  25,\n","  25,\n","  25,\n","  25,\n","  25,\n","  25,\n","  25,\n","  31,\n","  31,\n","  31,\n","  31,\n","  31,\n","  31,\n","  31,\n","  31,\n","  31,\n","  31,\n","  36,\n","  36,\n","  36,\n","  36,\n","  36,\n","  36,\n","  36,\n","  36,\n","  36,\n","  36,\n","  40,\n","  40,\n","  40,\n","  40,\n","  40,\n","  40,\n","  40,\n","  40,\n","  40,\n","  40,\n","  43,\n","  43,\n","  43,\n","  43,\n","  43,\n","  43,\n","  43,\n","  43,\n","  43,\n","  43,\n","  51,\n","  51,\n","  51,\n","  51,\n","  51,\n","  51,\n","  51,\n","  51,\n","  51,\n","  51,\n","  60,\n","  60,\n","  60,\n","  60,\n","  60,\n","  60,\n","  60,\n","  60,\n","  60,\n","  60])"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["# import gensim.downloader\n","\n","# vectors = gensim.downloader.load('fasttext-wiki-news-subwords-300')\n","\n","# vectors.most_similar('twitter')"],"metadata":{"id":"SxbYf5QcSl5q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pprint import pprint\n","from collections import defaultdict\n","from string import punctuation\n","import re\n","import copy\n","\n","splitter = re.compile(\"[\\.!\\\\n]\")\n","\n","def sentence_tokenizer(str_tokens):\n","  \"\"\"Split tokenized text into sentences\"\"\"\n","  sentences = []\n","  sentence = []\n","  sentence_to_token_indices = defaultdict(list)\n","  token_to_sentence_indices = {}\n","  \n","  for i, str_token in enumerate(str_tokens):\n","    sentence.append(str_token)\n","    sentence_to_token_indices[len(sentences)].append(i)\n","    token_to_sentence_indices[i] = len(sentences)\n","    if splitter.search(str_token) is not None or i + 1 == len(str_tokens):\n","      sentences.append(sentence)\n","      sentence = []    \n","\n","  return sentences, sentence_to_token_indices, token_to_sentence_indices\n","\n","\n","def prune(model, layer, neuron, prompt, max_length=1024, proportion_threshold=-0.5, absolute_threshold=None, window=0, return_maxes=False, **kwargs):\n","  \"\"\"Prune an input prompt to the shortest string that preserves x% of neuron activation on the most activating token.\"\"\"\n","\n","  prepend_bos = True\n","  tokens = model.to_tokens(prompt, prepend_bos=prepend_bos)\n","  str_tokens = model.to_str_tokens(prompt, prepend_bos=prepend_bos)\n","\n","  if len(tokens[0]) > max_length:\n","    tokens = tokens[0, :max_length].unsqueeze(0)\n","\n","  logits, cache = model.run_with_cache(tokens)\n","  activations = cache[layer][0, :, neuron]\n","\n","  initial_max = torch.max(activations).cpu().item()\n","  initial_argmax = torch.argmax(activations).cpu().item()\n","\n","  sentences, sentence_to_token_indices, token_to_sentence_indices = sentence_tokenizer(str_tokens)\n","\n","  max_sentence_index = token_to_sentence_indices[initial_argmax]\n","  relevant_str_tokens = [str_token for sentence in sentences[:max_sentence_index + 1] for str_token in sentence]\n","\n","  shortest_successful_prompt = None\n","  final_max_index = None\n","\n","  count = 0\n","  for i, str_token in reversed(list(enumerate(relevant_str_tokens[:max(0, initial_argmax - window + 1)]))):\n","    count += 1\n","    if count >= 20 and count % 10 != 0:\n","      continue\n","\n","    truncated_prompt = relevant_str_tokens[i:]\n","\n","    joined = \"\".join(truncated_prompt)\n","    \n","    truncated_tokens = model.to_tokens(joined, prepend_bos=prepend_bos)\n","    logits, cache = model.run_with_cache(truncated_tokens)\n","    truncated_activations = cache[layer][0, :, neuron]\n","    truncated_argmax = torch.argmax(truncated_activations).cpu().item() + i\n","    final_max_index = torch.argmax(truncated_activations).cpu().item()\n","\n","    if prepend_bos:\n","      truncated_argmax -= 1\n","      final_max_index -= 1\n","    truncated_max = torch.max(truncated_activations).cpu().item()\n","\n","    shortest_prompt = truncated_prompt\n","\n","    if truncated_argmax == initial_argmax and (\n","        (truncated_max - initial_max) / initial_max > proportion_threshold or \n","        (absolute_threshold is not None and truncated_max >= absolute_threshold)):        \n","      shortest_successful_prompt = truncated_prompt\n","      break\n","\n","  pruned_sentence = \"\".join(shortest_successful_prompt) if shortest_successful_prompt is not None else None\n","  \n","  if return_maxes:\n","    return pruned_sentence, final_max_index, initial_max, truncated_max\n","  return pruned_sentence, final_max_index\n","\n","\n","def augment(model, layer, index, prompt, aug, max_length=1024, inclusion_threshold=-0.5, exclusion_threshold=-0.5, n=5, **kwargs):\n","  \"\"\"Generate variations of a prompt using an augmenter\"\"\"\n","  prepend_bos = True\n","  tokens = model.to_tokens(prompt, prepend_bos=prepend_bos)\n","  str_tokens = model.to_str_tokens(prompt, prepend_bos=prepend_bos)\n","\n","  # print(prompt)\n","\n","  if len(tokens[0]) > max_length:\n","    tokens = tokens[0, :max_length].unsqueeze(0)\n","\n","  logits, cache = model.run_with_cache(tokens)\n","  activations = cache[layer][0, :, index]\n","\n","  initial_max = torch.max(activations).cpu().item()\n","  initial_argmax = torch.argmax(activations).cpu().item()\n","  max_char_position = len(\"\".join(str_tokens[int(prepend_bos):initial_argmax + 1]))\n","\n","  positive_prompts = [(prompt, initial_max, 1)]\n","  negative_prompts = []\n","\n","  if n == 0:\n","    return positive_prompts, negative_prompts\n","  \n","  aug_prompts, aug_positions = aug.augment(prompt, max_char_position=max_char_position, n=n, **kwargs)\n","  if not aug_prompts:\n","    return positive_prompts, negative_prompts\n","    \n","  aug_tokens = model.to_tokens(aug_prompts, prepend_bos=prepend_bos)\n","\n","  aug_logits, aug_cache = model.run_with_cache(aug_tokens)\n","  all_aug_activations = aug_cache[layer][:, :, index]\n","\n","  for aug_prompt, char_position, aug_activations in zip(aug_prompts, aug_positions, all_aug_activations):\n","    aug_max = torch.max(aug_activations).cpu().item()\n","    aug_argmax = torch.argmax(aug_activations).cpu().item()\n","\n","    # TODO implement this properly - when we mask multiple tokens, if they cross the max_char_position this will not necessarily be correct\n","    if char_position < max_char_position:\n","      new_str_tokens = model.to_str_tokens(aug_prompt, prepend_bos=prepend_bos)\n","      aug_argmax += len(new_str_tokens) - len(str_tokens)\n","\n","    proportion_drop = (aug_max - initial_max) / initial_max\n","\n","    if proportion_drop >= inclusion_threshold:\n","      positive_prompts.append((aug_prompt, aug_max, proportion_drop))\n","    elif proportion_drop < exclusion_threshold:\n","      negative_prompts.append((aug_prompt, aug_max, proportion_drop))\n","\n","  return positive_prompts, negative_prompts"],"metadata":{"id":"4lVq8zY1ZNNd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import math\n","\n","\n","def batch(arr, n=None, batch_size=None):\n","    if n is None and batch_size is None:\n","        raise ValueError(\"Either n or batch_size must be provided\")\n","    if n is not None and batch_size is not None:\n","        raise ValueError(\"Either n or batch_size must be provided, not both\")\n","\n","    if n is not None:\n","        batch_size = math.floor(len(arr) / n)\n","    elif batch_size is not None:\n","        n = math.ceil(len(arr) / batch_size)\n","\n","    extras = len(arr) - (batch_size * n)\n","    groups = []\n","    group = []\n","    added_extra = False\n","    for element in arr:\n","        group.append(element)\n","        if len(group) >= batch_size:\n","            if extras and not added_extra:\n","                extras -= 1\n","                added_extra = True\n","                continue\n","            groups.append(group)\n","            group = []\n","            added_extra = False\n","\n","    if group:\n","        groups.append(group)\n","\n","    return groups"],"metadata":{"id":"1E1RldVtZBs7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def fast_prune(model, layer, neuron, prompt, max_length=1024, proportion_threshold=-0.5, absolute_threshold=None, window=0, return_maxes=False, cutoff=30, batch_size=4, max_post_context_tokens=5, skip_threshold=0, skip_interval=5, return_intermediates=False, **kwargs):\n","  \"\"\"Prune an input prompt to the shortest string that preserves x% of neuron activation on the most activating token.\"\"\"\n","\n","  prepend_bos = True\n","  tokens = model.to_tokens(prompt, prepend_bos=prepend_bos)\n","  str_tokens = model.to_str_tokens(prompt, prepend_bos=prepend_bos)\n","\n","  if len(tokens[0]) > max_length:\n","    tokens = tokens[0, :max_length].unsqueeze(0)\n","\n","  logits, cache = model.run_with_cache(tokens)\n","  activations = cache[layer][0, :, neuron]\n","\n","  initial_max = torch.max(activations).cpu().item()\n","  initial_argmax = torch.argmax(activations).cpu().item()\n","\n","  sentences, sentence_to_token_indices, token_to_sentence_indices = sentence_tokenizer(str_tokens)\n","\n","  max_sentence_index = token_to_sentence_indices[initial_argmax]\n","  relevant_str_tokens = [str_token for sentence in sentences[:max_sentence_index + 1] for str_token in sentence]\n","\n","  prior_context = relevant_str_tokens[:initial_argmax + 1]\n","\n","  post_context = relevant_str_tokens[initial_argmax + 1:]\n","\n","  shortest_successful_prompt = None\n","  final_max_index = None\n","\n","  truncated_prompts = []\n","  added_tokens = []\n","\n","  count = 0\n","  for i, str_token in reversed(list(enumerate(prior_context[:max(0, initial_argmax - window + 1)]))):\n","    count += 1\n","\n","    if count > cutoff:\n","      break\n","\n","    if count >= skip_threshold and count % skip_interval != 0:\n","      continue\n","\n","    truncated_prompt = prior_context[i:]\n","    joined = \"\".join(truncated_prompt)\n","    truncated_prompts.append(joined)\n","    added_tokens.append(i)\n","\n","  batched_truncated_prompts = batch(truncated_prompts, batch_size=batch_size)\n","  batched_added_tokens = batch(added_tokens, batch_size=batch_size)\n","  \n","  finished = False\n","  intermediates = []\n","  for i, (truncated_batch, added_tokens_batch) in enumerate(zip(batched_truncated_prompts, batched_added_tokens)):\n","    # print(\"length\", len(truncated_batch))\n","    # pprint(truncated_batch)\n","\n","    truncated_tokens = model.to_tokens(truncated_batch, prepend_bos=prepend_bos)\n","\n","    # pprint(truncated_tokens)\n","\n","    logits, cache = model.run_with_cache(truncated_tokens)\n","    all_truncated_activations = cache[layer][:, :, neuron]\n","\n","    # print(\"shape\", all_truncated_activations.shape)\n","\n","    for j, truncated_activations in enumerate(all_truncated_activations):\n","      num_added_tokens = added_tokens_batch[j]\n","      # print(\"single shape\", truncated_activations.shape)\n","      truncated_argmax = torch.argmax(truncated_activations).cpu().item() + num_added_tokens\n","      final_max_index = torch.argmax(truncated_activations).cpu().item()\n","\n","      if prepend_bos:\n","        truncated_argmax -= 1\n","        final_max_index -= 1\n","      truncated_max = torch.max(truncated_activations).cpu().item()\n","    \n","      # trunc_logits, trunc_cache = model.run_with_cache(model.to_tokens(truncated_batch[j], prepend_bos=prepend_bos))\n","      # trunc_activations = trunc_cache[layer][0, :, neuron]\n","\n","      # print(truncated_activations)\n","      # print(trunc_activations)\n","      # print(\"truncated_argmax\", truncated_argmax)\n","      # print(truncated_max)\n","\n","      shortest_prompt = truncated_batch[j]\n","\n","      if not shortest_prompt.startswith(\"<|endoftext|>\"):\n","        truncated_str_tokens = model.to_str_tokens(truncated_batch[j], prepend_bos=False)\n","        intermediates.append((shortest_prompt, truncated_str_tokens[0], truncated_max))\n","\n","      if (truncated_argmax == initial_argmax and (\n","          (truncated_max - initial_max) / initial_max > proportion_threshold or \n","          (absolute_threshold is not None and truncated_max >= absolute_threshold))) or (i == len(batched_truncated_prompts) - 1 and j == len(all_truncated_activations) - 1):        \n","        shortest_successful_prompt = shortest_prompt\n","        finished = True\n","        break\n","    \n","    if finished:\n","      break\n","\n","  # if shortest_successful_prompt is None:\n","  #   pruned_sentence = \"\".join(relevant_str_tokens)\n","  #   final_max_index = initial_argmax\n","  # else:\n","  pruned_sentence = \"\".join(shortest_successful_prompt)\n","\n","  if max_post_context_tokens is not None:\n","    pruned_sentence += \"\".join(post_context[:max_post_context_tokens])\n","  \n","  if return_maxes:\n","    return pruned_sentence, final_max_index, initial_max, truncated_max\n","\n","  elif return_intermediates:\n","    return pruned_sentence, intermediates\n","\n","  return pruned_sentence, final_max_index"],"metadata":{"id":"k5sa3ATzWVVz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import seaborn as sns\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from collections import Counter\n","\n","def visualise(tokens_and_activations, tokens_and_importances, max_index=None, title=None, truncate=False, labels=[\"Activation\", \"Importance\"], **kwargs):\n","  \"\"\"Visualise relative token activation and importance\"\"\"\n","  if max_index is None:\n","    max_index = len(tokens_and_activations)\n","\n","  zero_width = u'\\u200b'\n","  token_counter = Counter()\n","  data = {}\n","  count = 0\n","\n","  for i, ((token, importance), (_, activation)) in enumerate(zip(tokens_and_importances, tokens_and_activations)):\n","    if token == \"<|endoftext|>\":\n","      continue\n","\n","    if i > max_index and truncate:\n","      break\n","\n","    # This is a horrible hack to allow us to have a dict with the \"same\" token as multiple keys - by adding zero width spaces the tokens look the same but are actually different\n","    seen_count = token_counter[token]\n","    add = zero_width * seen_count\n","    deduped_token = token + add\n","    # Have to escape dollars so matplotlib doesn't interpret them as latex\n","    deduped_token = deduped_token.replace(\"$\", \"\\$\")\n","    data[deduped_token] = [activation, importance]\n","    token_counter[token] += 1\n","    count += 1\n","\n","  df = pd.DataFrame(data, index=labels)\n","  plt.figure(figsize=[int(count * 1.5), 1.2])\n","  sns.heatmap(df, vmin=0, vmax=1, xticklabels=True, annot=True)\n","\n","  if title is not None:\n","    title = title.replace(\"$\", \"\\$\")\n","    plt.title(title)"],"metadata":{"id":"V3NcQiIKeNjC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def measure_importance(model, layer, neuron, prompt, max_length=1024, max_activation=None, masking_token=1, threshold=0.8, **kwargs):\n","  \"\"\"Compute a measure of token importance by masking each token and measuring the drop in activation on the max activating token\"\"\"\n","  \n","  prepend_bos = True\n","  tokens = model.to_tokens(prompt, prepend_bos=prepend_bos)\n","  str_tokens = model.to_str_tokens(prompt, prepend_bos=prepend_bos)\n","\n","  if len(tokens[0]) > max_length:\n","    tokens = tokens[0, :max_length].unsqueeze(0)\n","\n","  logits, cache = model.run_with_cache(tokens)\n","  activations = cache[layer][0, :, neuron]\n","\n","  initial_max = torch.max(activations).cpu().item()\n","  initial_argmax = torch.argmax(activations).cpu().item()\n","\n","  if max_activation is None:\n","    max_activation = initial_max\n","  scale = min(1, initial_max / max_activation)\n","\n","  tokens_and_activations = [(str_token, round(activation.cpu().item() / max_activation, 3)) for str_token, activation in zip(str_tokens, activations)]\n","  important_tokens = []\n","  tokens_and_importances = []\n","\n","  shortest_successful_prompt = None\n","  for i, str_token in enumerate(str_tokens):\n","    joined = \"\".join(str_tokens)\n","    \n","    masked_tokens = model.to_tokens(joined, prepend_bos=False)\n","\n","    masked_tokens[0, i] = masking_token\n","\n","    logits, cache = model.run_with_cache(masked_tokens)\n","    masked_activations = cache[layer][0, :, neuron]\n","    masked_max = masked_activations[initial_argmax].cpu().item()\n","    normalised_activation = (1 - (masked_max / initial_max))\n","    \n","    tokens_and_importances.append((str_token, masked_max, normalised_activation))\n","    if normalised_activation >= threshold and str_token != \"<|endoftext|>\":\n","      important_tokens.append(str_token)\n","\n","  return tokens_and_importances, initial_max, important_tokens, tokens_and_activations, initial_argmax"],"metadata":{"id":"QJP191Y9D42w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import copy\n","\n","def fast_measure_importance(model, layer, neuron, prompt, initial_argmax=None, max_length=1024, max_activation=None, masking_token=1, threshold=0.8, scale_factor=1, return_all=False, activation_threshold=0.1, **kwargs):\n","  \"\"\"Compute a measure of token importance by masking each token and measuring the drop in activation on the max activating token\"\"\"\n","  \n","  prepend_bos = True\n","  tokens = model.to_tokens(prompt, prepend_bos=prepend_bos)\n","  str_tokens = model.to_str_tokens(prompt, prepend_bos=prepend_bos)\n","\n","  if len(tokens[0]) > max_length:\n","    tokens = tokens[0, :max_length].unsqueeze(0)\n","\n","  # logits, cache = model.run_with_cache(tokens)\n","\n","  # print(tokens_and_activations)\n","\n","  importances_matrix = []\n","\n","  shortest_successful_prompt = None\n","  # cutoff = 50\n","\n","  masked_prompts = tokens.repeat(len(tokens[0]) + 1, 1)\n","\n","  # print(f\"{len(masked_prompts)=}, {initial_argmax=}, {starting_point=}\")\n","\n","  for i in range(1, len(masked_prompts)):\n","    masked_prompts[i, i - 1] = masking_token\n","\n","  # for i, str_token in enumerate(str_tokens):\n","  #   if i >= cutoff:\n","  #     break\n","\n","  #   masked_tokens = tokens\n","\n","  #   if i >= len(masked_tokens[0]):\n","  #     continue\n","\n","  #   token_to_mask = copy.deepcopy(tokens[0, i])\n","  #   masked_tokens[0, i] = masking_token\n","\n","  #   masked_prompts.append(masked_tokens[0])\n","  #   tokens[0, i] = token_to_mask\n","\n","  # pprint(masked_prompts)\n","  \n","  logits, cache = model.run_with_cache(masked_prompts)\n","  all_masked_activations = cache[layer][1:, :, neuron]\n","\n","  activations = cache[layer][0, :, neuron]\n","\n","  if initial_argmax is None:\n","    initial_argmax = torch.argmax(activations).cpu().item()\n","  else:\n","    # This could be wrong\n","    initial_argmax = min(initial_argmax, len(activations) - 1)\n","\n","  # print(activations)\n","  # print(activation_threshold)\n","  # activation_indexes = [i for i, activation in enumerate(activations) if activation * scale_factor / max_activation > activation_threshold]\n","  # print(activation_indexes)\n","  # final_activating = initial_argmax if len(activation_indexes) == 0 else activation_indexes[-1]\n","    \n","  initial_max = activations[initial_argmax].cpu().item()\n","\n","  if max_activation is None:\n","    max_activation = initial_max\n","  scale = min(1, initial_max / max_activation)\n","\n","  # print(\"scale_factor measure_importance\", scale_factor)\n","\n","  tokens_and_activations = [[str_token, round(activation.cpu().item() * scale_factor / max_activation, 3)] for str_token, activation in zip(str_tokens, activations)]\n","  important_tokens = []\n","  tokens_and_importances = [[str_token, 0] for str_token in str_tokens]\n","\n","  for i, masked_activations in enumerate(all_masked_activations):\n","    if return_all:\n","      # Get importance of the given token for all tokens\n","      importances_row = []\n","      for j, activation in enumerate(masked_activations):\n","        activation = activation.cpu().item()\n","        normalised_activation = (1 - (activation / activations[j].cpu().item()))\n","        importances_row.append((str_tokens[j], normalised_activation))\n","\n","      # for j, str_token in enumerate(str_tokens[cutoff:]):\n","      #   importances_row.append((str_token, 0))\n","\n","      # print(\"importances_row\", importances_row)\n","      importances_matrix.append(np.array(importances_row))\n","\n","    masked_max = masked_activations[initial_argmax].cpu().item()\n","    normalised_activation = (1 - (masked_max / initial_max))\n","\n","    str_token = tokens_and_importances[i][0]\n","    tokens_and_importances[i][1] = normalised_activation\n","    if normalised_activation >= threshold and str_token != \"<|endoftext|>\":\n","      important_tokens.append(str_token)\n","\n","  # for i, str_token in enumerate(str_tokens[cutoff:]):\n","  #   tokens_and_importances.append((str_token, 0))  \n","\n","  if return_all:\n","    # Flip so we have the importance of all tokens for a given token\n","    importances_matrix = np.array(importances_matrix)\n","    return importances_matrix, initial_max, important_tokens, tokens_and_activations, initial_argmax\n","\n","  return tokens_and_importances, initial_max, important_tokens, tokens_and_activations, initial_argmax"],"metadata":{"id":"QYmV9VphiXic"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","\n","def layer_index_to_name(layer_index):\n","  return f\"blocks.{layer_index}.{layer_ending}\"\n","\n","\n","def train_and_eval(model, layer, neuron, aug=fast_aug, train_proportion=0.7, max_train_size=10, max_eval_size=20, fire_threshold=0.5, random_state=0, train_indexes=None, return_paths=False, **kwargs):\n","  if isinstance(layer, int):\n","    layer = layer_index_to_name(layer)\n","\n","  layer_num = int(layer.split(\".\")[1])\n","  base_max_act = float(activation_matrix[layer_num, neuron])\n","\n","  snippets = get_snippets(model_name, layer_num, neuron)\n","  # data = get_data(layer_num, neuron)\n","\n","  if train_indexes is None:\n","    train_snippets, test_snippets = train_test_split(snippets, train_size=train_proportion, random_state=random_state)\n","  else:\n","    train_snippets = [snippet for i, snippet in enumerate(snippets) if i in train_indexes]\n","    test_snippets = [snippet for i, snippet in enumerate(snippets) if i not in train_indexes]\n","  # train_data, test_data = train_test_split(data, train_size=train_proportion, random_state=0)\n","\n","  # train_data_snippets = [\"\".join(tokens) for tokens, activations in train_data if any(activation > fire_threshold for activation in activations)][:max_train_size] \n","  train_data_snippets = []\n","  all_train_snippets = train_snippets + train_data_snippets\n","\n","  all_info = []\n","  pruned_prompts = []\n","  for i, snippet in enumerate(all_train_snippets):\n","    # if i % 10 == 0:\n","    print(f\"Processing {i + 1} of {len(all_train_snippets)}\")\n","\n","    pruned_prompt, _, initial_max_act, truncated_max_act = fast_prune(model, layer, neuron, snippet, return_maxes=True, **kwargs)\n","    pruned_prompts.append(pruned_prompt)\n","\n","    # tokens = model.to_tokens(pruned_prompt, prepend_bos=True)\n","    # str_tokens = model.to_str_tokens(pruned_prompt, prepend_bos=True)\n","    # logits, cache = model.run_with_cache(tokens)\n","    # activations = cache[layer][0, :, neuron].cpu()\n","    # max_pruned_activation = torch.max(activations).item()\n","    scale_factor = initial_max_act / truncated_max_act\n","    # scale_factor = 1\n","\n","    # print(scale_factor)\n","    # scaled_activations = activations * scale_factor / base_max_act\n","    \n","    # print(list(zip(str_tokens, activations)))\n","\n","    # print(pruned_prompt)\n","\n","    # print(len(pruned_prompt))\n","\n","    if pruned_prompt is None:\n","      continue  \n","\n","    info = augment_and_return(model, layer, neuron, aug, pruned_prompt, base_max_act=base_max_act, scale_factor=scale_factor, **kwargs)\n","    all_info.append(info)\n","\n","  neuron_model = NeuronModel(layer_num, neuron, **kwargs)\n","  paths = neuron_model.fit(all_info)\n","\n","  print(\"Fitted model\")\n","\n","  max_test_data = []\n","  for snippet in test_snippets:\n","    # pruned_prompt, _ = prune(model, layer, neuron, snippet, **kwargs)\n","    # if pruned_prompt is None:\n","    #   continue  \n","    tokens = model.to_tokens(snippet, prepend_bos=True)\n","    str_tokens = model.to_str_tokens(snippet, prepend_bos=True)\n","    logits, cache = model.run_with_cache(tokens)\n","    activations = cache[layer][0, :, neuron]\n","    max_test_data.append((str_tokens, activations.cpu() / base_max_act))\n","\n","  # pprint(max_test_data[0])\n","  # print(\"\\n\\n\")\n","  # pprint(test_data[0])\n","\n","  # print(\"Evaluation data\")\n","  # test_data = test_data[:max_eval_size]\n","  # evaluate(neuron_model, test_data, fire_threshold=fire_threshold, **kwargs)\n","\n","  print(\"Max Activating Evaluation Data\")\n","  try:\n","    stats = evaluate(neuron_model, max_test_data, fire_threshold=fire_threshold, **kwargs)\n","  except Exception as e:\n","    stats = {}\n","    print(f\"Stats failed with error: {e}\")\n","\n","  if return_paths:\n","    return stats, paths\n","  return stats\n","\n","\n","def run_with_func(model, layer, neuron, aug=contextual_aug, snippets=None, eval_snippets=None, eval_data=None, max_eval_data=None, example_indexes=None, eval_indexes=None, use_base_max_act=True, visualise=True, **kwargs):\n","  \"\"\"For a given neuron, grab the max activating dataset examples, run them through the pruning and augmentation steps, create a neuron graph, and evaluate it\"\"\"\n","  if snippets is None:\n","    snippets = []\n","\n","  if eval_snippets is None:\n","    eval_snippets = []\n","    \n","  if example_indexes is not None or eval_indexes is not None:\n","    all_snippets = get_snippets(\"model_name\", layer, neuron)\n","  \n","  if example_indexes is not None:\n","    snippets.extend([snippet for i, snippet in enumerate(all_snippets) if i in example_indexes])\n","    \n","  if eval_indexes is not None:\n","    eval_snippets.extend([snippet for i, snippet in enumerate(all_snippets) if i in eval_indexes])\n","\n","  if isinstance(layer, int):\n","    layer = f\"blocks.{layer}.{layer_ending}\"\n","\n","  layer_num = int(layer.split(\".\")[1])\n","\n","  base_max_act = float(activation_matrix[layer_num, neuron]) if use_base_max_act else None\n","\n","  all_info = []\n","  for snippet in snippets:\n","    pruned_prompt, _ = prune(model, layer, neuron, snippet, **kwargs)\n","\n","    if pruned_prompt is None:\n","      continue  \n","\n","    info = augment_and_return(model, layer, neuron, aug, pruned_prompt, base_max_act=base_max_act, **kwargs)\n","    all_info.append(info)\n","\n","  eval_info = []\n","\n","  for snippet in eval_snippets:\n","    pruned_prompt, _ = prune(model, layer, neuron, snippet, **kwargs)\n","\n","    if pruned_prompt is None:\n","      continue  \n","\n","    info = augment_and_return(model, layer, neuron, aug, pruned_prompt, base_max_act=base_max_act, **kwargs)\n","    eval_info.append(info)\n","\n","  neuron_model = NeuronModel(layer_num, neuron, **kwargs)\n","  neuron_model.fit(all_info)\n","\n","  if visualise:\n","    for info in all_info:\n","      for _, tokens_and_activations, _ in info:\n","        tokens = [token for token, _ in tokens_and_activations]\n","        pred_activations = neuron_model.forward([tokens])[0]\n","        tokens_with_pred_activations = list(zip(tokens, pred_activations))\n","        # print(tokens_and_activations)\n","        # print(tokens_with_pred_activations)\n","        visualise(tokens_and_activations, tokens_with_pred_activations, labels=[\"True\", \"Predicted\"], title=\"Train\")\n","\n","    for info in eval_info:\n","      for _, tokens_and_activations, _ in info:\n","        tokens = [token for token, _ in tokens_and_activations]\n","        pred_activations = neuron_model.forward([tokens])[0]\n","        tokens_with_pred_activations = list(zip(tokens, pred_activations))\n","        # print(tokens_and_activations)\n","        # print(tokens_with_pred_activations)\n","        visualise(tokens_and_activations, tokens_with_pred_activations, labels=[\"True\", \"Predicted\"], title=\"Eval\")\n","\n","  eval_data = get_data(layer_num, neuron)\n","\n","  # for i, (prompt_tokens, prompt_activations) in enumerate(eval_data):\n","  #   non_zero_indices = [j for j, activation in enumerate(prompt_activations) if activation > 0]\n","  #   print(list(zip(prompt_tokens, prompt_activations))[max(0, non_zero_indices[0] - 10):min(len(prompt_tokens) - 1, non_zero_indices[0] + 10)])\n","  #   if i >= 4:\n","  #     break\n","\n","  print(\"Evaluation data\")\n","  evaluate(neuron_model, eval_data, fire_threshold=0.2)\n","\n","  # neuron_model.visualise()\n","  # debug(neuron_model)\n","  return neuron_model\n","\n","\n","def augment_and_return(model, layer, neuron, aug, pruned_prompt, base_max_act=None, use_index=False, scale_factor=1, **kwargs):\n","  info = []\n","  importances_matrix, initial_max_act, important_tokens, tokens_and_activations, initial_max_index = fast_measure_importance(model, layer, neuron, pruned_prompt, max_activation=base_max_act, scale_factor=scale_factor, return_all=True)\n","  \n","  if base_max_act is not None:\n","    initial_max_act = base_max_act\n","\n","  positive_prompts, negative_prompts = augment(model, layer, neuron, pruned_prompt, aug, important_tokens=set(important_tokens), **kwargs)  \n","\n","  for i, (prompt, activation, change) in enumerate(positive_prompts):\n","    title = prompt\n","    if i == 0:\n","      title = \"Original - \" + prompt\n","\n","    #   print(\"Original\")\n","    #   print(prompt, \"\\n\")\n","    # elif i > 1:\n","    #   print(\"Augmented\")\n","    #   print(prompt, \"\\n\")\n","\n","    if use_index:\n","      importances_matrix, max_act, _, tokens_and_activations, max_index = fast_measure_importance(model, layer, neuron, prompt, max_activation=initial_max_act, initial_argmax=initial_max_index, scale_factor=scale_factor, return_all=True)\n","    else:\n","      importances_matrix, max_act, _, tokens_and_activations, max_index = fast_measure_importance(model, layer, neuron, prompt, max_activation=initial_max_act, scale_factor=scale_factor, return_all=True)\n","    info.append((importances_matrix, tokens_and_activations, max_index))\n","\n","  for prompt, activation, change in negative_prompts:\n","    if use_index:\n","      importances_matrix, max_act, _, tokens_and_activations, max_index = fast_measure_importance(model, layer, neuron, prompt, max_activation=initial_max_act, initial_argmax=initial_max_index, scale_factor=scale_factor, return_all=True)\n","    else:\n","      importances_matrix, max_act, _, tokens_and_activations, max_index = fast_measure_importance(model, layer, neuron, prompt, max_activation=initial_max_act, scale_factor=scale_factor, return_all=True)\n","    info.append((importances_matrix, tokens_and_activations, max_index))\n","\n","  return info\n","\n","\n","def augment_and_visualise(model, layer, neuron, aug, pruned_prompt, use_index=False, **kwargs):\n","  tokens_and_importances, max_act, important_tokens, tokens_and_activations, initial_max_index = measure_importance(model, layer, neuron, pruned_prompt)\n","    \n","  positive_prompts, negative_prompts = augment(model, layer, neuron, pruned_prompt, aug, important_tokens=set(important_tokens), **kwargs)  \n","  for i, (prompt, activation, change) in enumerate(positive_prompts):\n","    title = prompt\n","    if i == 0:\n","      title = \"Original - \" + prompt\n","    if use_index:\n","      tokens_and_importances, _, _, tokens_and_activations, max_index = measure_importance(model, layer, neuron, prompt, max_activation=max_act, initial_argmax=initial_max_index)\n","    else:\n","      tokens_and_importances, _, _, tokens_and_activations, max_index = measure_importance(model, layer, neuron, prompt, max_activation=max_act)\n","    # visualise(tokens_and_activations, tokens_and_importances, max_index, title=title, **kwargs)\n","\n","  for prompt, activation, change in negative_prompts:\n","    if use_index:\n","      tokens_and_importances, _, _, tokens_and_activations, max_index = measure_importance(model, layer, neuron, prompt, max_activation=max_act, initial_argmax=initial_max_index)\n","    else:\n","      tokens_and_importances, _, _, tokens_and_activations, max_index = measure_importance(model, layer, neuron, prompt, max_activation=max_act)\n","    # visualise(tokens_and_activations, tokens_and_importances, max_index, title=prompt, **kwargs)\n","\n","\n","def fast_augment_and_visualise(model, layer, neuron, aug, pruned_prompt, use_index=False, **kwargs):\n","  tokens_and_importances, max_act, important_tokens, tokens_and_activations, initial_max_index = fast_measure_importance(model, layer, neuron, pruned_prompt)\n","    \n","  positive_prompts, negative_prompts = augment(model, layer, neuron, pruned_prompt, aug, important_tokens=set(important_tokens), **kwargs)  \n","  for i, (prompt, activation, change) in enumerate(positive_prompts):\n","    title = prompt\n","    if i == 0:\n","      title = \"Original - \" + prompt\n","    if use_index:\n","      tokens_and_importances, _, _, tokens_and_activations, max_index = fast_measure_importance(model, layer, neuron, prompt, max_activation=max_act, initial_argmax=initial_max_index)\n","    else:\n","      tokens_and_importances, _, _, tokens_and_activations, max_index = fast_measure_importance(model, layer, neuron, prompt, max_activation=max_act)\n","    # visualise(tokens_and_activations, tokens_and_importances, max_index, title=title, **kwargs)\n","\n","  for prompt, activation, change in negative_prompts:\n","    if use_index:\n","      tokens_and_importances, _, _, tokens_and_activations, max_index = fast_measure_importance(model, layer, neuron, prompt, max_activation=max_act, initial_argmax=initial_max_index)\n","    else:\n","      tokens_and_importances, _, _, tokens_and_activations, max_index = fast_measure_importance(model, layer, neuron, prompt, max_activation=max_act)\n","    # visualise(tokens_and_activations, tokens_and_importances, max_index, title=prompt, **kwargs)\n","\n","\n","def run(model, layer, neuron, aug=contextual_aug, snippets=None, num_examples=5, example_indexes=None, **kwargs):\n","  \"\"\"For a given neuron, grab the max activating dataset examples, run them through the pruning and augmentation steps, and visualise the results\"\"\"\n","  if snippets is None:\n","    snippets = get_snippets(model_name, layer, neuron)\n","    if example_indexes is not None:\n","      snippets = [snippet for i, snippet in enumerate(snippets) if i in example_indexes]\n","    else:\n","      snippets = snippets[:num_examples]\n","\n","  if isinstance(layer, int):\n","    layer = f\"blocks.{layer}.{layer_ending}\"\n","\n","  for snippet in snippets:\n","    pruned_prompt, _ = prune(model, layer, neuron, snippet, **kwargs)\n","\n","    if pruned_prompt is None:\n","      continue  \n","\n","    augment_and_visualise(model, layer, neuron, aug, pruned_prompt, **kwargs)\n","\n","def fast_run(model, layer, neuron, aug=fast_aug, snippets=None, num_examples=5, example_indexes=None, **kwargs):\n","  \"\"\"For a given neuron, grab the max activating dataset examples, run them through the pruning and augmentation steps, and visualise the results\"\"\"\n","  if snippets is None:\n","    snippets = get_snippets(model_name, layer, neuron)\n","    if example_indexes is not None:\n","      snippets = [snippet for i, snippet in enumerate(snippets) if i in example_indexes]\n","    else:\n","      snippets = snippets[:num_examples]\n","\n","  if isinstance(layer, int):\n","    layer = f\"blocks.{layer}.{layer_ending}\"\n","\n","  for snippet in snippets:\n","    pruned_prompt, _ = fast_prune(model, layer, neuron, snippet, include_post_context=False, **kwargs)\n","\n","    if pruned_prompt is None:\n","      continue  \n","\n","    fast_augment_and_visualise(model, layer, neuron, aug, pruned_prompt, **kwargs)"],"metadata":{"id":"ubClmAkwUdqU","executionInfo":{"status":"ok","timestamp":1684098536380,"user_tz":-60,"elapsed":2,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}}},"execution_count":287,"outputs":[]},{"cell_type":"markdown","source":["## Evaluate"],"metadata":{"id":"_5mtIy1j5Ace"}},{"cell_type":"code","source":["with open(os.path.join(base_path, f\"data/activation_matrix-{model_name}.json\")) as ifh:\n","    activation_matrix = json.load(ifh)\n","    activation_matrix = np.array(activation_matrix)"],"metadata":{"id":"y9WgCFeX2-ks"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def layer_and_neuron_to_index(layer, neuron, width=3072, block_size=None):\n","  index = (layer * width) + neuron\n","  if block_size is None:\n","    return index\n","  return divmod(index, block_size)\n","\n","def index_to_layer_and_neuron(index, width=3072):\n","  return divmod(index, width)"],"metadata":{"id":"JLoRh_lP_Nuy","executionInfo":{"status":"ok","timestamp":1684096744622,"user_tz":-60,"elapsed":404,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}}},"execution_count":234,"outputs":[]},{"cell_type":"code","source":["import json\n","import gzip\n","from tqdm.autonotebook import tqdm\n","\n","\n","def get_data(layer, neuron):  \n","  block, index = layer_and_neuron_to_index(layer, neuron, block_size=1000)\n","\n","  # Hack because we're missing the first element of each block (except the 0th)\n","  index -= block\n","\n","  # print(block, index)\n","\n","  neuron = str(neuron)\n","  prompt_indices = set()\n","  prompt_index_to_activation_dict = {}\n","\n","  with gzip.open(os.path.join(base_path, f\"data/activation_data_by_neuron_block_{block}.jsonl.gz\")) as ifh:\n","    for i, line in tqdm(enumerate(ifh), total=index + 1, desc=\"Progress\"):\n","      if i > index:\n","        break\n","\n","      if i != index:\n","        continue\n","\n","      all_neuron_info = json.loads(line)\n","\n","      for neuron_activation_info in all_neuron_info:\n","        prompt_index = neuron_activation_info[\"prompt_index\"]\n","        prompt_indices.add(prompt_index)\n","        prompt_index_to_activation_dict[prompt_index] = neuron_activation_info[\"token_activations\"]\n","\n","      # print(len(all_neuron_info))\n","\n","  all_prompts_and_activations = []\n","  with open(os.path.join(base_path, \"data/prompts.jsonl\")) as ifh:\n","    for i, line in enumerate(ifh):\n","      if i in prompt_indices:\n","        prompt_tokens = json.loads(line)\n","        # print(len(prompt_tokens))\n","        prompt_activation_dict = prompt_index_to_activation_dict[i]\n","        prompt_activations = [prompt_activation_dict.get(str(j), 0) for j, _ in enumerate(prompt_tokens)]\n","        non_zero_indices = [j for j, activation in enumerate(prompt_activations) if activation > 0]\n","        # print([activation for activation in prompt_activations if activation > 0])\n","        # print(list(zip(prompt_tokens, prompt_activations))[max(0, non_zero_indices[0] - 10):min(len(prompt_tokens) - 1, non_zero_indices[0] + 10)])\n","        all_prompts_and_activations.append((prompt_tokens, prompt_activations))\n","\n","  return all_prompts_and_activations"],"metadata":{"id":"jR41JgY2WzeM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","\n","def evaluate(neuron_model, data, fire_threshold=0.2, **kwargs):\n","  y = []\n","  y_pred = []\n","  y_act = []\n","  y_pred_act = []\n","  for prompt_tokens, activations in data:\n","    # print(\"truth\")\n","    non_zero_indices = [i for i, activation in enumerate(activations) if activation > 0]\n","    start = max(0, non_zero_indices[0] - 10)\n","    end = min(len(prompt_tokens) - 1, non_zero_indices[-1] + 10)\n","    pred_activations = neuron_model.forward([prompt_tokens], return_activations=True)[0]\n","\n","    y_act.extend(activations)\n","    y_pred_act.extend(pred_activations)\n","\n","    important_context = list(zip(prompt_tokens, activations, pred_activations))[start:end]\n","\n","    # print(important_context)\n","    # print(len(pred_activations))\n","    pred_firings = [int(pred_activation >= fire_threshold) for pred_activation in pred_activations]\n","    firings = [int(activation >= fire_threshold) for activation in activations]\n","    y_pred.extend(pred_firings)\n","    y.extend(firings)\n","  # print(len(y), len(y_pred))\n","  print(classification_report(y, y_pred))\n","  report = classification_report(y, y_pred, output_dict=True)\n","  \n","  y_act = np.array(y_act)\n","  y_pred_act = np.array(y_pred_act)\n","\n","  # y_pred_act = y_pred_act[y_act > 0.5]\n","  # y_act = y_act[y_act > 0.5]\n","\n","  # print(y_act[:10])\n","  # print(y_pred_act[:10])\n","  \n","\n","  # y_pred_act = y_pred_act * np.mean(y_act) / np.mean(y_pred_act)\n","  # y_pred_act = \n","\n","  act_diff = y_pred_act - y_act\n","  mse = np.mean(np.power(act_diff, 2))\n","  variance = np.var(y_act)\n","  correlation = 1 - (mse / variance)\n","  print(f\"{correlation=:.3f}, {mse=:.3f}, {variance=:.4f}\")\n","\n","  report[\"correlation\"] = correlation\n","  return "],"metadata":{"id":"VavtQT1bI2qH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dev"],"metadata":{"id":"l0rwOS2mC8fj"}},{"cell_type":"markdown","source":["## Neuron Models"],"metadata":{"id":"QhhhmdWUnyCT"}},{"cell_type":"markdown","source":["Merge rules\n","- If there's an ignore node in a set of children we look to merge the other children into the ignore node.\n","- If we're trying to merge an ignore node and another node:\n","  - Fully merge if the other node is not an end node\n","  - Give the ignore node the other node's children (if it has any) if the other node is an end node\n"],"metadata":{"id":"k2-m6lR1aXdG"}},{"cell_type":"code","source":["!pip install --upgrade graphviz"],"metadata":{"id":"9V99weiOeJ_i","executionInfo":{"status":"ok","timestamp":1684069445664,"user_tz":-60,"elapsed":5244,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"761fc02b-f2da-4d09-c6b7-95b1e59c0569"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.1)\n"]}]},{"cell_type":"code","source":["from collections import defaultdict, namedtuple, Counter\n","from itertools import zip_longest\n","import json\n","# from pyvis.network import Network\n","from graphviz import Digraph, Graph, escape\n","from typing import List, Dict\n","import os\n","from IPython.display import Image, display\n","\n","\n","class NeuronStore:\n","  def __init__(self, path):\n","    if not os.path.exists(path):\n","      neuron_store = {\n","          \"activating\": {},\n","          \"important\": {}\n","      }\n","      with open(path, \"w\") as ofh:\n","        json.dump(neuron_store, ofh, indent=2, ensure_ascii=False)\n","\n","    with open(path) as ifh:\n","      self.store = json.load(ifh)\n","\n","    self.to_sets()    \n","    self.path = path\n","    self.count_tokens()\n","    self.by_neuron()\n","\n","  def save(self):\n","    self.to_lists()\n","    with open(self.path, \"w\") as ofh:\n","      json.dump(self.store, ofh, indent=2, ensure_ascii=False)\n","    self.to_sets()\n","\n","  def to_sets(self):\n","    self.store = {token_type: {token: set(info) for token, info in token_dict.items()} for token_type, token_dict in self.store.items()}\n","\n","  def to_lists(self):\n","    self.store = {token_type: {token: list(set(info)) for token, info in token_dict.items()} for token_type, token_dict in self.store.items()}\n","\n","  def by_neuron(self):\n","    self.neuron_to_tokens = {}\n","    for token_type, token_dict in self.store.items():\n","      for token, neurons in token_dict.items():\n","        for neuron in neurons:\n","          if neuron not in self.neuron_to_tokens:\n","            self.neuron_to_tokens[neuron] = {\"activating\": set(), \"important\": set()}\n","          self.neuron_to_tokens[neuron][token_type].add(token)\n","\n","  def search(self, tokens_and_types):\n","    match_arr = []\n","\n","    for token, token_type in tokens_and_types:\n","      token_types = [token_type] if token_type is not None else [\"activating\", \"important\"]\n","      token_matches = set()\n","\n","      for token_type in token_types:\n","        matches = self.store[token_type].get(token, set())\n","        token_matches |= matches\n","\n","      match_arr.append(token_matches)\n","\n","    valid_matches = set.intersection(*match_arr)\n","    return valid_matches\n","\n","  def count_tokens(self):\n","    self.neuron_individual_token_counts = defaultdict(Counter)\n","    self.neuron_total_token_counts = Counter()\n","    for token_type, token_dict in self.store.items():\n","      for token, neurons in token_dict.items():\n","        for neuron in neurons:\n","          self.neuron_individual_token_counts[neuron][token] += 1\n","          self.neuron_total_token_counts[neuron] += 1\n","\n","  def find_similar(self, target_token_types=None, threshold=0.9):\n","    if target_token_types is None:\n","      target_token_types = {\"activating\", \"important\"}\n","\n","    similar_pairs = []\n","    subset_pairs = []\n","\n","    for i, (neuron_1, neuron_dict_1) in enumerate(self.neuron_to_tokens.items()):\n","      if i % 1000 == 0:\n","        print(f\"{i} of {len(self.neuron_to_tokens.items())} complete\")\n","\n","      for j, (neuron_2, neuron_dict_2) in enumerate(self.neuron_to_tokens.items()):\n","        if i <= j:\n","          continue\n","\n","        all_similar = []\n","        all_subset = []\n","\n","        for token_type in target_token_types:\n","          length_1 = len(neuron_dict_1[token_type])\n","          length_2 = len(neuron_dict_2[token_type])\n","\n","          intersection = neuron_dict_1[token_type] & neuron_dict_2[token_type]\n","          similar = (len(intersection) / max(length_1, length_2, 1)) >= threshold\n","          subset = len(intersection) / max(min(length_1, length_2), 1) >= threshold\n","\n","          all_similar.append(similar)\n","          all_subset.append(subset)\n","\n","        if all(all_similar):\n","          similar_pairs.append((neuron_1, neuron_2))\n","        elif all(all_subset):\n","          # The first token indicates the superset neuron and the second the subset neuron\n","          subset_pair = (neuron_1, neuron_2) if length_2 < length_1 else (neuron_2, neuron_1)\n","          subset_pairs.append(subset_pair)\n","\n","    return similar_pairs, subset_pairs\n","          \n","\n","test_neuron_store = NeuronStore(f\"{base_path}/data/neuron_store_{model_name}_test.json\")\n","\n","\n","def view_neuron(path):\n","  display(Image(filename=path))\n","\n","\n","class NeuronNode:\n","  def __init__(self, id_=None, value=None, children=None, depth=None, important=False, activator=False):\n","    if value is None:\n","      value = {}\n","    if children is None:\n","      children = {}\n","    self.id_ = id_\n","    self.value = value\n","    self.children = children\n","    self.depth = depth\n","\n","  def __repr__(self):\n","    return f\"ID: {self.id_}, Value: {json.dumps(self.value)}\"\n","\n","  def paths(self):\n","    if not self.children:\n","      return [[self.value]]  # one path: only contains self.value\n","    paths = []\n","    for child_token, child_tuple in self.children.items():\n","      child_node, _ = child_tuple\n","      for path in child_node.paths():\n","          paths.append([self.value] + path)\n","    return paths\n","\n","\n","class NeuronEdge:\n","  def __init__(self, weight=0, parent=None, child=None):\n","    self.weight = weight\n","    self.parent = parent\n","    self.child = child\n","\n","  def __repr__(self):\n","    parent_str = json.dumps(self.parent.id_) if self.parent is not None else \"None\"\n","    child_str = json.dumps(self.child.id_) if self.child is not None else \"None\"\n","    return f\"Weight: {self.weight:.3f}\\nParent: {parent_str}\\nChild: {child_str}\"\n","\n","\n","class NeuronModel:\n","  def __init__(self, layer, neuron, activation_threshold=0.1, importance_threshold=0.5, folder_name=None, neuron_store=None, **kwargs):\n","    self.layer = layer\n","    self.neuron = neuron\n","    self.Element = namedtuple(\"Element\", \"importance, activation, token, important, activator, ignore, is_end, token_value\")\n","    self.neuron_store = neuron_store\n","\n","    self.root_token = \"**ROOT**\"\n","    self.ignore_token = \"**IGNORE**\"\n","    self.end_token = \"**END**\"\n","    self.special_tokens = {self.root_token, self.ignore_token, self.end_token}\n","\n","    self.root = (NeuronNode(-1, self.Element(0, 0, self.root_token, False, False, True, False, self.root_token), depth=-1), NeuronEdge())\n","    self.trie_root = (NeuronNode(-1, self.Element(0, 0, self.root_token, False, False, True, False, self.root_token), depth=-1), NeuronEdge())\n","    self.activation_threshold = activation_threshold\n","    self.importance_threshold = importance_threshold\n","    # self.net = Network(notebook=True)\n","    # self.net = Graph(graph_attr={\"rankdir\": \"LR\", \"splines\": \"spline\", \"ranksep\": \"20\", \"nodesep\": \"1\"}, node_attr={\"fixedsize\": \"true\", \"width\": \"1.5\"})\n","    # self.net = Graph(\n","    #     graph_attr={\"rankdir\": \"RL\", \"splines\": \"spline\", \"ranksep\": \"5\", \"nodesep\": \"1\"},\n","    #     node_attr={\"fixedsize\": \"true\", \"width\": \"2\"}\n","    # )\n","    # self.net = Graph(\n","    #     graph_attr={\"rankdir\": \"RL\", \"splines\": \"spline\", \"ranksep\": \"2\", \"nodesep\": \"0.25\"},\n","    #     node_attr={\"fixedsize\": \"true\", \"width\": \"2\", \"height\": \"0.75\"}\n","    # )\n","    self.net = Digraph(\n","        graph_attr={\"rankdir\": \"RL\", \"splines\": \"spline\", \"ranksep\": \"3\", \"nodesep\": \"0.2\"},\n","        node_attr={\"fixedsize\": \"true\", \"width\": \"2\", \"height\": \"0.75\"}\n","    )\n","    self.node_count = 0\n","    self.trie_node_count = 0\n","    self.max_depth = 0\n","    self.folder_name = folder_name\n","\n","  def __call__(self, tokens_arr: List[List[str]]) -> List[List[float]]:\n","    return self.forward(tokens_arr)    \n","\n","  def fit(self, data):\n","    for example_data in data:\n","      for j, info in enumerate(example_data):\n","        if j == 0:\n","          lines, important_index_sets = self.make_line(info)\n","        else:\n","          lines, _ = self.make_line(info, important_index_sets)\n","        \n","        for line in lines:\n","          # print(\"\\nline\", line)\n","          self.add(self.root, line, graph=True)     \n","          self.add(self.trie_root, line, graph=False) \n","\n","    # print(\"Paths before merge\")\n","    # for path in self.trie_root[0].paths():\n","    #   print(path)\n","\n","    self.build(self.root)\n","    self.merge_ignores()\n","\n","    self.save_neurons()\n","\n","    print(\"Paths after merge\")\n","    paths = []\n","    for path in self.trie_root[0].paths():\n","      # print(path)\n","      paths.append(path)\n","\n","    return paths\n","\n","  def save_neurons(self):\n","    visited = set() # List to keep track of visited nodes.\n","    queue = []      # Initialize a queue\n","\n","    visited.add(self.trie_root[0].id_)\n","    queue.append(self.trie_root)\n","\n","    while queue:\n","      node, edge = queue.pop(0) \n","\n","      token = node.value.token\n","\n","      if token not in self.special_tokens:\n","        add_dict = self.neuron_store.store[\"activating\"] if node.value.activator else self.neuron_store.store[\"important\"]\n","        if token not in add_dict:\n","          add_dict[token] = set()\n","        add_dict[token].add(f\"{self.layer}_{self.neuron}\")         \n","\n","      for token, neighbour in node.children.items():\n","        new_node, new_edge = neighbour\n","        if new_node.id_ not in visited:\n","          visited.add(new_node.id_)\n","          queue.append(neighbour)    \n","\n","  @staticmethod\n","  def normalise(token):\n","      normalised_token = token.lower() if token.istitle() and len(token) > 1 else token\n","      normalised_token = normalised_token.strip() if len(normalised_token) > 1 and any(c.isalpha() for c in normalised_token) else normalised_token\n","      return normalised_token\n","\n","  def make_line(self, info, important_index_sets=None):\n","    if important_index_sets is None:\n","      important_index_sets = []\n","      create_indices = True\n","    else:\n","      create_indices = False\n","\n","    importances_matrix, tokens_and_activations, max_index = info\n","\n","    # print(tokens_and_activations)\n","\n","    all_lines = []\n","    \n","    for i, (token, activation) in enumerate(tokens_and_activations):\n","      if create_indices:\n","        important_index_sets.append(set())\n","\n","      # if activation > 0.2:\n","      #   print([token], activation)\n","\n","      if not activation > self.activation_threshold:\n","        continue\n","\n","      # print(\"\\ntoken\", token)\n","\n","      before = tokens_and_activations[:i + 1]\n","      \n","      line = []\n","      last_important = 0\n","\n","      if not create_indices:\n","        # The if else is a bit of a hack to account for augmentations that have a different number of tokens to the original prompt\n","        important_indices = important_index_sets[i] if i < len(important_index_sets) else important_index_sets[-1]\n","      else:\n","        important_indices = set()\n","\n","      # print(\"before\", before)\n","\n","      for j, (seq_token, seq_activation) in enumerate(reversed(before)):\n","        if seq_token == \"<|endoftext|>\":\n","          continue\n","\n","        seq_index = len(before) - j - 1\n","        # Stop when we reach the last matrix entry, which corresponds to the last activating token\n","        # if seq_index >= len(importances_matrix):\n","        #   break\n","        important_token, importance = importances_matrix[seq_index, i]\n","        importance = float(importance)\n","        # print(\"importance\", importance)\n","\n","        important = importance > self.importance_threshold or (not create_indices and seq_index in important_indices)  \n","        activator = seq_activation > self.activation_threshold     \n","\n","        # print(\"important_index_sets[i]\", important_index_sets[i])\n","        # print(\"create_indices\", create_indices)\n","        # print(\"important\", important)\n","        # print(\"seq_token\", seq_token) \n","        # print(\"seq_index\", seq_index)\n","        # print(\"important_token\", important_token)\n","\n","        if important and create_indices:\n","          important_indices.add(seq_index)\n","          # print(\"important_indices\", important_indices)\n","\n","        ignore = not important and j != 0\n","        is_end = False\n","\n","        seq_token_identifier = self.ignore_token if ignore else seq_token\n","\n","        new_element = self.Element(importance, seq_activation, seq_token_identifier, important, activator, ignore, is_end, seq_token)\n","\n","        # print(\"new_element\", new_element)\n","\n","        if not ignore:\n","          last_important = j\n","\n","        line.append(new_element)\n","      \n","      line = line[:last_important + 1]\n","      # Add an end node\n","      line.append(self.Element(0, activation, self.end_token, False, False, True, True, self.end_token))\n","      # print(line)\n","      all_lines.append(line)\n","\n","      if create_indices:\n","        important_index_sets[i] = important_indices\n","    \n","    # print(\"From\", tokens_and_activations)\n","    # for line in all_lines:\n","    #   print(\"\\nMade\", line)\n","    \n","    return all_lines, important_index_sets\n","\n","  def add(self, start_tuple, line, graph=True):\n","    current_tuple = start_tuple\n","    previous_element = None\n","    important_count = 0\n","\n","    # print(\"starting at\", current_tuple)\n","    # print(\"adding\", line)\n","\n","    start_depth = current_tuple[0].depth\n","\n","    for i, element in enumerate(line):  \n","      # print(\"\\nelement\", element)    \n","      if element is None and i > 0:\n","        break\n","\n","      # importance, activation, token, important, activator, ignore, is_end = element\n","\n","      if element.ignore and graph:\n","        continue\n","\n","      # Normalise token\n","      element = element._replace(token=self.normalise(element.token))      \n","\n","      if graph:\n","        # Set end value as we don't have end nodes in the graph\n","        # The current node is an end if there's only one more node, as that will be the end node that we don't add\n","        is_end = i == len(line) - 2\n","        element = element._replace(is_end=is_end)\n","\n","      important_count += 1\n","\n","      current_node, current_edge = current_tuple\n","\n","      if not current_node.value.ignore:\n","        prev_important_node = current_node\n","\n","      # print(\"current_node\", current_node)\n","      # print(\"children\", current_node.children)\n","\n","      if element.token in current_node.children:\n","        current_tuple = current_node.children[element.token]\n","        # print(\"Already in children\")\n","        continue\n","\n","      # if i == 0:\n","      #   weight = 0\n","      # # elif i == 1:\n","      #   # weight = previous_element.value[\"activation\"] * element.value[\"importance\"]\n","      # else:\n","      #   weight = prev_important_node.value.importance * element.importance     \n","      weight = 0 \n","\n","      depth = start_depth + important_count\n","      new_node = NeuronNode(self.node_count, element, {}, depth=depth)\n","      new_tuple = (new_node, NeuronEdge(weight, current_node, new_node))\n","\n","      self.max_depth = depth if depth > self.max_depth else self.max_depth\n","      # print(current_node)\n","      # print(new_node)\n","\n","      current_node.children[element.token] = new_tuple\n","\n","      # print(\"Added new node\")\n","      # print(\"children\", current_node.children)\n","\n","      current_tuple = new_tuple\n","      \n","      self.node_count += 1\n","\n","    return current_tuple\n","\n","  # def merge(self, parent_tuple, merge_tuple):\n","  #   visited = set() # List to keep track of visited nodes.\n","  #   queue = []      # Initialize a queue\n","\n","  #   visited.add(merge_tuple[0].id_)\n","  #   queue.append(merge_tuple)\n","\n","  #   while queue:\n","  #     node, edge = queue.pop(0) \n","\n","  #     parent_node, _ = parent_tuple\n","\n","  #     parent_tuple = self.add(parent_node, [node.value])\n","\n","  #     for token, neighbour in node.children.items():\n","  #       new_node, new_edge = neighbour\n","  #       if new_node.id_ not in visited:\n","  #         visited.add(new_node.id_)\n","  #         queue.append(neighbour)\n","\n","  def merge_ignores(self):\n","    \"\"\"\n","    Where a set of children contain an ignore token, merge the other nodes into it:\n","      - Fully merge if the other node is not an end node\n","      - Give the ignore node the other node's children (if it has any) if the other node is an end node\n","    \"\"\"\n","    # print(\"\\n\\n******MERGING*******\")\n","    visited = set() # List to keep track of visited nodes.\n","    queue = []      # Initialize a queue\n","\n","    visited.add(self.trie_root[0].id_)\n","    queue.append(self.trie_root)\n","\n","    while queue:\n","      node, edge = queue.pop(0) \n","\n","      token = node.value.token\n","\n","      # print(node)\n","\n","      if self.ignore_token in node.children:\n","        ignore_tuple = node.children[self.ignore_token]\n","\n","        # print(\"ignore_tuple\", ignore_tuple)\n","\n","        to_remove = []\n","\n","        for child_token, child_tuple in node.children.items():\n","          if child_token == self.ignore_token:\n","            continue\n","\n","          child_node, child_edge = child_tuple\n","\n","          child_paths = child_node.paths()\n","\n","          for path in child_paths:\n","            # print(\"path\", path)\n","            # Don't merge if the path is only the first tuple, or the first tuple and an end tuple\n","            if len(path) <= 1 or (len(path) == 2 and path[-1].token == self.end_token):\n","              continue\n","            # Merge the path (not including the first tuple that we're merging)\n","            self.add(ignore_tuple, path[1:], graph=False)\n","\n","          # Add the node to a list to be removed later if it isn't an end node and doesn't have an end node in its children\n","          if not child_node.value.is_end and not self.end_token in child_node.children:\n","          # if not self.end_token in child_node.children:\n","            to_remove.append(child_token)\n","\n","        for child_token in to_remove:\n","          node.children.pop(child_token)\n","\n","      for token, neighbour in node.children.items():\n","        new_node, new_edge = neighbour\n","        if new_node.id_ not in visited:\n","          visited.add(new_node.id_)\n","          queue.append(neighbour)\n","\n","  def search(self, tokens: List[str]) -> float:\n","    \"\"\"Evaluate the activation on the first token in tokens\"\"\"\n","    current_tuple = self.trie_root\n","\n","    # print(\"\\n\")\n","    activations = [0] \n","    \n","    for i, token in enumerate(reversed(tokens)):   \n","      token = self.normalise(token)\n","\n","      current_node, current_edge = current_tuple\n","\n","      # print(\"i, token\", i, [token])   \n","      # print(\"current_node.children\", current_node.children)\n","\n","      if token in current_node.children or self.ignore_token in current_node.children:\n","        current_tuple = current_node.children[token] if token in current_node.children else current_node.children[self.ignore_token]\n","      \n","        node, edge = current_tuple\n","        # If the first token is not an activator, return early\n","        if i == 0:\n","          if not node.value.activator:\n","            break\n","          activation = node.value.activation\n","\n","        # print(\"node\", node)\n","\n","        if self.end_token in node.children:\n","          # debug(\"Returning\", activation)\n","          end_node, _ = node.children[self.end_token]\n","          end_activation = end_node.value.activation\n","          activations.append(end_activation)\n","          \n","      else:\n","        break\n","\n","    # Return the activation on the longest sequence\n","    return activations[-1]\n","\n","  def forward(self, tokens_arr: List[List[str]], return_activations=True) -> List[List[float]]:\n","    if isinstance(tokens_arr[0], str):\n","      raise ValueError(f\"tokens_arr must be of type List[List[str]]\")\n","\n","    # print(\"\\n\\n******PROCESSING*******\")\n","    # print(tokens_arr)\n","    \"\"\"Evaluate the activation on each token in some input tokens\"\"\"\n","    all_activations = []\n","    all_firings = []\n","\n","    for tokens in tokens_arr:\n","      activations = []\n","      firings = []\n","\n","      for j in range(len(tokens)):\n","        token_activation = self.search(tokens[:len(tokens) - j])\n","        activations.append(token_activation)\n","        firings.append(token_activation > self.activation_threshold)\n","\n","      activations = list(reversed(activations))\n","      firings = list(reversed(firings))\n","\n","      all_activations.append(activations)\n","      all_firings.append(firings)\n","\n","      # print(list(zip(tokens, activations)))\n","\n","    if return_activations:\n","      return all_activations\n","    return all_firings\n","\n","  def build(self, start_node, graph=True):\n","    \"\"\"Build a graph to visualise\"\"\"\n","    # print(\"\\n\\n******BUILDING*******\")\n","    visited = set() # List to keep track of visited nodes.\n","    queue = []     #Initialize a queue\n","\n","    visited.add(start_node[0].id_)\n","    queue.append(start_node)\n","\n","    zero_width = u'\\u200b'\n","    # zero_width = \"a\"\n","\n","    tokens_by_layer = {}\n","    node_id_to_graph_id = {}\n","    token_by_layer_count = defaultdict(Counter)\n","    added_ids = set()\n","    node_count = 0\n","    depth_to_subgraph = {}\n","    added_edges = set()\n","\n","    node_edge_tuples = []\n","\n","    adjust = lambda x, y: (x - y) / (1 - y)\n","\n","    while queue:\n","      # print(queue)\n","      node, edge = queue.pop(0) \n","\n","      node_edge_tuples.append((node, edge))\n","\n","      for token, neighbour in node.children.items():\n","        # print(\"token\", token)\n","        new_node, new_edge = neighbour\n","        if new_node.id_ not in visited:\n","          visited.add(new_node.id_)\n","          queue.append(neighbour)\n","\n","    for node, edge in node_edge_tuples:\n","      token = node.value.token\n","      depth = node.depth\n","\n","      # if token == \"\":\n","      #   continue\n","\n","      if depth not in tokens_by_layer:\n","        tokens_by_layer[depth] = {}\n","        # depth_to_subgraph[depth] = Graph(name=f\"cluster_{str(self.max_depth - depth)}\")  \n","        depth_to_subgraph[depth] = Digraph(name=f\"cluster_{str(self.max_depth - depth)}\")  \n","        # depth_to_subgraph[depth].attr(label=f\"Depth {str(depth)}\") \n","        depth_to_subgraph[depth].attr(pencolor=\"white\", penwidth=\"3\") \n","\n","      token_by_layer_count[depth][token] += 1\n","\n","      if not graph:\n","        # This is a horrible hack to allow us to have a dict with the \"same\" token as multiple keys - by adding zero width spaces the tokens look the same but are actually different. This allows us to display a trie rather than a node-collapsed graph\n","        seen_count = token_by_layer_count[depth][token] - 1\n","        add = zero_width * seen_count\n","        token += add\n","\n","      if token not in tokens_by_layer[depth]:\n","        tokens_by_layer[depth][token] = str(node_count)\n","        node_count += 1\n","\n","      graph_node_id = tokens_by_layer[depth][token]\n","      node_id_to_graph_id[node.id_] = graph_node_id\n","\n","    # for node, edge in reversed(node_edge_tuples):\n","    #   token = node.value.token\n","    #   depth = node.depth      \n","\n","      # graph_node_id = tokens_by_layer[depth][token]\n","      # node_id_to_graph_id[node.id_] = graph_node_id\n","      current_graph = depth_to_subgraph[depth]      \n","\n","      if depth == 0:\n","        # colour red according to activation for depth 0 tokens\n","        scaled_activation = int(adjust(node.value.activation, max(0, self.activation_threshold - 0.2)) * 255)\n","        rgb = (255, 255 - scaled_activation, 255 - scaled_activation)\n","      else:\n","        # colour blue according to importance for all other tokens\n","        # Shift and scale importance so the importance threshold becomes 0\n","        \n","        scaled_importance = int(adjust(node.value.importance, max(0.1, self.importance_threshold - 0.2)) * 255)\n","        rgb = (255 - scaled_importance, 255 - scaled_importance, 255)\n","\n","      hex = \"#{0:02x}{1:02x}{2:02x}\".format(*self.clamp(rgb))\n","\n","      # self.net.add_node(node.id_, label=node.value[\"token\"], color=hex)\n","\n","      if graph_node_id not in added_ids and not node.value.ignore:\n","        display_token = token.strip(zero_width)\n","        display_token = json.dumps(display_token).strip('[]\"')\n","        if set(display_token) == {\" \"}:\n","          display_token = f\"'{display_token}'\"\n","\n","        # self.net.node(graph_node_id, node.value[\"token\"])\n","        # print(\"token\", token, escape(token))\n","        fontcolor = \"white\" if depth != 0 and rgb[1] < 150 else \"black\"\n","        fontsize = \"25\" if len(display_token) < 12 else \"18\"\n","        edge_width = \"7\" if node.value.is_end else \"3\"\n","        # current_graph.node(\n","        #     graph_node_id, f\"< <B> {escape(token)} </B> >\", fillcolor=hex, shape=\"box\", \n","        #     style=\"filled,solid\", fontcolor=fontcolor, fontsize=fontsize,\n","        #     penwidth=edge_width\n","        # )\n","\n","        current_graph.node(\n","            graph_node_id, f\"{escape(display_token)}\", fillcolor=hex, shape=\"box\", \n","            style=\"filled,solid\", fontcolor=fontcolor, fontsize=fontsize,\n","            penwidth=edge_width\n","        )\n","        added_ids.add(graph_node_id)      \n","      \n","      if edge.parent is not None and edge.parent.id_ in visited and not edge.parent.value.ignore:\n","        # self.net.add_edge(node.id_, edge.parent.id_, value=edge.weight, title=round(edge.weight, 2))\n","        # pprint(node_id_to_graph_id)\n","        # print([token])\n","        # print([edge.parent.value.token])\n","        # print([edge.parent.value.importance])\n","        graph_parent_id = node_id_to_graph_id[edge.parent.id_]\n","        # current_graph.edge(graph_parent_id, graph_node_id, constraint='false')\n","        edge_tuple = (graph_parent_id, graph_node_id)\n","        if edge_tuple not in added_edges:\n","          self.net.edge(*edge_tuple, penwidth=\"3\", dir=\"back\")\n","          added_edges.add(edge_tuple)\n","\n","      # print(\"node\", node) \n","      # print(\"edge\", edge)\n","      # print(\"node.children\", node.children)\n","\n","      # for token, neighbour in node.children.items():\n","      #   # print(\"token\", token)\n","      #   new_node, new_edge = neighbour\n","      #   if new_node.id_ not in visited:\n","      #     visited.add(new_node.id_)\n","      #     queue.append(neighbour)\n","\n","    for depth, subgraph in depth_to_subgraph.items():\n","      self.net.subgraph(subgraph)\n","\n","    path_parts = ['neuron_graphs', model_name]\n","\n","    if self.folder_name is not None:\n","      path_parts.append(self.folder_name)\n","\n","    path_parts.append(f\"{self.layer}_{self.neuron}\")\n","\n","    save_path = base_path\n","    for path_part in path_parts:\n","      save_path += f\"/{path_part}\"\n","      if not os.path.exists(save_path):\n","        os.mkdir(save_path)\n","\n","    self.net.format = 'svg'\n","    filename = \"graph\" if graph else \"trie\"\n","    self.net.render(f\"{save_path}/{filename}\", view=False)\n","    self.net.format = 'png'\n","    self.net.render(f\"{save_path}/{filename}\", view=False)\n","    # print(self.net.source)\n","\n","  @staticmethod\n","  def clamp(arr): \n","    return [max(0, min(x, 255)) for x in arr]"],"metadata":{"id":"uSgLzlPWNNIO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","\n","class TokenPredictor:\n","  def __init__(self, model, layer, neuron, activation_threshold=0.5):\n","    self.model = model\n","    self.layer = layer\n","    self.neuron = neuron\n","    self.activation_threshold = activation_threshold\n","\n","    self.layer_name = layer_index_to_name(layer)\n","    self.max_activation = activation_matrix[layer, neuron]\n","\n","  def fit(self, texts):\n","    prepend_bos = False\n","    all_tokens = model.to_tokens(texts, prepend_bos=prepend_bos)\n","    logits, cache = model.run_with_cache(all_tokens)\n","    neuron_activations = cache[self.layer_name][:, :, self.neuron]\n","\n","    all_str_tokens = model.to_str_tokens(texts, prepend_bos=prepend_bos)\n","    neuron_activations = neuron_activations.to(\"cpu\")\n","\n","    self.token_to_activations = defaultdict(list)\n","    for tokens, activations in zip(all_str_tokens, neuron_activations):\n","      for token, activation in zip(tokens, activations):\n","        activation = activation.item()\n","        self.token_to_activations[token].append(activation / self.max_activation)\n","\n","    self.token_to_activation = {token: np.max(activations) for token, activations in self.token_to_activations.items()}\n","\n","  def forward(self, tokens_arr: List[List[str]], return_activations=True) -> List[List[float]]:\n","    all_activations = []\n","    all_firings = []\n","\n","    for tokens in tokens_arr:\n","      activations = []\n","      firings = []\n","\n","      for token in tokens:\n","        activation = self.token_to_activation.get(token, 0)\n","\n","        activations.append(activation)\n","        firings.append(activation > self.activation_threshold)\n","\n","      all_activations.append(activations)\n","      all_firings.append(firings)\n","\n","    if return_activations:\n","      return all_activations\n","    return all_firings"],"metadata":{"id":"IpJSpwqh97lS","executionInfo":{"status":"ok","timestamp":1684098748017,"user_tz":-60,"elapsed":368,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}}},"execution_count":301,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","\n","class PreciseBaseline:\n","  def __init__(self, model, layer, neuron, activation_threshold=0.5):\n","    self.model = model\n","    self.layer = layer\n","    self.neuron = neuron\n","    self.activation_threshold = activation_threshold\n","\n","    self.layer_name = layer_index_to_name(layer)\n","    self.max_activation = activation_matrix[layer, neuron]\n","\n","  def fit(self, texts):\n","    prepend_bos = False\n","    all_tokens = model.to_tokens(texts, prepend_bos=prepend_bos)\n","    logits, cache = model.run_with_cache(all_tokens)\n","    neuron_activations = cache[self.layer_name][:, :, self.neuron]\n","\n","    all_str_tokens = model.to_str_tokens(texts, prepend_bos=prepend_bos)\n","    neuron_activations = neuron_activations.to(\"cpu\")\n","\n","    self.token_to_activations = defaultdict(list)\n","    for tokens, activations in zip(all_str_tokens, neuron_activations):\n","      for token, activation in zip(tokens, activations):\n","        activation = activation.item()\n","        self.token_to_activations[token].append(activation / self.max_activation)\n","\n","    self.token_to_activation = {token: np.max(activations) for token, activations in self.token_to_activations.items()}\n","\n","  def forward(self, tokens_arr: List[List[str]], return_activations=True) -> List[List[float]]:\n","    all_activations = []\n","    all_firings = []\n","\n","    for tokens in tokens_arr:\n","      activations = []\n","      firings = []\n","\n","      for token in tokens:\n","        activation = self.token_to_activation.get(token, 0)\n","\n","        activations.append(activation)\n","        firings.append(activation > self.activation_threshold)\n","\n","      all_activations.append(activations)\n","      all_firings.append(firings)\n","\n","    if return_activations:\n","      return all_activations\n","    return all_firings"],"metadata":{"id":"CbCpQeYjHCTP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_and_eval_baseline(model, layer, neuron, Baseline, train_proportion=0.5, fire_threshold=0.5, random_state=0, train_indexes=None, **kwargs):\n","  if isinstance(layer, int):\n","    layer = layer_index_to_name(layer)\n","\n","  layer_num = int(layer.split(\".\")[1])\n","\n","  base_max_act = float(activation_matrix[layer_num, neuron])\n","\n","  snippets = get_snippets(model_name, layer_num, neuron)\n","  # data = get_data(layer_num, neuron)\n","\n","  if train_indexes is None:\n","    train_snippets, test_snippets = train_test_split(snippets, train_size=train_proportion, random_state=random_state)\n","  else:\n","    train_snippets = [snippet for i, snippet in enumerate(snippets) if i in train_indexes]\n","    test_snippets = [snippet for i, snippet in enumerate(snippets) if i not in train_indexes]\n","  # train_data, test_data = train_test_split(data, train_size=train_proportion, random_state=0)\n","\n","  # train_data_snippets = [\"\".join(tokens) for tokens, activations in train_data if any(activation > fire_threshold for activation in activations)][:max_train_size] \n","  train_data_snippets = []\n","  all_train_snippets = train_snippets + train_data_snippets\n","\n","  baseline_model = Baseline(model, layer_num, neuron, **kwargs)\n","  baseline_model.fit(all_train_snippets)\n","\n","  print(\"Fitted model\")\n","\n","  # Not pruning so don't need to prepend_bos\n","  prepend_bos = False\n","\n","  max_test_data = []\n","  for snippet in test_snippets:\n","    tokens = model.to_tokens(snippet, prepend_bos=prepend_bos)\n","    str_tokens = model.to_str_tokens(snippet, prepend_bos=prepend_bos)\n","    logits, cache = model.run_with_cache(tokens)\n","    activations = cache[layer][0, :, neuron]\n","    max_test_data.append((str_tokens, activations.cpu() / base_max_act))\n","\n","  print(\"Max Activating Evaluation Data\")\n","  try:\n","    stats = evaluate(baseline_model, max_test_data, fire_threshold=fire_threshold, **kwargs)\n","  except Exception as e:\n","    stats = {}\n","    print(f\"Stats failed with error: {e}\")\n","\n","  return stats"],"metadata":{"id":"_R3lhVysBlyM","executionInfo":{"status":"ok","timestamp":1684098748341,"user_tz":-60,"elapsed":3,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}}},"execution_count":302,"outputs":[]},{"cell_type":"code","source":["train_and_eval_baseline(model, 3, 13, TokenPredictor, train_indexes=[0], train_proportion=0.5, fire_threshold=0.5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fxo0s7lcCapa","executionInfo":{"status":"ok","timestamp":1684098750551,"user_tz":-60,"elapsed":2212,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"93e1b8bc-f47d-4251-d422-631356bc1301"},"execution_count":303,"outputs":[{"output_type":"stream","name":"stdout","text":["[3, 13]\n","[0.48002245873045024]\n","0.48002245873045024\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99     19436\n","           1       0.02      0.35      0.04        20\n","\n","    accuracy                           0.98     19456\n","   macro avg       0.51      0.67      0.51     19456\n","weighted avg       1.00      0.98      0.99     19456\n","\n","correlation=-20.630, mse=0.020, variance=0.0009\n"]}]},{"cell_type":"markdown","source":["# Experiments"],"metadata":{"id":"sBnaTLx51Ra7"}},{"cell_type":"markdown","source":["## Examples"],"metadata":{"id":"94naXMRU3SCv"}},{"cell_type":"code","source":["# Example build\n","\n","layer = 3\n","neuron = 13\n","stats = train_and_eval(model, layer, neuron, n=5, train_proportion=0.5, activation_threshold=0.5, fire_threshold=0.5, importance_threshold=0.75, folder_name=\"test_examples\", neuron_store=test_neuron_store)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2sO_IKRk2FgB","executionInfo":{"status":"ok","timestamp":1684094574652,"user_tz":-60,"elapsed":10118,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"6afabbb0-9ccb-4857-d313-d13cd5b85287"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.83      1.00      0.91        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.92      1.00      0.95     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","correlation=0.737, mse=0.000, variance=0.0009\n"]}]},{"cell_type":"code","source":["# Load the neuron store for solu-6l-pile - do not save to this one (i.e., don't pass it to train_and_eval or call neuron_store.save)\n","neuron_store = NeuronStore(f\"{base_path}/neuron_graphs/{model_name}/neuron_store.json\")"],"metadata":{"id":"AgUIrZig3ev2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# You can search the store for graphs that contain particular tokens - specifying whether they should be important (context), activating, or either (None)\n","neuron_store.search([\n","    (\"this\", None),\n","    (\"is\", \"important\"),\n","    (\"example\", \"activating\")\n","])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RrLKRD-R3DlO","executionInfo":{"status":"ok","timestamp":1684096140150,"user_tz":-60,"elapsed":309,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"e1777acd-eb04-4246-e371-d2491e92e5fe"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'1_1268', '4_2787'}"]},"metadata":{},"execution_count":233}]},{"cell_type":"code","source":["neuron_name = \"4_2787\"\n","layer, neuron = neuron_name.split(\"_\")\n","path = f\"{base_path}/neuron_graphs/{model_name}/layer_{layer}/{layer}_{neuron}/graph.png\"\n","view_neuron(path)"],"metadata":{"id":"dtyKMSbp78yB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Dev"],"metadata":{"id":"qTsJypc13UHx"}},{"cell_type":"code","source":["folder_name = \"test_examples\"\n","\n","neuron_name = \"5_9\"\n","layer, neuron = neuron_name.split(\"_\")\n","\n","_, paths = train_and_eval(model, int(layer), int(neuron), n=15, train_indexes=[5], activation_threshold=0.5, fire_threshold=0.5, importance_threshold=0.5, proportion_threshold=-0.5, folder_name=folder_name, neuron_store=test_neuron_store, return_paths=True)\n","\n","trajectories = paths_to_trajectories(model, int(layer), int(neuron), paths)\n","\n","with open(f\"{base_path}/neuron_graphs/{model_name}/{folder_name}/{layer}_{neuron}/trajectories.json\", \"w\") as ofh:\n","  json.dump(trajectories, ofh) \n","\n","path = f\"{base_path}/neuron_graphs/{model_name}/{folder_name}/{layer}_{neuron}/graph.png\"\n","view_neuron(path)\n","plot_trajectories(trajectories)"],"metadata":{"id":"Twd0DTp1rL0A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","def plot_trajectories(trajectories):\n","  plt.figure()\n","  for trajectory in trajectories:\n","    # If we reverse everything lines up better, but it's confusing as it goes backwards\n","    # activations = [info[\"normalised_activation\"] for info in reversed(trajectory[\"trajectory\"])]\n","    activations = [info[\"normalised_activation\"] for info in trajectory[\"trajectory\"]]\n","    plt.plot(activations)\n","  plt.xlabel(\"Token Index\")\n","  plt.ylabel(\"Activation\")\n","\n","  plt.figure()\n","  for trajectory in trajectories:\n","    # importances = [info[\"importance\"] for info in reversed(trajectory[\"trajectory\"])]\n","    importances = [info[\"importance\"] for info in trajectory[\"trajectory\"]]\n","    plt.plot(importances)\n","  plt.xlabel(\"Token Index\")\n","  plt.ylabel(\"Importance\")"],"metadata":{"id":"heE2nPoQ81I8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def paths_to_trajectories(model, layer, neuron, paths, **kwargs):\n","  max_activation = activation_matrix[layer][neuron]\n","  # print(max_activation)\n","  trajectories = []\n","  for i, path in enumerate(paths):\n","    input = \"\".join([element.token_value for element in reversed(path) if element.token_value not in {\"**ROOT**\", \"**END**\"}])\n","    # print(\"\\n\", [input])\n","    pruned_path, intermediates = fast_prune(model, layer_index_to_name(layer), neuron, input, return_intermediates=True, proportion_threshold=100, skip_interval=1)\n","    # pprint(intermediates)\n","    # Add a 0 in case there's nothing there\n","    activations = [activation / max_activation for _, _, activation in intermediates] + [0]\n","    max_prop_activation = max(activations)\n","    if max_prop_activation > 0.1:\n","      trajectory = [{\"token\": token, \"important\": element.important, \"normalised_activation\": activation / max_activation, \"importance\": element.importance} for (_, token, activation), (element) in zip(reversed(intermediates), reversed(path[1:-1]))]\n","      trajectories.append({\"trajectory\": trajectory, \"is_augmented\": i > 0})\n","      print(trajectory)\n","      print(max_prop_activation)\n","  return trajectories"],"metadata":{"id":"Z5YDFP07txT5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["length_to_neurons = defaultdict(list)"],"metadata":{"id":"UuA8-o1V-fzR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","layer = 4\n","for neuron in range(200):\n","  _, paths = train_and_eval(model, int(layer), int(neuron), n=0, train_indexes=[0], activation_threshold=0.5, fire_threshold=0.5, importance_threshold=0.5, folder_name=\"test_examples\", neuron_store=test_neuron_store, return_paths=True)\n","  longest_path = max(len(path) for path in paths)\n","  length_to_neurons[longest_path].append((layer, neuron))\n","  print(f\"{layer=}, {neuron=}, {longest_path=}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WlowF_5o4suO","executionInfo":{"status":"ok","timestamp":1684079457777,"user_tz":-60,"elapsed":603608,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"2d82a1fe-bebd-4628-b5e6-cb83c6474f1f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing 1 of 1\n"]},{"output_type":"stream","name":"stderr","text":["Warning: node '5', graph '%3' size too small for label\n","Warning: node '5', graph '%3' size too small for label\n"]},{"output_type":"stream","name":"stdout","text":["Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19432\n","           1       0.00      0.00      0.00        21\n","\n","    accuracy                           1.00     19453\n","   macro avg       0.50      0.50      0.50     19453\n","weighted avg       1.00      1.00      1.00     19453\n","\n","correlation=-0.036, mse=0.001, variance=0.0012\n","layer=4, neuron=0, longest_path=20\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       0.00      0.00      0.00        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.271, mse=0.001, variance=0.0008\n","layer=4, neuron=1, longest_path=6\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       1.00      0.53      0.69        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       1.00      0.76      0.84     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.337, mse=0.001, variance=0.0008\n","layer=4, neuron=2, longest_path=7\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19400\n","           1       0.00      0.00      0.00        56\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       0.99      1.00      1.00     19456\n","\n","correlation=-0.083, mse=0.003, variance=0.0031\n","layer=4, neuron=3, longest_path=13\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19433\n","           1       0.00      0.00      0.00        20\n","\n","    accuracy                           1.00     19453\n","   macro avg       0.50      0.50      0.50     19453\n","weighted avg       1.00      1.00      1.00     19453\n","\n","correlation=-0.048, mse=0.001, variance=0.0007\n","layer=4, neuron=4, longest_path=25\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19427\n","           1       1.00      0.23      0.38        26\n","\n","    accuracy                           1.00     19453\n","   macro avg       1.00      0.62      0.69     19453\n","weighted avg       1.00      1.00      1.00     19453\n","\n","correlation=0.016, mse=0.001, variance=0.0011\n","layer=4, neuron=5, longest_path=4\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19436\n","           1       0.00      0.00      0.00        20\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.010, mse=0.001, variance=0.0009\n","layer=4, neuron=6, longest_path=5\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19433\n","           1       0.00      0.00      0.00        19\n","\n","    accuracy                           1.00     19452\n","   macro avg       0.50      0.50      0.50     19452\n","weighted avg       1.00      1.00      1.00     19452\n","\n","correlation=-0.072, mse=0.001, variance=0.0008\n","layer=4, neuron=7, longest_path=9\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19434\n","           1       0.00      0.00      0.00        22\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.248, mse=0.002, variance=0.0018\n","layer=4, neuron=8, longest_path=31\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       1.00      0.74      0.85        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       1.00      0.87      0.92     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.573, mse=0.000, variance=0.0009\n","layer=4, neuron=9, longest_path=6\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19425\n","           1       0.00      0.00      0.00        22\n","\n","    accuracy                           1.00     19447\n","   macro avg       0.50      0.50      0.50     19447\n","weighted avg       1.00      1.00      1.00     19447\n","\n","correlation=-0.042, mse=0.001, variance=0.0008\n","layer=4, neuron=10, longest_path=12\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19430\n","           1       0.00      0.00      0.00        26\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.021, mse=0.001, variance=0.0013\n","layer=4, neuron=11, longest_path=11\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19427\n","           1       0.00      0.00      0.00        29\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.064, mse=0.003, variance=0.0025\n","layer=4, neuron=12, longest_path=18\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19436\n","           1       1.00      0.11      0.19        19\n","\n","    accuracy                           1.00     19455\n","   macro avg       1.00      0.55      0.60     19455\n","weighted avg       1.00      1.00      1.00     19455\n","\n","correlation=0.012, mse=0.001, variance=0.0006\n","layer=4, neuron=13, longest_path=7\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.96      0.98     19432\n","           1       0.00      0.04      0.00        24\n","\n","    accuracy                           0.96     19456\n","   macro avg       0.50      0.50      0.49     19456\n","weighted avg       1.00      0.96      0.98     19456\n","\n","correlation=-8.362, mse=0.012, variance=0.0013\n","layer=4, neuron=14, longest_path=8\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19398\n","           1       0.00      0.00      0.00        19\n","\n","    accuracy                           1.00     19417\n","   macro avg       0.50      0.50      0.50     19417\n","weighted avg       1.00      1.00      1.00     19417\n","\n","correlation=-0.027, mse=0.001, variance=0.0008\n","layer=4, neuron=15, longest_path=12\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19419\n","           1       0.00      0.00      0.00        37\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.154, mse=0.002, variance=0.0016\n","layer=4, neuron=16, longest_path=13\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19434\n","           1       0.00      0.00      0.00        22\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.147, mse=0.002, variance=0.0016\n","layer=4, neuron=17, longest_path=13\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19436\n","           1       1.00      0.05      0.10        19\n","\n","    accuracy                           1.00     19455\n","   macro avg       1.00      0.53      0.55     19455\n","weighted avg       1.00      1.00      1.00     19455\n","\n","correlation=-0.068, mse=0.001, variance=0.0007\n","layer=4, neuron=18, longest_path=5\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19434\n","           1       0.00      0.00      0.00        22\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-2.700, mse=0.004, variance=0.0012\n","layer=4, neuron=19, longest_path=4\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19423\n","           1       0.00      0.00      0.00        23\n","\n","    accuracy                           1.00     19446\n","   macro avg       0.50      0.50      0.50     19446\n","weighted avg       1.00      1.00      1.00     19446\n","\n","correlation=-0.052, mse=0.001, variance=0.0011\n","layer=4, neuron=20, longest_path=7\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19428\n","           1       0.00      0.00      0.00        28\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.036, mse=0.001, variance=0.0014\n","layer=4, neuron=21, longest_path=4\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       0.00      0.00      0.00        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.003, mse=0.001, variance=0.0007\n","layer=4, neuron=22, longest_path=6\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19423\n","           1       1.00      0.03      0.06        33\n","\n","    accuracy                           1.00     19456\n","   macro avg       1.00      0.52      0.53     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.106, mse=0.002, variance=0.0022\n","layer=4, neuron=23, longest_path=12\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19411\n","           1       0.00      0.00      0.00        45\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.067, mse=0.004, variance=0.0036\n","layer=4, neuron=24, longest_path=12\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19434\n","           1       0.70      0.90      0.79        21\n","\n","    accuracy                           1.00     19455\n","   macro avg       0.85      0.95      0.90     19455\n","weighted avg       1.00      1.00      1.00     19455\n","\n","correlation=0.215, mse=0.001, variance=0.0011\n","layer=4, neuron=25, longest_path=3\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19409\n","           1       0.00      0.00      0.00        32\n","\n","    accuracy                           1.00     19441\n","   macro avg       0.50      0.50      0.50     19441\n","weighted avg       1.00      1.00      1.00     19441\n","\n","correlation=-0.018, mse=0.001, variance=0.0012\n","layer=4, neuron=26, longest_path=8\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       0.98      1.00      0.99     19080\n","           1       0.80      0.01      0.02       376\n","\n","    accuracy                           0.98     19456\n","   macro avg       0.89      0.51      0.51     19456\n","weighted avg       0.98      0.98      0.97     19456\n","\n","correlation=-0.012, mse=0.009, variance=0.0092\n","layer=4, neuron=27, longest_path=6\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19432\n","           1       0.00      0.00      0.00        24\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.056, mse=0.001, variance=0.0012\n","layer=4, neuron=28, longest_path=9\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19425\n","           1       0.00      0.00      0.00        31\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.043, mse=0.002, variance=0.0019\n","layer=4, neuron=29, longest_path=20\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19436\n","           1       0.00      0.00      0.00        20\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.105, mse=0.002, variance=0.0015\n","layer=4, neuron=30, longest_path=17\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19435\n","           1       1.00      0.05      0.10        20\n","\n","    accuracy                           1.00     19455\n","   macro avg       1.00      0.53      0.55     19455\n","weighted avg       1.00      1.00      1.00     19455\n","\n","correlation=0.019, mse=0.001, variance=0.0007\n","layer=4, neuron=31, longest_path=4\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19436\n","           1       0.00      0.00      0.00        20\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.046, mse=0.001, variance=0.0010\n","layer=4, neuron=32, longest_path=5\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19436\n","           1       0.00      0.00      0.00        20\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.016, mse=0.001, variance=0.0008\n","layer=4, neuron=33, longest_path=8\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19403\n","           1       0.00      0.00      0.00        53\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       0.99      1.00      1.00     19456\n","\n","correlation=-0.313, mse=0.009, variance=0.0072\n","layer=4, neuron=34, longest_path=11\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19384\n","           1       0.00      0.00      0.00        28\n","\n","    accuracy                           1.00     19412\n","   macro avg       0.50      0.50      0.50     19412\n","weighted avg       1.00      1.00      1.00     19412\n","\n","correlation=-0.143, mse=0.002, variance=0.0018\n","layer=4, neuron=35, longest_path=10\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19414\n","           1       0.00      0.00      0.00        42\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.048, mse=0.003, variance=0.0029\n","layer=4, neuron=36, longest_path=15\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19412\n","           1       0.00      0.00      0.00        27\n","\n","    accuracy                           1.00     19439\n","   macro avg       0.50      0.50      0.50     19439\n","weighted avg       1.00      1.00      1.00     19439\n","\n","correlation=-0.033, mse=0.001, variance=0.0012\n","layer=4, neuron=37, longest_path=10\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       0.00      0.00      0.00        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.016, mse=0.001, variance=0.0006\n","layer=4, neuron=38, longest_path=4\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19428\n","           1       0.00      0.00      0.00        28\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.157, mse=0.002, variance=0.0014\n","layer=4, neuron=39, longest_path=9\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     19438\n","           1       0.02      0.17      0.04        18\n","\n","    accuracy                           0.99     19456\n","   macro avg       0.51      0.58      0.52     19456\n","weighted avg       1.00      0.99      1.00     19456\n","\n","correlation=-2.694, mse=0.006, variance=0.0016\n","layer=4, neuron=40, longest_path=22\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19433\n","           1       0.00      0.00      0.00        23\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.079, mse=0.002, variance=0.0019\n","layer=4, neuron=41, longest_path=30\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19431\n","           1       0.95      1.00      0.97        19\n","\n","    accuracy                           1.00     19450\n","   macro avg       0.97      1.00      0.99     19450\n","weighted avg       1.00      1.00      1.00     19450\n","\n","correlation=0.815, mse=0.000, variance=0.0006\n","layer=4, neuron=42, longest_path=4\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19431\n","           1       1.00      0.19      0.32        21\n","\n","    accuracy                           1.00     19452\n","   macro avg       1.00      0.60      0.66     19452\n","weighted avg       1.00      1.00      1.00     19452\n","\n","correlation=-0.198, mse=0.002, variance=0.0016\n","layer=4, neuron=43, longest_path=5\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19428\n","           1       1.00      0.04      0.07        28\n","\n","    accuracy                           1.00     19456\n","   macro avg       1.00      0.52      0.53     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.322, mse=0.002, variance=0.0012\n","layer=4, neuron=44, longest_path=15\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19395\n","           1       1.00      0.02      0.04        47\n","\n","    accuracy                           1.00     19442\n","   macro avg       1.00      0.51      0.52     19442\n","weighted avg       1.00      1.00      1.00     19442\n","\n","correlation=-0.039, mse=0.002, variance=0.0020\n","layer=4, neuron=45, longest_path=12\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19403\n","           1       0.00      0.00      0.00        53\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       0.99      1.00      1.00     19456\n","\n","correlation=-0.662, mse=0.010, variance=0.0059\n","layer=4, neuron=46, longest_path=35\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19441\n","           1       0.00      0.00      0.00        13\n","\n","    accuracy                           1.00     19454\n","   macro avg       0.50      0.50      0.50     19454\n","weighted avg       1.00      1.00      1.00     19454\n","\n","correlation=-0.041, mse=0.000, variance=0.0003\n","layer=4, neuron=47, longest_path=8\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       0.00      0.00      0.00        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.010, mse=0.000, variance=0.0005\n","layer=4, neuron=48, longest_path=14\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19408\n","           1       0.00      0.00      0.00        19\n","\n","    accuracy                           1.00     19427\n","   macro avg       0.50      0.50      0.50     19427\n","weighted avg       1.00      1.00      1.00     19427\n","\n","correlation=-0.006, mse=0.001, variance=0.0010\n","layer=4, neuron=49, longest_path=14\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       1.00      0.05      0.10        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       1.00      0.53      0.55     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.274, mse=0.001, variance=0.0010\n","layer=4, neuron=50, longest_path=5\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19432\n","           1       0.92      0.96      0.94        23\n","\n","    accuracy                           1.00     19455\n","   macro avg       0.96      0.98      0.97     19455\n","weighted avg       1.00      1.00      1.00     19455\n","\n","correlation=0.167, mse=0.001, variance=0.0017\n","layer=4, neuron=51, longest_path=4\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19436\n","           1       0.00      0.00      0.00        19\n","\n","    accuracy                           1.00     19455\n","   macro avg       0.50      0.50      0.50     19455\n","weighted avg       1.00      1.00      1.00     19455\n","\n","correlation=-0.026, mse=0.001, variance=0.0008\n","layer=4, neuron=52, longest_path=21\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19436\n","           1       0.00      0.00      0.00        20\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.044, mse=0.001, variance=0.0007\n","layer=4, neuron=53, longest_path=6\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19438\n","           1       0.00      0.00      0.00        18\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.067, mse=0.001, variance=0.0006\n","layer=4, neuron=54, longest_path=17\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19308\n","           1       0.84      0.60      0.70       148\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.92      0.80      0.85     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.196, mse=0.003, variance=0.0041\n","layer=4, neuron=55, longest_path=4\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19428\n","           1       0.00      0.00      0.00        25\n","\n","    accuracy                           1.00     19453\n","   macro avg       0.50      0.50      0.50     19453\n","weighted avg       1.00      1.00      1.00     19453\n","\n","correlation=-0.180, mse=0.002, variance=0.0017\n","layer=4, neuron=56, longest_path=4\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19436\n","           1       1.00      0.37      0.54        19\n","\n","    accuracy                           1.00     19455\n","   macro avg       1.00      0.68      0.77     19455\n","weighted avg       1.00      1.00      1.00     19455\n","\n","correlation=0.314, mse=0.000, variance=0.0007\n","layer=4, neuron=57, longest_path=7\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19436\n","           1       0.62      0.50      0.56        20\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.81      0.75      0.78     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.160, mse=0.001, variance=0.0009\n","layer=4, neuron=58, longest_path=4\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19431\n","           1       0.65      0.48      0.55        23\n","\n","    accuracy                           1.00     19454\n","   macro avg       0.82      0.74      0.77     19454\n","weighted avg       1.00      1.00      1.00     19454\n","\n","correlation=0.039, mse=0.001, variance=0.0013\n","layer=4, neuron=59, longest_path=6\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19436\n","           1       0.40      0.20      0.27        20\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.70      0.60      0.63     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.162, mse=0.001, variance=0.0009\n","layer=4, neuron=60, longest_path=6\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19433\n","           1       0.00      0.00      0.00        20\n","\n","    accuracy                           1.00     19453\n","   macro avg       0.50      0.50      0.50     19453\n","weighted avg       1.00      1.00      1.00     19453\n","\n","correlation=-0.096, mse=0.001, variance=0.0010\n","layer=4, neuron=61, longest_path=3\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19427\n","           1       1.00      0.21      0.34        29\n","\n","    accuracy                           1.00     19456\n","   macro avg       1.00      0.60      0.67     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.085, mse=0.001, variance=0.0016\n","layer=4, neuron=62, longest_path=6\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99     19435\n","           1       0.00      0.00      0.00        20\n","\n","    accuracy                           0.98     19455\n","   macro avg       0.50      0.49      0.50     19455\n","weighted avg       1.00      0.98      0.99     19455\n","\n","correlation=-5.946, mse=0.007, variance=0.0010\n","layer=4, neuron=63, longest_path=5\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19426\n","           1       0.54      0.41      0.47        17\n","\n","    accuracy                           1.00     19443\n","   macro avg       0.77      0.71      0.73     19443\n","weighted avg       1.00      1.00      1.00     19443\n","\n","correlation=-0.439, mse=0.001, variance=0.0004\n","layer=4, neuron=64, longest_path=8\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19438\n","           1       0.19      0.39      0.26        18\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.60      0.69      0.63     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-1.516, mse=0.002, variance=0.0007\n","layer=4, neuron=65, longest_path=3\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       0.83      1.00      0.90        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.91      1.00      0.95     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.836, mse=0.000, variance=0.0009\n","layer=4, neuron=66, longest_path=3\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19430\n","           1       0.83      0.19      0.31        26\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.92      0.60      0.66     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.031, mse=0.002, variance=0.0020\n","layer=4, neuron=67, longest_path=7\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19411\n","           1       0.43      0.23      0.30        43\n","\n","    accuracy                           1.00     19454\n","   macro avg       0.72      0.62      0.65     19454\n","weighted avg       1.00      1.00      1.00     19454\n","\n","correlation=-0.089, mse=0.002, variance=0.0022\n","layer=4, neuron=68, longest_path=9\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     19376\n","           1       0.30      0.76      0.43        80\n","\n","    accuracy                           0.99     19456\n","   macro avg       0.65      0.88      0.72     19456\n","weighted avg       1.00      0.99      0.99     19456\n","\n","correlation=-0.704, mse=0.005, variance=0.0030\n","layer=4, neuron=69, longest_path=16\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19431\n","           1       0.41      0.50      0.45        22\n","\n","    accuracy                           1.00     19453\n","   macro avg       0.70      0.75      0.72     19453\n","weighted avg       1.00      1.00      1.00     19453\n","\n","correlation=0.116, mse=0.001, variance=0.0011\n","layer=4, neuron=70, longest_path=4\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19436\n","           1       0.00      0.00      0.00        20\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.007, mse=0.001, variance=0.0007\n","layer=4, neuron=71, longest_path=27\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19434\n","           1       0.00      0.00      0.00        19\n","\n","    accuracy                           1.00     19453\n","   macro avg       0.50      0.50      0.50     19453\n","weighted avg       1.00      1.00      1.00     19453\n","\n","correlation=-0.178, mse=0.001, variance=0.0010\n","layer=4, neuron=72, longest_path=8\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19438\n","           1       1.00      0.50      0.67        18\n","\n","    accuracy                           1.00     19456\n","   macro avg       1.00      0.75      0.83     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.308, mse=0.000, variance=0.0006\n","layer=4, neuron=73, longest_path=7\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19379\n","           1       1.00      0.04      0.07        28\n","\n","    accuracy                           1.00     19407\n","   macro avg       1.00      0.52      0.53     19407\n","weighted avg       1.00      1.00      1.00     19407\n","\n","correlation=-0.105, mse=0.002, variance=0.0018\n","layer=4, neuron=74, longest_path=4\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19443\n","           1       0.00      0.00      0.00        13\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.306, mse=0.002, variance=0.0012\n","layer=4, neuron=75, longest_path=7\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       1.00      1.00      1.00        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       1.00      1.00      1.00     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.913, mse=0.000, variance=0.0006\n","layer=4, neuron=76, longest_path=4\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19346\n","           1       1.00      0.03      0.06        34\n","\n","    accuracy                           1.00     19380\n","   macro avg       1.00      0.51      0.53     19380\n","weighted avg       1.00      1.00      1.00     19380\n","\n","correlation=0.019, mse=0.001, variance=0.0012\n","layer=4, neuron=77, longest_path=6\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19391\n","           1       0.00      0.00      0.00        23\n","\n","    accuracy                           1.00     19414\n","   macro avg       0.50      0.50      0.50     19414\n","weighted avg       1.00      1.00      1.00     19414\n","\n","correlation=-0.064, mse=0.001, variance=0.0014\n","layer=4, neuron=78, longest_path=4\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     19409\n","           1       0.00      0.00      0.00        27\n","\n","    accuracy                           0.99     19436\n","   macro avg       0.50      0.50      0.50     19436\n","weighted avg       1.00      0.99      0.99     19436\n","\n","correlation=-1.626, mse=0.003, variance=0.0012\n","layer=4, neuron=79, longest_path=10\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19422\n","           1       0.09      0.03      0.04        34\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.54      0.51      0.52     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.098, mse=0.003, variance=0.0026\n","layer=4, neuron=80, longest_path=4\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19423\n","           1       0.97      1.00      0.99        33\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.99      1.00      0.99     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.890, mse=0.000, variance=0.0010\n","layer=4, neuron=81, longest_path=9\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19435\n","           1       0.00      0.00      0.00        21\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.112, mse=0.001, variance=0.0010\n","layer=4, neuron=82, longest_path=5\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       0.00      0.00      0.00        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.005, mse=0.001, variance=0.0009\n","layer=4, neuron=83, longest_path=5\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       0.50      0.05      0.10        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.75      0.53      0.55     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.023, mse=0.001, variance=0.0007\n","layer=4, neuron=84, longest_path=25\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19433\n","           1       0.00      0.00      0.00        23\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.057, mse=0.001, variance=0.0010\n","layer=4, neuron=85, longest_path=6\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.99      1.00      1.00     19305\n","           1       0.00      0.00      0.00       151\n","\n","    accuracy                           0.99     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       0.98      0.99      0.99     19456\n","\n","correlation=-0.111, mse=0.010, variance=0.0087\n","layer=4, neuron=86, longest_path=13\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19435\n","           1       1.00      0.09      0.17        11\n","\n","    accuracy                           1.00     19446\n","   macro avg       1.00      0.55      0.58     19446\n","weighted avg       1.00      1.00      1.00     19446\n","\n","correlation=0.027, mse=0.000, variance=0.0004\n","layer=4, neuron=87, longest_path=7\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19429\n","           1       0.00      0.00      0.00        27\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.006, mse=0.001, variance=0.0009\n","layer=4, neuron=88, longest_path=10\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19433\n","           1       0.00      0.00      0.00        22\n","\n","    accuracy                           1.00     19455\n","   macro avg       0.50      0.50      0.50     19455\n","weighted avg       1.00      1.00      1.00     19455\n","\n","correlation=-0.052, mse=0.002, variance=0.0014\n","layer=4, neuron=89, longest_path=13\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19435\n","           1       0.00      0.00      0.00        21\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.169, mse=0.002, variance=0.0014\n","layer=4, neuron=90, longest_path=13\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19434\n","           1       0.00      0.00      0.00        22\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.161, mse=0.001, variance=0.0008\n","layer=4, neuron=91, longest_path=10\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19436\n","           1       0.71      0.25      0.37        20\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.86      0.62      0.68     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.108, mse=0.001, variance=0.0008\n","layer=4, neuron=92, longest_path=5\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19435\n","           1       0.00      0.00      0.00        21\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.083, mse=0.001, variance=0.0011\n","layer=4, neuron=93, longest_path=4\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19429\n","           1       1.00      0.16      0.27        19\n","\n","    accuracy                           1.00     19448\n","   macro avg       1.00      0.58      0.64     19448\n","weighted avg       1.00      1.00      1.00     19448\n","\n","correlation=0.131, mse=0.001, variance=0.0008\n","layer=4, neuron=94, longest_path=4\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19423\n","           1       1.00      0.05      0.10        20\n","\n","    accuracy                           1.00     19443\n","   macro avg       1.00      0.53      0.55     19443\n","weighted avg       1.00      1.00      1.00     19443\n","\n","correlation=-0.074, mse=0.001, variance=0.0013\n","layer=4, neuron=95, longest_path=4\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19436\n","           1       1.00      0.10      0.18        20\n","\n","    accuracy                           1.00     19456\n","   macro avg       1.00      0.55      0.59     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.081, mse=0.001, variance=0.0008\n","layer=4, neuron=96, longest_path=4\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.97      0.98     19409\n","           1       0.01      0.10      0.01        42\n","\n","    accuracy                           0.96     19451\n","   macro avg       0.50      0.53      0.50     19451\n","weighted avg       1.00      0.96      0.98     19451\n","\n","correlation=-10.252, mse=0.028, variance=0.0025\n","layer=4, neuron=97, longest_path=3\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19431\n","           1       1.00      0.56      0.72        25\n","\n","    accuracy                           1.00     19456\n","   macro avg       1.00      0.78      0.86     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.236, mse=0.001, variance=0.0011\n","layer=4, neuron=98, longest_path=5\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19416\n","           1       1.00      0.03      0.06        34\n","\n","    accuracy                           1.00     19450\n","   macro avg       1.00      0.51      0.53     19450\n","weighted avg       1.00      1.00      1.00     19450\n","\n","correlation=-0.079, mse=0.003, variance=0.0024\n","layer=4, neuron=99, longest_path=6\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19434\n","           1       0.00      0.00      0.00        22\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.076, mse=0.002, variance=0.0019\n","layer=4, neuron=100, longest_path=6\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19435\n","           1       0.80      0.38      0.52        21\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.90      0.69      0.76     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.150, mse=0.001, variance=0.0013\n","layer=4, neuron=101, longest_path=6\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19389\n","           1       0.00      0.00      0.00        67\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       0.99      1.00      0.99     19456\n","\n","correlation=-0.060, mse=0.005, variance=0.0045\n","layer=4, neuron=102, longest_path=8\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19412\n","           1       0.00      0.00      0.00        30\n","\n","    accuracy                           1.00     19442\n","   macro avg       0.50      0.50      0.50     19442\n","weighted avg       1.00      1.00      1.00     19442\n","\n","correlation=-0.051, mse=0.002, variance=0.0016\n","layer=4, neuron=103, longest_path=5\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19408\n","           1       1.00      0.03      0.06        31\n","\n","    accuracy                           1.00     19439\n","   macro avg       1.00      0.52      0.53     19439\n","weighted avg       1.00      1.00      1.00     19439\n","\n","correlation=-0.199, mse=0.002, variance=0.0021\n","layer=4, neuron=104, longest_path=10\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       0.00      0.00      0.00        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.032, mse=0.001, variance=0.0006\n","layer=4, neuron=105, longest_path=15\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19280\n","           1       1.00      0.05      0.09        22\n","\n","    accuracy                           1.00     19302\n","   macro avg       1.00      0.52      0.54     19302\n","weighted avg       1.00      1.00      1.00     19302\n","\n","correlation=0.016, mse=0.001, variance=0.0009\n","layer=4, neuron=106, longest_path=28\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19346\n","           1       0.00      0.00      0.00        20\n","\n","    accuracy                           1.00     19366\n","   macro avg       0.50      0.50      0.50     19366\n","weighted avg       1.00      1.00      1.00     19366\n","\n","correlation=-0.035, mse=0.001, variance=0.0006\n","layer=4, neuron=107, longest_path=8\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19403\n","           1       0.00      0.00      0.00        38\n","\n","    accuracy                           1.00     19441\n","   macro avg       0.50      0.50      0.50     19441\n","weighted avg       1.00      1.00      1.00     19441\n","\n","correlation=-0.038, mse=0.002, variance=0.0018\n","layer=4, neuron=108, longest_path=11\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19433\n","           1       0.88      0.91      0.89        23\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.94      0.96      0.95     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.579, mse=0.000, variance=0.0009\n","layer=4, neuron=109, longest_path=4\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19429\n","           1       0.00      0.00      0.00        27\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.314, mse=0.004, variance=0.0031\n","layer=4, neuron=110, longest_path=15\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19428\n","           1       0.00      0.00      0.00        28\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.248, mse=0.002, variance=0.0020\n","layer=4, neuron=111, longest_path=6\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19435\n","           1       1.00      0.14      0.25        21\n","\n","    accuracy                           1.00     19456\n","   macro avg       1.00      0.57      0.62     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.115, mse=0.001, variance=0.0008\n","layer=4, neuron=112, longest_path=7\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19436\n","           1       0.00      0.00      0.00        20\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.063, mse=0.001, variance=0.0006\n","layer=4, neuron=113, longest_path=19\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       0.00      0.00      0.00        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.132, mse=0.002, variance=0.0014\n","layer=4, neuron=114, longest_path=10\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19429\n","           1       1.00      0.04      0.07        27\n","\n","    accuracy                           1.00     19456\n","   macro avg       1.00      0.52      0.54     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.016, mse=0.001, variance=0.0014\n","layer=4, neuron=115, longest_path=10\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       0.21      0.79      0.33        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.61      0.89      0.67     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-1.247, mse=0.002, variance=0.0008\n","layer=4, neuron=116, longest_path=3\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19435\n","           1       1.00      0.14      0.25        21\n","\n","    accuracy                           1.00     19456\n","   macro avg       1.00      0.57      0.62     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.092, mse=0.001, variance=0.0008\n","layer=4, neuron=117, longest_path=4\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19431\n","           1       1.00      0.04      0.08        25\n","\n","    accuracy                           1.00     19456\n","   macro avg       1.00      0.52      0.54     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.038, mse=0.001, variance=0.0009\n","layer=4, neuron=118, longest_path=30\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19434\n","           1       0.00      0.00      0.00        21\n","\n","    accuracy                           1.00     19455\n","   macro avg       0.50      0.50      0.50     19455\n","weighted avg       1.00      1.00      1.00     19455\n","\n","correlation=-0.068, mse=0.001, variance=0.0011\n","layer=4, neuron=119, longest_path=13\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19421\n","           1       0.39      1.00      0.56        22\n","\n","    accuracy                           1.00     19443\n","   macro avg       0.70      1.00      0.78     19443\n","weighted avg       1.00      1.00      1.00     19443\n","\n","correlation=-0.371, mse=0.001, variance=0.0008\n","layer=4, neuron=120, longest_path=3\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19446\n","           1       0.17      1.00      0.29        10\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.58      1.00      0.64     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-3.044, mse=0.002, variance=0.0004\n","layer=4, neuron=121, longest_path=11\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       0.00      0.00      0.00        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.043, mse=0.001, variance=0.0006\n","layer=4, neuron=122, longest_path=9\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19434\n","           1       0.00      0.00      0.00        22\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.060, mse=0.001, variance=0.0012\n","layer=4, neuron=123, longest_path=6\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19422\n","           1       1.00      0.03      0.06        33\n","\n","    accuracy                           1.00     19455\n","   macro avg       1.00      0.52      0.53     19455\n","weighted avg       1.00      1.00      1.00     19455\n","\n","correlation=0.010, mse=0.001, variance=0.0011\n","layer=4, neuron=124, longest_path=30\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19436\n","           1       0.00      0.00      0.00        19\n","\n","    accuracy                           1.00     19455\n","   macro avg       0.50      0.50      0.50     19455\n","weighted avg       1.00      1.00      1.00     19455\n","\n","correlation=-0.081, mse=0.001, variance=0.0009\n","layer=4, neuron=125, longest_path=8\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       0.87      0.68      0.76        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.93      0.84      0.88     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.269, mse=0.001, variance=0.0010\n","layer=4, neuron=126, longest_path=5\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19433\n","           1       0.00      0.00      0.00        23\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.017, mse=0.001, variance=0.0009\n","layer=4, neuron=127, longest_path=26\n","Processing 1 of 1\n"]},{"output_type":"stream","name":"stderr","text":["\n","(process:45709): Pango-CRITICAL **: 15:47:24.129: pango_cairo_show_layout: assertion 'PANGO_IS_LAYOUT (layout)' failed\n"]},{"output_type":"stream","name":"stdout","text":["Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19414\n","           1       0.00      0.00      0.00        21\n","\n","    accuracy                           1.00     19435\n","   macro avg       0.50      0.50      0.50     19435\n","weighted avg       1.00      1.00      1.00     19435\n","\n","correlation=-0.060, mse=0.001, variance=0.0007\n","layer=4, neuron=128, longest_path=10\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19422\n","           1       0.00      0.00      0.00        33\n","\n","    accuracy                           1.00     19455\n","   macro avg       0.50      0.50      0.50     19455\n","weighted avg       1.00      1.00      1.00     19455\n","\n","correlation=-0.028, mse=0.001, variance=0.0013\n","layer=4, neuron=129, longest_path=13\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     19426\n","           1       0.10      0.63      0.18        27\n","\n","    accuracy                           0.99     19453\n","   macro avg       0.55      0.81      0.59     19453\n","weighted avg       1.00      0.99      0.99     19453\n","\n","correlation=-7.407, mse=0.007, variance=0.0009\n","layer=4, neuron=130, longest_path=21\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19386\n","           1       1.00      0.25      0.40        20\n","\n","    accuracy                           1.00     19406\n","   macro avg       1.00      0.62      0.70     19406\n","weighted avg       1.00      1.00      1.00     19406\n","\n","correlation=0.173, mse=0.001, variance=0.0007\n","layer=4, neuron=131, longest_path=3\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       0.00      0.00      0.00        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.010, mse=0.000, variance=0.0005\n","layer=4, neuron=132, longest_path=11\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19379\n","           1       0.00      0.00      0.00        75\n","\n","    accuracy                           1.00     19454\n","   macro avg       0.50      0.50      0.50     19454\n","weighted avg       0.99      1.00      0.99     19454\n","\n","correlation=-0.331, mse=0.009, variance=0.0067\n","layer=4, neuron=133, longest_path=16\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19436\n","           1       1.00      0.26      0.42        19\n","\n","    accuracy                           1.00     19455\n","   macro avg       1.00      0.63      0.71     19455\n","weighted avg       1.00      1.00      1.00     19455\n","\n","correlation=0.237, mse=0.000, variance=0.0004\n","layer=4, neuron=134, longest_path=5\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19415\n","           1       1.00      0.34      0.51        38\n","\n","    accuracy                           1.00     19453\n","   macro avg       1.00      0.67      0.75     19453\n","weighted avg       1.00      1.00      1.00     19453\n","\n","correlation=-0.049, mse=0.004, variance=0.0038\n","layer=4, neuron=135, longest_path=5\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19435\n","           1       0.58      0.71      0.64        21\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.79      0.86      0.82     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.154, mse=0.001, variance=0.0010\n","layer=4, neuron=136, longest_path=7\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19414\n","           1       0.00      0.00      0.00        39\n","\n","    accuracy                           0.99     19453\n","   macro avg       0.50      0.50      0.50     19453\n","weighted avg       1.00      0.99      1.00     19453\n","\n","correlation=-0.633, mse=0.002, variance=0.0014\n","layer=4, neuron=137, longest_path=9\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19406\n","           1       0.00      0.00      0.00        22\n","\n","    accuracy                           1.00     19428\n","   macro avg       0.50      0.50      0.50     19428\n","weighted avg       1.00      1.00      1.00     19428\n","\n","correlation=-0.083, mse=0.001, variance=0.0012\n","layer=4, neuron=138, longest_path=6\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19429\n","           1       0.00      0.00      0.00        27\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.628, mse=0.005, variance=0.0029\n","layer=4, neuron=139, longest_path=11\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19428\n","           1       0.95      0.95      0.95        19\n","\n","    accuracy                           1.00     19447\n","   macro avg       0.97      0.97      0.97     19447\n","weighted avg       1.00      1.00      1.00     19447\n","\n","correlation=0.825, mse=0.000, variance=0.0007\n","layer=4, neuron=140, longest_path=5\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19415\n","           1       0.50      0.02      0.05        41\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.75      0.51      0.52     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.001, mse=0.001, variance=0.0014\n","layer=4, neuron=141, longest_path=11\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19435\n","           1       0.00      0.00      0.00        21\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.096, mse=0.001, variance=0.0012\n","layer=4, neuron=142, longest_path=5\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19396\n","           1       0.00      0.00      0.00        60\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       0.99      1.00      1.00     19456\n","\n","correlation=-0.015, mse=0.002, variance=0.0018\n","layer=4, neuron=143, longest_path=9\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19422\n","           1       0.50      0.05      0.09        21\n","\n","    accuracy                           1.00     19443\n","   macro avg       0.75      0.52      0.54     19443\n","weighted avg       1.00      1.00      1.00     19443\n","\n","correlation=-0.033, mse=0.001, variance=0.0008\n","layer=4, neuron=144, longest_path=4\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19432\n","           1       0.00      0.00      0.00        21\n","\n","    accuracy                           1.00     19453\n","   macro avg       0.50      0.50      0.50     19453\n","weighted avg       1.00      1.00      1.00     19453\n","\n","correlation=-0.044, mse=0.001, variance=0.0011\n","layer=4, neuron=145, longest_path=23\n","Processing 1 of 1\n"]},{"output_type":"stream","name":"stderr","text":["Warning: node '5', graph '%3' size too small for label\n","Warning: node '5', graph '%3' size too small for label\n"]},{"output_type":"stream","name":"stdout","text":["Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19436\n","           1       0.46      0.60      0.52        20\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.73      0.80      0.76     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.103, mse=0.001, variance=0.0007\n","layer=4, neuron=146, longest_path=14\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19434\n","           1       1.00      1.00      1.00        22\n","\n","    accuracy                           1.00     19456\n","   macro avg       1.00      1.00      1.00     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.695, mse=0.000, variance=0.0009\n","layer=4, neuron=147, longest_path=5\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19400\n","           1       0.00      0.00      0.00        20\n","\n","    accuracy                           1.00     19420\n","   macro avg       0.50      0.50      0.50     19420\n","weighted avg       1.00      1.00      1.00     19420\n","\n","correlation=-0.082, mse=0.001, variance=0.0010\n","layer=4, neuron=148, longest_path=7\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19417\n","           1       0.00      0.00      0.00        38\n","\n","    accuracy                           1.00     19455\n","   macro avg       0.50      0.50      0.50     19455\n","weighted avg       1.00      1.00      1.00     19455\n","\n","correlation=-0.127, mse=0.003, variance=0.0024\n","layer=4, neuron=149, longest_path=9\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19428\n","           1       1.00      0.05      0.10        20\n","\n","    accuracy                           1.00     19448\n","   macro avg       1.00      0.53      0.55     19448\n","weighted avg       1.00      1.00      1.00     19448\n","\n","correlation=0.016, mse=0.001, variance=0.0007\n","layer=4, neuron=150, longest_path=10\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       0.99      1.00      1.00     19351\n","           1       0.60      0.06      0.10       105\n","\n","    accuracy                           0.99     19456\n","   macro avg       0.80      0.53      0.55     19456\n","weighted avg       0.99      0.99      0.99     19456\n","\n","correlation=-0.002, mse=0.004, variance=0.0039\n","layer=4, neuron=151, longest_path=10\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       0.00      0.00      0.00        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.015, mse=0.001, variance=0.0006\n","layer=4, neuron=152, longest_path=6\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       0.21      0.42      0.28        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.60      0.71      0.64     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-2.136, mse=0.002, variance=0.0006\n","layer=4, neuron=153, longest_path=5\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19433\n","           1       0.00      0.00      0.00        23\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.049, mse=0.001, variance=0.0011\n","layer=4, neuron=154, longest_path=13\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19398\n","           1       0.00      0.00      0.00        49\n","\n","    accuracy                           1.00     19447\n","   macro avg       0.50      0.50      0.50     19447\n","weighted avg       0.99      1.00      1.00     19447\n","\n","correlation=-0.043, mse=0.003, variance=0.0030\n","layer=4, neuron=155, longest_path=11\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.94      0.97     19419\n","           1       0.01      0.32      0.02        37\n","\n","    accuracy                           0.94     19456\n","   macro avg       0.50      0.63      0.49     19456\n","weighted avg       1.00      0.94      0.97     19456\n","\n","correlation=-20.296, mse=0.048, variance=0.0022\n","layer=4, neuron=156, longest_path=3\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19420\n","           1       0.00      0.00      0.00        36\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.342, mse=0.004, variance=0.0030\n","layer=4, neuron=157, longest_path=5\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19432\n","           1       0.86      0.50      0.63        24\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.93      0.75      0.82     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.250, mse=0.001, variance=0.0015\n","layer=4, neuron=158, longest_path=29\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       0.00      0.00      0.00        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.008, mse=0.001, variance=0.0006\n","layer=4, neuron=159, longest_path=9\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19435\n","           1       0.00      0.00      0.00        21\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.038, mse=0.001, variance=0.0008\n","layer=4, neuron=160, longest_path=8\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19431\n","           1       0.00      0.00      0.00        19\n","\n","    accuracy                           1.00     19450\n","   macro avg       0.50      0.50      0.50     19450\n","weighted avg       1.00      1.00      1.00     19450\n","\n","correlation=-0.060, mse=0.001, variance=0.0006\n","layer=4, neuron=161, longest_path=5\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       0.00      0.00      0.00        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.007, mse=0.001, variance=0.0007\n","layer=4, neuron=162, longest_path=7\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19434\n","           1       0.80      0.20      0.32        20\n","\n","    accuracy                           1.00     19454\n","   macro avg       0.90      0.60      0.66     19454\n","weighted avg       1.00      1.00      1.00     19454\n","\n","correlation=0.185, mse=0.001, variance=0.0007\n","layer=4, neuron=163, longest_path=6\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       0.00      0.00      0.00        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.005, mse=0.001, variance=0.0007\n","layer=4, neuron=164, longest_path=15\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19433\n","           1       0.00      0.00      0.00        22\n","\n","    accuracy                           1.00     19455\n","   macro avg       0.50      0.50      0.50     19455\n","weighted avg       1.00      1.00      1.00     19455\n","\n","correlation=-0.015, mse=0.001, variance=0.0008\n","layer=4, neuron=165, longest_path=15\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19434\n","           1       0.00      0.00      0.00        22\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.003, mse=0.001, variance=0.0007\n","layer=4, neuron=166, longest_path=6\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19435\n","           1       0.00      0.00      0.00        20\n","\n","    accuracy                           1.00     19455\n","   macro avg       0.50      0.50      0.50     19455\n","weighted avg       1.00      1.00      1.00     19455\n","\n","correlation=-0.083, mse=0.001, variance=0.0012\n","layer=4, neuron=167, longest_path=8\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19443\n","           1       0.00      0.00      0.00        13\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.042, mse=0.001, variance=0.0007\n","layer=4, neuron=168, longest_path=20\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       0.00      0.00      0.00        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.032, mse=0.001, variance=0.0006\n","layer=4, neuron=169, longest_path=7\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       0.00      0.00      0.00        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.002, mse=0.000, variance=0.0004\n","layer=4, neuron=170, longest_path=8\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       0.00      0.00      0.00        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.067, mse=0.001, variance=0.0008\n","layer=4, neuron=171, longest_path=10\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19428\n","           1       0.00      0.00      0.00        20\n","\n","    accuracy                           1.00     19448\n","   macro avg       0.50      0.50      0.50     19448\n","weighted avg       1.00      1.00      1.00     19448\n","\n","correlation=-0.148, mse=0.001, variance=0.0010\n","layer=4, neuron=172, longest_path=7\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19261\n","           1       0.00      0.00      0.00        26\n","\n","    accuracy                           1.00     19287\n","   macro avg       0.50      0.50      0.50     19287\n","weighted avg       1.00      1.00      1.00     19287\n","\n","correlation=-0.053, mse=0.001, variance=0.0013\n","layer=4, neuron=173, longest_path=10\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19429\n","           1       0.00      0.00      0.00        27\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.040, mse=0.001, variance=0.0013\n","layer=4, neuron=174, longest_path=6\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       0.67      0.11      0.18        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.83      0.55      0.59     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.043, mse=0.001, variance=0.0010\n","layer=4, neuron=175, longest_path=5\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19436\n","           1       0.00      0.00      0.00        20\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.006, mse=0.000, variance=0.0004\n","layer=4, neuron=176, longest_path=6\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19419\n","           1       0.00      0.00      0.00        26\n","\n","    accuracy                           1.00     19445\n","   macro avg       0.50      0.50      0.50     19445\n","weighted avg       1.00      1.00      1.00     19445\n","\n","correlation=-0.059, mse=0.002, variance=0.0017\n","layer=4, neuron=177, longest_path=5\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19436\n","           1       0.00      0.00      0.00        20\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.054, mse=0.001, variance=0.0009\n","layer=4, neuron=178, longest_path=9\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19435\n","           1       0.00      0.00      0.00        21\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.016, mse=0.001, variance=0.0008\n","layer=4, neuron=179, longest_path=19\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19428\n","           1       0.00      0.00      0.00        19\n","\n","    accuracy                           1.00     19447\n","   macro avg       0.50      0.50      0.50     19447\n","weighted avg       1.00      1.00      1.00     19447\n","\n","correlation=-0.010, mse=0.001, variance=0.0007\n","layer=4, neuron=180, longest_path=12\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99     19437\n","           1       0.00      0.05      0.00        19\n","\n","    accuracy                           0.98     19456\n","   macro avg       0.50      0.52      0.50     19456\n","weighted avg       1.00      0.98      0.99     19456\n","\n","correlation=-13.579, mse=0.017, variance=0.0011\n","layer=4, neuron=181, longest_path=24\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19438\n","           1       0.00      0.00      0.00        18\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.046, mse=0.001, variance=0.0009\n","layer=4, neuron=182, longest_path=21\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       0.00      0.00      0.00        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.013, mse=0.001, variance=0.0007\n","layer=4, neuron=183, longest_path=6\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     19434\n","           1       0.00      0.00      0.00        22\n","\n","    accuracy                           0.99     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      0.99      1.00     19456\n","\n","correlation=-1.718, mse=0.003, variance=0.0010\n","layer=4, neuron=184, longest_path=30\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       0.30      0.53      0.38        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.65      0.76      0.69     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-1.840, mse=0.001, variance=0.0005\n","layer=4, neuron=185, longest_path=5\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19436\n","           1       0.69      1.00      0.82        20\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.84      1.00      0.91     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.575, mse=0.000, variance=0.0007\n","layer=4, neuron=186, longest_path=3\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19432\n","           1       0.00      0.00      0.00        24\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.081, mse=0.001, variance=0.0012\n","layer=4, neuron=187, longest_path=14\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       1.00      0.11      0.19        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       1.00      0.55      0.60     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.089, mse=0.001, variance=0.0006\n","layer=4, neuron=188, longest_path=5\n","Processing 1 of 1\n"]},{"output_type":"stream","name":"stderr","text":["Warning: node '3', graph '%3' size too small for label\n","Warning: node '7', graph '%3' size too small for label\n","Warning: node '3', graph '%3' size too small for label\n","Warning: node '7', graph '%3' size too small for label\n"]},{"output_type":"stream","name":"stdout","text":["Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       0.00      0.00      0.00        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.022, mse=0.001, variance=0.0009\n","layer=4, neuron=189, longest_path=13\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19427\n","           1       0.11      0.25      0.16        28\n","\n","    accuracy                           1.00     19455\n","   macro avg       0.56      0.62      0.58     19455\n","weighted avg       1.00      1.00      1.00     19455\n","\n","correlation=-1.043, mse=0.005, variance=0.0026\n","layer=4, neuron=190, longest_path=5\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19435\n","           1       0.00      0.00      0.00        21\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.007, mse=0.001, variance=0.0008\n","layer=4, neuron=191, longest_path=15\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19434\n","           1       1.00      0.18      0.31        22\n","\n","    accuracy                           1.00     19456\n","   macro avg       1.00      0.59      0.65     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.094, mse=0.001, variance=0.0010\n","layer=4, neuron=192, longest_path=5\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19432\n","           1       0.93      0.54      0.68        24\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.96      0.77      0.84     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.239, mse=0.001, variance=0.0014\n","layer=4, neuron=193, longest_path=4\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19437\n","           1       1.00      1.00      1.00        19\n","\n","    accuracy                           1.00     19456\n","   macro avg       1.00      1.00      1.00     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.876, mse=0.000, variance=0.0008\n","layer=4, neuron=194, longest_path=5\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19405\n","           1       1.00      0.02      0.04        51\n","\n","    accuracy                           1.00     19456\n","   macro avg       1.00      0.51      0.52     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=0.003, mse=0.002, variance=0.0021\n","layer=4, neuron=195, longest_path=7\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19430\n","           1       0.00      0.00      0.00        26\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.044, mse=0.002, variance=0.0015\n","layer=4, neuron=196, longest_path=4\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19424\n","           1       0.00      0.00      0.00        32\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.175, mse=0.002, variance=0.0019\n","layer=4, neuron=197, longest_path=7\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      0.99     19432\n","           1       0.00      0.00      0.00        22\n","\n","    accuracy                           0.99     19454\n","   macro avg       0.50      0.50      0.50     19454\n","weighted avg       1.00      0.99      0.99     19454\n","\n","correlation=-9.468, mse=0.008, variance=0.0008\n","layer=4, neuron=198, longest_path=5\n","Processing 1 of 1\n","Paths after merge\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     19436\n","           1       0.00      0.00      0.00        20\n","\n","    accuracy                           1.00     19456\n","   macro avg       0.50      0.50      0.50     19456\n","weighted avg       1.00      1.00      1.00     19456\n","\n","correlation=-0.036, mse=0.001, variance=0.0008\n","layer=4, neuron=199, longest_path=6\n","CPU times: user 7min 5s, sys: 1.93 s, total: 7min 7s\n","Wall time: 10min 3s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["length_to_neurons_arr = [(k, v) for k, v in sorted(length_to_neurons.items(), key=lambda x: x[0], reverse=True)]"],"metadata":{"id":"Dm4kusHX6Izf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["length_to_neurons_arr[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sAlHC0r06Sp8","executionInfo":{"status":"ok","timestamp":1684079752948,"user_tz":-60,"elapsed":2,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"a00d1c54-65a0-407a-c6d1-43ab1afed198"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(35, [(4, 46)]),\n"," (31, [(4, 8)]),\n"," (30, [(4, 41), (4, 118), (4, 124), (4, 184)]),\n"," (29, [(4, 158)]),\n"," (28, [(4, 106)])]"]},"metadata":{},"execution_count":125}]},{"cell_type":"code","source":["paths"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_IFOxOW8trCV","executionInfo":{"status":"ok","timestamp":1684058588264,"user_tz":-60,"elapsed":3,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"8eb6c850-d328-48dc-d08c-d08399385d55"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[Element(importance=0, activation=0, token='**ROOT**', important=False, activator=False, ignore=True, is_end=False, token_value='**ROOT**'),\n","  Element(importance=0.9709031997441744, activation=0.92, token='version', important=True, activator=True, ignore=False, is_end=False, token_value='Version'),\n","  Element(importance=0.5417771086320593, activation=0.022, token='**IGNORE**', important=False, activator=False, ignore=True, is_end=False, token_value=','),\n","  Element(importance=0.508158976551, activation=0.026, token='**IGNORE**', important=False, activator=False, ignore=True, is_end=False, token_value='\\n\\t\\t'),\n","  Element(importance=0.9507949938540465, activation=0.014, token='LICENSE', important=True, activator=False, ignore=False, is_end=False, token_value=' LICENSE'),\n","  Element(importance=0.7534219422678958, activation=0.001, token='PUBLIC', important=True, activator=False, ignore=False, is_end=False, token_value=' PUBLIC'),\n","  Element(importance=0, activation=0.92, token='**END**', important=False, activator=False, ignore=True, is_end=True, token_value='**END**')],\n"," [Element(importance=0, activation=0, token='**ROOT**', important=False, activator=False, ignore=True, is_end=False, token_value='**ROOT**'),\n","  Element(importance=0.9709031997441744, activation=0.92, token='version', important=True, activator=True, ignore=False, is_end=False, token_value='Version'),\n","  Element(importance=0.5417771086320593, activation=0.022, token='**IGNORE**', important=False, activator=False, ignore=True, is_end=False, token_value=','),\n","  Element(importance=0.508158976551, activation=0.026, token='**IGNORE**', important=False, activator=False, ignore=True, is_end=False, token_value='\\n\\t\\t'),\n","  Element(importance=0.7847055125726388, activation=0.227, token='apache', important=True, activator=False, ignore=False, is_end=False, token_value=' Apache'),\n","  Element(importance=0, activation=0.829, token='**END**', important=False, activator=False, ignore=True, is_end=True, token_value='**END**')],\n"," [Element(importance=0, activation=0, token='**ROOT**', important=False, activator=False, ignore=True, is_end=False, token_value='**ROOT**'),\n","  Element(importance=0.9955180813439475, activation=0.977, token='to', important=True, activator=True, ignore=False, is_end=False, token_value=' to'),\n","  Element(importance=0.6620850688440527, activation=0.035, token='**IGNORE**', important=False, activator=False, ignore=True, is_end=False, token_value=' *'),\n","  Element(importance=0.7008779243645162, activation=0.053, token='**IGNORE**', important=False, activator=False, ignore=True, is_end=False, token_value='\\n'),\n","  Element(importance=0.8095441812276435, activation=0.037, token='file', important=True, activator=False, ignore=False, is_end=False, token_value=' file'),\n","  Element(importance=0.8605522568495336, activation=0.008, token='this', important=True, activator=False, ignore=False, is_end=False, token_value=' this'),\n","  Element(importance=0.975003226264508, activation=0.0, token='licenses', important=True, activator=False, ignore=False, is_end=False, token_value=' licenses'),\n","  Element(importance=0, activation=0.51, token='**END**', important=False, activator=False, ignore=True, is_end=True, token_value='**END**')],\n"," [Element(importance=0, activation=0, token='**ROOT**', important=False, activator=False, ignore=True, is_end=False, token_value='**ROOT**'),\n","  Element(importance=0.9955180813439475, activation=0.977, token='to', important=True, activator=True, ignore=False, is_end=False, token_value=' to'),\n","  Element(importance=0.6620850688440527, activation=0.035, token='**IGNORE**', important=False, activator=False, ignore=True, is_end=False, token_value=' *'),\n","  Element(importance=0.7008779243645162, activation=0.053, token='**IGNORE**', important=False, activator=False, ignore=True, is_end=False, token_value='\\n'),\n","  Element(importance=0.8446230103196203, activation=0.014, token='licenses', important=True, activator=False, ignore=False, is_end=False, token_value=' licenses'),\n","  Element(importance=0, activation=0.977, token='**END**', important=False, activator=False, ignore=True, is_end=True, token_value='**END**')],\n"," [Element(importance=0, activation=0, token='**ROOT**', important=False, activator=False, ignore=True, is_end=False, token_value='**ROOT**'),\n","  Element(importance=0.9955180813439475, activation=0.977, token='to', important=True, activator=True, ignore=False, is_end=False, token_value=' to'),\n","  Element(importance=0.6620850688440527, activation=0.035, token='**IGNORE**', important=False, activator=False, ignore=True, is_end=False, token_value=' *'),\n","  Element(importance=0.7008779243645162, activation=0.053, token='**IGNORE**', important=False, activator=False, ignore=True, is_end=False, token_value='\\n'),\n","  Element(importance=0.8411032651700581, activation=0.036, token='releases', important=True, activator=False, ignore=False, is_end=False, token_value=' releases'),\n","  Element(importance=0, activation=0.955, token='**END**', important=False, activator=False, ignore=True, is_end=True, token_value='**END**')]]"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["neuron_store = NeuronStore(f\"{base_path}/neuron_graphs/{model_name}/neuron_store.json\")"],"metadata":{"id":"ULdUhs2jfEnH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["similar_pairs, subset_pairs = neuron_store.find_similar()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZyhnKQTbfLA3","executionInfo":{"status":"ok","timestamp":1683916918224,"user_tz":-60,"elapsed":523790,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"45c0ff40-1bc6-4473-c5c0-2f0dbd2dd12d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0 of 18149 complete\n","1000 of 18149 complete\n","2000 of 18149 complete\n","3000 of 18149 complete\n","4000 of 18149 complete\n","5000 of 18149 complete\n","6000 of 18149 complete\n","7000 of 18149 complete\n","8000 of 18149 complete\n","9000 of 18149 complete\n","10000 of 18149 complete\n","11000 of 18149 complete\n","12000 of 18149 complete\n","13000 of 18149 complete\n","14000 of 18149 complete\n","15000 of 18149 complete\n","16000 of 18149 complete\n","17000 of 18149 complete\n","18000 of 18149 complete\n"]}]},{"cell_type":"code","source":["(len(similar_pairs), len(subset_pairs))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YVSHk-wYgAIJ","executionInfo":{"status":"ok","timestamp":1683916948998,"user_tz":-60,"elapsed":229,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"b63a2c63-1fb7-47a3-92ea-bc5beeb3dde4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(61, 14352)"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["list(enumerate(similar_pairs))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BVlzREIZgEsb","executionInfo":{"status":"ok","timestamp":1683916952105,"user_tz":-60,"elapsed":234,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"b3b00726-7074-4c76-d8d4-8649617a995c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(0, ('5_2150', '3_1623')),\n"," (1, ('4_212', '3_1623')),\n"," (2, ('4_212', '5_2150')),\n"," (3, ('5_1514', '4_2700')),\n"," (4, ('0_2628', '3_1623')),\n"," (5, ('0_2628', '5_2150')),\n"," (6, ('0_2628', '4_212')),\n"," (7, ('1_2767', '3_1623')),\n"," (8, ('1_2767', '5_2150')),\n"," (9, ('1_2767', '4_212')),\n"," (10, ('1_2767', '0_2628')),\n"," (11, ('1_1573', '4_2700')),\n"," (12, ('1_1573', '5_1514')),\n"," (13, ('3_1732', '1_1183')),\n"," (14, ('3_1888', '1_1183')),\n"," (15, ('3_1888', '3_1732')),\n"," (16, ('3_2500', '1_1183')),\n"," (17, ('3_2500', '3_1732')),\n"," (18, ('3_2500', '3_1888')),\n"," (19, ('1_2683', '3_1871')),\n"," (20, ('0_2315', '3_1871')),\n"," (21, ('0_2315', '1_2683')),\n"," (22, ('1_409', '0_555')),\n"," (23, ('1_1490', '2_2098')),\n"," (24, ('0_2081', '0_1279')),\n"," (25, ('1_1994', '2_2059')),\n"," (26, ('0_1537', '1_1228')),\n"," (27, ('4_1828', '4_1638')),\n"," (28, ('1_2148', '2_2713')),\n"," (29, ('5_1384', '3_1462')),\n"," (30, ('1_1734', '1_458')),\n"," (31, ('2_2690', '1_469')),\n"," (32, ('0_2491', '1_2872')),\n"," (33, ('2_334', '4_1876')),\n"," (34, ('5_366', '5_1900')),\n"," (35, ('2_2211', '3_2711')),\n"," (36, ('3_170', '2_289')),\n"," (37, ('1_885', '1_2030')),\n"," (38, ('3_1655', '0_1599')),\n"," (39, ('2_804', '0_1599')),\n"," (40, ('2_804', '3_1655')),\n"," (41, ('1_1199', '5_2246')),\n"," (42, ('1_2186', '4_2871')),\n"," (43, ('2_515', '1_1492')),\n"," (44, ('2_763', '1_2441')),\n"," (45, ('3_1299', '0_1504')),\n"," (46, ('5_1244', '3_1880')),\n"," (47, ('0_1014', '0_149')),\n"," (48, ('0_2427', '0_361')),\n"," (49, ('0_380', '0_361')),\n"," (50, ('0_380', '0_2427')),\n"," (51, ('4_364', '3_2560')),\n"," (52, ('2_2855', '0_1061')),\n"," (53, ('1_2265', '0_1061')),\n"," (54, ('1_2265', '2_2855')),\n"," (55, ('5_109', '1_1925')),\n"," (56, ('0_2780', '1_2532')),\n"," (57, ('1_574', '0_1860')),\n"," (58, ('0_473', '2_2776')),\n"," (59, ('0_2765', '1_636')),\n"," (60, ('1_1960', '0_580'))]"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["neuron_names = list(similar_pairs[11])\n","neuron_names.append(\"5_1514\")\n","\n","print(neuron_names)\n","\n","for neuron_name in neuron_names:\n","  layer, neuron = neuron_name.split(\"_\")\n","  path = f\"{base_path}/neuron_graphs/{model_name}/layer_{layer}/{layer}_{neuron}/graph.png\"\n","  view_neuron(path)"],"metadata":{"id":"pbjVqIOSgoCf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab = [token.replace(\"Ġ\", \"\").lower() for token in model.tokenizer.vocab]"],"metadata":{"id":"eM0Lt2YNB6FR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from collections import defaultdict, Counter\n","\n","neuron_to_repeats = defaultdict(list)\n","repeat_counter = Counter()\n","\n","for i, token in enumerate(vocab):\n","  repeat_neurons = neuron_store.search([\n","      (token, \"activating\"),\n","      (token, \"important\")\n","  ])\n","\n","  repeat_counter.update(repeat_neurons)\n","\n","  for neuron in repeat_neurons:\n","    neuron_to_repeats[neuron].append(token)\n","\n","repeat_ratio = Counter({neuron: repeat_count / neuron_store.neuron_total_token_counts[neuron] for neuron, repeat_count in repeat_counter.items()})"],"metadata":{"id":"1Rn_hWeIDZgM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["repeat_counter.most_common(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5gRDLwAPEJYI","executionInfo":{"status":"ok","timestamp":1683569755301,"user_tz":-60,"elapsed":19,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"6a552769-5dcc-4d65-ff6a-d0f6fcfb7a74"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('3_669', 86),\n"," ('3_2092', 78),\n"," ('4_1583', 67),\n"," ('2_510', 66),\n"," ('2_2348', 64),\n"," ('2_2470', 63),\n"," ('2_2806', 62),\n"," ('2_1552', 52),\n"," ('3_77', 49),\n"," ('2_2182', 49)]"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["repeat_ratio.most_common(20)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xSmry7lrKDUv","executionInfo":{"status":"ok","timestamp":1683569755301,"user_tz":-60,"elapsed":18,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"8f9575f6-f57a-403c-a67d-d8a435494b90"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('2_1250', 3.0),\n"," ('3_663', 2.75),\n"," ('3_921', 2.0),\n"," ('2_73', 2.0),\n"," ('1_73', 2.0),\n"," ('2_2096', 2.0),\n"," ('1_2531', 2.0),\n"," ('1_2117', 2.0),\n"," ('3_847', 2.0),\n"," ('2_3', 1.9411764705882353),\n"," ('2_2348', 1.8823529411764706),\n"," ('4_1042', 1.7142857142857142),\n"," ('3_1695', 1.6842105263157894),\n"," ('3_558', 1.6666666666666667),\n"," ('4_2619', 1.6666666666666667),\n"," ('4_451', 1.6428571428571428),\n"," ('2_1718', 1.6363636363636365),\n"," ('3_2304', 1.6),\n"," ('2_181', 1.5),\n"," ('2_1789', 1.5)]"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["token = \"i\"\n","neuron_store.search([\n","    (token, None),\n","    (\"=\", None),\n","])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z8j0zBpffHel","executionInfo":{"status":"ok","timestamp":1683921957427,"user_tz":-60,"elapsed":3,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"72c2480a-e09c-440e-8fd5-b45dd029c28c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'0_350',\n"," '2_1416',\n"," '2_589',\n"," '3_1301',\n"," '5_1806',\n"," '5_1877',\n"," '5_2137',\n"," '5_2786',\n"," '5_813',\n"," '5_908'}"]},"metadata":{},"execution_count":148}]},{"cell_type":"code","source":["neuron_name = \"2_1416\"\n","layer, neuron = neuron_name.split(\"_\")\n","path = f\"{base_path}/neuron_graphs/{model_name}/layer_{layer}/{layer}_{neuron}/graph.png\"\n","view_neuron(path)"],"metadata":{"id":"ZYOam4v6gueQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["neuron_name = \"2_683\"\n","layer, neuron = neuron_name.split(\"_\")\n","\n","_ = train_and_eval(model, int(layer), int(neuron), n=5, max_train_size=None, train_proportion=0.5, max_eval_size=None, activation_threshold=0.5, fire_threshold=0.5, importance_threshold=0.75, folder_name=\"test_examples\", neuron_store=test_neuron_store)\n","test_neuron_store.save()\n","\n","path = f\"{base_path}/neuron_graphs/{model_name}/test_examples/{layer}_{neuron}/graph.png\"\n","view_neuron(path)"],"metadata":{"id":"SMoJXwijgkM2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["neuron_store_2_100 = NeuronStore(f\"{base_path}/data/neuron_store_{model_name}_2_100.json\")\n","_ = train_and_eval(model, 2, 100, n=5, max_train_size=None, train_proportion=0.5, max_eval_size=None, activation_threshold=0.5, fire_threshold=0.5, importance_threshold=0.75, folder_name=\"fast_examples\", neuron_store=neuron_store_2_100)\n","neuron_store_2_100.save()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sYXH1_43uzWy","executionInfo":{"status":"ok","timestamp":1683236966025,"user_tz":-60,"elapsed":23789,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"9aab930a-d78b-44a1-d35d-084874746ca9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       0.99      1.00      1.00     10153\n","           1       0.54      0.24      0.33        87\n","\n","    accuracy                           0.99     10240\n","   macro avg       0.77      0.62      0.66     10240\n","weighted avg       0.99      0.99      0.99     10240\n","\n"]}]},{"cell_type":"code","source":["neuron_store_2_100.search([(\"to\", None)])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O1yeNinvyAeC","executionInfo":{"status":"ok","timestamp":1682953744539,"user_tz":-60,"elapsed":410,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"14f1d175-7f5f-4d7d-8601-35eb8c3de64a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'0_583', '1_2'}"]},"metadata":{},"execution_count":124}]},{"cell_type":"code","source":["_ = train_and_eval(model, 1, 2, n=0, max_train_size=None, train_proportion=0.3, random_state=0, max_eval_size=None, \n","                   activation_threshold=0.5, fire_threshold=0.5, importance_threshold=0.6, folder_name=\"fast_examples\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O1M8tPZ_X6MP","executionInfo":{"status":"ok","timestamp":1682952387012,"user_tz":-60,"elapsed":3746,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"34058e16-da40-44bf-c173-3c075155cde6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing 1 of 6\n","Processing 2 of 6\n","Processing 3 of 6\n","Processing 4 of 6\n","Processing 5 of 6\n","Processing 6 of 6\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14322\n","           1       0.92      0.79      0.85        14\n","\n","    accuracy                           1.00     14336\n","   macro avg       0.96      0.89      0.92     14336\n","weighted avg       1.00      1.00      1.00     14336\n","\n"]}]},{"cell_type":"code","source":["%%time\n","interesting_layers_and_neurons = [\n","    (0, 365),\n","    (0, 375),\n","    (0, 1577),\n","    (0, 583),\n","    (1, 158),\n","    (1, 903),\n","    (2, 39),\n","    (2, 42),\n","    (3, 13),\n","    (3, 15),\n","    (3, 28),\n","    (4, 9),\n","    (4, 13),\n","    (4, 22),\n","    (4, 337),\n","    (5, 9),\n","    (5, 83),\n","    (5, 2309)\n","]\n","if True:\n","  for layer, neuron in interesting_layers_and_neurons:\n","    print(layer, neuron)\n","    _ = train_and_eval(model, layer, neuron, n=5, max_train_size=None, train_proportion=0.5, max_eval_size=None, activation_threshold=0.5, fire_threshold=0.5, importance_threshold=0.75, folder_name=\"new_fast_examples\", neuron_store=test_neuron_store)\n","  neuron_store.save()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"myYo_V82sFyr","executionInfo":{"status":"ok","timestamp":1683750534293,"user_tz":-60,"elapsed":167827,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"6e12d161-6f61-4802-c88f-8eaee7b3ce85"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0 365\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      1.00      1.00        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","0 375\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10196\n","           1       0.26      1.00      0.41        13\n","\n","    accuracy                           1.00     10209\n","   macro avg       0.63      1.00      0.71     10209\n","weighted avg       1.00      1.00      1.00     10209\n","\n","0 1577\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10221\n","           1       0.59      1.00      0.74        16\n","\n","    accuracy                           1.00     10237\n","   macro avg       0.80      1.00      0.87     10237\n","weighted avg       1.00      1.00      1.00     10237\n","\n","0 583\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       1.00      0.92      0.96        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.96      0.98     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","1 158\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.92      1.00      0.96        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.96      1.00      0.98     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","1 903\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10212\n","           1       0.96      0.93      0.95        28\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.98      0.96      0.97     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","2 39\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       1.00      0.82      0.90        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.91      0.95     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","2 42\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      0.90      0.95        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.95      0.97     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","3 13\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.83      1.00      0.91        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.92      1.00      0.95     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","3 15\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Warning: node '2', graph '%3' size too small for label\n","Warning: node '2', graph '%3' size too small for label\n"]},{"output_type":"stream","name":"stdout","text":["Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.20      0.09      0.13        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.60      0.55      0.56     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","3 28\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      1.00      1.00        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","4 9\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.91      1.00      0.95        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.95      1.00      0.98     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","4 13\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      0.90      0.95        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.95      0.97     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","4 22\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.91      1.00      0.95        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.95      1.00      0.98     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","4 337\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     10229\n","           1       0.12      1.00      0.22        11\n","\n","    accuracy                           0.99     10240\n","   macro avg       0.56      1.00      0.61     10240\n","weighted avg       1.00      0.99      1.00     10240\n","\n","5 9\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10203\n","           1       1.00      0.90      0.95        10\n","\n","    accuracy                           1.00     10213\n","   macro avg       1.00      0.95      0.97     10213\n","weighted avg       1.00      1.00      1.00     10213\n","\n","5 83\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.17      0.90      0.29        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.58      0.95      0.64     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","5 2309\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.34      1.00      0.51        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.67      1.00      0.76     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","CPU times: user 2min 30s, sys: 624 ms, total: 2min 30s\n","Wall time: 2min 47s\n"]}]},{"cell_type":"code","source":["%%time\n","\n","import random\n","\n","random.seed(0)\n","\n","layer = 0\n","neurons = 3072\n","all_neuron_indices = [i for i in range(neurons)]\n","\n","all_stats = {}\n","folder_name = f\"layer_{layer}\"\n","\n","neuron_store = NeuronStore(f\"{base_path}/neuron_graphs/{model_name}/neuron_store.json\")\n","\n","if True:\n","  chosen_neuron_indices = all_neuron_indices\n","  all_stats[layer] = {}\n","  for i, neuron in enumerate(chosen_neuron_indices):\n","    print(f\"{layer=} {neuron=}\")\n","    try:\n","      stats = train_and_eval(model, layer, neuron, n=5, max_train_size=None, train_proportion=0.5, max_eval_size=None, activation_threshold=0.5, fire_threshold=0.5, importance_threshold=0.75, folder_name=folder_name, neuron_store=neuron_store)\n","      \n","      all_stats[layer][neuron] = stats\n","\n","      if i % 10 == 0:\n","        neuron_store.save()\n","        with open(os.path.join(base_path, f\"neuron_graphs/{model_name}/{folder_name}/stats.json\"), \"w\") as ofh:\n","          json.dump(all_stats, ofh, indent=2)\n","\n","    except Exception as e:\n","      print(e)\n","      print(\"Failed\")\n","\n","neuron_store.save()\n","with open(os.path.join(base_path, f\"neuron_graphs/{model_name}/{folder_name}/stats.json\"), \"w\") as ofh:\n","  json.dump(all_stats, ofh, indent=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1jrX553rk_OvjEmoqbTL_zL_6X5xpNC2b"},"id":"DfNhKJZCtxxa","executionInfo":{"status":"ok","timestamp":1683857234326,"user_tz":-60,"elapsed":16920128,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"fda9609d-1aab-4f29-c15e-78c9ab8ea9c5"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["neuron_store.search([(\"trump\", None)])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oVNCQpBGzdAL","executionInfo":{"status":"ok","timestamp":1683270697458,"user_tz":-60,"elapsed":423,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"48e67099-cb05-4d0a-af84-ad5bca636417"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'3_1723', '3_2728', '3_3030', '3_591'}"]},"metadata":{},"execution_count":122}]},{"cell_type":"code","source":["%%time\n","\n","import random\n","\n","random.seed(0)\n","\n","layers = 6\n","neurons = 3072\n","all_neuron_indices = [i for i in range(neurons)]\n","\n","all_stats = []\n","folder_name = \"eval_4\"\n","\n","if False:\n","  for layer in range(6):\n","    chosen_neuron_indices = sorted(random.sample(all_neuron_indices, 100))\n","    all_stats.append({})\n","    for neuron in chosen_neuron_indices:\n","      print(f\"{layer=} {neuron=}\")\n","      try:\n","        stats = train_and_eval(model, layer, neuron, n=5, max_train_size=None, train_proportion=0.5, max_eval_size=None, activation_threshold=0.5, fire_threshold=0.5, importance_threshold=0.75, folder_name=folder_name)\n","        all_stats[layer][neuron] = stats\n","      except Exception as e:\n","        print(e)\n","        print(\"Failed\")\n","\n","with open(os.path.join(base_path, f\"neuron_graphs/{model_name}/{folder_name}/stats.json\"), \"w\") as ofh:\n","  json.dump(all_stats, ofh, indent=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N02q7_ncfGm8","executionInfo":{"status":"ok","timestamp":1679812967878,"user_tz":-60,"elapsed":36825074,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"7f32f5ce-a16e-4084-fa25-1373d28c5217"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["layer=0 neuron=4\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10219\n","           1       0.37      0.92      0.52        12\n","\n","    accuracy                           1.00     10231\n","   macro avg       0.68      0.96      0.76     10231\n","weighted avg       1.00      1.00      1.00     10231\n","\n","layer=0 neuron=57\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10226\n","           1       0.88      1.00      0.93        14\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.94      1.00      0.97     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=135\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10173\n","           1       1.00      0.79      0.88        19\n","\n","    accuracy                           1.00     10192\n","   macro avg       1.00      0.89      0.94     10192\n","weighted avg       1.00      1.00      1.00     10192\n","\n","layer=0 neuron=165\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10159\n","           1       1.00      0.96      0.98        27\n","\n","    accuracy                           1.00     10186\n","   macro avg       1.00      0.98      0.99     10186\n","weighted avg       1.00      1.00      1.00     10186\n","\n","layer=0 neuron=255\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10226\n","           1       1.00      1.00      1.00        12\n","\n","    accuracy                           1.00     10238\n","   macro avg       1.00      1.00      1.00     10238\n","weighted avg       1.00      1.00      1.00     10238\n","\n","layer=0 neuron=257\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.56      1.00      0.71        10\n","\n","    accuracy                           1.00     10239\n","   macro avg       0.78      1.00      0.86     10239\n","weighted avg       1.00      1.00      1.00     10239\n","\n","layer=0 neuron=302\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10225\n","           1       0.94      1.00      0.97        15\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.97      1.00      0.98     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=329\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10225\n","           1       0.87      1.00      0.93        13\n","\n","    accuracy                           1.00     10238\n","   macro avg       0.93      1.00      0.96     10238\n","weighted avg       1.00      1.00      1.00     10238\n","\n","layer=0 neuron=373\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10175\n","           1       0.27      0.84      0.41        19\n","\n","    accuracy                           1.00     10194\n","   macro avg       0.63      0.92      0.70     10194\n","weighted avg       1.00      1.00      1.00     10194\n","\n","layer=0 neuron=375\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10196\n","           1       0.26      1.00      0.41        13\n","\n","    accuracy                           1.00     10209\n","   macro avg       0.63      1.00      0.71     10209\n","weighted avg       1.00      1.00      1.00     10209\n","\n","layer=0 neuron=382\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.90      0.90      0.90        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.95      0.95      0.95     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=388\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       1.00      0.83      0.91        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.92      0.95     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=404\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.32      0.50      0.39        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.66      0.75      0.69     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=412\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.44      0.58      0.50        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.72      0.79      0.75     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=446\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00      9832\n","           1       0.15      1.00      0.26        10\n","\n","    accuracy                           0.99      9842\n","   macro avg       0.57      1.00      0.63      9842\n","weighted avg       1.00      0.99      1.00      9842\n","\n","layer=0 neuron=511\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      0.90      0.95        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.95      0.97     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=570\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10226\n","           1       0.48      0.79      0.59        14\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.74      0.89      0.80     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=572\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10166\n","           1       0.78      1.00      0.88        14\n","\n","    accuracy                           1.00     10180\n","   macro avg       0.89      1.00      0.94     10180\n","weighted avg       1.00      1.00      1.00     10180\n","\n","layer=0 neuron=583\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       1.00      0.92      0.96        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.96      0.98     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=601\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       1.00      0.92      0.96        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.96      0.98     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=753\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99     10192\n","           1       0.20      0.92      0.32        48\n","\n","    accuracy                           0.98     10240\n","   macro avg       0.60      0.95      0.66     10240\n","weighted avg       1.00      0.98      0.99     10240\n","\n","layer=0 neuron=764\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10007\n","           1       0.42      1.00      0.59         8\n","\n","    accuracy                           1.00     10015\n","   macro avg       0.71      1.00      0.80     10015\n","weighted avg       1.00      1.00      1.00     10015\n","\n","layer=0 neuron=775\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10227\n","           1       1.00      1.00      1.00        13\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=782\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.59      1.00      0.74        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.79      1.00      0.87     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=832\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10213\n","           1       0.87      0.74      0.80        27\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.93      0.87      0.90     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=837\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       1.00      1.00      1.00        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=894\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10161\n","           1       0.88      0.78      0.82         9\n","\n","    accuracy                           1.00     10170\n","   macro avg       0.94      0.89      0.91     10170\n","weighted avg       1.00      1.00      1.00     10170\n","\n","layer=0 neuron=908\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10227\n","           1       0.81      1.00      0.90        13\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.91      1.00      0.95     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=977\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      9899\n","           1       1.00      0.86      0.92         7\n","\n","    accuracy                           1.00      9906\n","   macro avg       1.00      0.93      0.96      9906\n","weighted avg       1.00      1.00      1.00      9906\n","\n","layer=0 neuron=991\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10226\n","           1       1.00      1.00      1.00        14\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=999\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10227\n","           1       0.28      0.77      0.41        13\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.64      0.88      0.70     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=1026\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10222\n","           1       0.59      0.56      0.57        18\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.79      0.78      0.79     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=1060\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10218\n","           1       0.57      0.59      0.58        22\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.78      0.79      0.79     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=1066\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10220\n","           1       0.77      1.00      0.87        20\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.88      1.00      0.93     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=1154\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       1.00      1.00      1.00        10\n","\n","    accuracy                           1.00     10239\n","   macro avg       1.00      1.00      1.00     10239\n","weighted avg       1.00      1.00      1.00     10239\n","\n","layer=0 neuron=1178\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.91      1.00      0.95        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.95      1.00      0.98     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=1189\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      9544\n","           1       1.00      0.78      0.88         9\n","\n","    accuracy                           1.00      9553\n","   macro avg       1.00      0.89      0.94      9553\n","weighted avg       1.00      1.00      1.00      9553\n","\n","layer=0 neuron=1192\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10103\n","           1       0.87      1.00      0.93       137\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.93      1.00      0.96     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=1234\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      0.90      0.95        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.95      0.97     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=1242\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10156\n","           1       1.00      1.00      1.00        11\n","\n","    accuracy                           1.00     10167\n","   macro avg       1.00      1.00      1.00     10167\n","weighted avg       1.00      1.00      1.00     10167\n","\n","layer=0 neuron=1270\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Warning: node '12', graph '%3' size too small for label\n","Warning: node '13', graph '%3' size too small for label\n","Warning: node '14', graph '%3' size too small for label\n","Warning: node '7', graph '%3' size too small for label\n","Warning: node '11', graph '%3' size too small for label\n","Warning: node '12', graph '%3' size too small for label\n","Warning: node '13', graph '%3' size too small for label\n","Warning: node '14', graph '%3' size too small for label\n","Warning: node '7', graph '%3' size too small for label\n","Warning: node '11', graph '%3' size too small for label\n"]},{"output_type":"stream","name":"stdout","text":["Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10204\n","           1       0.55      0.50      0.52        36\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.77      0.75      0.76     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=1295\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      8684\n","           1       0.02      1.00      0.05         1\n","\n","    accuracy                           1.00      8685\n","   macro avg       0.51      1.00      0.52      8685\n","weighted avg       1.00      1.00      1.00      8685\n","\n","layer=0 neuron=1298\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.86      0.92      9685\n","           1       0.09      0.81      0.16       161\n","\n","    accuracy                           0.86      9846\n","   macro avg       0.54      0.84      0.54      9846\n","weighted avg       0.98      0.86      0.91      9846\n","\n","layer=0 neuron=1310\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10217\n","           1       0.39      0.92      0.55        13\n","\n","    accuracy                           1.00     10230\n","   macro avg       0.69      0.96      0.77     10230\n","weighted avg       1.00      1.00      1.00     10230\n","\n","layer=0 neuron=1332\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.91      0.91      0.91        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.95      0.95      0.95     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=1352\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10215\n","           1       0.86      0.76      0.81        25\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.93      0.88      0.90     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=1362\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10215\n","           1       0.78      0.95      0.86        22\n","\n","    accuracy                           1.00     10237\n","   macro avg       0.89      0.98      0.93     10237\n","weighted avg       1.00      1.00      1.00     10237\n","\n","layer=0 neuron=1364\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10224\n","           1       1.00      1.00      1.00        16\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=1449\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10208\n","           1       1.00      1.00      1.00        15\n","\n","    accuracy                           1.00     10223\n","   macro avg       1.00      1.00      1.00     10223\n","weighted avg       1.00      1.00      1.00     10223\n","\n","layer=0 neuron=1466\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10174\n","           1       0.95      0.97      0.96        40\n","\n","    accuracy                           1.00     10214\n","   macro avg       0.98      0.99      0.98     10214\n","weighted avg       1.00      1.00      1.00     10214\n","\n","layer=0 neuron=1576\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10222\n","           1       1.00      0.94      0.97        18\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.97      0.99     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=1577\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10221\n","           1       0.59      1.00      0.74        16\n","\n","    accuracy                           1.00     10237\n","   macro avg       0.80      1.00      0.87     10237\n","weighted avg       1.00      1.00      1.00     10237\n","\n","layer=0 neuron=1633\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.91      1.00      0.95        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.95      1.00      0.98     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=1658\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: graph: syntax error in line 12 near '>'\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b\"Error: graph: syntax error in line 12 near '>'\\n\"]\n","Failed\n","layer=0 neuron=1722\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Warning: node '8', graph '%3' size too small for label\n","Warning: node '8', graph '%3' size too small for label\n"]},{"output_type":"stream","name":"stdout","text":["Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      0.90      0.95        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.95      0.97     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=1778\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      1.00      1.00        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=1813\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10215\n","           1       0.95      0.86      0.90        21\n","\n","    accuracy                           1.00     10236\n","   macro avg       0.97      0.93      0.95     10236\n","weighted avg       1.00      1.00      1.00     10236\n","\n","layer=0 neuron=1822\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      9784\n","           1       1.00      0.25      0.40        12\n","\n","    accuracy                           1.00      9796\n","   macro avg       1.00      0.62      0.70      9796\n","weighted avg       1.00      1.00      1.00      9796\n","\n","layer=0 neuron=1834\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.83      0.83      0.83        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.92      0.92      0.92     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=1933\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99     10008\n","           1       0.52      1.00      0.68       230\n","\n","    accuracy                           0.98     10238\n","   macro avg       0.76      0.99      0.84     10238\n","weighted avg       0.99      0.98      0.98     10238\n","\n","layer=0 neuron=1952\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      9227\n","           1       0.87      0.93      0.90        14\n","\n","    accuracy                           1.00      9241\n","   macro avg       0.93      0.96      0.95      9241\n","weighted avg       1.00      1.00      1.00      9241\n","\n","layer=0 neuron=1953\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10226\n","           1       1.00      1.00      1.00        14\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=1990\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      0.80      0.89        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.90      0.94     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=2004\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10221\n","           1       0.92      0.71      0.80        17\n","\n","    accuracy                           1.00     10238\n","   macro avg       0.96      0.85      0.90     10238\n","weighted avg       1.00      1.00      1.00     10238\n","\n","layer=0 neuron=2021\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      0.99     10219\n","           1       0.11      0.71      0.18        21\n","\n","    accuracy                           0.99     10240\n","   macro avg       0.55      0.85      0.59     10240\n","weighted avg       1.00      0.99      0.99     10240\n","\n","layer=0 neuron=2067\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10208\n","           1       0.37      1.00      0.54        25\n","\n","    accuracy                           1.00     10233\n","   macro avg       0.69      1.00      0.77     10233\n","weighted avg       1.00      1.00      1.00     10233\n","\n","layer=0 neuron=2080\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10225\n","           1       0.33      0.40      0.36        15\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.67      0.70      0.68     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=2094\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.93      0.96     10226\n","           1       0.02      1.00      0.03        13\n","\n","    accuracy                           0.93     10239\n","   macro avg       0.51      0.96      0.50     10239\n","weighted avg       1.00      0.93      0.96     10239\n","\n","layer=0 neuron=2135\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10226\n","           1       1.00      1.00      1.00        14\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=2181\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       1.00      1.00      1.00        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=2213\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.97      0.98      9249\n","           1       0.03      1.00      0.05         8\n","\n","    accuracy                           0.97      9257\n","   macro avg       0.51      0.98      0.52      9257\n","weighted avg       1.00      0.97      0.98      9257\n","\n","layer=0 neuron=2224\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     10220\n","           1       0.16      1.00      0.27        18\n","\n","    accuracy                           0.99     10238\n","   macro avg       0.58      1.00      0.63     10238\n","weighted avg       1.00      0.99      0.99     10238\n","\n","layer=0 neuron=2241\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.96      0.98     10117\n","           1       0.26      1.00      0.41       123\n","\n","    accuracy                           0.96     10240\n","   macro avg       0.63      0.98      0.69     10240\n","weighted avg       0.99      0.96      0.98     10240\n","\n","layer=0 neuron=2242\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10213\n","           1       0.87      1.00      0.93        27\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.94      1.00      0.97     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=2247\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Warning: node '4', graph '%3' size too small for label\n","Warning: node '4', graph '%3' size too small for label\n"]},{"output_type":"stream","name":"stdout","text":["Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.91      0.91      0.91        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.95      0.95      0.95     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=2257\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       1.00      0.36      0.53        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.68      0.77     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=2263\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10202\n","           1       0.96      0.96      0.96        25\n","\n","    accuracy                           1.00     10227\n","   macro avg       0.98      0.98      0.98     10227\n","weighted avg       1.00      1.00      1.00     10227\n","\n","layer=0 neuron=2292\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10223\n","           1       1.00      0.53      0.69        17\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.76      0.85     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=2324\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10208\n","           1       0.95      0.70      0.81        30\n","\n","    accuracy                           1.00     10238\n","   macro avg       0.98      0.85      0.90     10238\n","weighted avg       1.00      1.00      1.00     10238\n","\n","layer=0 neuron=2357\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       1.00      0.92      0.96        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.96      0.98     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=2389\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.92      0.96     10209\n","           1       0.04      1.00      0.07        31\n","\n","    accuracy                           0.92     10240\n","   macro avg       0.52      0.96      0.51     10240\n","weighted avg       1.00      0.92      0.95     10240\n","\n","layer=0 neuron=2406\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       1.00      1.00      1.00        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=2442\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10224\n","           1       0.43      0.81      0.57        16\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.72      0.91      0.78     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=2465\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10207\n","           1       0.43      0.86      0.57        14\n","\n","    accuracy                           1.00     10221\n","   macro avg       0.71      0.93      0.79     10221\n","weighted avg       1.00      1.00      1.00     10221\n","\n","layer=0 neuron=2470\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10219\n","           1       0.95      1.00      0.98        21\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.98      1.00      0.99     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=2502\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       1.00      1.00      1.00        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=2506\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      1.00      1.00        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=2509\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      0.90      0.95        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.95      0.97     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=2532\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10212\n","           1       0.38      0.93      0.54        28\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.69      0.96      0.77     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=2561\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10217\n","           1       1.00      0.91      0.95        22\n","\n","    accuracy                           1.00     10239\n","   macro avg       1.00      0.95      0.98     10239\n","weighted avg       1.00      1.00      1.00     10239\n","\n","layer=0 neuron=2623\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: not well-formed (invalid token) in line 1 \n","... <B> \u0003  ...\n","in label of node 1\n","Error: not well-formed (invalid token) in line 1 \n","... <B> \u0016  ...\n","in label of node 6\n","Error: not well-formed (invalid token) in line 1 \n","... <B> \u0015  ...\n","in label of node 7\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b'Error: not well-formed (invalid token) in line 1 \\n... <B> \\x03  ...\\nin label of node 1\\nError: not well-formed (invalid token) in line 1 \\n... <B> \\x16  ...\\nin label of node 6\\nError: not well-formed (invalid token) in line 1 \\n... <B> \\x15  ...\\nin label of node 7\\n']\n","Failed\n","layer=0 neuron=2736\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10227\n","           1       0.92      0.85      0.88        13\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.96      0.92      0.94     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=2801\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: graph: syntax error in line 27 near '>'\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b\"Error: graph: syntax error in line 27 near '>'\\n\"]\n","Failed\n","layer=0 neuron=2882\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      0.60      0.75        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.80      0.87     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=2888\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      9859\n","           1       0.00      0.00      0.00         1\n","\n","    accuracy                           1.00      9860\n","   macro avg       0.50      0.50      0.50      9860\n","weighted avg       1.00      1.00      1.00      9860\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["layer=0 neuron=2894\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10240\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=2909\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       1.00      0.75      0.86        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.88      0.93     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=2947\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      1.00      1.00        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=0 neuron=2989\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10221\n","           1       0.60      0.50      0.55        18\n","\n","    accuracy                           1.00     10239\n","   macro avg       0.80      0.75      0.77     10239\n","weighted avg       1.00      1.00      1.00     10239\n","\n","layer=0 neuron=2991\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10119\n","           1       0.83      0.91      0.87        11\n","\n","    accuracy                           1.00     10130\n","   macro avg       0.92      0.95      0.93     10130\n","weighted avg       1.00      1.00      1.00     10130\n","\n","layer=1 neuron=66\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.75      1.00      0.86        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.88      1.00      0.93     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=88\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.71      1.00      0.83        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.86      1.00      0.92     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=93\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10222\n","           1       1.00      0.94      0.97        16\n","\n","    accuracy                           1.00     10238\n","   macro avg       1.00      0.97      0.98     10238\n","weighted avg       1.00      1.00      1.00     10238\n","\n","layer=1 neuron=109\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: graph: syntax error in line 31 scanning a HTML string (missing '>'? bad nesting? longer than 16384?)\n","String starting:< <B> < </B> > fillcolor=\"#1010ff\" fontcolor=white fontsize=25 penwidth=7 shape=c\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b'Error: graph: syntax error in line 31 scanning a HTML string (missing \\'>\\'? bad nesting? longer than 16384?)\\nString starting:< <B> < </B> > fillcolor=\"#1010ff\" fontcolor=white fontsize=25 penwidth=7 shape=c\\n']\n","Failed\n","layer=1 neuron=149\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10214\n","           1       0.95      0.86      0.90        22\n","\n","    accuracy                           1.00     10236\n","   macro avg       0.97      0.93      0.95     10236\n","weighted avg       1.00      1.00      1.00     10236\n","\n","layer=1 neuron=158\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.92      1.00      0.96        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.96      1.00      0.98     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=185\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.71      1.00      0.83        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.86      1.00      0.92     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=250\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.71      1.00      0.83        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.86      1.00      0.92     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=254\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.71      0.91      0.80        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.86      0.95      0.90     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=282\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.83      1.00      0.91        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.92      1.00      0.95     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=286\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10213\n","           1       0.46      0.92      0.62        13\n","\n","    accuracy                           1.00     10226\n","   macro avg       0.73      0.96      0.81     10226\n","weighted avg       1.00      1.00      1.00     10226\n","\n","layer=1 neuron=294\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.91      1.00      0.95        10\n","\n","    accuracy                           1.00     10239\n","   macro avg       0.95      1.00      0.98     10239\n","weighted avg       1.00      1.00      1.00     10239\n","\n","layer=1 neuron=303\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      9132\n","           1       0.00      0.00      0.00         1\n","\n","    accuracy                           1.00      9133\n","   macro avg       0.50      0.50      0.50      9133\n","weighted avg       1.00      1.00      1.00      9133\n","\n","layer=1 neuron=328\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10178\n","           1       1.00      0.60      0.75        10\n","\n","    accuracy                           1.00     10188\n","   macro avg       1.00      0.80      0.87     10188\n","weighted avg       1.00      1.00      1.00     10188\n","\n","layer=1 neuron=337\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10227\n","           1       0.57      1.00      0.73        12\n","\n","    accuracy                           1.00     10239\n","   macro avg       0.79      1.00      0.86     10239\n","weighted avg       1.00      1.00      1.00     10239\n","\n","layer=1 neuron=367\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     10230\n","           1       0.12      1.00      0.21        10\n","\n","    accuracy                           0.99     10240\n","   macro avg       0.56      1.00      0.60     10240\n","weighted avg       1.00      0.99      1.00     10240\n","\n","layer=1 neuron=374\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10227\n","           1       0.43      0.77      0.56        13\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.72      0.88      0.78     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=412\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       1.00      0.73      0.84        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.86      0.92     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=415\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99     10204\n","           1       0.15      1.00      0.26        36\n","\n","    accuracy                           0.98     10240\n","   macro avg       0.57      0.99      0.62     10240\n","weighted avg       1.00      0.98      0.99     10240\n","\n","layer=1 neuron=472\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.79      0.92      0.85        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.89      0.96      0.92     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=475\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10226\n","           1       0.91      0.91      0.91        11\n","\n","    accuracy                           1.00     10237\n","   macro avg       0.95      0.95      0.95     10237\n","weighted avg       1.00      1.00      1.00     10237\n","\n","layer=1 neuron=479\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       1.00      0.82      0.90        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.91      0.95     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=490\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.85      1.00      0.92        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.92      1.00      0.96     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=507\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      1.00      1.00        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=509\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      1.00      1.00        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=533\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10225\n","           1       1.00      1.00      1.00        11\n","\n","    accuracy                           1.00     10236\n","   macro avg       1.00      1.00      1.00     10236\n","weighted avg       1.00      1.00      1.00     10236\n","\n","layer=1 neuron=599\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10231\n","           1       0.41      1.00      0.58         9\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.70      1.00      0.79     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=612\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10225\n","           1       0.92      1.00      0.96        12\n","\n","    accuracy                           1.00     10237\n","   macro avg       0.96      1.00      0.98     10237\n","weighted avg       1.00      1.00      1.00     10237\n","\n","layer=1 neuron=698\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.86      0.92     10118\n","           1       0.08      0.98      0.14       122\n","\n","    accuracy                           0.86     10240\n","   macro avg       0.54      0.92      0.53     10240\n","weighted avg       0.99      0.86      0.91     10240\n","\n","layer=1 neuron=738\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.85      1.00      0.92        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.92      1.00      0.96     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=757\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       1.00      0.42      0.59        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.71      0.79     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=772\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.93      0.96     10226\n","           1       0.02      1.00      0.04        14\n","\n","    accuracy                           0.93     10240\n","   macro avg       0.51      0.96      0.50     10240\n","weighted avg       1.00      0.93      0.96     10240\n","\n","layer=1 neuron=779\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10227\n","           1       0.44      0.92      0.60        13\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.72      0.96      0.80     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=797\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      1.00      1.00        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=862\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      1.00      1.00        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=881\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.00      0.00      0.00        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.50      0.50      0.50     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=896\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10220\n","           1       1.00      0.58      0.74        12\n","\n","    accuracy                           1.00     10232\n","   macro avg       1.00      0.79      0.87     10232\n","weighted avg       1.00      1.00      1.00     10232\n","\n","layer=1 neuron=903\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10212\n","           1       0.96      0.93      0.95        28\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.98      0.96      0.97     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=904\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10168\n","           1       0.86      1.00      0.92        12\n","\n","    accuracy                           1.00     10180\n","   macro avg       0.93      1.00      0.96     10180\n","weighted avg       1.00      1.00      1.00     10180\n","\n","layer=1 neuron=964\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.39      0.70      0.50        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.69      0.85      0.75     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=995\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10227\n","           1       1.00      0.50      0.67        12\n","\n","    accuracy                           1.00     10239\n","   macro avg       1.00      0.75      0.83     10239\n","weighted avg       1.00      1.00      1.00     10239\n","\n","layer=1 neuron=1064\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       1.00      0.73      0.84        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.86      0.92     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=1065\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.40      1.00      0.57        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.70      1.00      0.79     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=1110\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99     10227\n","           1       0.06      1.00      0.12        13\n","\n","    accuracy                           0.98     10240\n","   macro avg       0.53      0.99      0.56     10240\n","weighted avg       1.00      0.98      0.99     10240\n","\n","layer=1 neuron=1127\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      0.10      0.18        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.55      0.59     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=1128\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.65      1.00      0.79        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.82      1.00      0.89     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=1233\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.11      0.27      0.16        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.56      0.64      0.58     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=1328\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10227\n","           1       0.83      1.00      0.91        10\n","\n","    accuracy                           1.00     10237\n","   macro avg       0.92      1.00      0.95     10237\n","weighted avg       1.00      1.00      1.00     10237\n","\n","layer=1 neuron=1362\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10192\n","           1       0.90      0.82      0.86        11\n","\n","    accuracy                           1.00     10203\n","   macro avg       0.95      0.91      0.93     10203\n","weighted avg       1.00      1.00      1.00     10203\n","\n","layer=1 neuron=1373\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10216\n","           1       0.53      0.91      0.67        11\n","\n","    accuracy                           1.00     10227\n","   macro avg       0.76      0.95      0.83     10227\n","weighted avg       1.00      1.00      1.00     10227\n","\n","layer=1 neuron=1434\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10224\n","           1       1.00      0.50      0.67        16\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.75      0.83     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=1463\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: not well-formed (invalid token) in line 1 \n","... <B> &  ...\n","in label of node 4\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b'Error: not well-formed (invalid token) in line 1 \\n... <B> &  ...\\nin label of node 4\\n']\n","Failed\n","layer=1 neuron=1516\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      1.00      1.00        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=1523\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10205\n","           1       0.67      1.00      0.80        14\n","\n","    accuracy                           1.00     10219\n","   macro avg       0.83      1.00      0.90     10219\n","weighted avg       1.00      1.00      1.00     10219\n","\n","layer=1 neuron=1602\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: graph: syntax error in line 36 scanning a HTML string (missing '>'? bad nesting? longer than 16384?)\n","String starting:< <B> < </B> > fillcolor=\"#1313ff\" fontcolor=white fontsize=25 penwidth=3 shape=c\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b'Error: graph: syntax error in line 36 scanning a HTML string (missing \\'>\\'? bad nesting? longer than 16384?)\\nString starting:< <B> < </B> > fillcolor=\"#1313ff\" fontcolor=white fontsize=25 penwidth=3 shape=c\\n']\n","Failed\n","layer=1 neuron=1717\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.69      0.90      0.78        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.85      0.95      0.89     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=1743\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      9679\n","           1       0.29      1.00      0.44        16\n","\n","    accuracy                           1.00      9695\n","   macro avg       0.64      1.00      0.72      9695\n","weighted avg       1.00      1.00      1.00      9695\n","\n","layer=1 neuron=1745\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.71      1.00      0.83        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.86      1.00      0.92     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=1786\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10222\n","           1       0.48      0.94      0.64        16\n","\n","    accuracy                           1.00     10238\n","   macro avg       0.74      0.97      0.82     10238\n","weighted avg       1.00      1.00      1.00     10238\n","\n","layer=1 neuron=1845\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.50      0.10      0.17        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.75      0.55      0.58     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=1951\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      0.80      0.89        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.90      0.94     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=1962\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.29      0.45      0.36        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.65      0.73      0.68     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=1992\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      0.99     10230\n","           1       0.07      0.90      0.13        10\n","\n","    accuracy                           0.99     10240\n","   macro avg       0.53      0.94      0.56     10240\n","weighted avg       1.00      0.99      0.99     10240\n","\n","layer=1 neuron=2017\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     10067\n","           1       0.70      1.00      0.83       173\n","\n","    accuracy                           0.99     10240\n","   macro avg       0.85      1.00      0.91     10240\n","weighted avg       0.99      0.99      0.99     10240\n","\n","layer=1 neuron=2062\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.67      0.60      0.63        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.83      0.80      0.82     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=2137\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      0.99     10230\n","           1       0.06      0.70      0.11        10\n","\n","    accuracy                           0.99     10240\n","   macro avg       0.53      0.84      0.55     10240\n","weighted avg       1.00      0.99      0.99     10240\n","\n","layer=1 neuron=2148\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.97      0.99     10226\n","           1       0.05      1.00      0.09        14\n","\n","    accuracy                           0.97     10240\n","   macro avg       0.52      0.99      0.54     10240\n","weighted avg       1.00      0.97      0.99     10240\n","\n","layer=1 neuron=2188\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.67      1.00      0.80        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.83      1.00      0.90     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=2214\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       1.00      0.92      0.96        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.96      0.98     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=2229\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      9540\n","           1       0.57      0.73      0.64        11\n","\n","    accuracy                           1.00      9551\n","   macro avg       0.79      0.86      0.82      9551\n","weighted avg       1.00      1.00      1.00      9551\n","\n","layer=1 neuron=2350\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10224\n","           1       0.77      1.00      0.87        10\n","\n","    accuracy                           1.00     10234\n","   macro avg       0.88      1.00      0.93     10234\n","weighted avg       1.00      1.00      1.00     10234\n","\n","layer=1 neuron=2359\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10223\n","           1       0.60      0.88      0.71        17\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.80      0.94      0.86     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=2374\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      0.80      0.89        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.90      0.94     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=2404\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      0.99     10228\n","           1       0.07      1.00      0.14        12\n","\n","    accuracy                           0.99     10240\n","   macro avg       0.54      0.99      0.57     10240\n","weighted avg       1.00      0.99      0.99     10240\n","\n","layer=1 neuron=2415\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10240\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=2466\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10227\n","           1       0.62      1.00      0.76        13\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.81      1.00      0.88     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=2480\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.71      1.00      0.83        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.86      1.00      0.92     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=2483\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       1.00      0.82      0.90        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.91      0.95     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=2509\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10158\n","           1       1.00      1.00      1.00        10\n","\n","    accuracy                           1.00     10168\n","   macro avg       1.00      1.00      1.00     10168\n","weighted avg       1.00      1.00      1.00     10168\n","\n","layer=1 neuron=2541\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10164\n","           1       0.80      0.80      0.80        15\n","\n","    accuracy                           1.00     10179\n","   macro avg       0.90      0.90      0.90     10179\n","weighted avg       1.00      1.00      1.00     10179\n","\n","layer=1 neuron=2581\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10218\n","           1       0.80      0.80      0.80        10\n","\n","    accuracy                           1.00     10228\n","   macro avg       0.90      0.90      0.90     10228\n","weighted avg       1.00      1.00      1.00     10228\n","\n","layer=1 neuron=2597\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10240\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=2600\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10169\n","           1       0.67      1.00      0.80        10\n","\n","    accuracy                           1.00     10179\n","   macro avg       0.83      1.00      0.90     10179\n","weighted avg       1.00      1.00      1.00     10179\n","\n","layer=1 neuron=2626\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       1.00      0.75      0.86        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.88      0.93     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=2649\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10226\n","           1       0.17      0.77      0.28        13\n","\n","    accuracy                           1.00     10239\n","   macro avg       0.59      0.88      0.64     10239\n","weighted avg       1.00      1.00      1.00     10239\n","\n","layer=1 neuron=2689\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10227\n","           1       0.81      1.00      0.90        13\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.91      1.00      0.95     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=2704\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       1.00      0.55      0.71        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.77      0.85     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=2780\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10224\n","           1       0.71      0.94      0.81        16\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.86      0.97      0.91     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=2782\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: graph: syntax error in line 40 near '>'\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b\"Error: graph: syntax error in line 40 near '>'\\n\"]\n","Failed\n","layer=1 neuron=2783\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      0.40      0.57        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.70      0.79     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=2787\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.91      0.91      0.91        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.95      0.95      0.95     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=2799\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10216\n","           1       0.39      0.38      0.38        24\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.69      0.69      0.69     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=2857\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.91      1.00      0.95        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.95      1.00      0.98     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=2864\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10225\n","           1       0.91      0.83      0.87        12\n","\n","    accuracy                           1.00     10237\n","   macro avg       0.95      0.92      0.93     10237\n","weighted avg       1.00      1.00      1.00     10237\n","\n","layer=1 neuron=2868\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10226\n","           1       0.17      0.64      0.27        11\n","\n","    accuracy                           1.00     10237\n","   macro avg       0.59      0.82      0.64     10237\n","weighted avg       1.00      1.00      1.00     10237\n","\n","layer=1 neuron=2888\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: graph: syntax error in line 42 near '>'\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b\"Error: graph: syntax error in line 42 near '>'\\n\"]\n","Failed\n","layer=1 neuron=2889\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.25      0.20      0.22        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.62      0.60      0.61     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=2941\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      0.99     10220\n","           1       0.14      1.00      0.25        20\n","\n","    accuracy                           0.99     10240\n","   macro avg       0.57      0.99      0.62     10240\n","weighted avg       1.00      0.99      0.99     10240\n","\n","layer=1 neuron=2978\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10227\n","           1       0.50      1.00      0.67        13\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.75      1.00      0.83     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=1 neuron=2996\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10226\n","           1       0.22      0.36      0.27        14\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.61      0.68      0.63     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=6\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: not well-formed (invalid token) in line 1 \n","... <B> &&  ...\n","in label of node 2\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b'Error: not well-formed (invalid token) in line 1 \\n... <B> &&  ...\\nin label of node 2\\n']\n","Failed\n","layer=2 neuron=50\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10207\n","           1       0.48      1.00      0.65        10\n","\n","    accuracy                           1.00     10217\n","   macro avg       0.74      1.00      0.82     10217\n","weighted avg       1.00      1.00      1.00     10217\n","\n","layer=2 neuron=54\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10193\n","           1       0.40      0.40      0.40        10\n","\n","    accuracy                           1.00     10203\n","   macro avg       0.70      0.70      0.70     10203\n","weighted avg       1.00      1.00      1.00     10203\n","\n","layer=2 neuron=129\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      0.80      0.89        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.90      0.94     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=161\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      1.00      1.00        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=187\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.75      0.90      0.82        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.87      0.95      0.91     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=191\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.19      0.25      0.21        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.59      0.62      0.61     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=237\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      1.00      1.00        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=261\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10227\n","           1       0.60      0.50      0.55        12\n","\n","    accuracy                           1.00     10239\n","   macro avg       0.80      0.75      0.77     10239\n","weighted avg       1.00      1.00      1.00     10239\n","\n","layer=2 neuron=323\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     10220\n","           1       0.25      1.00      0.40        20\n","\n","    accuracy                           0.99     10240\n","   macro avg       0.62      1.00      0.70     10240\n","weighted avg       1.00      0.99      1.00     10240\n","\n","layer=2 neuron=330\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10231\n","           1       0.88      0.78      0.82         9\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.94      0.89      0.91     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=413\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.00      0.00      0.00        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.50      0.50      0.50     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=480\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.70      0.70      0.70        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.85      0.85      0.85     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=542\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","The size of tensor a (621) must match the size of tensor b (512) at non-singleton dimension 1\n","Failed\n","layer=2 neuron=552\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      0.60      0.75        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.80      0.87     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=628\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: graph: syntax error in line 72 near '>'\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b\"Error: graph: syntax error in line 72 near '>'\\n\"]\n","Failed\n","layer=2 neuron=645\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      1.00      1.00        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=648\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.48      1.00      0.65        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.74      1.00      0.82     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=655\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      0.80      0.89        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.90      0.94     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=663\n","Processing 1 of 10\n","Processing 2 of 10\n","CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 14.75 GiB total capacity; 12.57 GiB already allocated; 2.81 MiB free; 13.74 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","Failed\n","layer=2 neuron=678\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.83      1.00      0.91        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.92      1.00      0.95     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=693\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     10214\n","           1       0.04      0.27      0.08        11\n","\n","    accuracy                           0.99     10225\n","   macro avg       0.52      0.63      0.54     10225\n","weighted avg       1.00      0.99      1.00     10225\n","\n","layer=2 neuron=716\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.00      0.00      0.00        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.50      0.50      0.50     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=787\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10212\n","           1       1.00      0.60      0.75        10\n","\n","    accuracy                           1.00     10222\n","   macro avg       1.00      0.80      0.87     10222\n","weighted avg       1.00      1.00      1.00     10222\n","\n","layer=2 neuron=816\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      9924\n","           1       0.80      1.00      0.89         4\n","\n","    accuracy                           1.00      9928\n","   macro avg       0.90      1.00      0.94      9928\n","weighted avg       1.00      1.00      1.00      9928\n","\n","layer=2 neuron=833\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      0.99     10230\n","           1       0.08      1.00      0.14        10\n","\n","    accuracy                           0.99     10240\n","   macro avg       0.54      0.99      0.57     10240\n","weighted avg       1.00      0.99      0.99     10240\n","\n","layer=2 neuron=913\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      0.70      0.82        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.85      0.91     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=980\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.59      1.00      0.74        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.79      1.00      0.87     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=983\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.91      1.00      0.95        10\n","\n","    accuracy                           1.00     10238\n","   macro avg       0.95      1.00      0.98     10238\n","weighted avg       1.00      1.00      1.00     10238\n","\n","layer=2 neuron=1026\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.42      1.00      0.59        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.71      1.00      0.80     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=1027\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.77      1.00      0.87        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.88      1.00      0.93     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=1061\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      9719\n","\n","    accuracy                           1.00      9719\n","   macro avg       1.00      1.00      1.00      9719\n","weighted avg       1.00      1.00      1.00      9719\n","\n","layer=2 neuron=1065\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.75      0.90      0.82        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.87      0.95      0.91     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=1150\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10227\n","           1       0.55      0.92      0.69        13\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.77      0.96      0.84     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=1179\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99     10228\n","           1       0.06      0.92      0.12        12\n","\n","    accuracy                           0.98     10240\n","   macro avg       0.53      0.95      0.56     10240\n","weighted avg       1.00      0.98      0.99     10240\n","\n","layer=2 neuron=1270\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.52      1.00      0.69        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.76      1.00      0.84     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=1275\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10227\n","           1       0.83      0.77      0.80        13\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.92      0.88      0.90     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=1369\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10018\n","           1       0.90      0.82      0.86        11\n","\n","    accuracy                           1.00     10029\n","   macro avg       0.95      0.91      0.93     10029\n","weighted avg       1.00      1.00      1.00     10029\n","\n","layer=2 neuron=1375\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10218\n","           1       0.29      0.09      0.14        22\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.64      0.55      0.57     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=1402\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10231\n","           1       0.90      1.00      0.95         9\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.95      1.00      0.97     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=1442\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10233\n","           1       0.67      0.86      0.75         7\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.83      0.93      0.87     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=1462\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.12      0.30      0.17        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.56      0.65      0.58     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=1468\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      0.99     10228\n","           1       0.08      1.00      0.15        12\n","\n","    accuracy                           0.99     10240\n","   macro avg       0.54      0.99      0.57     10240\n","weighted avg       1.00      0.99      0.99     10240\n","\n","layer=2 neuron=1471\n","Processing 1 of 10\n","CUDA out of memory. Tried to allocate 290.00 MiB (GPU 0; 14.75 GiB total capacity; 12.43 GiB already allocated; 8.81 MiB free; 13.74 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","Failed\n","layer=2 neuron=1550\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     10213\n","           1       0.18      0.96      0.30        23\n","\n","    accuracy                           0.99     10236\n","   macro avg       0.59      0.97      0.65     10236\n","weighted avg       1.00      0.99      0.99     10236\n","\n","layer=2 neuron=1589\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10225\n","           1       0.68      1.00      0.81        15\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.84      1.00      0.91     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=1591\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Warning: node '5', graph '%3' size too small for label\n","Warning: node '5', graph '%3' size too small for label\n"]},{"output_type":"stream","name":"stdout","text":["Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.00      0.00      0.00        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.50      0.50      0.50     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=1602\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      1.00      1.00        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=1647\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       1.00      0.45      0.62        11\n","\n","    accuracy                           1.00     10239\n","   macro avg       1.00      0.73      0.81     10239\n","weighted avg       1.00      1.00      1.00     10239\n","\n","layer=2 neuron=1678\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.88      0.70      0.78        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.94      0.85      0.89     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=1697\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: graph: syntax error in line 54 scanning a HTML string (missing '>'? bad nesting? longer than 16384?)\n","String starting:< <B> < </B> > fillcolor=\"#5555ff\" fontcolor=white fontsize=25 penwidth=3 shape=c\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b'Error: graph: syntax error in line 54 scanning a HTML string (missing \\'>\\'? bad nesting? longer than 16384?)\\nString starting:< <B> < </B> > fillcolor=\"#5555ff\" fontcolor=white fontsize=25 penwidth=3 shape=c\\n']\n","Failed\n","layer=2 neuron=1713\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      9869\n","           1       0.00      0.00      0.00         2\n","\n","    accuracy                           1.00      9871\n","   macro avg       0.50      0.50      0.50      9871\n","weighted avg       1.00      1.00      1.00      9871\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["layer=2 neuron=1811\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.65      1.00      0.79        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.82      1.00      0.89     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=1824\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10152\n","           1       0.85      1.00      0.92        88\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.93      1.00      0.96     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=1828\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.97      0.99     10225\n","           1       0.04      0.85      0.07        13\n","\n","    accuracy                           0.97     10238\n","   macro avg       0.52      0.91      0.53     10238\n","weighted avg       1.00      0.97      0.99     10238\n","\n","layer=2 neuron=1835\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.22      0.17      0.19        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.61      0.58      0.59     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=1875\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      1.00      1.00        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=1913\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10222\n","           1       1.00      0.73      0.84        11\n","\n","    accuracy                           1.00     10233\n","   macro avg       1.00      0.86      0.92     10233\n","weighted avg       1.00      1.00      1.00     10233\n","\n","layer=2 neuron=1926\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","CUDA out of memory. Tried to allocate 38.00 MiB (GPU 0; 14.75 GiB total capacity; 12.75 GiB already allocated; 10.81 MiB free; 13.73 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","Failed\n","layer=2 neuron=1931\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     10225\n","           1       0.15      1.00      0.27        10\n","\n","    accuracy                           0.99     10235\n","   macro avg       0.58      1.00      0.63     10235\n","weighted avg       1.00      0.99      1.00     10235\n","\n","layer=2 neuron=1973\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10225\n","           1       1.00      0.20      0.33        15\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.60      0.67     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=2083\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: not well-formed (invalid token) in line 1 \n","... <B> &  ...\n","in label of node 3\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b'Error: not well-formed (invalid token) in line 1 \\n... <B> &  ...\\nin label of node 3\\n']\n","Failed\n","layer=2 neuron=2168\n","Processing 1 of 10\n","CUDA out of memory. Tried to allocate 62.00 MiB (GPU 0; 14.75 GiB total capacity; 12.56 GiB already allocated; 42.81 MiB free; 13.70 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","Failed\n","layer=2 neuron=2229\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      1.00      1.00        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=2296\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.47      0.80      0.59        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.74      0.90      0.80     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=2324\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     10230\n","           1       0.12      0.90      0.21        10\n","\n","    accuracy                           0.99     10240\n","   macro avg       0.56      0.95      0.60     10240\n","weighted avg       1.00      0.99      1.00     10240\n","\n","layer=2 neuron=2327\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.50      0.80      0.62        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.75      0.90      0.81     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=2331\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10217\n","           1       0.71      1.00      0.83        12\n","\n","    accuracy                           1.00     10229\n","   macro avg       0.85      1.00      0.91     10229\n","weighted avg       1.00      1.00      1.00     10229\n","\n","layer=2 neuron=2333\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.96      0.98     10230\n","           1       0.02      1.00      0.05        10\n","\n","    accuracy                           0.96     10240\n","   macro avg       0.51      0.98      0.51     10240\n","weighted avg       1.00      0.96      0.98     10240\n","\n","layer=2 neuron=2417\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10206\n","           1       0.41      0.41      0.41        34\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.70      0.70      0.70     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=2435\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10115\n","           1       0.50      0.90      0.64        10\n","\n","    accuracy                           1.00     10125\n","   macro avg       0.75      0.95      0.82     10125\n","weighted avg       1.00      1.00      1.00     10125\n","\n","layer=2 neuron=2443\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.19      0.83      0.31        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.59      0.91      0.65     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=2444\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.93      0.97     10230\n","           1       0.01      1.00      0.03        10\n","\n","    accuracy                           0.93     10240\n","   macro avg       0.51      0.97      0.50     10240\n","weighted avg       1.00      0.93      0.97     10240\n","\n","layer=2 neuron=2499\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      0.80      0.89        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.90      0.94     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=2543\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: not well-formed (invalid token) in line 1 \n","... <B> &  ...\n","in label of node 1\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b'Error: not well-formed (invalid token) in line 1 \\n... <B> &  ...\\nin label of node 1\\n']\n","Failed\n","layer=2 neuron=2595\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.97      0.98     10183\n","           1       0.03      1.00      0.05         9\n","\n","    accuracy                           0.97     10192\n","   macro avg       0.51      0.98      0.52     10192\n","weighted avg       1.00      0.97      0.98     10192\n","\n","layer=2 neuron=2610\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.91      0.91      0.91        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.95      0.95      0.95     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=2658\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       1.00      1.00      1.00        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=2665\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10226\n","           1       0.91      1.00      0.95        10\n","\n","    accuracy                           1.00     10236\n","   macro avg       0.95      1.00      0.98     10236\n","weighted avg       1.00      1.00      1.00     10236\n","\n","layer=2 neuron=2693\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: graph: syntax error in line 21 near '>'\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b\"Error: graph: syntax error in line 21 near '>'\\n\"]\n","Failed\n","layer=2 neuron=2712\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: graph: syntax error in line 148 scanning a HTML string (missing '>'? bad nesting? longer than 16384?)\n","String starting:< <B> </ </B> > fillcolor=\"#3939ff\" fontcolor=white fontsize=25 penwidth=3 shape=\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b'Error: graph: syntax error in line 148 scanning a HTML string (missing \\'>\\'? bad nesting? longer than 16384?)\\nString starting:< <B> </ </B> > fillcolor=\"#3939ff\" fontcolor=white fontsize=25 penwidth=3 shape=\\n']\n","Failed\n","layer=2 neuron=2726\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10208\n","           1       0.00      0.00      0.00        10\n","\n","    accuracy                           1.00     10218\n","   macro avg       0.50      0.50      0.50     10218\n","weighted avg       1.00      1.00      1.00     10218\n","\n","layer=2 neuron=2755\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10219\n","           1       0.80      1.00      0.89        20\n","\n","    accuracy                           1.00     10239\n","   macro avg       0.90      1.00      0.94     10239\n","weighted avg       1.00      1.00      1.00     10239\n","\n","layer=2 neuron=2758\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10220\n","           1       0.00      0.00      0.00        20\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.50      0.50      0.50     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["layer=2 neuron=2759\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      1.00      1.00        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=2769\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.60      0.30      0.40        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.80      0.65      0.70     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=2790\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10227\n","           1       0.22      1.00      0.36        13\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.61      1.00      0.68     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=2829\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     10220\n","           1       0.15      0.55      0.24        20\n","\n","    accuracy                           0.99     10240\n","   macro avg       0.58      0.77      0.62     10240\n","weighted avg       1.00      0.99      1.00     10240\n","\n","layer=2 neuron=2857\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      0.99     10222\n","           1       0.12      1.00      0.22        16\n","\n","    accuracy                           0.99     10238\n","   macro avg       0.56      0.99      0.61     10238\n","weighted avg       1.00      0.99      0.99     10238\n","\n","layer=2 neuron=2861\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.95      0.98     10229\n","           1       0.02      1.00      0.04        11\n","\n","    accuracy                           0.95     10240\n","   macro avg       0.51      0.98      0.51     10240\n","weighted avg       1.00      0.95      0.97     10240\n","\n","layer=2 neuron=2864\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.91      1.00      0.95        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.95      1.00      0.98     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=2873\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10225\n","           1       0.46      0.93      0.62        14\n","\n","    accuracy                           1.00     10239\n","   macro avg       0.73      0.96      0.81     10239\n","weighted avg       1.00      1.00      1.00     10239\n","\n","layer=2 neuron=2874\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.86      1.00      0.92        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.93      1.00      0.96     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=2904\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: graph: syntax error in line 19 scanning a HTML string (missing '>'? bad nesting? longer than 16384?)\n","String starting:< <B> ;< </B> > fillcolor=\"#3838ff\" fontcolor=white fontsize=25 penwidth=7 shape=\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b'Error: graph: syntax error in line 19 scanning a HTML string (missing \\'>\\'? bad nesting? longer than 16384?)\\nString starting:< <B> ;< </B> > fillcolor=\"#3838ff\" fontcolor=white fontsize=25 penwidth=7 shape=\\n']\n","Failed\n","layer=2 neuron=2909\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.83      1.00      0.91        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.92      1.00      0.95     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=2931\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10224\n","           1       1.00      1.00      1.00        11\n","\n","    accuracy                           1.00     10235\n","   macro avg       1.00      1.00      1.00     10235\n","weighted avg       1.00      1.00      1.00     10235\n","\n","layer=2 neuron=2996\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.67      0.55      0.60        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.83      0.77      0.80     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=3027\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      0.90      0.95        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.95      0.97     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=3037\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10168\n","           1       1.00      0.46      0.63        72\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.73      0.81     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=2 neuron=3065\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10234\n","           1       0.75      1.00      0.86         6\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.88      1.00      0.93     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=0\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10227\n","           1       0.85      1.00      0.92        11\n","\n","    accuracy                           1.00     10238\n","   macro avg       0.92      1.00      0.96     10238\n","weighted avg       1.00      1.00      1.00     10238\n","\n","layer=3 neuron=9\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.86      0.60      0.71        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.93      0.80      0.85     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=13\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.83      1.00      0.91        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.92      1.00      0.95     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=36\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10174\n","\n","    accuracy                           1.00     10174\n","   macro avg       1.00      1.00      1.00     10174\n","weighted avg       1.00      1.00      1.00     10174\n","\n","layer=3 neuron=58\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10225\n","           1       0.00      0.00      0.00        15\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.50      0.50      0.50     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=60\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.65      0.92      0.76        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.82      0.96      0.88     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=76\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99     10230\n","           1       0.04      1.00      0.08        10\n","\n","    accuracy                           0.98     10240\n","   macro avg       0.52      0.99      0.53     10240\n","weighted avg       1.00      0.98      0.99     10240\n","\n","layer=3 neuron=89\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.91      0.83      0.87        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.95      0.92      0.93     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=146\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.80      1.00      0.89        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.90      1.00      0.94     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=159\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      0.80      0.89        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.90      0.94     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=166\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.83      1.00      0.91        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.92      1.00      0.95     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=168\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.25      0.50      0.33        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.62      0.75      0.67     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=172\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.96      0.98     10229\n","           1       0.02      0.73      0.03        11\n","\n","    accuracy                           0.96     10240\n","   macro avg       0.51      0.84      0.51     10240\n","weighted avg       1.00      0.96      0.98     10240\n","\n","layer=3 neuron=173\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     10230\n","           1       0.10      0.90      0.17        10\n","\n","    accuracy                           0.99     10240\n","   macro avg       0.55      0.95      0.59     10240\n","weighted avg       1.00      0.99      1.00     10240\n","\n","layer=3 neuron=204\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10223\n","           1       0.00      0.00      0.00        17\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.50      0.50      0.50     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["layer=3 neuron=333\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.58      1.00      0.73        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.79      1.00      0.87     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=341\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10224\n","           1       0.73      0.80      0.76        10\n","\n","    accuracy                           1.00     10234\n","   macro avg       0.86      0.90      0.88     10234\n","weighted avg       1.00      1.00      1.00     10234\n","\n","layer=3 neuron=383\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     10224\n","           1       0.12      0.81      0.20        16\n","\n","    accuracy                           0.99     10240\n","   macro avg       0.56      0.90      0.60     10240\n","weighted avg       1.00      0.99      0.99     10240\n","\n","layer=3 neuron=400\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.90      0.90      0.90        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.95      0.95      0.95     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=410\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10224\n","           1       0.89      1.00      0.94        16\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.94      1.00      0.97     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=471\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10231\n","           1       0.26      1.00      0.42         9\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.63      1.00      0.71     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=474\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.94      0.97     10225\n","           1       0.02      1.00      0.05        15\n","\n","    accuracy                           0.94     10240\n","   macro avg       0.51      0.97      0.51     10240\n","weighted avg       1.00      0.94      0.97     10240\n","\n","layer=3 neuron=487\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10231\n","           1       0.89      0.89      0.89         9\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.94      0.94      0.94     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=534\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      0.10      0.18        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.55      0.59     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=546\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10227\n","           1       0.23      0.62      0.33        13\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.61      0.81      0.67     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=567\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.23      0.80      0.36        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.61      0.90      0.68     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=618\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     10230\n","           1       0.10      0.70      0.18        10\n","\n","    accuracy                           0.99     10240\n","   macro avg       0.55      0.85      0.59     10240\n","weighted avg       1.00      0.99      1.00     10240\n","\n","layer=3 neuron=632\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","The size of tensor a (701) must match the size of tensor b (512) at non-singleton dimension 1\n","Failed\n","layer=3 neuron=730\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10226\n","           1       1.00      0.71      0.83        14\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.86      0.92     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=746\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       1.00      0.73      0.84        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.86      0.92     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=770\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","CUDA out of memory. Tried to allocate 468.00 MiB (GPU 0; 14.75 GiB total capacity; 11.58 GiB already allocated; 406.81 MiB free; 13.35 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","Failed\n","layer=3 neuron=780\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10222\n","           1       0.50      0.64      0.56        14\n","\n","    accuracy                           1.00     10236\n","   macro avg       0.75      0.82      0.78     10236\n","weighted avg       1.00      1.00      1.00     10236\n","\n","layer=3 neuron=813\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10226\n","           1       0.42      1.00      0.60        14\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.71      1.00      0.80     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=842\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      9922\n","           1       1.00      1.00      1.00        10\n","\n","    accuracy                           1.00      9932\n","   macro avg       1.00      1.00      1.00      9932\n","weighted avg       1.00      1.00      1.00      9932\n","\n","layer=3 neuron=851\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: graph: syntax error in line 56 near '>'\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b\"Error: graph: syntax error in line 56 near '>'\\n\"]\n","Failed\n","layer=3 neuron=874\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.95      0.97     10234\n","           1       0.00      0.17      0.00         6\n","\n","    accuracy                           0.95     10240\n","   macro avg       0.50      0.56      0.49     10240\n","weighted avg       1.00      0.95      0.97     10240\n","\n","layer=3 neuron=1050\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10231\n","           1       0.89      0.89      0.89         9\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.94      0.94      0.94     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=1063\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10226\n","           1       0.33      1.00      0.49        14\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.66      1.00      0.74     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=1111\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10223\n","           1       0.33      0.70      0.45        10\n","\n","    accuracy                           1.00     10233\n","   macro avg       0.67      0.85      0.73     10233\n","weighted avg       1.00      1.00      1.00     10233\n","\n","layer=3 neuron=1125\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10221\n","           1       0.60      0.79      0.68        19\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.80      0.89      0.84     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=1140\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       1.00      0.64      0.78        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.82      0.89     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=1146\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.91      1.00      0.95        10\n","\n","    accuracy                           1.00     10238\n","   macro avg       0.95      1.00      0.98     10238\n","weighted avg       1.00      1.00      1.00     10238\n","\n","layer=3 neuron=1192\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99     10229\n","           1       0.05      0.91      0.10        11\n","\n","    accuracy                           0.98     10240\n","   macro avg       0.53      0.95      0.55     10240\n","weighted avg       1.00      0.98      0.99     10240\n","\n","layer=3 neuron=1238\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.10      0.30      0.15        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.55      0.65      0.57     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=1278\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Warning: node '2', graph '%3' size too small for label\n","Warning: node '2', graph '%3' size too small for label\n"]},{"output_type":"stream","name":"stdout","text":["Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.82      0.90      0.86        10\n","\n","    accuracy                           1.00     10238\n","   macro avg       0.91      0.95      0.93     10238\n","weighted avg       1.00      1.00      1.00     10238\n","\n","layer=3 neuron=1289\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99     10117\n","           1       0.04      0.83      0.08        12\n","\n","    accuracy                           0.98     10129\n","   macro avg       0.52      0.90      0.53     10129\n","weighted avg       1.00      0.98      0.99     10129\n","\n","layer=3 neuron=1295\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      1.00      1.00        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=1335\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","CUDA out of memory. Tried to allocate 132.00 MiB (GPU 0; 14.75 GiB total capacity; 12.86 GiB already allocated; 24.81 MiB free; 13.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","Failed\n","layer=3 neuron=1365\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       1.00      0.09      0.17        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.55      0.58     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=1382\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.50      0.55      0.52        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.75      0.77      0.76     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=1385\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.30      1.00      0.47        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.65      1.00      0.73     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=1421\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","The size of tensor a (943) must match the size of tensor b (512) at non-singleton dimension 1\n","Failed\n","layer=3 neuron=1502\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      1.00      1.00        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=1504\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10231\n","           1       0.28      1.00      0.44         9\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.64      1.00      0.72     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=1525\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10224\n","           1       0.25      1.00      0.40        16\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.62      1.00      0.70     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=1538\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10221\n","           1       0.83      1.00      0.90        19\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.91      1.00      0.95     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=1624\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.97      0.99     10230\n","           1       0.00      0.10      0.01        10\n","\n","    accuracy                           0.97     10240\n","   macro avg       0.50      0.54      0.50     10240\n","weighted avg       1.00      0.97      0.99     10240\n","\n","layer=3 neuron=1645\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.94      0.97     10228\n","           1       0.01      0.91      0.03        11\n","\n","    accuracy                           0.94     10239\n","   macro avg       0.51      0.92      0.50     10239\n","weighted avg       1.00      0.94      0.97     10239\n","\n","layer=3 neuron=1700\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10225\n","           1       0.20      1.00      0.33        11\n","\n","    accuracy                           1.00     10236\n","   macro avg       0.60      1.00      0.66     10236\n","weighted avg       1.00      1.00      1.00     10236\n","\n","layer=3 neuron=1710\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: graph: syntax error in line 307 scanning a HTML string (missing '>'? bad nesting? longer than 16384?)\n","String starting:< <B> < </B> > fillcolor=\"#0d0dff\" fontcolor=white fontsize=25 penwidth=3 shape=c\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b'Error: graph: syntax error in line 307 scanning a HTML string (missing \\'>\\'? bad nesting? longer than 16384?)\\nString starting:< <B> < </B> > fillcolor=\"#0d0dff\" fontcolor=white fontsize=25 penwidth=3 shape=c\\n']\n","Failed\n","layer=3 neuron=1783\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10215\n","           1       0.20      1.00      0.33        11\n","\n","    accuracy                           1.00     10226\n","   macro avg       0.60      1.00      0.66     10226\n","weighted avg       1.00      1.00      1.00     10226\n","\n","layer=3 neuron=1855\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99     10187\n","           1       0.04      0.89      0.07         9\n","\n","    accuracy                           0.98     10196\n","   macro avg       0.52      0.93      0.53     10196\n","weighted avg       1.00      0.98      0.99     10196\n","\n","layer=3 neuron=1878\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.89      0.94     10229\n","           1       0.01      0.64      0.01        11\n","\n","    accuracy                           0.89     10240\n","   macro avg       0.50      0.76      0.48     10240\n","weighted avg       1.00      0.89      0.94     10240\n","\n","layer=3 neuron=1912\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10205\n","           1       0.24      0.91      0.38        11\n","\n","    accuracy                           1.00     10216\n","   macro avg       0.62      0.95      0.69     10216\n","weighted avg       1.00      1.00      1.00     10216\n","\n","layer=3 neuron=1948\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.56      0.90      0.69        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.78      0.95      0.85     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=1995\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      0.60      0.75        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.80      0.87     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=2025\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.92      1.00      0.96        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.96      1.00      0.98     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=2133\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.64      0.90      0.75        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.82      0.95      0.87     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=2160\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.28      1.00      0.43        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.64      1.00      0.72     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=2164\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Warning: node '7', graph '%3' size too small for label\n","Warning: node '7', graph '%3' size too small for label\n"]},{"output_type":"stream","name":"stdout","text":["Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99     10200\n","           1       0.19      1.00      0.32        40\n","\n","    accuracy                           0.98     10240\n","   macro avg       0.59      0.99      0.65     10240\n","weighted avg       1.00      0.98      0.99     10240\n","\n","layer=3 neuron=2203\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: graph: syntax error in line 39 near '>'\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b\"Error: graph: syntax error in line 39 near '>'\\n\"]\n","Failed\n","layer=3 neuron=2246\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10226\n","           1       0.00      0.00      0.00        11\n","\n","    accuracy                           1.00     10237\n","   macro avg       0.50      0.50      0.50     10237\n","weighted avg       1.00      1.00      1.00     10237\n","\n","layer=3 neuron=2287\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.97      0.98     10226\n","           1       0.03      0.64      0.05        14\n","\n","    accuracy                           0.97     10240\n","   macro avg       0.51      0.81      0.52     10240\n","weighted avg       1.00      0.97      0.98     10240\n","\n","layer=3 neuron=2299\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10223\n","           1       1.00      0.94      0.97        17\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.97      0.98     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=2324\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10232\n","           1       0.00      0.00      0.00         8\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.50      0.50      0.50     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=2404\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.17      0.91      0.28        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.58      0.95      0.64     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=2473\n","Processing 1 of 10\n","Processing 2 of 10\n","The size of tensor a (832) must match the size of tensor b (512) at non-singleton dimension 1\n","Failed\n","layer=3 neuron=2488\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10225\n","           1       0.33      0.08      0.12        13\n","\n","    accuracy                           1.00     10238\n","   macro avg       0.67      0.54      0.56     10238\n","weighted avg       1.00      1.00      1.00     10238\n","\n","layer=3 neuron=2491\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.77      1.00      0.87        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.88      1.00      0.93     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=2507\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","CUDA out of memory. Tried to allocate 116.00 MiB (GPU 0; 14.75 GiB total capacity; 12.62 GiB already allocated; 46.81 MiB free; 13.70 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","Failed\n","layer=3 neuron=2541\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10225\n","           1       0.00      0.00      0.00        15\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.50      0.50      0.50     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=2570\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10231\n","           1       0.82      1.00      0.90         9\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.91      1.00      0.95     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=2593\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.20      0.10      0.13        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.60      0.55      0.57     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=2622\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.82      0.90      0.86        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.91      0.95      0.93     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=2638\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.09      0.50      0.16        10\n","\n","    accuracy                           0.99     10240\n","   macro avg       0.55      0.75      0.58     10240\n","weighted avg       1.00      0.99      1.00     10240\n","\n","layer=3 neuron=2641\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      1.00      1.00        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=2659\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10226\n","           1       0.25      0.29      0.27        14\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.62      0.64      0.63     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=2665\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.77      1.00      0.87        10\n","\n","    accuracy                           1.00     10239\n","   macro avg       0.88      1.00      0.93     10239\n","weighted avg       1.00      1.00      1.00     10239\n","\n","layer=3 neuron=2677\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       1.00      0.73      0.84        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.86      0.92     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=2684\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      1.00      1.00        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=2767\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: not well-formed (invalid token) in line 1 \n","...  < </B> ...\n","in label of node 6\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b'Error: not well-formed (invalid token) in line 1 \\n...  < </B> ...\\nin label of node 6\\n']\n","Failed\n","layer=3 neuron=2779\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","CUDA out of memory. Tried to allocate 182.00 MiB (GPU 0; 14.75 GiB total capacity; 12.13 GiB already allocated; 4.81 MiB free; 13.74 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","Failed\n","layer=3 neuron=2789\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.26      0.90      0.41        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.63      0.95      0.70     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=2820\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.18      1.00      0.30        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.59      1.00      0.65     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=2872\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: graph: syntax error in line 35 scanning a HTML string (missing '>'? bad nesting? longer than 16384?)\n","String starting:< <B> < </B> > fillcolor=\"#5353ff\" fontcolor=white fontsize=25 penwidth=7 shape=c\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b'Error: graph: syntax error in line 35 scanning a HTML string (missing \\'>\\'? bad nesting? longer than 16384?)\\nString starting:< <B> < </B> > fillcolor=\"#5353ff\" fontcolor=white fontsize=25 penwidth=7 shape=c\\n']\n","Failed\n","layer=3 neuron=2917\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10226\n","           1       1.00      0.07      0.13        14\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.54      0.57     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=2938\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      0.50      0.67        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.75      0.83     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=2942\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.97      0.99     10228\n","           1       0.02      0.50      0.04        12\n","\n","    accuracy                           0.97     10240\n","   macro avg       0.51      0.74      0.51     10240\n","weighted avg       1.00      0.97      0.98     10240\n","\n","layer=3 neuron=2971\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       1.00      0.91      0.95        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.95      0.98     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=3 neuron=3068\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.29      0.70      0.41        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.65      0.85      0.71     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=32\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.71      1.00      0.83        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.86      1.00      0.92     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=113\n","Processing 1 of 10\n","CUDA out of memory. Tried to allocate 1.54 GiB (GPU 0; 14.75 GiB total capacity; 12.36 GiB already allocated; 754.81 MiB free; 13.01 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","Failed\n","layer=4 neuron=154\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10226\n","           1       0.36      0.36      0.36        14\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.68      0.68      0.68     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=172\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.97      0.99     10221\n","           1       0.02      0.55      0.04        11\n","\n","    accuracy                           0.97     10232\n","   macro avg       0.51      0.76      0.51     10232\n","weighted avg       1.00      0.97      0.98     10232\n","\n","layer=4 neuron=197\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.89      0.94     10223\n","           1       0.01      0.88      0.03        17\n","\n","    accuracy                           0.89     10240\n","   macro avg       0.51      0.89      0.49     10240\n","weighted avg       1.00      0.89      0.94     10240\n","\n","layer=4 neuron=250\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      0.50      0.67        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.75      0.83     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=261\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Warning: node '5', graph '%3' size too small for label\n","Warning: node '5', graph '%3' size too small for label\n"]},{"output_type":"stream","name":"stdout","text":["Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10226\n","           1       0.62      0.57      0.59        14\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.81      0.79      0.80     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=269\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.97      0.99     10228\n","           1       0.04      1.00      0.08        12\n","\n","    accuracy                           0.97     10240\n","   macro avg       0.52      0.99      0.54     10240\n","weighted avg       1.00      0.97      0.99     10240\n","\n","layer=4 neuron=290\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10220\n","           1       0.30      0.19      0.23        16\n","\n","    accuracy                           1.00     10236\n","   macro avg       0.65      0.59      0.61     10236\n","weighted avg       1.00      1.00      1.00     10236\n","\n","layer=4 neuron=342\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.71      0.83      0.77        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.86      0.92      0.88     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=346\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.33      0.09      0.14        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.67      0.55      0.57     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=356\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.92      0.96     10223\n","           1       0.00      0.12      0.01        17\n","\n","    accuracy                           0.92     10240\n","   macro avg       0.50      0.52      0.48     10240\n","weighted avg       1.00      0.92      0.96     10240\n","\n","layer=4 neuron=401\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.50      0.91      0.65        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.75      0.95      0.82     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=407\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: not well-formed (invalid token) in line 1 \n","... <B> &&  ...\n","in label of node 1\n","Error: not well-formed (invalid token) in line 1 \n","... <B> &&  ...\n","in label of node 6\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b'Error: not well-formed (invalid token) in line 1 \\n... <B> &&  ...\\nin label of node 1\\nError: not well-formed (invalid token) in line 1 \\n... <B> &&  ...\\nin label of node 6\\n']\n","Failed\n","layer=4 neuron=428\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.99      1.00      1.00     10166\n","           1       0.00      0.00      0.00        73\n","\n","    accuracy                           0.99     10239\n","   macro avg       0.50      0.50      0.50     10239\n","weighted avg       0.99      0.99      0.99     10239\n","\n","layer=4 neuron=445\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.15      0.73      0.25        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.58      0.86      0.63     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=470\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10231\n","           1       0.54      0.78      0.64         9\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.77      0.89      0.82     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=471\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.67      1.00      0.80        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.83      1.00      0.90     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=475\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.07      0.10      0.08        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.53      0.55      0.54     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=487\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.79      1.00      0.88        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.89      1.00      0.94     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=509\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10173\n","           1       1.00      0.49      0.66        67\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.75      0.83     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=531\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.59      1.00      0.74        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.79      1.00      0.87     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=599\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.39      0.58      0.47        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.69      0.79      0.73     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=612\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.47      0.90      0.62        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.74      0.95      0.81     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=637\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: graph: syntax error in line 92 scanning a HTML string (missing '>'? bad nesting? longer than 16384?)\n","String starting:< <B> < </B> > fillcolor=\"#0a0aff\" fontcolor=white fontsize=25 penwidth=7 shape=c\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b'Error: graph: syntax error in line 92 scanning a HTML string (missing \\'>\\'? bad nesting? longer than 16384?)\\nString starting:< <B> < </B> > fillcolor=\"#0a0aff\" fontcolor=white fontsize=25 penwidth=7 shape=c\\n']\n","Failed\n","layer=4 neuron=671\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      0.80      0.89        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.90      0.94     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=682\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.90      0.95     10215\n","           1       0.01      0.52      0.02        25\n","\n","    accuracy                           0.90     10240\n","   macro avg       0.51      0.71      0.48     10240\n","weighted avg       1.00      0.90      0.94     10240\n","\n","layer=4 neuron=735\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","CUDA out of memory. Tried to allocate 194.00 MiB (GPU 0; 14.75 GiB total capacity; 12.86 GiB already allocated; 42.81 MiB free; 13.70 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","Failed\n","layer=4 neuron=786\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.95      0.97     10226\n","           1       0.02      0.71      0.04        14\n","\n","    accuracy                           0.95     10240\n","   macro avg       0.51      0.83      0.51     10240\n","weighted avg       1.00      0.95      0.97     10240\n","\n","layer=4 neuron=810\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.60      0.90      0.72        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.80      0.95      0.86     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=811\n","Processing 1 of 10\n","Processing 2 of 10\n","CUDA out of memory. Tried to allocate 34.00 MiB (GPU 0; 14.75 GiB total capacity; 11.89 GiB already allocated; 10.81 MiB free; 13.73 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","Failed\n","layer=4 neuron=826\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99     10227\n","           1       0.06      0.77      0.11        13\n","\n","    accuracy                           0.98     10240\n","   macro avg       0.53      0.88      0.55     10240\n","weighted avg       1.00      0.98      0.99     10240\n","\n","layer=4 neuron=848\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10223\n","           1       0.07      0.20      0.11        10\n","\n","    accuracy                           1.00     10233\n","   macro avg       0.54      0.60      0.55     10233\n","weighted avg       1.00      1.00      1.00     10233\n","\n","layer=4 neuron=884\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.95      0.97     10229\n","           1       0.02      0.91      0.04        11\n","\n","    accuracy                           0.95     10240\n","   macro avg       0.51      0.93      0.51     10240\n","weighted avg       1.00      0.95      0.97     10240\n","\n","layer=4 neuron=889\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.97      0.99     10219\n","           1       0.02      0.24      0.04        21\n","\n","    accuracy                           0.97     10240\n","   macro avg       0.51      0.61      0.51     10240\n","weighted avg       1.00      0.97      0.98     10240\n","\n","layer=4 neuron=901\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.97      0.98     10190\n","           1       0.04      1.00      0.07        13\n","\n","    accuracy                           0.97     10203\n","   macro avg       0.52      0.98      0.53     10203\n","weighted avg       1.00      0.97      0.98     10203\n","\n","layer=4 neuron=905\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","The size of tensor a (583) must match the size of tensor b (512) at non-singleton dimension 1\n","Failed\n","layer=4 neuron=981\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.50      1.00      0.67        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.75      1.00      0.83     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=1050\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.67      1.00      0.80        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.83      1.00      0.90     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=1068\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      0.99     10102\n","           1       0.07      0.90      0.13        10\n","\n","    accuracy                           0.99     10112\n","   macro avg       0.54      0.94      0.56     10112\n","weighted avg       1.00      0.99      0.99     10112\n","\n","layer=4 neuron=1104\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99     10227\n","           1       0.03      0.62      0.06        13\n","\n","    accuracy                           0.98     10240\n","   macro avg       0.52      0.80      0.52     10240\n","weighted avg       1.00      0.98      0.99     10240\n","\n","layer=4 neuron=1185\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10221\n","           1       1.00      0.89      0.94        19\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.95      0.97     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=1187\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.59      1.00      0.74        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.79      1.00      0.87     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=1201\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10227\n","           1       0.69      1.00      0.81        11\n","\n","    accuracy                           1.00     10238\n","   macro avg       0.84      1.00      0.91     10238\n","weighted avg       1.00      1.00      1.00     10238\n","\n","layer=4 neuron=1225\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99     10230\n","           1       0.04      0.90      0.08        10\n","\n","    accuracy                           0.98     10240\n","   macro avg       0.52      0.94      0.54     10240\n","weighted avg       1.00      0.98      0.99     10240\n","\n","layer=4 neuron=1236\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.00      0.00      0.00        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.50      0.50      0.50     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=1239\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10220\n","           1       0.44      0.35      0.39        20\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.72      0.67      0.69     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=1261\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10227\n","           1       0.64      0.54      0.58        13\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.82      0.77      0.79     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=1345\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.91      1.00      0.95        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.95      1.00      0.98     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=1372\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.80      0.33      0.47        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.90      0.67      0.74     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=1380\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: not well-formed (invalid token) in line 1 \n","... <B> &  ...\n","in label of node 4\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b'Error: not well-formed (invalid token) in line 1 \\n... <B> &  ...\\nin label of node 4\\n']\n","Failed\n","layer=4 neuron=1407\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.42      1.00      0.59        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.71      1.00      0.79     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=1468\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.95      0.97     10210\n","           1       0.05      1.00      0.10        30\n","\n","    accuracy                           0.95     10240\n","   macro avg       0.53      0.97      0.54     10240\n","weighted avg       1.00      0.95      0.97     10240\n","\n","layer=4 neuron=1478\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: graph: syntax error in line 34 near '>'\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b\"Error: graph: syntax error in line 34 near '>'\\n\"]\n","Failed\n","layer=4 neuron=1508\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.90      0.90      0.90        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.95      0.95      0.95     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=1538\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.56      0.50      0.53        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.78      0.75      0.76     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=1548\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10222\n","           1       0.58      1.00      0.73        11\n","\n","    accuracy                           1.00     10233\n","   macro avg       0.79      1.00      0.87     10233\n","weighted avg       1.00      1.00      1.00     10233\n","\n","layer=4 neuron=1576\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Warning: node '3', graph '%3' size too small for label\n","Warning: node '3', graph '%3' size too small for label\n"]},{"output_type":"stream","name":"stdout","text":["Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10225\n","           1       0.56      0.93      0.70        15\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.78      0.97      0.85     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=1613\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     10183\n","           1       0.06      0.40      0.11        10\n","\n","    accuracy                           0.99     10193\n","   macro avg       0.53      0.70      0.55     10193\n","weighted avg       1.00      0.99      1.00     10193\n","\n","layer=4 neuron=1617\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: not well-formed (invalid token) in line 1 \n","... <B> &  ...\n","in label of node 39\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b'Error: not well-formed (invalid token) in line 1 \\n... <B> &  ...\\nin label of node 39\\n']\n","Failed\n","layer=4 neuron=1630\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      1.00      1.00        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=1651\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.26      1.00      0.41        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.63      1.00      0.70     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=1698\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.88      0.70      0.78        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.94      0.85      0.89     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=1732\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.67      1.00      0.80        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.83      1.00      0.90     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=1747\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.77      1.00      0.87        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.88      1.00      0.93     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=1766\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.96      0.98     10230\n","           1       0.03      1.00      0.05        10\n","\n","    accuracy                           0.96     10240\n","   macro avg       0.51      0.98      0.52     10240\n","weighted avg       1.00      0.96      0.98     10240\n","\n","layer=4 neuron=1837\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.94      0.97     10223\n","           1       0.03      1.00      0.06        17\n","\n","    accuracy                           0.94     10240\n","   macro avg       0.51      0.97      0.51     10240\n","weighted avg       1.00      0.94      0.97     10240\n","\n","layer=4 neuron=1849\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Warning: node '26', graph '%3' size too small for label\n","Warning: node '26', graph '%3' size too small for label\n"]},{"output_type":"stream","name":"stdout","text":["Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.00      0.00      0.00        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.50      0.50      0.50     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=1877\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10169\n","           1       0.18      0.60      0.28        10\n","\n","    accuracy                           1.00     10179\n","   macro avg       0.59      0.80      0.64     10179\n","weighted avg       1.00      1.00      1.00     10179\n","\n","layer=4 neuron=1941\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.00      0.00      0.00        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.50      0.50      0.50     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=1958\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10226\n","           1       1.00      0.36      0.53        11\n","\n","    accuracy                           1.00     10237\n","   macro avg       1.00      0.68      0.77     10237\n","weighted avg       1.00      1.00      1.00     10237\n","\n","layer=4 neuron=1962\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.62      1.00      0.77        10\n","\n","    accuracy                           1.00     10238\n","   macro avg       0.81      1.00      0.88     10238\n","weighted avg       1.00      1.00      1.00     10238\n","\n","layer=4 neuron=1970\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     10224\n","           1       0.08      0.31      0.13        16\n","\n","    accuracy                           0.99     10240\n","   macro avg       0.54      0.65      0.56     10240\n","weighted avg       1.00      0.99      1.00     10240\n","\n","layer=4 neuron=2001\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.18      0.60      0.27        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.59      0.80      0.64     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=2036\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","CUDA out of memory. Tried to allocate 1.34 GiB (GPU 0; 14.75 GiB total capacity; 12.63 GiB already allocated; 288.81 MiB free; 13.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","Failed\n","layer=4 neuron=2038\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.75      0.27      0.40        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.87      0.64      0.70     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=2125\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Warning: node '28', graph '%3' size too small for label\n","Warning: node '36', graph '%3' size too small for label\n","Warning: node '46', graph '%3' size too small for label\n","Warning: node '28', graph '%3' size too small for label\n","Warning: node '36', graph '%3' size too small for label\n","Warning: node '46', graph '%3' size too small for label\n"]},{"output_type":"stream","name":"stdout","text":["Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99     10218\n","           1       0.03      0.37      0.06        19\n","\n","    accuracy                           0.98     10237\n","   macro avg       0.51      0.67      0.52     10237\n","weighted avg       1.00      0.98      0.99     10237\n","\n","layer=4 neuron=2142\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","CUDA out of memory. Tried to allocate 126.00 MiB (GPU 0; 14.75 GiB total capacity; 12.55 GiB already allocated; 68.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","Failed\n","layer=4 neuron=2153\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     10219\n","           1       0.13      0.62      0.21        21\n","\n","    accuracy                           0.99     10240\n","   macro avg       0.56      0.81      0.61     10240\n","weighted avg       1.00      0.99      0.99     10240\n","\n","layer=4 neuron=2246\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.75      1.00      0.86        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.88      1.00      0.93     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=2279\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     10224\n","           1       0.10      0.38      0.16        16\n","\n","    accuracy                           0.99     10240\n","   macro avg       0.55      0.68      0.58     10240\n","weighted avg       1.00      0.99      1.00     10240\n","\n","layer=4 neuron=2297\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     10221\n","           1       0.17      1.00      0.28        19\n","\n","    accuracy                           0.99     10240\n","   macro avg       0.58      1.00      0.64     10240\n","weighted avg       1.00      0.99      0.99     10240\n","\n","layer=4 neuron=2312\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: graph: syntax error in line 54 near '='\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b\"Error: graph: syntax error in line 54 near '='\\n\"]\n","Failed\n","layer=4 neuron=2389\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       1.00      1.00      1.00        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=2395\n","Processing 1 of 10\n","The size of tensor a (558) must match the size of tensor b (512) at non-singleton dimension 1\n","Failed\n","layer=4 neuron=2397\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10221\n","           1       0.37      0.79      0.50        19\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.68      0.89      0.75     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=2553\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     10228\n","           1       0.10      1.00      0.18        10\n","\n","    accuracy                           0.99     10238\n","   macro avg       0.55      1.00      0.59     10238\n","weighted avg       1.00      0.99      0.99     10238\n","\n","layer=4 neuron=2567\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.53      1.00      0.69        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.76      1.00      0.84     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=2616\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.83      0.42      0.56        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.92      0.71      0.78     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=2625\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99     10227\n","           1       0.06      0.92      0.10        13\n","\n","    accuracy                           0.98     10240\n","   macro avg       0.53      0.95      0.55     10240\n","weighted avg       1.00      0.98      0.99     10240\n","\n","layer=4 neuron=2772\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.97      0.99     10225\n","           1       0.03      0.60      0.06        15\n","\n","    accuracy                           0.97     10240\n","   macro avg       0.52      0.79      0.53     10240\n","weighted avg       1.00      0.97      0.99     10240\n","\n","layer=4 neuron=2782\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10220\n","           1       0.53      0.94      0.68        18\n","\n","    accuracy                           1.00     10238\n","   macro avg       0.77      0.97      0.84     10238\n","weighted avg       1.00      1.00      1.00     10238\n","\n","layer=4 neuron=2814\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10226\n","           1       0.79      0.79      0.79        14\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.89      0.89      0.89     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=2865\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.75      0.90      0.82        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.87      0.95      0.91     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=2875\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10213\n","           1       0.86      1.00      0.92         6\n","\n","    accuracy                           1.00     10219\n","   macro avg       0.93      1.00      0.96     10219\n","weighted avg       1.00      1.00      1.00     10219\n","\n","layer=4 neuron=2926\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10222\n","           1       0.30      0.93      0.45        15\n","\n","    accuracy                           1.00     10237\n","   macro avg       0.65      0.97      0.72     10237\n","weighted avg       1.00      1.00      1.00     10237\n","\n","layer=4 neuron=2984\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      0.70      0.82        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.85      0.91     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=4 neuron=2992\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     10228\n","           1       0.12      1.00      0.21        12\n","\n","    accuracy                           0.99     10240\n","   macro avg       0.56      1.00      0.60     10240\n","weighted avg       1.00      0.99      0.99     10240\n","\n","layer=4 neuron=3009\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.98      0.99     10228\n","           1       0.04      1.00      0.08        10\n","\n","    accuracy                           0.98     10238\n","   macro avg       0.52      0.99      0.53     10238\n","weighted avg       1.00      0.98      0.99     10238\n","\n","layer=4 neuron=3071\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.83      1.00      0.91        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.92      1.00      0.95     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=0\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.44      0.36      0.40        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.72      0.68      0.70     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=39\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10226\n","           1       0.60      0.21      0.32        14\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.80      0.61      0.66     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=62\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10227\n","           1       0.38      0.62      0.47        13\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.69      0.81      0.73     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=83\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.24      0.90      0.38        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.62      0.95      0.69     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=137\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.00      0.00      0.00        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.50      0.50      0.50     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=145\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.14      0.50      0.22        10\n","\n","    accuracy                           1.00     10239\n","   macro avg       0.57      0.75      0.61     10239\n","weighted avg       1.00      1.00      1.00     10239\n","\n","layer=5 neuron=161\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10219\n","           1       0.53      0.80      0.64        10\n","\n","    accuracy                           1.00     10229\n","   macro avg       0.77      0.90      0.82     10229\n","weighted avg       1.00      1.00      1.00     10229\n","\n","layer=5 neuron=166\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     10230\n","           1       0.12      1.00      0.21        10\n","\n","    accuracy                           0.99     10240\n","   macro avg       0.56      1.00      0.60     10240\n","weighted avg       1.00      0.99      1.00     10240\n","\n","layer=5 neuron=255\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10192\n","           1       0.00      0.00      0.00        45\n","\n","    accuracy                           1.00     10237\n","   macro avg       0.50      0.50      0.50     10237\n","weighted avg       0.99      1.00      0.99     10237\n","\n","layer=5 neuron=268\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.38      0.75      0.50        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.69      0.87      0.75     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=271\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.91      1.00      0.95        10\n","\n","    accuracy                           1.00     10238\n","   macro avg       0.95      1.00      0.98     10238\n","weighted avg       1.00      1.00      1.00     10238\n","\n","layer=5 neuron=312\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Warning: node '23', graph '%3' size too small for label\n","Warning: node '23', graph '%3' size too small for label\n"]},{"output_type":"stream","name":"stdout","text":["Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      0.20      0.33        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.60      0.67     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=346\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.23      0.64      0.33        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.61      0.82      0.67     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=371\n","Processing 1 of 10\n","CUDA out of memory. Tried to allocate 1.38 GiB (GPU 0; 14.75 GiB total capacity; 12.90 GiB already allocated; 42.81 MiB free; 13.70 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","Failed\n","layer=5 neuron=429\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     10226\n","           1       0.09      0.50      0.15        14\n","\n","    accuracy                           0.99     10240\n","   macro avg       0.54      0.75      0.57     10240\n","weighted avg       1.00      0.99      0.99     10240\n","\n","layer=5 neuron=521\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.69      0.90      0.78        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.85      0.95      0.89     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=534\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.24      0.90      0.38        10\n","\n","    accuracy                           1.00     10239\n","   macro avg       0.62      0.95      0.69     10239\n","weighted avg       1.00      1.00      1.00     10239\n","\n","layer=5 neuron=607\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.50      0.60      0.55        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.75      0.80      0.77     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=609\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.13      0.64      0.22        11\n","\n","    accuracy                           1.00     10239\n","   macro avg       0.57      0.82      0.61     10239\n","weighted avg       1.00      1.00      1.00     10239\n","\n","layer=5 neuron=619\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.83      0.45      0.59        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.92      0.73      0.79     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=638\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     10226\n","           1       0.20      1.00      0.34        14\n","\n","    accuracy                           0.99     10240\n","   macro avg       0.60      1.00      0.67     10240\n","weighted avg       1.00      0.99      1.00     10240\n","\n","layer=5 neuron=658\n","Processing 1 of 10\n","The size of tensor a (745) must match the size of tensor b (512) at non-singleton dimension 1\n","Failed\n","layer=5 neuron=670\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.19      0.90      0.31        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.59      0.95      0.65     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=745\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 14.75 GiB total capacity; 12.61 GiB already allocated; 6.81 MiB free; 13.74 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","Failed\n","layer=5 neuron=827\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10213\n","           1       0.87      0.48      0.62        27\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.93      0.74      0.81     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=844\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.64      0.70      0.67        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.82      0.85      0.83     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=896\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10218\n","           1       0.44      1.00      0.61        11\n","\n","    accuracy                           1.00     10229\n","   macro avg       0.72      1.00      0.81     10229\n","weighted avg       1.00      1.00      1.00     10229\n","\n","layer=5 neuron=921\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.94      0.97     10222\n","           1       0.02      0.61      0.03        18\n","\n","    accuracy                           0.94     10240\n","   macro avg       0.51      0.77      0.50     10240\n","weighted avg       1.00      0.94      0.97     10240\n","\n","layer=5 neuron=956\n","Processing 1 of 10\n","CUDA out of memory. Tried to allocate 68.00 MiB (GPU 0; 14.75 GiB total capacity; 12.60 GiB already allocated; 4.81 MiB free; 13.74 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","Failed\n","layer=5 neuron=1042\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.96      0.98     10233\n","           1       0.02      1.00      0.03         7\n","\n","    accuracy                           0.96     10240\n","   macro avg       0.51      0.98      0.51     10240\n","weighted avg       1.00      0.96      0.98     10240\n","\n","layer=5 neuron=1052\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10226\n","           1       0.43      0.75      0.55        12\n","\n","    accuracy                           1.00     10238\n","   macro avg       0.71      0.87      0.77     10238\n","weighted avg       1.00      1.00      1.00     10238\n","\n","layer=5 neuron=1073\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.87      0.93     10217\n","           1       0.01      0.48      0.02        23\n","\n","    accuracy                           0.87     10240\n","   macro avg       0.50      0.68      0.47     10240\n","weighted avg       1.00      0.87      0.93     10240\n","\n","layer=5 neuron=1186\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","CUDA out of memory. Tried to allocate 1.39 GiB (GPU 0; 14.75 GiB total capacity; 12.11 GiB already allocated; 990.81 MiB free; 12.78 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","Failed\n","layer=5 neuron=1205\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.24      0.45      0.31        11\n","\n","    accuracy                           1.00     10239\n","   macro avg       0.62      0.73      0.66     10239\n","weighted avg       1.00      1.00      1.00     10239\n","\n","layer=5 neuron=1230\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       1.00      0.33      0.50        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.67      0.75     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=1238\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.90      0.95     10208\n","           1       0.02      0.78      0.05        32\n","\n","    accuracy                           0.90     10240\n","   macro avg       0.51      0.84      0.50     10240\n","weighted avg       1.00      0.90      0.94     10240\n","\n","layer=5 neuron=1240\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Warning: node '4', graph '%3' size too small for label\n","Warning: node '4', graph '%3' size too small for label\n"]},{"output_type":"stream","name":"stdout","text":["Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10226\n","           1       0.55      0.46      0.50        13\n","\n","    accuracy                           1.00     10239\n","   macro avg       0.77      0.73      0.75     10239\n","weighted avg       1.00      1.00      1.00     10239\n","\n","layer=5 neuron=1303\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","CUDA out of memory. Tried to allocate 1.15 GiB (GPU 0; 14.75 GiB total capacity; 11.61 GiB already allocated; 1.05 GiB free; 12.69 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","Failed\n","layer=5 neuron=1318\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.20      0.75      0.32        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.60      0.87      0.66     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=1320\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     10209\n","           1       0.09      0.64      0.16        14\n","\n","    accuracy                           0.99     10223\n","   macro avg       0.54      0.82      0.58     10223\n","weighted avg       1.00      0.99      0.99     10223\n","\n","layer=5 neuron=1354\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10227\n","           1       0.21      0.92      0.34        13\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.60      0.96      0.67     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=1362\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       0.99      1.00      1.00     10161\n","           1       1.00      0.17      0.29        66\n","\n","    accuracy                           0.99     10227\n","   macro avg       1.00      0.58      0.64     10227\n","weighted avg       0.99      0.99      0.99     10227\n","\n","layer=5 neuron=1393\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10237\n","           1       0.20      0.33      0.25         3\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.60      0.67      0.62     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=1481\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.80      0.73      0.76        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.90      0.86      0.88     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=1520\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.90      0.90      0.90        10\n","\n","    accuracy                           1.00     10239\n","   macro avg       0.95      0.95      0.95     10239\n","weighted avg       1.00      1.00      1.00     10239\n","\n","layer=5 neuron=1552\n","Processing 1 of 10\n","CUDA out of memory. Tried to allocate 120.00 MiB (GPU 0; 14.75 GiB total capacity; 12.57 GiB already allocated; 78.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","Failed\n","layer=5 neuron=1565\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","CUDA out of memory. Tried to allocate 534.00 MiB (GPU 0; 14.75 GiB total capacity; 12.14 GiB already allocated; 450.81 MiB free; 13.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","Failed\n","layer=5 neuron=1571\n","Processing 1 of 10\n","CUDA out of memory. Tried to allocate 36.00 MiB (GPU 0; 14.75 GiB total capacity; 12.33 GiB already allocated; 8.81 MiB free; 13.74 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","Failed\n","layer=5 neuron=1573\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.83      1.00      0.91        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.92      1.00      0.95     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=1591\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.94      0.97     10207\n","           1       0.03      0.58      0.06        33\n","\n","    accuracy                           0.94     10240\n","   macro avg       0.52      0.76      0.51     10240\n","weighted avg       1.00      0.94      0.97     10240\n","\n","layer=5 neuron=1662\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10238\n","           1       0.20      1.00      0.33         2\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.60      1.00      0.67     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=1671\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.00      0.00      0.00        11\n","\n","    accuracy                           1.00     10239\n","   macro avg       0.50      0.50      0.50     10239\n","weighted avg       1.00      1.00      1.00     10239\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["layer=5 neuron=1711\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10237\n","           1       1.00      0.33      0.50         3\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.67      0.75     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=1733\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","The size of tensor a (783) must match the size of tensor b (512) at non-singleton dimension 1\n","Failed\n","layer=5 neuron=1746\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.91      1.00      0.95        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.95      1.00      0.98     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=1837\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      0.99     10230\n","           1       0.06      0.70      0.12        10\n","\n","    accuracy                           0.99     10240\n","   macro avg       0.53      0.84      0.56     10240\n","weighted avg       1.00      0.99      0.99     10240\n","\n","layer=5 neuron=1887\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.50      1.00      0.67         9\n","\n","    accuracy                           1.00     10239\n","   macro avg       0.75      1.00      0.83     10239\n","weighted avg       1.00      1.00      1.00     10239\n","\n","layer=5 neuron=1926\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10238\n","           1       0.00      0.00      0.00         2\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.50      0.50      0.50     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=1975\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.95      0.98     10230\n","           1       0.02      0.80      0.03        10\n","\n","    accuracy                           0.95     10240\n","   macro avg       0.51      0.88      0.50     10240\n","weighted avg       1.00      0.95      0.98     10240\n","\n","layer=5 neuron=1998\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10226\n","           1       1.00      0.71      0.83        14\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.86      0.92     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=2021\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.94      0.97     10213\n","           1       0.03      1.00      0.06        19\n","\n","    accuracy                           0.94     10232\n","   macro avg       0.52      0.97      0.51     10232\n","weighted avg       1.00      0.94      0.97     10232\n","\n","layer=5 neuron=2029\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: not well-formed (invalid token) in line 1 \n","... <B> (&  ...\n","in label of node 1\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b'Error: not well-formed (invalid token) in line 1 \\n... <B> (&  ...\\nin label of node 1\\n']\n","Failed\n","layer=5 neuron=2041\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","CUDA out of memory. Tried to allocate 284.00 MiB (GPU 0; 14.75 GiB total capacity; 12.19 GiB already allocated; 270.81 MiB free; 13.48 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","Failed\n","layer=5 neuron=2042\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: graph: syntax error in line 72 near 'fillcolor'\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b\"Error: graph: syntax error in line 72 near 'fillcolor'\\n\"]\n","Failed\n","layer=5 neuron=2057\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      0.80      0.89        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.90      0.94     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=2068\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10224\n","           1       0.91      0.62      0.74        16\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.95      0.81      0.87     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=2076\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10190\n","           1       0.67      0.55      0.60        11\n","\n","    accuracy                           1.00     10201\n","   macro avg       0.83      0.77      0.80     10201\n","weighted avg       1.00      1.00      1.00     10201\n","\n","layer=5 neuron=2115\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10229\n","           1       0.00      0.00      0.00        11\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.50      0.50      0.50     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=2121\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Warning: node '19', graph '%3' size too small for label\n","Warning: node '19', graph '%3' size too small for label\n"]},{"output_type":"stream","name":"stdout","text":["Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       0.27      0.67      0.38        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.63      0.83      0.69     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=2134\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     10181\n","           1       0.12      1.00      0.22        10\n","\n","    accuracy                           0.99     10191\n","   macro avg       0.56      1.00      0.61     10191\n","weighted avg       1.00      0.99      1.00     10191\n","\n","layer=5 neuron=2150\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.94      0.97     10204\n","           1       0.06      1.00      0.11        36\n","\n","    accuracy                           0.94     10240\n","   macro avg       0.53      0.97      0.54     10240\n","weighted avg       1.00      0.94      0.97     10240\n","\n","layer=5 neuron=2170\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10226\n","           1       1.00      0.07      0.13        14\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.54      0.57     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=2193\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","CUDA out of memory. Tried to allocate 58.00 MiB (GPU 0; 14.75 GiB total capacity; 12.23 GiB already allocated; 26.81 MiB free; 13.72 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","Failed\n","layer=5 neuron=2223\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.82      0.90      0.86        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.91      0.95      0.93     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=2238\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      1.00      1.00        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=2309\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.34      1.00      0.51        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.67      1.00      0.76     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=2335\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10215\n","           1       0.71      1.00      0.83        25\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.86      1.00      0.92     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=2350\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10227\n","           1       0.62      0.83      0.71        12\n","\n","    accuracy                           1.00     10239\n","   macro avg       0.81      0.92      0.86     10239\n","weighted avg       1.00      1.00      1.00     10239\n","\n","layer=5 neuron=2387\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: graph: syntax error in line 121 near '>'\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b\"Error: graph: syntax error in line 121 near '>'\\n\"]\n","Failed\n","layer=5 neuron=2401\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.89      0.94     10225\n","           1       0.01      0.40      0.01        15\n","\n","    accuracy                           0.89     10240\n","   macro avg       0.50      0.65      0.48     10240\n","weighted avg       1.00      0.89      0.94     10240\n","\n","layer=5 neuron=2442\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.21      0.90      0.34        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.60      0.95      0.67     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=2451\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.67      0.80      0.73        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.83      0.90      0.86     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=2458\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","CUDA out of memory. Tried to allocate 1.41 GiB (GPU 0; 14.75 GiB total capacity; 11.72 GiB already allocated; 1.07 GiB free; 12.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","Failed\n","layer=5 neuron=2468\n","Processing 1 of 10\n","CUDA out of memory. Tried to allocate 188.00 MiB (GPU 0; 14.75 GiB total capacity; 11.99 GiB already allocated; 158.81 MiB free; 13.59 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","Failed\n","layer=5 neuron=2488\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      1.00      1.00        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      1.00      1.00     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=2497\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.83      0.50      0.62        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.92      0.75      0.81     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=2601\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: not well-formed (invalid token) in line 1 \n","... <B> &  ...\n","in label of node 13\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b'Error: not well-formed (invalid token) in line 1 \\n... <B> &  ...\\nin label of node 13\\n']\n","Failed\n","layer=5 neuron=2614\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       1.00      0.90      0.95        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.95      0.97     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=2625\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.20      1.00      0.33        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.60      1.00      0.66     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=2687\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00     10220\n","           1       0.17      1.00      0.28        20\n","\n","    accuracy                           0.99     10240\n","   macro avg       0.58      1.00      0.64     10240\n","weighted avg       1.00      0.99      0.99     10240\n","\n","layer=5 neuron=2691\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Warning: node '17', graph '%3' size too small for label\n","Warning: node '31', graph '%3' size too small for label\n","Warning: node '36', graph '%3' size too small for label\n","Warning: node '38', graph '%3' size too small for label\n","Warning: node '17', graph '%3' size too small for label\n","Warning: node '31', graph '%3' size too small for label\n","Warning: node '36', graph '%3' size too small for label\n","Warning: node '38', graph '%3' size too small for label\n"]},{"output_type":"stream","name":"stdout","text":["Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10222\n","           1       0.44      0.39      0.41        18\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.72      0.69      0.71     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=2744\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.40      1.00      0.57        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.70      1.00      0.79     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=2779\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n"]},{"output_type":"stream","name":"stderr","text":["Error: graph: syntax error in line 181 scanning a HTML string (missing '>'? bad nesting? longer than 16384?)\n","String starting:< <B> </ </B> > fillcolor=\"#0d0dff\" fontcolor=white fontsize=25 penwidth=3 shape=\n"]},{"output_type":"stream","name":"stdout","text":["Command '[PosixPath('dot'), '-Kdot', '-Tsvg', '-O', 'graph']' returned non-zero exit status 1. [stderr: b'Error: graph: syntax error in line 181 scanning a HTML string (missing \\'>\\'? bad nesting? longer than 16384?)\\nString starting:< <B> </ </B> > fillcolor=\"#0d0dff\" fontcolor=white fontsize=25 penwidth=3 shape=\\n']\n","Failed\n","layer=5 neuron=2782\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.93      0.96     10215\n","           1       0.02      0.70      0.04        23\n","\n","    accuracy                           0.93     10238\n","   macro avg       0.51      0.81      0.50     10238\n","weighted avg       1.00      0.93      0.96     10238\n","\n","layer=5 neuron=2784\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","CUDA out of memory. Tried to allocate 84.00 MiB (GPU 0; 14.75 GiB total capacity; 12.43 GiB already allocated; 40.81 MiB free; 13.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","Failed\n","layer=5 neuron=2890\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.67      0.60      0.63        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.83      0.80      0.82     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=2893\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10228\n","           1       1.00      0.08      0.15        12\n","\n","    accuracy                           1.00     10240\n","   macro avg       1.00      0.54      0.58     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","layer=5 neuron=2941\n","Processing 1 of 10\n","CUDA out of memory. Tried to allocate 1.23 GiB (GPU 0; 14.75 GiB total capacity; 12.19 GiB already allocated; 822.81 MiB free; 12.94 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","Failed\n","layer=5 neuron=3034\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      0.99     10227\n","           1       0.04      0.46      0.08        13\n","\n","    accuracy                           0.99     10240\n","   macro avg       0.52      0.72      0.53     10240\n","weighted avg       1.00      0.99      0.99     10240\n","\n","layer=5 neuron=3059\n","Processing 1 of 10\n","Processing 2 of 10\n","Processing 3 of 10\n","Processing 4 of 10\n","Processing 5 of 10\n","Processing 6 of 10\n","Processing 7 of 10\n","Processing 8 of 10\n","Processing 9 of 10\n","Processing 10 of 10\n","Fitted model\n","Max Activating Evaluation Data\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     10230\n","           1       0.30      0.60      0.40        10\n","\n","    accuracy                           1.00     10240\n","   macro avg       0.65      0.80      0.70     10240\n","weighted avg       1.00      1.00      1.00     10240\n","\n","CPU times: user 9h 51min 22s, sys: 3min 42s, total: 9h 55min 4s\n","Wall time: 10h 13min 42s\n"]}]},{"cell_type":"code","source":["from collections import defaultdict\n","import random\n","\n","summary_stats = []\n","\n","with open(os.path.join(base_path, f\"neuron_graphs/{model_name}/eval_4/stats.json\")) as ifh:\n","  stats = json.load(ifh)\n","\n","missing = 0\n","\n","random.seed(0)\n","\n","for layer, layer_stats in enumerate(stats):\n","  eligible_neurons = [neuron for neuron, neuron_stats in layer_stats.items() if \"1\" in neuron_stats]\n","  neuron_sample = set(random.sample(eligible_neurons, 50))\n","\n","  aggr_stats_dict = {\"Inactivating\": defaultdict(list), \"Activating\": defaultdict(list)}\n","  for neuron, neuron_stats in layer_stats.items():\n","    if neuron not in neuron_sample:\n","      continue\n","\n","    aggr_stats_dict[\"Inactivating\"][\"Precision\"].append(neuron_stats[\"0\"][\"precision\"])\n","    aggr_stats_dict[\"Inactivating\"][\"Recall\"].append(neuron_stats[\"0\"][\"recall\"])   \n","    aggr_stats_dict[\"Inactivating\"][\"F1\"].append(neuron_stats[\"0\"][\"f1-score\"])  \n","\n","    aggr_stats_dict[\"Activating\"][\"Precision\"].append(neuron_stats[\"1\"][\"precision\"])\n","    aggr_stats_dict[\"Activating\"][\"Recall\"].append(neuron_stats[\"1\"][\"recall\"])\n","    aggr_stats_dict[\"Activating\"][\"F1\"].append(neuron_stats[\"1\"][\"f1-score\"])  \n","\n","    if neuron_stats[\"1\"][\"recall\"] > 0.8:\n","      print(f'{layer}, {neuron}, {neuron_stats[\"1\"][\"precision\"]:.3f}, {neuron_stats[\"1\"][\"recall\"]:.3f}, {neuron_stats[\"1\"][\"f1-score\"]:.3f}')\n","\n","  print(len(aggr_stats_dict[\"Inactivating\"][\"Precision\"]))\n","\n","  avg_stats_dict = {\"Inactivating\": {}, \"Activating\": {}}\n","  for token_type, inner_stats_dict in aggr_stats_dict.items():\n","    for stat_type, stat_arr in inner_stats_dict.items():\n","      avg_stats_dict[token_type][stat_type] = round(np.mean(stat_arr), 3)\n","\n","  summary_stats.append(avg_stats_dict)\n","  # break\n","\n","for layer, summary in enumerate(summary_stats):\n","  print(\"\\nLayer\", layer)\n","  pprint(summary)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lMVnoxGxg0kK","executionInfo":{"status":"ok","timestamp":1679833389633,"user_tz":-60,"elapsed":547,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"47ca5e88-4abb-414a-8ee1-511e4f094afe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0, 4, 0.367, 0.917, 0.524\n","0, 165, 1.000, 0.963, 0.981\n","0, 257, 0.556, 1.000, 0.714\n","0, 375, 0.260, 1.000, 0.413\n","0, 572, 0.778, 1.000, 0.875\n","0, 583, 1.000, 0.917, 0.957\n","0, 837, 1.000, 1.000, 1.000\n","0, 908, 0.812, 1.000, 0.897\n","0, 1066, 0.769, 1.000, 0.870\n","0, 1178, 0.909, 1.000, 0.952\n","0, 1234, 1.000, 0.900, 0.947\n","0, 1242, 1.000, 1.000, 1.000\n","0, 1298, 0.088, 0.814, 0.159\n","0, 1362, 0.778, 0.955, 0.857\n","0, 1466, 0.951, 0.975, 0.963\n","0, 1576, 1.000, 0.944, 0.971\n","0, 1577, 0.593, 1.000, 0.744\n","0, 1722, 1.000, 0.900, 0.947\n","0, 1813, 0.947, 0.857, 0.900\n","0, 1834, 0.833, 0.833, 0.833\n","0, 1933, 0.518, 1.000, 0.682\n","0, 1953, 1.000, 1.000, 1.000\n","0, 2067, 0.373, 1.000, 0.543\n","0, 2135, 1.000, 1.000, 1.000\n","0, 2181, 1.000, 1.000, 1.000\n","0, 2213, 0.027, 1.000, 0.052\n","0, 2241, 0.255, 1.000, 0.407\n","0, 2242, 0.871, 1.000, 0.931\n","0, 2263, 0.960, 0.960, 0.960\n","0, 2389, 0.036, 1.000, 0.069\n","0, 2465, 0.429, 0.857, 0.571\n","0, 2506, 1.000, 1.000, 1.000\n","0, 2509, 1.000, 0.900, 0.947\n","0, 2532, 0.382, 0.929, 0.542\n","0, 2736, 0.917, 0.846, 0.880\n","0, 2947, 1.000, 1.000, 1.000\n","50\n","1, 93, 1.000, 0.938, 0.968\n","1, 158, 0.917, 1.000, 0.957\n","1, 185, 0.714, 1.000, 0.833\n","1, 282, 0.833, 1.000, 0.909\n","1, 286, 0.462, 0.923, 0.615\n","1, 294, 0.909, 1.000, 0.952\n","1, 337, 0.571, 1.000, 0.727\n","1, 472, 0.786, 0.917, 0.846\n","1, 533, 1.000, 1.000, 1.000\n","1, 612, 0.923, 1.000, 0.960\n","1, 738, 0.846, 1.000, 0.917\n","1, 772, 0.019, 1.000, 0.037\n","1, 779, 0.444, 0.923, 0.600\n","1, 903, 0.963, 0.929, 0.945\n","1, 904, 0.857, 1.000, 0.923\n","1, 1065, 0.400, 1.000, 0.571\n","1, 1110, 0.065, 1.000, 0.121\n","1, 1717, 0.692, 0.900, 0.783\n","1, 1786, 0.484, 0.938, 0.638\n","1, 1992, 0.069, 0.900, 0.128\n","1, 2188, 0.667, 1.000, 0.800\n","1, 2214, 1.000, 0.917, 0.957\n","1, 2350, 0.769, 1.000, 0.870\n","1, 2404, 0.075, 1.000, 0.139\n","1, 2466, 0.619, 1.000, 0.765\n","1, 2480, 0.714, 1.000, 0.833\n","1, 2509, 1.000, 1.000, 1.000\n","1, 2787, 0.909, 0.909, 0.909\n","1, 2864, 0.909, 0.833, 0.870\n","50\n","2, 161, 1.000, 1.000, 1.000\n","2, 187, 0.750, 0.900, 0.818\n","2, 237, 1.000, 1.000, 1.000\n","2, 648, 0.476, 1.000, 0.645\n","2, 833, 0.076, 1.000, 0.142\n","2, 980, 0.588, 1.000, 0.741\n","2, 983, 0.909, 1.000, 0.952\n","2, 1065, 0.750, 0.900, 0.818\n","2, 1270, 0.524, 1.000, 0.688\n","2, 1402, 0.900, 1.000, 0.947\n","2, 1442, 0.667, 0.857, 0.750\n","2, 1550, 0.180, 0.957, 0.303\n","2, 1602, 1.000, 1.000, 1.000\n","2, 1811, 0.647, 1.000, 0.786\n","2, 1824, 0.854, 1.000, 0.921\n","2, 1828, 0.039, 0.846, 0.074\n","2, 2229, 1.000, 1.000, 1.000\n","2, 2324, 0.118, 0.900, 0.209\n","2, 2331, 0.706, 1.000, 0.828\n","2, 2443, 0.189, 0.833, 0.308\n","2, 2444, 0.015, 1.000, 0.029\n","2, 2595, 0.028, 1.000, 0.054\n","2, 2610, 0.909, 0.909, 0.909\n","2, 2658, 1.000, 1.000, 1.000\n","2, 2665, 0.909, 1.000, 0.952\n","2, 2790, 0.217, 1.000, 0.356\n","2, 2857, 0.125, 1.000, 0.222\n","2, 2864, 0.909, 1.000, 0.952\n","2, 2909, 0.833, 1.000, 0.909\n","2, 3027, 1.000, 0.900, 0.947\n","2, 3065, 0.750, 1.000, 0.857\n","50\n","3, 13, 0.833, 1.000, 0.909\n","3, 60, 0.647, 0.917, 0.759\n","3, 89, 0.909, 0.833, 0.870\n","3, 146, 0.800, 1.000, 0.889\n","3, 166, 0.833, 1.000, 0.909\n","3, 173, 0.097, 0.900, 0.175\n","3, 333, 0.579, 1.000, 0.733\n","3, 383, 0.117, 0.812, 0.205\n","3, 487, 0.889, 0.889, 0.889\n","3, 813, 0.424, 1.000, 0.596\n","3, 842, 1.000, 1.000, 1.000\n","3, 1050, 0.889, 0.889, 0.889\n","3, 1063, 0.326, 1.000, 0.491\n","3, 1192, 0.054, 0.909, 0.102\n","3, 1295, 1.000, 1.000, 1.000\n","3, 1502, 1.000, 1.000, 1.000\n","3, 1504, 0.281, 1.000, 0.439\n","3, 1700, 0.196, 1.000, 0.328\n","3, 1855, 0.037, 0.889, 0.070\n","3, 2160, 0.278, 1.000, 0.435\n","3, 2299, 1.000, 0.941, 0.970\n","3, 2491, 0.769, 1.000, 0.870\n","3, 2622, 0.818, 0.900, 0.857\n","3, 2665, 0.769, 1.000, 0.870\n","3, 2789, 0.265, 0.900, 0.409\n","3, 2971, 1.000, 0.909, 0.952\n","50\n","4, 32, 0.714, 1.000, 0.833\n","4, 342, 0.714, 0.833, 0.769\n","4, 471, 0.667, 1.000, 0.800\n","4, 487, 0.786, 1.000, 0.880\n","4, 531, 0.588, 1.000, 0.741\n","4, 612, 0.474, 0.900, 0.621\n","4, 884, 0.019, 0.909, 0.037\n","4, 901, 0.037, 1.000, 0.071\n","4, 1050, 0.667, 1.000, 0.800\n","4, 1185, 1.000, 0.895, 0.944\n","4, 1201, 0.688, 1.000, 0.815\n","4, 1225, 0.045, 0.900, 0.085\n","4, 1345, 0.909, 1.000, 0.952\n","4, 1468, 0.054, 1.000, 0.102\n","4, 1576, 0.560, 0.933, 0.700\n","4, 1651, 0.256, 1.000, 0.408\n","4, 1732, 0.667, 1.000, 0.800\n","4, 1766, 0.027, 1.000, 0.053\n","4, 1837, 0.029, 1.000, 0.057\n","4, 1962, 0.625, 1.000, 0.769\n","4, 2246, 0.750, 1.000, 0.857\n","4, 2297, 0.165, 1.000, 0.284\n","4, 2389, 1.000, 1.000, 1.000\n","4, 2567, 0.526, 1.000, 0.690\n","4, 2625, 0.055, 0.923, 0.104\n","4, 2782, 0.531, 0.944, 0.680\n","4, 2992, 0.115, 1.000, 0.207\n","50\n","5, 83, 0.237, 0.900, 0.375\n","5, 166, 0.116, 1.000, 0.208\n","5, 638, 0.203, 1.000, 0.337\n","5, 670, 0.188, 0.900, 0.310\n","5, 1042, 0.016, 1.000, 0.032\n","5, 1573, 0.833, 1.000, 0.909\n","5, 1662, 0.200, 1.000, 0.333\n","5, 1887, 0.500, 1.000, 0.667\n","5, 2134, 0.125, 1.000, 0.222\n","5, 2150, 0.057, 1.000, 0.107\n","5, 2223, 0.818, 0.900, 0.857\n","5, 2238, 1.000, 1.000, 1.000\n","5, 2309, 0.345, 1.000, 0.513\n","5, 2335, 0.714, 1.000, 0.833\n","5, 2488, 1.000, 1.000, 1.000\n","5, 2614, 1.000, 0.900, 0.947\n","5, 2625, 0.196, 1.000, 0.328\n","5, 2744, 0.400, 1.000, 0.571\n","50\n","\n","Layer 0\n","{'Activating': {'F1': 0.741, 'Precision': 0.74, 'Recall': 0.854},\n"," 'Inactivating': {'F1': 0.996, 'Precision': 1.0, 'Recall': 0.993}}\n","\n","Layer 1\n","{'Activating': {'F1': 0.638, 'Precision': 0.661, 'Recall': 0.769},\n"," 'Inactivating': {'F1': 0.998, 'Precision': 1.0, 'Recall': 0.997}}\n","\n","Layer 2\n","{'Activating': {'F1': 0.6, 'Precision': 0.599, 'Recall': 0.766},\n"," 'Inactivating': {'F1': 0.998, 'Precision': 1.0, 'Recall': 0.996}}\n","\n","Layer 3\n","{'Activating': {'F1': 0.484, 'Precision': 0.479, 'Recall': 0.703},\n"," 'Inactivating': {'F1': 0.996, 'Precision': 1.0, 'Recall': 0.993}}\n","\n","Layer 4\n","{'Activating': {'F1': 0.457, 'Precision': 0.44, 'Recall': 0.72},\n"," 'Inactivating': {'F1': 0.995, 'Precision': 0.999, 'Recall': 0.99}}\n","\n","Layer 5\n","{'Activating': {'F1': 0.423, 'Precision': 0.446, 'Recall': 0.667},\n"," 'Inactivating': {'F1': 0.995, 'Precision': 0.999, 'Recall': 0.991}}\n"]}]},{"cell_type":"markdown","source":["# Evaluation"],"metadata":{"id":"tViz8YG246hy"}},{"cell_type":"markdown","source":["## Process Data"],"metadata":{"id":"hAwgePrH49zq"}},{"cell_type":"markdown","source":["### Scrape Max Activations"],"metadata":{"id":"GKYJmKE7UtTV"}},{"cell_type":"code","source":["def get_max_acts(model_name, layer_and_neurons):\n","  layer, neurons = layer_and_neurons\n","  activations = []\n","  for i, neuron in enumerate(neurons):\n","    if i % 50 == 0:\n","      print(f\"\\nLayer {layer}: {i} of {len(neurons)} complete\")\n","    try:\n","      activation = get_max_activations(model_name, layer, neuron, n=1)\n","      activations.append(activation)\n","    except:\n","      print(f\"Neuron {neuron} in layer {layer} failed\")  \n","      # Use the previous activation as a hack to get around failures\n","      activations.append(activations[-1])  \n","  return activations"],"metadata":{"id":"gyzyya9vUwx8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import multiprocessing as mp\n","\n","layers = 48\n","neurons = 6400\n","model_name = \"gpt2-xl\"\n","\n","info = [(layer, [neuron for neuron in range(neurons)]) for layer in range(layers)]"],"metadata":{"id":"qQhSBheJUwx9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","\n","with mp.Pool(layers) as p:\n","    activation_matrix = p.map(partial(get_max_acts, model_name), info)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683887364445,"user_tz":-60,"elapsed":2404570,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"beb868ae-ce12-42a8-cccb-013c7398c961","id":"Jqj-qCMBUwx9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","\n","\n","Layer 18: 3800 of 6400 complete\n","\n","Layer 37: 3750 of 6400 complete\n","\n","Layer 19: 3800 of 6400 complete\n","\n","Layer 9: 3800 of 6400 complete\n","\n","Layer 32: 3800 of 6400 complete\n","Layer 15: 3800 of 6400 complete\n","\n","\n","Layer 47: 3800 of 6400 complete\n","\n","Layer 36: 3800 of 6400 complete\n","\n","Layer 30: 3800 of 6400 complete\n","Layer 1: 3800 of 6400 complete\n","Layer 0: 3800 of 6400 complete\n","\n","\n","\n","Layer 10: 3800 of 6400 complete\n","Layer 22: 3800 of 6400 complete\n","\n","\n","Layer 20: 3800 of 6400 complete\n","\n","Layer 4: 3800 of 6400 complete\n","\n","Layer 6: 3800 of 6400 complete\n","\n","Layer 44: 3750 of 6400 complete\n","\n","Layer 14: 3800 of 6400 complete\n","\n","Layer 40: 3800 of 6400 complete\n","\n","Layer 35: 3750 of 6400 complete\n","Layer 8: 3800 of 6400 complete\n","\n","\n","Layer 11: 3800 of 6400 complete\n","Layer 2: 3800 of 6400 complete\n","\n","\n","Layer 21: 3800 of 6400 complete\n","\n","Layer 34: 3800 of 6400 complete\n","\n","Layer 12: 3800 of 6400 complete\n","Layer 3: 3800 of 6400 complete\n","\n","\n","Layer 42: 3800 of 6400 complete\n","\n","Layer 26: 3800 of 6400 complete\n","\n","Layer 27: 3750 of 6400 complete\n","\n","Layer 29: 3800 of 6400 complete\n","\n","Layer 17: 3800 of 6400 complete\n","\n","Layer 46: 3800 of 6400 complete\n","\n","Layer 41: 3800 of 6400 complete\n","\n","Layer 45: 3800 of 6400 complete\n","\n","Layer 39: 3800 of 6400 complete\n","\n","Layer 24: 3800 of 6400 complete\n","\n","Layer 43: 3800 of 6400 complete\n","\n","Layer 38: 3800 of 6400 complete\n","\n","Layer 33: 3800 of 6400 complete\n","\n","Layer 16: 3850 of 6400 complete\n","\n","Layer 28: 3800 of 6400 complete\n","\n","Layer 13: 3850 of 6400 complete\n","\n","Layer 5: 3850 of 6400 complete\n","\n","Layer 23: 3850 of 6400 complete\n","Layer 31: 3850 of 6400 complete\n","\n","\n","Layer 7: 3850 of 6400 complete\n","Layer 25: 3800 of 6400 complete\n","\n","\n","Layer 18: 3850 of 6400 complete\n","\n","Layer 37: 3800 of 6400 complete\n","\n","Layer 19: 3850 of 6400 complete\n","\n","Layer 15: 3850 of 6400 complete\n","\n","Layer 9: 3850 of 6400 complete\n","\n","Layer 36: 3850 of 6400 complete\n","\n","Layer 32: 3850 of 6400 complete\n","\n","Layer 47: 3850 of 6400 complete\n","\n","Layer 14: 3850 of 6400 complete\n","\n","Layer 4: 3850 of 6400 complete\n","\n","Layer 22: 3850 of 6400 complete\n","\n","Layer 0: 3850 of 6400 complete\n","\n","Layer 20: 3850 of 6400 complete\n","Layer 1: 3850 of 6400 complete\n","Layer 8: 3850 of 6400 complete\n","\n","Layer 10: 3850 of 6400 complete\n","\n","\n","\n","Layer 30: 3850 of 6400 complete\n","\n","Layer 35: 3800 of 6400 complete\n","\n","Layer 40: 3850 of 6400 complete\n","\n","Layer 44: 3800 of 6400 complete\n","\n","Layer 21: 3850 of 6400 complete\n","\n","Layer 6: 3850 of 6400 complete\n","\n","Layer 12: 3850 of 6400 complete\n","\n","Layer 11: 3850 of 6400 complete\n","\n","Layer 2: 3850 of 6400 complete\n","\n","Layer 34: 3850 of 6400 complete\n","\n","Layer 26: 3850 of 6400 complete\n","\n","Layer 3: 3850 of 6400 complete\n","\n","Layer 27: 3800 of 6400 complete\n","\n","Layer 42: 3850 of 6400 complete\n","\n","Layer 17: 3850 of 6400 complete\n","\n","Layer 46: 3850 of 6400 complete\n","\n","Layer 29: 3850 of 6400 complete\n","\n","Layer 41: 3850 of 6400 complete\n","\n","Layer 45: 3850 of 6400 complete\n","\n","Layer 39: 3850 of 6400 complete\n","\n","Layer 24: 3850 of 6400 complete\n","\n","Layer 43: 3850 of 6400 complete\n","\n","Layer 33: 3850 of 6400 complete\n","\n","Layer 38: 3850 of 6400 complete\n","\n","Layer 28: 3850 of 6400 complete\n","\n","Layer 16: 3900 of 6400 complete\n","\n","Layer 5: 3900 of 6400 complete\n","\n","Layer 13: 3900 of 6400 complete\n","\n","Layer 18: 3900 of 6400 complete\n","\n","Layer 25: 3850 of 6400 complete\n","\n","Layer 23: 3900 of 6400 complete\n","Layer 7: 3900 of 6400 complete\n","\n","\n","Layer 31: 3900 of 6400 complete\n","\n","Layer 37: 3850 of 6400 complete\n","\n","Layer 9: 3900 of 6400 complete\n","\n","Layer 47: 3900 of 6400 complete\n","\n","Layer 15: 3900 of 6400 complete\n","\n","Layer 19: 3900 of 6400 complete\n","\n","Layer 32: 3900 of 6400 complete\n","\n","Layer 14: 3900 of 6400 complete\n","\n","Layer 36: 3900 of 6400 complete\n","\n","Layer 4: 3900 of 6400 complete\n","\n","Layer 40: 3900 of 6400 complete\n","\n","Layer 10: 3900 of 6400 complete\n","Layer 1: 3900 of 6400 complete\n","Layer 0: 3900 of 6400 complete\n","\n","\n","\n","Layer 30: 3900 of 6400 complete\n","\n","Layer 21: 3900 of 6400 complete\n","\n","Layer 22: 3900 of 6400 complete\n","\n","Layer 8: 3900 of 6400 complete\n","\n","Layer 20: 3900 of 6400 complete\n","\n","Layer 2: 3900 of 6400 complete\n","Layer 44: 3850 of 6400 complete\n","\n","\n","Layer 35: 3850 of 6400 complete\n","\n","Layer 26: 3900 of 6400 complete\n","\n","Layer 11: 3900 of 6400 complete\n","\n","Layer 12: 3900 of 6400 complete\n","Layer 34: 3900 of 6400 complete\n","\n","\n","Layer 6: 3900 of 6400 complete\n","\n","Layer 17: 3900 of 6400 complete\n","\n","Layer 46: 3900 of 6400 complete\n","\n","Layer 42: 3900 of 6400 complete\n","\n","Layer 29: 3900 of 6400 complete\n","\n","Layer 3: 3900 of 6400 complete\n","\n","Layer 27: 3850 of 6400 complete\n","\n","Layer 41: 3900 of 6400 complete\n","\n","Layer 45: 3900 of 6400 complete\n","\n","Layer 39: 3900 of 6400 complete\n","\n","Layer 43: 3900 of 6400 complete\n","\n","Layer 24: 3900 of 6400 complete\n","\n","Layer 33: 3900 of 6400 complete\n","\n","Layer 38: 3900 of 6400 complete\n","\n","Layer 28: 3900 of 6400 complete\n","\n","Layer 16: 3950 of 6400 complete\n","\n","Layer 18: 3950 of 6400 complete\n","\n","Layer 7: 3950 of 6400 complete\n","\n","Layer 5: 3950 of 6400 complete\n","\n","Layer 23: 3950 of 6400 complete\n","\n","Layer 31: 3950 of 6400 complete\n","\n","Layer 25: 3900 of 6400 complete\n","\n","Layer 13: 3950 of 6400 complete\n","\n","Layer 37: 3900 of 6400 complete\n","\n","Layer 9: 3950 of 6400 complete\n","\n","Layer 47: 3950 of 6400 complete\n","\n","Layer 14: 3950 of 6400 complete\n","\n","Layer 19: 3950 of 6400 complete\n","Layer 36: 3950 of 6400 complete\n","\n","\n","Layer 15: 3950 of 6400 complete\n","\n","Layer 4: 3950 of 6400 complete\n","\n","Layer 0: 3950 of 6400 complete\n","\n","Layer 8: 3950 of 6400 complete\n","\n","Layer 32: 3950 of 6400 complete\n","\n","Layer 10: 3950 of 6400 complete\n","\n","Layer 1: 3950 of 6400 complete\n","Layer 40: 3950 of 6400 complete\n","\n","\n","Layer 20: 3950 of 6400 complete\n","\n","Layer 21: 3950 of 6400 complete\n","\n","Layer 44: 3900 of 6400 complete\n","\n","Layer 22: 3950 of 6400 complete\n","\n","Layer 30: 3950 of 6400 complete\n","\n","Layer 12: 3950 of 6400 complete\n","\n","Layer 35: 3900 of 6400 complete\n","Layer 2: 3950 of 6400 complete\n","\n","Layer 26: 3950 of 6400 complete\n","\n","\n","Layer 17: 3950 of 6400 complete\n","Layer 46: 3950 of 6400 complete\n","\n","\n","Layer 6: 3950 of 6400 complete\n","\n","Layer 34: 3950 of 6400 complete\n","\n","Layer 11: 3950 of 6400 complete\n","\n","Layer 42: 3950 of 6400 complete\n","\n","Layer 27: 3900 of 6400 complete\n","\n","Layer 29: 3950 of 6400 complete\n","\n","Layer 3: 3950 of 6400 complete\n","\n","Layer 41: 3950 of 6400 complete\n","\n","Layer 45: 3950 of 6400 complete\n","\n","Layer 39: 3950 of 6400 complete\n","\n","Layer 33: 3950 of 6400 complete\n","\n","Layer 24: 3950 of 6400 complete\n","\n","Layer 43: 3950 of 6400 complete\n","\n","Layer 38: 3950 of 6400 complete\n","\n","Layer 16: 4000 of 6400 complete\n","Layer 28: 3950 of 6400 complete\n","\n","\n","Layer 7: 4000 of 6400 complete\n","\n","Layer 18: 4000 of 6400 complete\n","\n","Layer 23: 4000 of 6400 complete\n","\n","Layer 5: 4000 of 6400 complete\n","\n","Layer 37: 3950 of 6400 complete\n","Layer 31: 4000 of 6400 complete\n","\n","\n","Layer 9: 4000 of 6400 complete\n","\n","Layer 25: 3950 of 6400 complete\n","\n","Layer 13: 4000 of 6400 complete\n","\n","Layer 47: 4000 of 6400 complete\n","\n","Layer 36: 4000 of 6400 complete\n","\n","Layer 0: 4000 of 6400 complete\n","\n","Layer 14: 4000 of 6400 complete\n","Layer 4: 4000 of 6400 complete\n","\n","\n","Layer 15: 4000 of 6400 complete\n","\n","Layer 19: 4000 of 6400 complete\n","\n","Layer 8: 4000 of 6400 complete\n","\n","Layer 1: 4000 of 6400 complete\n","\n","Layer 12: 4000 of 6400 complete\n","\n","Layer 10: 4000 of 6400 complete\n","\n","Layer 44: 3950 of 6400 complete\n","\n","Layer 32: 4000 of 6400 complete\n","\n","Layer 22: 4000 of 6400 complete\n","\n","Layer 20: 4000 of 6400 complete\n","\n","Layer 21: 4000 of 6400 complete\n","\n","Layer 40: 4000 of 6400 complete\n","\n","Layer 26: 4000 of 6400 complete\n","\n","Layer 35: 3950 of 6400 complete\n","\n","Layer 30: 4000 of 6400 complete\n","\n","Layer 17: 4000 of 6400 complete\n","\n","Layer 2: 4000 of 6400 complete\n","\n","Layer 6: 4000 of 6400 complete\n","\n","Layer 46: 4000 of 6400 complete\n","\n","Layer 11: 4000 of 6400 complete\n","Layer 27: 3950 of 6400 complete\n","\n","\n","Layer 3: 4000 of 6400 complete\n","\n","Layer 34: 4000 of 6400 complete\n","Layer 42: 4000 of 6400 complete\n","Layer 29: 4000 of 6400 complete\n","\n","\n","\n","Layer 41: 4000 of 6400 complete\n","\n","Layer 39: 4000 of 6400 complete\n","\n","Layer 45: 4000 of 6400 complete\n","\n","Layer 33: 4000 of 6400 complete\n","\n","Layer 43: 4000 of 6400 complete\n","\n","Layer 24: 4000 of 6400 complete\n","\n","Layer 38: 4000 of 6400 complete\n","\n","Layer 16: 4050 of 6400 complete\n","\n","Layer 28: 4000 of 6400 complete\n","\n","Layer 5: 4050 of 6400 complete\n","\n","Layer 7: 4050 of 6400 complete\n","\n","Layer 18: 4050 of 6400 complete\n","\n","Layer 23: 4050 of 6400 complete\n","\n","Layer 37: 4000 of 6400 complete\n","\n","Layer 31: 4050 of 6400 complete\n","Layer 9: 4050 of 6400 complete\n","Layer 47: 4050 of 6400 complete\n","\n","\n","\n","Layer 13: 4050 of 6400 complete\n","\n","Layer 25: 4000 of 6400 complete\n","\n","Layer 15: 4050 of 6400 complete\n","\n","Layer 4: 4050 of 6400 complete\n","\n","Layer 8: 4050 of 6400 complete\n","\n","Layer 1: 4050 of 6400 complete\n","\n","Layer 36: 4050 of 6400 complete\n","\n","Layer 0: 4050 of 6400 complete\n","\n","Layer 19: 4050 of 6400 complete\n","\n","Layer 14: 4050 of 6400 complete\n","\n","Layer 12: 4050 of 6400 complete\n","\n","Layer 32: 4050 of 6400 complete\n","\n","Layer 20: 4050 of 6400 complete\n","\n","Layer 22: 4050 of 6400 complete\n","\n","Layer 40: 4050 of 6400 complete\n","\n","Layer 44: 4000 of 6400 complete\n","\n","Layer 10: 4050 of 6400 complete\n","\n","Layer 26: 4050 of 6400 complete\n","Layer 21: 4050 of 6400 complete\n","\n","\n","Layer 2: 4050 of 6400 complete\n","\n","Layer 17: 4050 of 6400 complete\n","\n","Layer 35: 4000 of 6400 complete\n","\n","Layer 6: 4050 of 6400 complete\n","\n","Layer 30: 4050 of 6400 complete\n","\n","Layer 46: 4050 of 6400 complete\n","\n","Layer 27: 4000 of 6400 complete\n","\n","Layer 11: 4050 of 6400 complete\n","\n","Layer 29: 4050 of 6400 complete\n","\n","Layer 34: 4050 of 6400 complete\n","\n","Layer 3: 4050 of 6400 complete\n","\n","Layer 41: 4050 of 6400 complete\n","\n","Layer 42: 4050 of 6400 complete\n","\n","Layer 45: 4050 of 6400 complete\n","\n","Layer 39: 4050 of 6400 complete\n","\n","Layer 43: 4050 of 6400 complete\n","\n","Layer 33: 4050 of 6400 complete\n","\n","Layer 24: 4050 of 6400 complete\n","\n","Layer 38: 4050 of 6400 complete\n","\n","Layer 16: 4100 of 6400 complete\n","\n","Layer 28: 4050 of 6400 complete\n","\n","Layer 18: 4100 of 6400 complete\n","\n","Layer 23: 4100 of 6400 complete\n","Layer 5: 4100 of 6400 complete\n","Layer 7: 4100 of 6400 complete\n","\n","Layer 31: 4100 of 6400 complete\n","\n","\n","\n","Layer 37: 4050 of 6400 complete\n","\n","Layer 47: 4100 of 6400 complete\n","Layer 9: 4100 of 6400 complete\n","\n","\n","Layer 25: 4050 of 6400 complete\n","Layer 13: 4100 of 6400 complete\n","\n","\n","Layer 0: 4100 of 6400 complete\n","\n","Layer 15: 4100 of 6400 complete\n","\n","Layer 4: 4100 of 6400 complete\n","\n","Layer 8: 4100 of 6400 complete\n","\n","Layer 36: 4100 of 6400 complete\n","Layer 1: 4100 of 6400 complete\n","\n","\n","Layer 32: 4100 of 6400 complete\n","\n","Layer 19: 4100 of 6400 complete\n","\n","Layer 12: 4100 of 6400 complete\n","\n","Layer 14: 4100 of 6400 complete\n","Layer 40: 4100 of 6400 complete\n","\n","\n","Layer 20: 4100 of 6400 complete\n","\n","Layer 22: 4100 of 6400 complete\n","\n","Layer 44: 4050 of 6400 complete\n","\n","Layer 35: 4050 of 6400 complete\n","\n","Layer 17: 4100 of 6400 complete\n","\n","Layer 2: 4100 of 6400 complete\n","\n","Layer 26: 4100 of 6400 complete\n","\n","Layer 21: 4100 of 6400 complete\n","\n","Layer 10: 4100 of 6400 complete\n","\n","Layer 46: 4100 of 6400 complete\n","\n","Layer 30: 4100 of 6400 complete\n","\n","Layer 11: 4100 of 6400 complete\n","\n","Layer 6: 4100 of 6400 complete\n","\n","Layer 27: 4050 of 6400 complete\n","\n","Layer 3: 4100 of 6400 complete\n","\n","Layer 34: 4100 of 6400 complete\n","\n","Layer 41: 4100 of 6400 complete\n","\n","Layer 29: 4100 of 6400 complete\n","\n","Layer 42: 4100 of 6400 complete\n","\n","Layer 45: 4100 of 6400 complete\n","\n","Layer 43: 4100 of 6400 complete\n","\n","Layer 39: 4100 of 6400 complete\n","\n","Layer 24: 4100 of 6400 complete\n","\n","Layer 33: 4100 of 6400 complete\n","\n","Layer 38: 4100 of 6400 complete\n","\n","Layer 28: 4100 of 6400 complete\n","\n","Layer 7: 4150 of 6400 complete\n","\n","Layer 18: 4150 of 6400 complete\n","\n","Layer 16: 4150 of 6400 complete\n","\n","Layer 23: 4150 of 6400 complete\n","\n","Layer 31: 4150 of 6400 complete\n","\n","Layer 5: 4150 of 6400 complete\n","\n","Layer 9: 4150 of 6400 complete\n","\n","Layer 47: 4150 of 6400 complete\n","\n","Layer 0: 4150 of 6400 complete\n","\n","Layer 37: 4100 of 6400 complete\n","\n","Layer 13: 4150 of 6400 complete\n","\n","Layer 15: 4150 of 6400 complete\n","\n","Layer 25: 4100 of 6400 complete\n","\n","Layer 8: 4150 of 6400 complete\n","\n","Layer 4: 4150 of 6400 complete\n","Layer 1: 4150 of 6400 complete\n","\n","\n","Layer 36: 4150 of 6400 complete\n","\n","Layer 32: 4150 of 6400 complete\n","\n","Layer 19: 4150 of 6400 complete\n","\n","Layer 20: 4150 of 6400 complete\n","\n","Layer 14: 4150 of 6400 complete\n","\n","Layer 12: 4150 of 6400 complete\n","\n","Layer 40: 4150 of 6400 complete\n","\n","Layer 22: 4150 of 6400 complete\n","\n","Layer 17: 4150 of 6400 complete\n","\n","Layer 44: 4100 of 6400 complete\n","\n","Layer 10: 4150 of 6400 complete\n","\n","Layer 2: 4150 of 6400 complete\n","Layer 35: 4100 of 6400 complete\n","Layer 26: 4150 of 6400 complete\n","\n","\n","\n","Layer 27: 4100 of 6400 complete\n","\n","Layer 21: 4150 of 6400 complete\n","\n","Layer 46: 4150 of 6400 complete\n","\n","Layer 30: 4150 of 6400 complete\n","\n","Layer 11: 4150 of 6400 complete\n","\n","Layer 6: 4150 of 6400 complete\n","\n","Layer 41: 4150 of 6400 complete\n","\n","Layer 29: 4150 of 6400 complete\n","\n","Layer 34: 4150 of 6400 complete\n","\n","Layer 3: 4150 of 6400 complete\n","\n","Layer 42: 4150 of 6400 complete\n","\n","Layer 45: 4150 of 6400 complete\n","\n","Layer 43: 4150 of 6400 complete\n","\n","Layer 39: 4150 of 6400 complete\n","\n","Layer 24: 4150 of 6400 complete\n","\n","Layer 33: 4150 of 6400 complete\n","\n","Layer 38: 4150 of 6400 complete\n","\n","Layer 16: 4200 of 6400 complete\n","\n","Layer 18: 4200 of 6400 complete\n","\n","Layer 28: 4150 of 6400 complete\n","\n","Layer 31: 4200 of 6400 complete\n","\n","Layer 0: 4200 of 6400 complete\n","\n","Layer 5: 4200 of 6400 complete\n","\n","Layer 23: 4200 of 6400 complete\n","\n","Layer 9: 4200 of 6400 complete\n","\n","Layer 47: 4200 of 6400 complete\n","\n","Layer 7: 4200 of 6400 complete\n","\n","Layer 25: 4150 of 6400 complete\n","\n","Layer 37: 4150 of 6400 complete\n","\n","Layer 13: 4200 of 6400 complete\n","\n","Layer 8: 4200 of 6400 complete\n","\n","Layer 15: 4200 of 6400 complete\n","\n","Layer 4: 4200 of 6400 complete\n","\n","Layer 14: 4200 of 6400 complete\n","\n","Layer 36: 4200 of 6400 complete\n","\n","Layer 40: 4200 of 6400 complete\n","Layer 32: 4200 of 6400 complete\n","\n","\n","Layer 1: 4200 of 6400 complete\n","\n","Layer 12: 4200 of 6400 complete\n","\n","Layer 19: 4200 of 6400 complete\n","\n","Layer 20: 4200 of 6400 complete\n","\n","Layer 22: 4200 of 6400 complete\n","Layer 17: 4200 of 6400 complete\n","\n","\n","Layer 27: 4150 of 6400 complete\n","\n","Layer 35: 4150 of 6400 complete\n","Layer 2: 4200 of 6400 complete\n","\n","Layer 10: 4200 of 6400 complete\n","\n","\n","Layer 44: 4150 of 6400 complete\n","\n","Layer 11: 4200 of 6400 complete\n","\n","Layer 21: 4200 of 6400 complete\n","\n","Layer 26: 4200 of 6400 complete\n","\n","Layer 46: 4200 of 6400 complete\n","\n","Layer 30: 4200 of 6400 complete\n","\n","Layer 29: 4200 of 6400 complete\n","\n","Layer 41: 4200 of 6400 complete\n","\n","Layer 6: 4200 of 6400 complete\n","\n","Layer 34: 4200 of 6400 complete\n","\n","Layer 3: 4200 of 6400 complete\n","\n","Layer 42: 4200 of 6400 complete\n","\n","Layer 43: 4200 of 6400 complete\n","\n","Layer 39: 4200 of 6400 complete\n","\n","Layer 45: 4200 of 6400 complete\n","\n","Layer 24: 4200 of 6400 complete\n","\n","Layer 33: 4200 of 6400 complete\n","\n","Layer 16: 4250 of 6400 complete\n","\n","Layer 38: 4200 of 6400 complete\n","\n","Layer 31: 4250 of 6400 complete\n","\n","Layer 0: 4250 of 6400 complete\n","\n","Layer 18: 4250 of 6400 complete\n","\n","Layer 5: 4250 of 6400 complete\n","\n","Layer 28: 4200 of 6400 complete\n","\n","Layer 7: 4250 of 6400 complete\n","\n","Layer 9: 4250 of 6400 complete\n","\n","Layer 25: 4200 of 6400 complete\n","\n","Layer 47: 4250 of 6400 complete\n","\n","Layer 23: 4250 of 6400 complete\n","\n","Layer 13: 4250 of 6400 complete\n","\n","Layer 8: 4250 of 6400 complete\n","\n","Layer 37: 4200 of 6400 complete\n","\n","Layer 15: 4250 of 6400 complete\n","\n","Layer 4: 4250 of 6400 complete\n","\n","Layer 1: 4250 of 6400 complete\n","\n","Layer 12: 4250 of 6400 complete\n","\n","Layer 14: 4250 of 6400 complete\n","\n","Layer 36: 4250 of 6400 complete\n","\n","Layer 20: 4250 of 6400 complete\n","Layer 40: 4250 of 6400 complete\n","Layer 32: 4250 of 6400 complete\n","\n","\n","\n","Layer 27: 4200 of 6400 complete\n","\n","Layer 19: 4250 of 6400 complete\n","\n","Layer 17: 4250 of 6400 complete\n","\n","Layer 22: 4250 of 6400 complete\n","\n","Layer 11: 4250 of 6400 complete\n","\n","Layer 44: 4200 of 6400 complete\n","\n","Layer 2: 4250 of 6400 complete\n","\n","Layer 21: 4250 of 6400 complete\n","\n","Layer 10: 4250 of 6400 complete\n","\n","Layer 35: 4200 of 6400 complete\n","\n","Layer 26: 4250 of 6400 complete\n","\n","Layer 6: 4250 of 6400 complete\n","Layer 46: 4250 of 6400 complete\n","\n","\n","Layer 30: 4250 of 6400 complete\n","\n","Layer 29: 4250 of 6400 complete\n","\n","Layer 41: 4250 of 6400 complete\n","\n","Layer 34: 4250 of 6400 complete\n","\n","Layer 3: 4250 of 6400 complete\n","\n","Layer 43: 4250 of 6400 complete\n","\n","Layer 24: 4250 of 6400 complete\n","\n","Layer 39: 4250 of 6400 complete\n","\n","Layer 45: 4250 of 6400 complete\n","\n","Layer 42: 4250 of 6400 complete\n","\n","Layer 33: 4250 of 6400 complete\n","\n","Layer 16: 4300 of 6400 complete\n","\n","Layer 38: 4250 of 6400 complete\n","\n","Layer 5: 4300 of 6400 complete\n","\n","Layer 31: 4300 of 6400 complete\n","\n","Layer 0: 4300 of 6400 complete\n","\n","Layer 7: 4300 of 6400 complete\n","\n","Layer 18: 4300 of 6400 complete\n","\n","Layer 9: 4300 of 6400 complete\n","\n","Layer 28: 4250 of 6400 complete\n","\n","Layer 25: 4250 of 6400 complete\n","\n","Layer 47: 4300 of 6400 complete\n","\n","Layer 13: 4300 of 6400 complete\n","\n","Layer 23: 4300 of 6400 complete\n","\n","Layer 8: 4300 of 6400 complete\n","\n","Layer 4: 4300 of 6400 complete\n","\n","Layer 15: 4300 of 6400 complete\n","\n","Layer 37: 4250 of 6400 complete\n","\n","Layer 36: 4300 of 6400 complete\n","\n","Layer 12: 4300 of 6400 complete\n","\n","Layer 1: 4300 of 6400 complete\n","\n","Layer 32: 4300 of 6400 complete\n","Layer 20: 4300 of 6400 complete\n","\n","\n","Layer 14: 4300 of 6400 complete\n","\n","Layer 40: 4300 of 6400 complete\n","\n","Layer 27: 4250 of 6400 complete\n","\n","Layer 22: 4300 of 6400 complete\n","\n","Layer 17: 4300 of 6400 complete\n","\n","Layer 19: 4300 of 6400 complete\n","\n","Layer 11: 4300 of 6400 complete\n","\n","Layer 44: 4250 of 6400 complete\n","Layer 10: 4300 of 6400 complete\n","\n","\n","Layer 2: 4300 of 6400 complete\n","\n","Layer 21: 4300 of 6400 complete\n","\n","Layer 35: 4250 of 6400 complete\n","Layer 46: 4300 of 6400 complete\n","\n","\n","Layer 6: 4300 of 6400 complete\n","\n","Layer 26: 4300 of 6400 complete\n","\n","Layer 34: 4300 of 6400 complete\n","\n","Layer 30: 4300 of 6400 complete\n","Layer 29: 4300 of 6400 complete\n","\n","\n","Layer 41: 4300 of 6400 complete\n","\n","Layer 3: 4300 of 6400 complete\n","\n","Layer 43: 4300 of 6400 complete\n","\n","Layer 24: 4300 of 6400 complete\n","Layer 39: 4300 of 6400 complete\n","\n","\n","Layer 45: 4300 of 6400 complete\n","\n","Layer 42: 4300 of 6400 complete\n","\n","Layer 33: 4300 of 6400 complete\n","\n","Layer 16: 4350 of 6400 complete\n","\n","Layer 18: 4350 of 6400 complete\n","\n","Layer 0: 4350 of 6400 complete\n","\n","Layer 31: 4350 of 6400 complete\n","\n","Layer 38: 4300 of 6400 complete\n","Layer 7: 4350 of 6400 complete\n","\n","\n","Layer 5: 4350 of 6400 complete\n","\n","Layer 28: 4300 of 6400 complete\n","\n","Layer 47: 4350 of 6400 complete\n","Layer 9: 4350 of 6400 complete\n","\n","Layer 8: 4350 of 6400 complete\n","\n","\n","Layer 25: 4300 of 6400 complete\n","\n","Layer 13: 4350 of 6400 complete\n","Layer 23: 4350 of 6400 complete\n","\n","\n","Layer 1: 4350 of 6400 complete\n","\n","Layer 15: 4350 of 6400 complete\n","\n","Layer 12: 4350 of 6400 complete\n","\n","Layer 4: 4350 of 6400 complete\n","\n","Layer 36: 4350 of 6400 complete\n","\n","Layer 20: 4350 of 6400 complete\n","\n","Layer 37: 4300 of 6400 complete\n","\n","Layer 40: 4350 of 6400 complete\n","\n","Layer 14: 4350 of 6400 complete\n","\n","Layer 17: 4350 of 6400 complete\n","\n","Layer 32: 4350 of 6400 complete\n","\n","Layer 27: 4300 of 6400 complete\n","\n","Layer 22: 4350 of 6400 complete\n","\n","Layer 19: 4350 of 6400 complete\n","\n","Layer 10: 4350 of 6400 complete\n","\n","Layer 46: 4350 of 6400 complete\n","\n","Layer 35: 4300 of 6400 complete\n","\n","Layer 21: 4350 of 6400 complete\n","\n","Layer 11: 4350 of 6400 complete\n","\n","Layer 2: 4350 of 6400 complete\n","\n","Layer 44: 4300 of 6400 complete\n","\n","Layer 30: 4350 of 6400 complete\n","Layer 6: 4350 of 6400 complete\n","\n","\n","Layer 34: 4350 of 6400 complete\n","\n","Layer 26: 4350 of 6400 complete\n","\n","Layer 29: 4350 of 6400 complete\n","\n","Layer 41: 4350 of 6400 complete\n","\n","Layer 3: 4350 of 6400 complete\n","\n","Layer 39: 4350 of 6400 complete\n","\n","Layer 24: 4350 of 6400 complete\n","\n","Layer 45: 4350 of 6400 complete\n","Layer 43: 4350 of 6400 complete\n","\n","\n","Layer 42: 4350 of 6400 complete\n","\n","Layer 33: 4350 of 6400 complete\n","\n","Layer 16: 4400 of 6400 complete\n","\n","Layer 18: 4400 of 6400 complete\n","Layer 31: 4400 of 6400 complete\n","\n","\n","Layer 7: 4400 of 6400 complete\n","\n","Layer 0: 4400 of 6400 complete\n","Layer 5: 4400 of 6400 complete\n","\n","Layer 38: 4350 of 6400 complete\n","\n","\n","Layer 9: 4400 of 6400 complete\n","\n","Layer 28: 4350 of 6400 complete\n","\n","Layer 8: 4400 of 6400 complete\n","\n","Layer 25: 4350 of 6400 complete\n","\n","Layer 47: 4400 of 6400 complete\n","\n","Layer 13: 4400 of 6400 complete\n","\n","Layer 1: 4400 of 6400 complete\n","\n","Layer 23: 4400 of 6400 complete\n","\n","Layer 12: 4400 of 6400 complete\n","\n","Layer 15: 4400 of 6400 complete\n","\n","Layer 36: 4400 of 6400 complete\n","\n","Layer 4: 4400 of 6400 complete\n","\n","Layer 40: 4400 of 6400 complete\n","Layer 20: 4400 of 6400 complete\n","Layer 37: 4350 of 6400 complete\n","\n","\n","\n","Layer 14: 4400 of 6400 complete\n","\n","Layer 17: 4400 of 6400 complete\n","\n","Layer 22: 4400 of 6400 complete\n","\n","Layer 32: 4400 of 6400 complete\n","\n","Layer 19: 4400 of 6400 complete\n","\n","Layer 27: 4350 of 6400 complete\n","Layer 21: 4400 of 6400 complete\n","\n","\n","Layer 35: 4350 of 6400 complete\n","\n","Layer 11: 4400 of 6400 complete\n","\n","Layer 10: 4400 of 6400 complete\n","\n","Layer 2: 4400 of 6400 complete\n","\n","Layer 44: 4350 of 6400 complete\n","\n","Layer 46: 4400 of 6400 complete\n","\n","Layer 6: 4400 of 6400 complete\n","\n","Layer 34: 4400 of 6400 complete\n","\n","Layer 30: 4400 of 6400 complete\n","\n","Layer 26: 4400 of 6400 complete\n","\n","Layer 41: 4400 of 6400 complete\n","\n","Layer 29: 4400 of 6400 complete\n","\n","Layer 43: 4400 of 6400 complete\n","\n","Layer 24: 4400 of 6400 complete\n","\n","Layer 3: 4400 of 6400 complete\n","\n","Layer 45: 4400 of 6400 complete\n","Layer 39: 4400 of 6400 complete\n","\n","\n","Layer 42: 4400 of 6400 complete\n","\n","Layer 16: 4450 of 6400 complete\n","\n","Layer 33: 4400 of 6400 complete\n","\n","Layer 31: 4450 of 6400 complete\n","\n","Layer 18: 4450 of 6400 complete\n","Layer 0: 4450 of 6400 complete\n","\n","\n","Layer 38: 4400 of 6400 complete\n","\n","Layer 7: 4450 of 6400 complete\n","\n","Layer 9: 4450 of 6400 complete\n","Layer 5: 4450 of 6400 complete\n","\n","\n","Layer 28: 4400 of 6400 complete\n","\n","Layer 8: 4450 of 6400 complete\n","\n","Layer 47: 4450 of 6400 complete\n","\n","Layer 1: 4450 of 6400 complete\n","\n","Layer 13: 4450 of 6400 complete\n","\n","Layer 23: 4450 of 6400 complete\n","\n","Layer 25: 4400 of 6400 complete\n","\n","Layer 12: 4450 of 6400 complete\n","\n","Layer 36: 4450 of 6400 complete\n","\n","Layer 15: 4450 of 6400 complete\n","\n","Layer 4: 4450 of 6400 complete\n","\n","Layer 37: 4400 of 6400 complete\n","\n","Layer 20: 4450 of 6400 complete\n","\n","Layer 14: 4450 of 6400 complete\n","\n","Layer 19: 4450 of 6400 complete\n","Layer 17: 4450 of 6400 complete\n","\n","\n","Layer 22: 4450 of 6400 complete\n","\n","Layer 40: 4450 of 6400 complete\n","\n","Layer 32: 4450 of 6400 complete\n","\n","Layer 27: 4400 of 6400 complete\n","\n","Layer 35: 4400 of 6400 complete\n","\n","Layer 21: 4450 of 6400 complete\n","\n","Layer 46: 4450 of 6400 complete\n","Layer 44: 4400 of 6400 complete\n","\n","\n","Layer 2: 4450 of 6400 complete\n","\n","Layer 11: 4450 of 6400 complete\n","\n","Layer 6: 4450 of 6400 complete\n","\n","Layer 10: 4450 of 6400 complete\n","\n","Layer 26: 4450 of 6400 complete\n","Layer 34: 4450 of 6400 complete\n","\n","\n","Layer 30: 4450 of 6400 complete\n","\n","Layer 41: 4450 of 6400 complete\n","\n","Layer 29: 4450 of 6400 complete\n","\n","Layer 43: 4450 of 6400 complete\n","\n","Layer 45: 4450 of 6400 complete\n","\n","Layer 24: 4450 of 6400 complete\n","\n","Layer 3: 4450 of 6400 complete\n","\n","Layer 39: 4450 of 6400 complete\n","\n","Layer 42: 4450 of 6400 complete\n","\n","Layer 0: 4500 of 6400 complete\n","\n","Layer 38: 4450 of 6400 complete\n","\n","Layer 33: 4450 of 6400 complete\n","\n","Layer 16: 4500 of 6400 complete\n","\n","Layer 18: 4500 of 6400 complete\n","\n","Layer 31: 4500 of 6400 complete\n","\n","Layer 5: 4500 of 6400 complete\n","\n","Layer 7: 4500 of 6400 complete\n","\n","Layer 9: 4500 of 6400 complete\n","\n","Layer 8: 4500 of 6400 complete\n","\n","Layer 47: 4500 of 6400 complete\n","\n","Layer 28: 4450 of 6400 complete\n","\n","Layer 23: 4500 of 6400 complete\n","\n","Layer 25: 4450 of 6400 complete\n","\n","Layer 1: 4500 of 6400 complete\n","\n","Layer 13: 4500 of 6400 complete\n","\n","Layer 12: 4500 of 6400 complete\n","\n","Layer 37: 4450 of 6400 complete\n","Layer 15: 4500 of 6400 complete\n","\n","\n","Layer 36: 4500 of 6400 complete\n","\n","Layer 17: 4500 of 6400 complete\n","\n","Layer 4: 4500 of 6400 complete\n","\n","Layer 20: 4500 of 6400 complete\n","\n","Layer 19: 4500 of 6400 complete\n","\n","Layer 32: 4500 of 6400 complete\n","\n","Layer 27: 4450 of 6400 complete\n","\n","Layer 14: 4500 of 6400 complete\n","\n","Layer 22: 4500 of 6400 complete\n","Layer 21: 4500 of 6400 complete\n","Layer 35: 4450 of 6400 complete\n","Layer 40: 4500 of 6400 complete\n","\n","Layer 11: 4500 of 6400 complete\n","\n","\n","\n","\n","Layer 2: 4500 of 6400 complete\n","Layer 44: 4450 of 6400 complete\n","\n","\n","Layer 6: 4500 of 6400 complete\n","\n","Layer 46: 4500 of 6400 complete\n","\n","Layer 10: 4500 of 6400 complete\n","\n","Layer 29: 4500 of 6400 complete\n","\n","Layer 26: 4500 of 6400 complete\n","\n","Layer 30: 4500 of 6400 complete\n","\n","Layer 34: 4500 of 6400 complete\n","\n","Layer 41: 4500 of 6400 complete\n","\n","Layer 45: 4500 of 6400 complete\n","\n","Layer 24: 4500 of 6400 complete\n","\n","Layer 43: 4500 of 6400 complete\n","Layer 42: 4500 of 6400 complete\n","\n","\n","Layer 3: 4500 of 6400 complete\n","\n","Layer 39: 4500 of 6400 complete\n","\n","Layer 0: 4550 of 6400 complete\n","\n","Layer 33: 4500 of 6400 complete\n","\n","Layer 16: 4550 of 6400 complete\n","\n","Layer 38: 4500 of 6400 complete\n","\n","Layer 5: 4550 of 6400 complete\n","\n","Layer 31: 4550 of 6400 complete\n","\n","Layer 18: 4550 of 6400 complete\n","\n","Layer 28: 4500 of 6400 complete\n","\n","Layer 7: 4550 of 6400 complete\n","\n","Layer 8: 4550 of 6400 complete\n","\n","Layer 9: 4550 of 6400 complete\n","Layer 47: 4550 of 6400 complete\n","\n","\n","Layer 1: 4550 of 6400 complete\n","\n","Layer 13: 4550 of 6400 complete\n","\n","Layer 23: 4550 of 6400 complete\n","\n","Layer 25: 4500 of 6400 complete\n","\n","Layer 36: 4550 of 6400 complete\n","\n","Layer 12: 4550 of 6400 complete\n","\n","Layer 15: 4550 of 6400 complete\n","\n","Layer 37: 4500 of 6400 complete\n","\n","Layer 20: 4550 of 6400 complete\n","\n","Layer 19: 4550 of 6400 complete\n","\n","Layer 4: 4550 of 6400 complete\n","\n","Layer 17: 4550 of 6400 complete\n","\n","Layer 14: 4550 of 6400 complete\n","\n","Layer 32: 4550 of 6400 complete\n","Layer 22: 4550 of 6400 complete\n","\n","\n","Layer 21: 4550 of 6400 complete\n","\n","Layer 40: 4550 of 6400 complete\n","Layer 6: 4550 of 6400 complete\n","\n","\n","Layer 27: 4500 of 6400 complete\n","\n","Layer 35: 4500 of 6400 complete\n","Layer 46: 4550 of 6400 complete\n","\n","\n","Layer 44: 4500 of 6400 complete\n","\n","Layer 11: 4550 of 6400 complete\n","\n","Layer 10: 4550 of 6400 complete\n","\n","Layer 2: 4550 of 6400 complete\n","\n","Layer 29: 4550 of 6400 complete\n","\n","Layer 26: 4550 of 6400 complete\n","\n","Layer 41: 4550 of 6400 complete\n","\n","Layer 30: 4550 of 6400 complete\n","\n","Layer 34: 4550 of 6400 complete\n","\n","Layer 45: 4550 of 6400 complete\n","\n","Layer 24: 4550 of 6400 complete\n","\n","Layer 43: 4550 of 6400 complete\n","\n","Layer 3: 4550 of 6400 complete\n","\n","Layer 42: 4550 of 6400 complete\n","\n","Layer 0: 4600 of 6400 complete\n","\n","Layer 39: 4550 of 6400 complete\n","\n","Layer 16: 4600 of 6400 complete\n","\n","Layer 33: 4550 of 6400 complete\n","\n","Layer 31: 4600 of 6400 complete\n","\n","Layer 38: 4550 of 6400 complete\n","\n","Layer 18: 4600 of 6400 complete\n","\n","Layer 5: 4600 of 6400 complete\n","\n","Layer 1: 4600 of 6400 complete\n","\n","Layer 13: 4600 of 6400 complete\n","\n","Layer 7: 4600 of 6400 complete\n","\n","Layer 25: 4550 of 6400 complete\n","\n","Layer 23: 4600 of 6400 complete\n","\n","Layer 28: 4550 of 6400 complete\n","\n","Layer 8: 4600 of 6400 complete\n","\n","Layer 9: 4600 of 6400 complete\n","\n","Layer 15: 4600 of 6400 complete\n","\n","Layer 47: 4600 of 6400 complete\n","\n","Layer 36: 4600 of 6400 complete\n","Layer 12: 4600 of 6400 complete\n","\n","\n","Layer 19: 4600 of 6400 complete\n","\n","Layer 20: 4600 of 6400 complete\n","\n","Layer 4: 4600 of 6400 complete\n","\n","Layer 17: 4600 of 6400 complete\n","\n","Layer 37: 4550 of 6400 complete\n","\n","Layer 14: 4600 of 6400 complete\n","\n","Layer 40: 4600 of 6400 complete\n","\n","Layer 32: 4600 of 6400 complete\n","\n","Layer 27: 4550 of 6400 complete\n","\n","Layer 10: 4600 of 6400 complete\n","Layer 21: 4600 of 6400 complete\n","\n","\n","Layer 35: 4550 of 6400 complete\n","\n","Layer 46: 4600 of 6400 complete\n","Layer 22: 4600 of 6400 complete\n","\n","\n","Layer 6: 4600 of 6400 complete\n","\n","Layer 11: 4600 of 6400 complete\n","\n","Layer 44: 4550 of 6400 complete\n","\n","Layer 2: 4600 of 6400 complete\n","\n","Layer 29: 4600 of 6400 complete\n","\n","Layer 41: 4600 of 6400 complete\n","\n","Layer 30: 4600 of 6400 complete\n","\n","Layer 26: 4600 of 6400 complete\n","\n","Layer 45: 4600 of 6400 complete\n","\n","Layer 34: 4600 of 6400 complete\n","\n","Layer 24: 4600 of 6400 complete\n","\n","Layer 43: 4600 of 6400 complete\n","\n","Layer 42: 4600 of 6400 complete\n","\n","Layer 3: 4600 of 6400 complete\n","Layer 0: 4650 of 6400 complete\n","\n","\n","Layer 39: 4600 of 6400 complete\n","\n","Layer 33: 4600 of 6400 complete\n","\n","Layer 16: 4650 of 6400 complete\n","\n","Layer 31: 4650 of 6400 complete\n","\n","Layer 38: 4600 of 6400 complete\n","\n","Layer 18: 4650 of 6400 complete\n","\n","Layer 5: 4650 of 6400 complete\n","\n","Layer 1: 4650 of 6400 complete\n","\n","Layer 28: 4600 of 6400 complete\n","\n","Layer 25: 4600 of 6400 complete\n","\n","Layer 13: 4650 of 6400 complete\n","\n","Layer 15: 4650 of 6400 complete\n","\n","Layer 8: 4650 of 6400 complete\n","\n","Layer 23: 4650 of 6400 complete\n","\n","Layer 7: 4650 of 6400 complete\n","\n","Layer 9: 4650 of 6400 complete\n","\n","Layer 47: 4650 of 6400 complete\n","\n","Layer 36: 4650 of 6400 complete\n","\n","Layer 17: 4650 of 6400 complete\n","\n","Layer 12: 4650 of 6400 complete\n","\n","Layer 20: 4650 of 6400 complete\n","\n","Layer 19: 4650 of 6400 complete\n","Layer 4: 4650 of 6400 complete\n","\n","\n","Layer 14: 4650 of 6400 complete\n","\n","Layer 37: 4600 of 6400 complete\n","\n","Layer 40: 4650 of 6400 complete\n","\n","Layer 27: 4600 of 6400 complete\n","Layer 10: 4650 of 6400 complete\n","\n","\n","Layer 21: 4650 of 6400 complete\n","\n","Layer 35: 4600 of 6400 complete\n","Layer 22: 4650 of 6400 complete\n","\n","\n","Layer 46: 4650 of 6400 complete\n","\n","Layer 32: 4650 of 6400 complete\n","\n","Layer 6: 4650 of 6400 complete\n","\n","Layer 44: 4600 of 6400 complete\n","\n","Layer 2: 4650 of 6400 complete\n","\n","Layer 11: 4650 of 6400 complete\n","\n","Layer 26: 4650 of 6400 complete\n","\n","Layer 41: 4650 of 6400 complete\n","\n","Layer 29: 4650 of 6400 complete\n","\n","Layer 30: 4650 of 6400 complete\n","\n","Layer 34: 4650 of 6400 complete\n","\n","Layer 24: 4650 of 6400 complete\n","\n","Layer 45: 4650 of 6400 complete\n","\n","Layer 43: 4650 of 6400 complete\n","\n","Layer 0: 4700 of 6400 complete\n","\n","Layer 3: 4650 of 6400 complete\n","\n","Layer 42: 4650 of 6400 complete\n","\n","Layer 39: 4650 of 6400 complete\n","\n","Layer 16: 4700 of 6400 complete\n","\n","Layer 18: 4700 of 6400 complete\n","\n","Layer 38: 4650 of 6400 complete\n","\n","Layer 31: 4700 of 6400 complete\n","\n","Layer 33: 4650 of 6400 complete\n","\n","Layer 5: 4700 of 6400 complete\n","\n","Layer 1: 4700 of 6400 complete\n","\n","Layer 25: 4650 of 6400 complete\n","\n","Layer 28: 4650 of 6400 complete\n","\n","Layer 13: 4700 of 6400 complete\n","\n","Layer 15: 4700 of 6400 complete\n","Layer 23: 4700 of 6400 complete\n","\n","\n","Layer 8: 4700 of 6400 complete\n","\n","Layer 17: 4700 of 6400 complete\n","\n","Layer 9: 4700 of 6400 complete\n","Layer 7: 4700 of 6400 complete\n","\n","\n","Layer 36: 4700 of 6400 complete\n","\n","Layer 47: 4700 of 6400 complete\n","\n","Layer 19: 4700 of 6400 complete\n","\n","Layer 12: 4700 of 6400 complete\n","\n","Layer 14: 4700 of 6400 complete\n","\n","Layer 37: 4650 of 6400 complete\n","\n","Layer 27: 4650 of 6400 complete\n","\n","Layer 20: 4700 of 6400 complete\n","Layer 4: 4700 of 6400 complete\n","\n","\n","Layer 40: 4700 of 6400 complete\n","\n","Layer 46: 4700 of 6400 complete\n","\n","Layer 10: 4700 of 6400 complete\n","\n","Layer 35: 4650 of 6400 complete\n","\n","Layer 22: 4700 of 6400 complete\n","\n","Layer 21: 4700 of 6400 complete\n","Layer 6: 4700 of 6400 complete\n","\n","\n","Layer 32: 4700 of 6400 complete\n","\n","Layer 44: 4650 of 6400 complete\n","\n","Layer 41: 4700 of 6400 complete\n","Layer 11: 4700 of 6400 complete\n","Layer 2: 4700 of 6400 complete\n","\n","\n","\n","Layer 26: 4700 of 6400 complete\n","\n","Layer 29: 4700 of 6400 complete\n","\n","Layer 34: 4700 of 6400 complete\n","\n","Layer 24: 4700 of 6400 complete\n","\n","Layer 30: 4700 of 6400 complete\n","\n","Layer 43: 4700 of 6400 complete\n","\n","Layer 45: 4700 of 6400 complete\n","\n","Layer 3: 4700 of 6400 complete\n","\n","Layer 0: 4750 of 6400 complete\n","\n","Layer 42: 4700 of 6400 complete\n","\n","Layer 16: 4750 of 6400 complete\n","\n","Layer 39: 4700 of 6400 complete\n","\n","Layer 33: 4700 of 6400 complete\n","Layer 18: 4750 of 6400 complete\n","\n","\n","Layer 31: 4750 of 6400 complete\n","\n","Layer 38: 4700 of 6400 complete\n","\n","Layer 5: 4750 of 6400 complete\n","\n","Layer 25: 4700 of 6400 complete\n","\n","Layer 1: 4750 of 6400 complete\n","\n","Layer 28: 4700 of 6400 complete\n","\n","Layer 15: 4750 of 6400 complete\n","\n","Layer 8: 4750 of 6400 complete\n","\n","Layer 17: 4750 of 6400 complete\n","Layer 13: 4750 of 6400 complete\n","\n","\n","Layer 23: 4750 of 6400 complete\n","\n","Layer 9: 4750 of 6400 complete\n","\n","Layer 7: 4750 of 6400 complete\n","\n","Layer 36: 4750 of 6400 complete\n","\n","Layer 47: 4750 of 6400 complete\n","\n","Layer 19: 4750 of 6400 complete\n","\n","Layer 14: 4750 of 6400 complete\n","\n","Layer 12: 4750 of 6400 complete\n","\n","Layer 37: 4700 of 6400 complete\n","\n","Layer 4: 4750 of 6400 complete\n","\n","Layer 20: 4750 of 6400 complete\n","\n","Layer 40: 4750 of 6400 complete\n","\n","Layer 27: 4700 of 6400 complete\n","Layer 10: 4750 of 6400 complete\n","\n","\n","Layer 22: 4750 of 6400 complete\n","\n","Layer 32: 4750 of 6400 complete\n","\n","Layer 46: 4750 of 6400 complete\n","\n","Layer 11: 4750 of 6400 complete\n","Layer 21: 4750 of 6400 complete\n","Layer 35: 4700 of 6400 complete\n","\n","\n","\n","Layer 6: 4750 of 6400 complete\n","\n","Layer 44: 4700 of 6400 complete\n","\n","Layer 2: 4750 of 6400 complete\n","\n","Layer 26: 4750 of 6400 complete\n","\n","Layer 41: 4750 of 6400 complete\n","\n","Layer 34: 4750 of 6400 complete\n","\n","Layer 29: 4750 of 6400 complete\n","\n","Layer 24: 4750 of 6400 complete\n","\n","Layer 30: 4750 of 6400 complete\n","\n","Layer 43: 4750 of 6400 complete\n","\n","Layer 45: 4750 of 6400 complete\n","\n","Layer 3: 4750 of 6400 complete\n","\n","Layer 0: 4800 of 6400 complete\n","\n","Layer 42: 4750 of 6400 complete\n","Layer 16: 4800 of 6400 complete\n","\n","\n","Layer 18: 4800 of 6400 complete\n","\n","Layer 39: 4750 of 6400 complete\n","\n","Layer 33: 4750 of 6400 complete\n","\n","Layer 1: 4800 of 6400 complete\n","\n","Layer 31: 4800 of 6400 complete\n","Layer 5: 4800 of 6400 complete\n","\n","\n","Layer 38: 4750 of 6400 complete\n","\n","Layer 25: 4750 of 6400 complete\n","\n","Layer 28: 4750 of 6400 complete\n","\n","Layer 15: 4800 of 6400 complete\n","\n","Layer 9: 4800 of 6400 complete\n","\n","Layer 13: 4800 of 6400 complete\n","\n","Layer 8: 4800 of 6400 complete\n","\n","Layer 37: 4750 of 6400 complete\n","\n","Layer 23: 4800 of 6400 complete\n","\n","Layer 17: 4800 of 6400 complete\n","Layer 19: 4800 of 6400 complete\n","\n","\n","Layer 36: 4800 of 6400 complete\n","\n","Layer 7: 4800 of 6400 complete\n","Layer 14: 4800 of 6400 complete\n","\n","\n","Layer 12: 4800 of 6400 complete\n","\n","Layer 47: 4800 of 6400 complete\n","\n","Layer 10: 4800 of 6400 complete\n","\n","Layer 4: 4800 of 6400 complete\n","\n","Layer 27: 4750 of 6400 complete\n","Layer 40: 4800 of 6400 complete\n","\n","\n","Layer 22: 4800 of 6400 complete\n","\n","Layer 11: 4800 of 6400 complete\n","\n","Layer 20: 4800 of 6400 complete\n","\n","Layer 6: 4800 of 6400 complete\n","\n","Layer 32: 4800 of 6400 complete\n","\n","Layer 21: 4800 of 6400 complete\n","\n","Layer 35: 4750 of 6400 complete\n","\n","Layer 46: 4800 of 6400 complete\n","\n","Layer 44: 4750 of 6400 complete\n","\n","Layer 2: 4800 of 6400 complete\n","\n","Layer 41: 4800 of 6400 complete\n","\n","Layer 30: 4800 of 6400 complete\n","\n","Layer 26: 4800 of 6400 complete\n","\n","Layer 34: 4800 of 6400 complete\n","\n","Layer 29: 4800 of 6400 complete\n","\n","Layer 45: 4800 of 6400 complete\n","\n","Layer 24: 4800 of 6400 complete\n","\n","Layer 0: 4850 of 6400 complete\n","\n","Layer 43: 4800 of 6400 complete\n","\n","Layer 3: 4800 of 6400 complete\n","\n","Layer 42: 4800 of 6400 complete\n","\n","Layer 16: 4850 of 6400 complete\n","\n","Layer 18: 4850 of 6400 complete\n","\n","Layer 39: 4800 of 6400 complete\n","\n","Layer 1: 4850 of 6400 complete\n","\n","Layer 33: 4800 of 6400 complete\n","\n","Layer 31: 4850 of 6400 complete\n","\n","Layer 5: 4850 of 6400 complete\n","\n","Layer 38: 4800 of 6400 complete\n","\n","Layer 28: 4800 of 6400 complete\n","\n","Layer 25: 4800 of 6400 complete\n","\n","Layer 15: 4850 of 6400 complete\n","Layer 9: 4850 of 6400 complete\n","\n","\n","Layer 13: 4850 of 6400 complete\n","\n","Layer 7: 4850 of 6400 complete\n","\n","Layer 23: 4850 of 6400 complete\n","\n","Layer 37: 4800 of 6400 complete\n","\n","Layer 8: 4850 of 6400 complete\n","\n","Layer 36: 4850 of 6400 complete\n","\n","Layer 19: 4850 of 6400 complete\n","Layer 14: 4850 of 6400 complete\n","\n","\n","Layer 17: 4850 of 6400 complete\n","\n","Layer 10: 4850 of 6400 complete\n","\n","Layer 12: 4850 of 6400 complete\n","Layer 47: 4850 of 6400 complete\n","\n","\n","Layer 27: 4800 of 6400 complete\n","\n","Layer 4: 4850 of 6400 complete\n","\n","Layer 11: 4850 of 6400 complete\n","\n","Layer 20: 4850 of 6400 complete\n","\n","Layer 22: 4850 of 6400 complete\n","\n","Layer 6: 4850 of 6400 complete\n","\n","Layer 40: 4850 of 6400 complete\n","\n","Layer 21: 4850 of 6400 complete\n","\n","Layer 32: 4850 of 6400 complete\n","\n","Layer 44: 4800 of 6400 complete\n","Layer 35: 4800 of 6400 complete\n","\n","\n","Layer 46: 4850 of 6400 complete\n","\n","Layer 2: 4850 of 6400 complete\n","\n","Layer 41: 4850 of 6400 complete\n","\n","Layer 30: 4850 of 6400 complete\n","\n","Layer 26: 4850 of 6400 complete\n","\n","Layer 29: 4850 of 6400 complete\n","\n","Layer 45: 4850 of 6400 complete\n","\n","Layer 24: 4850 of 6400 complete\n","\n","Layer 34: 4850 of 6400 complete\n","\n","Layer 43: 4850 of 6400 complete\n","\n","Layer 3: 4850 of 6400 complete\n","Layer 0: 4900 of 6400 complete\n","\n","\n","Layer 42: 4850 of 6400 complete\n","\n","Layer 16: 4900 of 6400 complete\n","\n","Layer 18: 4900 of 6400 complete\n","\n","Layer 39: 4850 of 6400 complete\n","\n","Layer 33: 4850 of 6400 complete\n","\n","Layer 31: 4900 of 6400 complete\n","\n","Layer 5: 4900 of 6400 complete\n","\n","Layer 1: 4900 of 6400 complete\n","\n","Layer 25: 4850 of 6400 complete\n","\n","Layer 28: 4850 of 6400 complete\n","\n","Layer 38: 4850 of 6400 complete\n","\n","Layer 13: 4900 of 6400 complete\n","\n","Layer 9: 4900 of 6400 complete\n","\n","Layer 23: 4900 of 6400 complete\n","\n","Layer 19: 4900 of 6400 complete\n","\n","Layer 15: 4900 of 6400 complete\n","\n","Layer 7: 4900 of 6400 complete\n","\n","Layer 14: 4900 of 6400 complete\n","\n","Layer 17: 4900 of 6400 complete\n","\n","Layer 12: 4900 of 6400 complete\n","\n","Layer 36: 4900 of 6400 complete\n","\n","Layer 8: 4900 of 6400 complete\n","\n","Layer 4: 4900 of 6400 complete\n","\n","Layer 37: 4850 of 6400 complete\n","\n","Layer 47: 4900 of 6400 complete\n","\n","Layer 11: 4900 of 6400 complete\n","\n","Layer 10: 4900 of 6400 complete\n","Layer 20: 4900 of 6400 complete\n","\n","\n","Layer 27: 4850 of 6400 complete\n","\n","Layer 22: 4900 of 6400 complete\n","\n","Layer 21: 4900 of 6400 complete\n","\n","Layer 6: 4900 of 6400 complete\n","\n","Layer 32: 4900 of 6400 complete\n","\n","Layer 40: 4900 of 6400 complete\n","\n","Layer 35: 4850 of 6400 complete\n","\n","Layer 46: 4900 of 6400 complete\n","\n","Layer 44: 4850 of 6400 complete\n","\n","Layer 41: 4900 of 6400 complete\n","Layer 2: 4900 of 6400 complete\n","\n","\n","Layer 30: 4900 of 6400 complete\n","\n","Layer 24: 4900 of 6400 complete\n","\n","Layer 29: 4900 of 6400 complete\n","\n","Layer 45: 4900 of 6400 complete\n","\n","Layer 26: 4900 of 6400 complete\n","\n","Layer 43: 4900 of 6400 complete\n","\n","Layer 34: 4900 of 6400 complete\n","\n","Layer 0: 4950 of 6400 complete\n","\n","Layer 3: 4900 of 6400 complete\n","\n","Layer 42: 4900 of 6400 complete\n","\n","Layer 16: 4950 of 6400 complete\n","\n","Layer 33: 4900 of 6400 complete\n","\n","Layer 31: 4950 of 6400 complete\n","\n","Layer 18: 4950 of 6400 complete\n","\n","Layer 39: 4900 of 6400 complete\n","\n","Layer 5: 4950 of 6400 complete\n","\n","Layer 28: 4900 of 6400 complete\n","\n","Layer 25: 4900 of 6400 complete\n","\n","Layer 1: 4950 of 6400 complete\n","\n","Layer 9: 4950 of 6400 complete\n","\n","Layer 38: 4900 of 6400 complete\n","\n","Layer 19: 4950 of 6400 complete\n","\n","Layer 15: 4950 of 6400 complete\n","\n","Layer 13: 4950 of 6400 complete\n","\n","Layer 23: 4950 of 6400 complete\n","\n","Layer 17: 4950 of 6400 complete\n","\n","Layer 12: 4950 of 6400 complete\n","\n","Layer 7: 4950 of 6400 complete\n","\n","Layer 11: 4950 of 6400 complete\n","\n","Layer 14: 4950 of 6400 complete\n","\n","Layer 4: 4950 of 6400 complete\n","\n","Layer 20: 4950 of 6400 complete\n","\n","Layer 8: 4950 of 6400 complete\n","\n","Layer 36: 4950 of 6400 complete\n","\n","Layer 37: 4900 of 6400 complete\n","\n","Layer 10: 4950 of 6400 complete\n","Layer 47: 4950 of 6400 complete\n","\n","\n","Layer 27: 4900 of 6400 complete\n","\n","Layer 22: 4950 of 6400 complete\n","\n","Layer 21: 4950 of 6400 complete\n","\n","Layer 35: 4900 of 6400 complete\n","\n","Layer 46: 4950 of 6400 complete\n","\n","Layer 6: 4950 of 6400 complete\n","\n","Layer 32: 4950 of 6400 complete\n","\n","Layer 40: 4950 of 6400 complete\n","\n","Layer 44: 4900 of 6400 complete\n","\n","Layer 41: 4950 of 6400 complete\n","Layer 2: 4950 of 6400 complete\n","\n","\n","Layer 30: 4950 of 6400 complete\n","\n","Layer 26: 4950 of 6400 complete\n","\n","Layer 29: 4950 of 6400 complete\n","Layer 45: 4950 of 6400 complete\n","Layer 24: 4950 of 6400 complete\n","\n","\n","\n","Layer 34: 4950 of 6400 complete\n","\n","Layer 43: 4950 of 6400 complete\n","\n","Layer 3: 4950 of 6400 complete\n","\n","Layer 0: 5000 of 6400 complete\n","\n","Layer 42: 4950 of 6400 complete\n","\n","Layer 16: 5000 of 6400 complete\n","\n","Layer 31: 5000 of 6400 complete\n","\n","Layer 33: 4950 of 6400 complete\n","\n","Layer 18: 5000 of 6400 complete\n","\n","Layer 28: 4950 of 6400 complete\n","\n","Layer 39: 4950 of 6400 complete\n","\n","Layer 25: 4950 of 6400 complete\n","\n","Layer 5: 5000 of 6400 complete\n","\n","Layer 1: 5000 of 6400 complete\n","\n","Layer 19: 5000 of 6400 complete\n","\n","Layer 9: 5000 of 6400 complete\n","\n","Layer 13: 5000 of 6400 complete\n","\n","Layer 38: 4950 of 6400 complete\n","\n","Layer 15: 5000 of 6400 complete\n","\n","Layer 12: 5000 of 6400 complete\n","\n","Layer 7: 5000 of 6400 complete\n","\n","Layer 14: 5000 of 6400 complete\n","Layer 10: 5000 of 6400 complete\n","\n","Layer 23: 5000 of 6400 complete\n","\n","\n","Layer 20: 5000 of 6400 complete\n","\n","Layer 11: 5000 of 6400 complete\n","\n","Layer 8: 5000 of 6400 complete\n","\n","Layer 37: 4950 of 6400 complete\n","\n","Layer 4: 5000 of 6400 complete\n","\n","Layer 17: 5000 of 6400 complete\n","\n","Layer 36: 5000 of 6400 complete\n","\n","Layer 47: 5000 of 6400 complete\n","\n","Layer 22: 5000 of 6400 complete\n","\n","Layer 21: 5000 of 6400 complete\n","\n","Layer 6: 5000 of 6400 complete\n","\n","Layer 27: 4950 of 6400 complete\n","\n","Layer 46: 5000 of 6400 complete\n","\n","Layer 40: 5000 of 6400 complete\n","\n","Layer 35: 4950 of 6400 complete\n","\n","Layer 32: 5000 of 6400 complete\n","\n","Layer 44: 4950 of 6400 complete\n","\n","Layer 2: 5000 of 6400 complete\n","\n","Layer 30: 5000 of 6400 complete\n","\n","Layer 41: 5000 of 6400 complete\n","\n","Layer 26: 5000 of 6400 complete\n","\n","Layer 45: 5000 of 6400 complete\n","Layer 29: 5000 of 6400 complete\n","\n","\n","Layer 24: 5000 of 6400 complete\n","\n","Layer 34: 5000 of 6400 complete\n","\n","Layer 43: 5000 of 6400 complete\n","\n","Layer 0: 5050 of 6400 complete\n","\n","Layer 3: 5000 of 6400 complete\n","\n","Layer 16: 5050 of 6400 complete\n","\n","Layer 42: 5000 of 6400 complete\n","\n","Layer 31: 5050 of 6400 complete\n","\n","Layer 33: 5000 of 6400 complete\n","\n","Layer 18: 5050 of 6400 complete\n","\n","Layer 39: 5000 of 6400 complete\n","\n","Layer 25: 5000 of 6400 complete\n","\n","Layer 28: 5000 of 6400 complete\n","\n","Layer 1: 5050 of 6400 complete\n","Layer 5: 5050 of 6400 complete\n","\n","\n","Layer 15: 5050 of 6400 complete\n","\n","Layer 38: 5000 of 6400 complete\n","\n","Layer 19: 5050 of 6400 complete\n","\n","Layer 9: 5050 of 6400 complete\n","\n","Layer 13: 5050 of 6400 complete\n","\n","Layer 14: 5050 of 6400 complete\n","\n","Layer 12: 5050 of 6400 complete\n","\n","Layer 23: 5050 of 6400 complete\n","Layer 10: 5050 of 6400 complete\n","\n","\n","Layer 20: 5050 of 6400 complete\n","Layer 4: 5050 of 6400 complete\n","\n","\n","Layer 17: 5050 of 6400 complete\n","\n","Layer 11: 5050 of 6400 complete\n","\n","Layer 8: 5050 of 6400 complete\n","\n","Layer 36: 5050 of 6400 complete\n","\n","Layer 37: 5000 of 6400 complete\n","\n","Layer 6: 5050 of 6400 complete\n","\n","Layer 46: 5050 of 6400 complete\n","Layer 22: 5050 of 6400 complete\n","\n","\n","Layer 47: 5050 of 6400 complete\n","\n","Layer 32: 5050 of 6400 complete\n","\n","Layer 27: 5000 of 6400 complete\n","Layer 21: 5050 of 6400 complete\n","\n","\n","Layer 35: 5000 of 6400 complete\n","\n","Layer 40: 5050 of 6400 complete\n","\n","Layer 44: 5000 of 6400 complete\n","\n","Layer 7: 5050 of 6400 complete\n","\n","Layer 2: 5050 of 6400 complete\n","\n","Layer 30: 5050 of 6400 complete\n","\n","Layer 41: 5050 of 6400 complete\n","\n","Layer 26: 5050 of 6400 complete\n","\n","Layer 29: 5050 of 6400 complete\n","\n","Layer 24: 5050 of 6400 complete\n","\n","Layer 45: 5050 of 6400 complete\n","\n","Layer 34: 5050 of 6400 complete\n","\n","Layer 0: 5100 of 6400 complete\n","\n","Layer 3: 5050 of 6400 complete\n","\n","Layer 43: 5050 of 6400 complete\n","\n","Layer 16: 5100 of 6400 complete\n","\n","Layer 42: 5050 of 6400 complete\n","\n","Layer 33: 5050 of 6400 complete\n","\n","Layer 31: 5100 of 6400 complete\n","\n","Layer 18: 5100 of 6400 complete\n","\n","Layer 28: 5050 of 6400 complete\n","\n","Layer 39: 5050 of 6400 complete\n","\n","Layer 25: 5050 of 6400 complete\n","\n","Layer 1: 5100 of 6400 complete\n","\n","Layer 5: 5100 of 6400 complete\n","\n","Layer 9: 5100 of 6400 complete\n","\n","Layer 19: 5100 of 6400 complete\n","\n","Layer 38: 5050 of 6400 complete\n","\n","Layer 15: 5100 of 6400 complete\n","\n","Layer 13: 5100 of 6400 complete\n","\n","Layer 14: 5100 of 6400 complete\n","\n","Layer 10: 5100 of 6400 complete\n","\n","Layer 12: 5100 of 6400 complete\n","\n","Layer 23: 5100 of 6400 complete\n","\n","Layer 4: 5100 of 6400 complete\n","Layer 36: 5100 of 6400 complete\n","\n","Layer 17: 5100 of 6400 complete\n","\n","\n","Layer 20: 5100 of 6400 complete\n","\n","Layer 11: 5100 of 6400 complete\n","\n","Layer 6: 5100 of 6400 complete\n","\n","Layer 8: 5100 of 6400 complete\n","\n","Layer 46: 5100 of 6400 complete\n","\n","Layer 22: 5100 of 6400 complete\n","\n","Layer 37: 5050 of 6400 complete\n","Layer 40: 5100 of 6400 complete\n","\n","Layer 32: 5100 of 6400 complete\n","\n","\n","Layer 47: 5100 of 6400 complete\n","\n","Layer 21: 5100 of 6400 complete\n","\n","Layer 27: 5050 of 6400 complete\n","\n","Layer 35: 5050 of 6400 complete\n","\n","Layer 44: 5050 of 6400 complete\n","\n","Layer 7: 5100 of 6400 complete\n","\n","Layer 2: 5100 of 6400 complete\n","\n","Layer 41: 5100 of 6400 complete\n","\n","Layer 30: 5100 of 6400 complete\n","\n","Layer 24: 5100 of 6400 complete\n","\n","Layer 26: 5100 of 6400 complete\n","Layer 45: 5100 of 6400 complete\n","\n","\n","Layer 29: 5100 of 6400 complete\n","\n","Layer 34: 5100 of 6400 complete\n","\n","Layer 3: 5100 of 6400 complete\n","\n","Layer 0: 5150 of 6400 complete\n","\n","Layer 43: 5100 of 6400 complete\n","\n","Layer 16: 5150 of 6400 complete\n","\n","Layer 33: 5100 of 6400 complete\n","\n","Layer 18: 5150 of 6400 complete\n","\n","Layer 42: 5100 of 6400 complete\n","\n","Layer 31: 5150 of 6400 complete\n","\n","Layer 25: 5100 of 6400 complete\n","\n","Layer 28: 5100 of 6400 complete\n","\n","Layer 1: 5150 of 6400 complete\n","\n","Layer 5: 5150 of 6400 complete\n","\n","Layer 39: 5100 of 6400 complete\n","\n","Layer 9: 5150 of 6400 complete\n","\n","Layer 10: 5150 of 6400 complete\n","\n","Layer 13: 5150 of 6400 complete\n","\n","Layer 38: 5100 of 6400 complete\n","\n","Layer 15: 5150 of 6400 complete\n","\n","Layer 14: 5150 of 6400 complete\n","\n","Layer 19: 5150 of 6400 complete\n","\n","Layer 12: 5150 of 6400 complete\n","\n","Layer 8: 5150 of 6400 complete\n","\n","Layer 36: 5150 of 6400 complete\n","\n","Layer 11: 5150 of 6400 complete\n","\n","Layer 17: 5150 of 6400 complete\n","\n","Layer 4: 5150 of 6400 complete\n","\n","Layer 20: 5150 of 6400 complete\n","\n","Layer 23: 5150 of 6400 complete\n","\n","Layer 6: 5150 of 6400 complete\n","\n","Layer 40: 5150 of 6400 complete\n","\n","Layer 32: 5150 of 6400 complete\n","\n","Layer 47: 5150 of 6400 complete\n","Layer 46: 5150 of 6400 complete\n","\n","\n","Layer 22: 5150 of 6400 complete\n","\n","Layer 37: 5100 of 6400 complete\n","\n","Layer 27: 5100 of 6400 complete\n","\n","Layer 21: 5150 of 6400 complete\n","\n","Layer 35: 5100 of 6400 complete\n","\n","Layer 44: 5100 of 6400 complete\n","\n","Layer 7: 5150 of 6400 complete\n","\n","Layer 2: 5150 of 6400 complete\n","\n","Layer 30: 5150 of 6400 complete\n","\n","Layer 41: 5150 of 6400 complete\n","\n","Layer 26: 5150 of 6400 complete\n","\n","Layer 29: 5150 of 6400 complete\n","\n","Layer 24: 5150 of 6400 complete\n","\n","Layer 45: 5150 of 6400 complete\n","\n","Layer 34: 5150 of 6400 complete\n","\n","Layer 3: 5150 of 6400 complete\n","\n","Layer 0: 5200 of 6400 complete\n","\n","Layer 43: 5150 of 6400 complete\n","\n","Layer 16: 5200 of 6400 complete\n","\n","Layer 18: 5200 of 6400 complete\n","\n","Layer 33: 5150 of 6400 complete\n","\n","Layer 42: 5150 of 6400 complete\n","\n","Layer 1: 5200 of 6400 complete\n","\n","Layer 31: 5200 of 6400 complete\n","\n","Layer 28: 5150 of 6400 complete\n","\n","Layer 25: 5150 of 6400 complete\n","\n","Layer 15: 5200 of 6400 complete\n","\n","Layer 39: 5150 of 6400 complete\n","\n","Layer 10: 5200 of 6400 complete\n","\n","Layer 5: 5200 of 6400 complete\n","\n","Layer 38: 5150 of 6400 complete\n","\n","Layer 9: 5200 of 6400 complete\n","\n","Layer 13: 5200 of 6400 complete\n","\n","Layer 12: 5200 of 6400 complete\n","\n","Layer 14: 5200 of 6400 complete\n","\n","Layer 19: 5200 of 6400 complete\n","\n","Layer 11: 5200 of 6400 complete\n","\n","Layer 20: 5200 of 6400 complete\n","\n","Layer 17: 5200 of 6400 complete\n","\n","Layer 8: 5200 of 6400 complete\n","\n","Layer 36: 5200 of 6400 complete\n","Layer 4: 5200 of 6400 complete\n","\n","Layer 23: 5200 of 6400 complete\n","\n","\n","Layer 40: 5200 of 6400 complete\n","\n","Layer 6: 5200 of 6400 complete\n","\n","Layer 47: 5200 of 6400 complete\n","\n","Layer 46: 5200 of 6400 complete\n","\n","Layer 22: 5200 of 6400 complete\n","\n","Layer 32: 5200 of 6400 complete\n","\n","Layer 37: 5150 of 6400 complete\n","\n","Layer 7: 5200 of 6400 complete\n","\n","Layer 44: 5150 of 6400 complete\n","Layer 27: 5150 of 6400 complete\n","\n","\n","Layer 35: 5150 of 6400 complete\n","\n","Layer 2: 5200 of 6400 complete\n","\n","Layer 21: 5200 of 6400 complete\n","\n","Layer 30: 5200 of 6400 complete\n","\n","Layer 41: 5200 of 6400 complete\n","\n","Layer 26: 5200 of 6400 complete\n","\n","Layer 29: 5200 of 6400 complete\n","\n","Layer 45: 5200 of 6400 complete\n","\n","Layer 34: 5200 of 6400 complete\n","\n","Layer 3: 5200 of 6400 complete\n","\n","Layer 24: 5200 of 6400 complete\n","\n","Layer 0: 5250 of 6400 complete\n","\n","Layer 43: 5200 of 6400 complete\n","\n","Layer 18: 5250 of 6400 complete\n","\n","Layer 33: 5200 of 6400 complete\n","Layer 16: 5250 of 6400 complete\n","\n","\n","Layer 25: 5200 of 6400 complete\n","\n","Layer 1: 5250 of 6400 complete\n","\n","Layer 31: 5250 of 6400 complete\n","\n","Layer 28: 5200 of 6400 complete\n","\n","Layer 42: 5200 of 6400 complete\n","\n","Layer 15: 5250 of 6400 complete\n","\n","Layer 39: 5200 of 6400 complete\n","\n","Layer 38: 5200 of 6400 complete\n","\n","Layer 10: 5250 of 6400 complete\n","\n","Layer 12: 5250 of 6400 complete\n","Layer 14: 5250 of 6400 complete\n","\n","\n","Layer 9: 5250 of 6400 complete\n","\n","Layer 20: 5250 of 6400 complete\n","\n","Layer 13: 5250 of 6400 complete\n","\n","Layer 5: 5250 of 6400 complete\n","\n","Layer 19: 5250 of 6400 complete\n","Layer 11: 5250 of 6400 complete\n","\n","\n","Layer 8: 5250 of 6400 complete\n","\n","Layer 36: 5250 of 6400 complete\n","\n","Layer 17: 5250 of 6400 complete\n","\n","Layer 4: 5250 of 6400 complete\n","\n","Layer 23: 5250 of 6400 complete\n","\n","Layer 6: 5250 of 6400 complete\n","\n","Layer 40: 5250 of 6400 complete\n","\n","Layer 22: 5250 of 6400 complete\n","\n","Layer 47: 5250 of 6400 complete\n","\n","Layer 46: 5250 of 6400 complete\n","\n","Layer 7: 5250 of 6400 complete\n","\n","Layer 44: 5200 of 6400 complete\n","\n","Layer 32: 5250 of 6400 complete\n","\n","Layer 27: 5200 of 6400 complete\n","\n","Layer 35: 5200 of 6400 complete\n","\n","Layer 37: 5200 of 6400 complete\n","\n","Layer 2: 5250 of 6400 complete\n","\n","Layer 30: 5250 of 6400 complete\n","\n","Layer 21: 5250 of 6400 complete\n","\n","Layer 41: 5250 of 6400 complete\n","\n","Layer 26: 5250 of 6400 complete\n","\n","Layer 45: 5250 of 6400 complete\n","\n","Layer 29: 5250 of 6400 complete\n","\n","Layer 24: 5250 of 6400 complete\n","\n","Layer 3: 5250 of 6400 complete\n","\n","Layer 34: 5250 of 6400 complete\n","\n","Layer 43: 5250 of 6400 complete\n","\n","Layer 0: 5300 of 6400 complete\n","\n","Layer 33: 5250 of 6400 complete\n","\n","Layer 16: 5300 of 6400 complete\n","\n","Layer 1: 5300 of 6400 complete\n","\n","Layer 18: 5300 of 6400 complete\n","\n","Layer 25: 5250 of 6400 complete\n","\n","Layer 31: 5300 of 6400 complete\n","\n","Layer 28: 5250 of 6400 complete\n","\n","Layer 42: 5250 of 6400 complete\n","\n","Layer 15: 5300 of 6400 complete\n","\n","Layer 39: 5250 of 6400 complete\n","\n","Layer 38: 5250 of 6400 complete\n","Layer 9: 5300 of 6400 complete\n","\n","\n","Layer 14: 5300 of 6400 complete\n","\n","Layer 12: 5300 of 6400 complete\n","Layer 19: 5300 of 6400 complete\n","\n","\n","Layer 10: 5300 of 6400 complete\n","\n","Layer 20: 5300 of 6400 complete\n","\n","Layer 8: 5300 of 6400 complete\n","\n","Layer 13: 5300 of 6400 complete\n","\n","Layer 11: 5300 of 6400 complete\n","\n","Layer 5: 5300 of 6400 complete\n","\n","Layer 17: 5300 of 6400 complete\n","\n","Layer 36: 5300 of 6400 complete\n","\n","Layer 6: 5300 of 6400 complete\n","\n","Layer 23: 5300 of 6400 complete\n","\n","Layer 4: 5300 of 6400 complete\n","Layer 47: 5300 of 6400 complete\n","\n","\n","Layer 40: 5300 of 6400 complete\n","\n","Layer 46: 5300 of 6400 complete\n","\n","Layer 22: 5300 of 6400 complete\n","\n","Layer 27: 5250 of 6400 complete\n","\n","Layer 32: 5300 of 6400 complete\n","\n","Layer 44: 5250 of 6400 complete\n","\n","Layer 35: 5250 of 6400 complete\n","Layer 7: 5300 of 6400 complete\n","\n","Layer 37: 5250 of 6400 complete\n","\n","\n","Layer 21: 5300 of 6400 complete\n","\n","Layer 2: 5300 of 6400 complete\n","\n","Layer 30: 5300 of 6400 complete\n","\n","Layer 41: 5300 of 6400 complete\n","\n","Layer 45: 5300 of 6400 complete\n","\n","Layer 26: 5300 of 6400 complete\n","\n","Layer 29: 5300 of 6400 complete\n","\n","Layer 3: 5300 of 6400 complete\n","Layer 24: 5300 of 6400 complete\n","\n","\n","Layer 34: 5300 of 6400 complete\n","\n","Layer 0: 5350 of 6400 complete\n","\n","Layer 16: 5350 of 6400 complete\n","\n","Layer 43: 5300 of 6400 complete\n","\n","Layer 25: 5300 of 6400 complete\n","\n","Layer 33: 5300 of 6400 complete\n","\n","Layer 1: 5350 of 6400 complete\n","\n","Layer 18: 5350 of 6400 complete\n","\n","Layer 42: 5300 of 6400 complete\n","\n","Layer 31: 5350 of 6400 complete\n","\n","Layer 19: 5350 of 6400 complete\n","\n","Layer 39: 5300 of 6400 complete\n","\n","Layer 9: 5350 of 6400 complete\n","Layer 15: 5350 of 6400 complete\n","\n","\n","Layer 28: 5300 of 6400 complete\n","\n","Layer 8: 5350 of 6400 complete\n","\n","Layer 14: 5350 of 6400 complete\n","Layer 38: 5300 of 6400 complete\n","\n","\n","Layer 12: 5350 of 6400 complete\n","\n","Layer 10: 5350 of 6400 complete\n","\n","Layer 13: 5350 of 6400 complete\n","Layer 20: 5350 of 6400 complete\n","\n","\n","Layer 11: 5350 of 6400 complete\n","\n","Layer 5: 5350 of 6400 complete\n","\n","Layer 17: 5350 of 6400 complete\n","\n","Layer 36: 5350 of 6400 complete\n","\n","Layer 4: 5350 of 6400 complete\n","Layer 40: 5350 of 6400 complete\n","\n","\n","Layer 47: 5350 of 6400 complete\n","\n","Layer 22: 5350 of 6400 complete\n","\n","Layer 46: 5350 of 6400 complete\n","\n","Layer 7: 5350 of 6400 complete\n","\n","Layer 23: 5350 of 6400 complete\n","\n","Layer 44: 5300 of 6400 complete\n","\n","Layer 27: 5300 of 6400 complete\n","\n","Layer 6: 5350 of 6400 complete\n","Layer 32: 5350 of 6400 complete\n","\n","\n","Layer 35: 5300 of 6400 complete\n","\n","Layer 37: 5300 of 6400 complete\n","\n","Layer 2: 5350 of 6400 complete\n","\n","Layer 21: 5350 of 6400 complete\n","\n","Layer 30: 5350 of 6400 complete\n","\n","Layer 41: 5350 of 6400 complete\n","\n","Layer 26: 5350 of 6400 complete\n","Layer 29: 5350 of 6400 complete\n","\n","\n","Layer 45: 5350 of 6400 complete\n","\n","Layer 3: 5350 of 6400 complete\n","\n","Layer 24: 5350 of 6400 complete\n","Layer 34: 5350 of 6400 complete\n","\n","\n","Layer 0: 5400 of 6400 complete\n","\n","Layer 43: 5350 of 6400 complete\n","\n","Layer 18: 5400 of 6400 complete\n","\n","Layer 16: 5400 of 6400 complete\n","\n","Layer 33: 5350 of 6400 complete\n","\n","Layer 1: 5400 of 6400 complete\n","\n","Layer 25: 5350 of 6400 complete\n","\n","Layer 31: 5400 of 6400 complete\n","\n","Layer 8: 5400 of 6400 complete\n","\n","Layer 9: 5400 of 6400 complete\n","\n","Layer 42: 5350 of 6400 complete\n","\n","Layer 19: 5400 of 6400 complete\n","\n","Layer 12: 5400 of 6400 complete\n","Layer 28: 5350 of 6400 complete\n","\n","\n","Layer 20: 5400 of 6400 complete\n","Layer 39: 5350 of 6400 complete\n","\n","Layer 15: 5400 of 6400 complete\n","\n","\n","Layer 13: 5400 of 6400 complete\n","\n","Layer 14: 5400 of 6400 complete\n","\n","Layer 38: 5350 of 6400 complete\n","\n","Layer 10: 5400 of 6400 complete\n","Layer 11: 5400 of 6400 complete\n","\n","\n","Layer 17: 5400 of 6400 complete\n","\n","Layer 5: 5400 of 6400 complete\n","\n","Layer 36: 5400 of 6400 complete\n","\n","Layer 4: 5400 of 6400 complete\n","\n","Layer 32: 5400 of 6400 complete\n","Layer 22: 5400 of 6400 complete\n","\n","\n","Layer 47: 5400 of 6400 complete\n","\n","Layer 40: 5400 of 6400 complete\n","\n","Layer 6: 5400 of 6400 complete\n","Layer 44: 5350 of 6400 complete\n","Layer 46: 5400 of 6400 complete\n","\n","\n","\n","Layer 23: 5400 of 6400 complete\n","Layer 7: 5400 of 6400 complete\n","\n","\n","Layer 37: 5350 of 6400 complete\n","\n","Layer 27: 5350 of 6400 complete\n","\n","Layer 35: 5350 of 6400 complete\n","\n","Layer 2: 5400 of 6400 complete\n","\n","Layer 21: 5400 of 6400 complete\n","\n","Layer 30: 5400 of 6400 complete\n","Layer 41: 5400 of 6400 complete\n","\n","\n","Layer 26: 5400 of 6400 complete\n","\n","Layer 29: 5400 of 6400 complete\n","\n","Layer 3: 5400 of 6400 complete\n","\n","Layer 45: 5400 of 6400 complete\n","\n","Layer 34: 5400 of 6400 complete\n","\n","Layer 0: 5450 of 6400 complete\n","\n","Layer 24: 5400 of 6400 complete\n","\n","Layer 43: 5400 of 6400 complete\n","Layer 1: 5450 of 6400 complete\n","\n","\n","Layer 33: 5400 of 6400 complete\n","\n","Layer 18: 5450 of 6400 complete\n","\n","Layer 16: 5450 of 6400 complete\n","\n","Layer 31: 5450 of 6400 complete\n","\n","Layer 25: 5400 of 6400 complete\n","\n","Layer 9: 5450 of 6400 complete\n","\n","Layer 12: 5450 of 6400 complete\n","\n","Layer 28: 5400 of 6400 complete\n","Layer 39: 5400 of 6400 complete\n","Layer 20: 5450 of 6400 complete\n","\n","\n","Layer 8: 5450 of 6400 complete\n","\n","\n","Layer 42: 5400 of 6400 complete\n","\n","Layer 13: 5450 of 6400 complete\n","\n","Layer 15: 5450 of 6400 complete\n","\n","Layer 19: 5450 of 6400 complete\n","\n","Layer 38: 5400 of 6400 complete\n","\n","Layer 14: 5450 of 6400 complete\n","\n","Layer 11: 5450 of 6400 complete\n","\n","Layer 10: 5450 of 6400 complete\n","\n","Layer 17: 5450 of 6400 complete\n","\n","Layer 5: 5450 of 6400 complete\n","\n","Layer 4: 5450 of 6400 complete\n","\n","Layer 47: 5450 of 6400 complete\n","\n","Layer 22: 5450 of 6400 complete\n","Layer 36: 5450 of 6400 complete\n","\n","\n","Layer 23: 5450 of 6400 complete\n","\n","Layer 6: 5450 of 6400 complete\n","Layer 32: 5450 of 6400 complete\n","\n","\n","Layer 40: 5450 of 6400 complete\n","Layer 46: 5450 of 6400 complete\n","\n","\n","Layer 27: 5400 of 6400 complete\n","Layer 7: 5450 of 6400 complete\n","\n","\n","Layer 35: 5400 of 6400 complete\n","\n","Layer 44: 5400 of 6400 complete\n","\n","Layer 37: 5400 of 6400 complete\n","\n","Layer 2: 5450 of 6400 complete\n","\n","Layer 21: 5450 of 6400 complete\n","\n","Layer 30: 5450 of 6400 complete\n","\n","Layer 26: 5450 of 6400 complete\n","\n","Layer 41: 5450 of 6400 complete\n","\n","Layer 29: 5450 of 6400 complete\n","\n","Layer 45: 5450 of 6400 complete\n","\n","Layer 3: 5450 of 6400 complete\n","\n","Layer 0: 5500 of 6400 complete\n","\n","Layer 24: 5450 of 6400 complete\n","\n","Layer 34: 5450 of 6400 complete\n","\n","Layer 33: 5450 of 6400 complete\n","\n","Layer 1: 5500 of 6400 complete\n","Layer 31: 5500 of 6400 complete\n","\n","\n","Layer 43: 5450 of 6400 complete\n","\n","Layer 18: 5500 of 6400 complete\n","\n","Layer 16: 5500 of 6400 complete\n","\n","Layer 25: 5450 of 6400 complete\n","\n","Layer 9: 5500 of 6400 complete\n","\n","Layer 12: 5500 of 6400 complete\n","Layer 39: 5450 of 6400 complete\n","\n","\n","Layer 20: 5500 of 6400 complete\n","\n","Layer 13: 5500 of 6400 complete\n","\n","Layer 15: 5500 of 6400 complete\n","\n","Layer 42: 5450 of 6400 complete\n","\n","Layer 28: 5450 of 6400 complete\n","\n","Layer 8: 5500 of 6400 complete\n","\n","Layer 19: 5500 of 6400 complete\n","\n","Layer 38: 5450 of 6400 complete\n","\n","Layer 17: 5500 of 6400 complete\n","\n","Layer 10: 5500 of 6400 complete\n","\n","Layer 14: 5500 of 6400 complete\n","\n","Layer 11: 5500 of 6400 complete\n","\n","Layer 5: 5500 of 6400 complete\n","\n","Layer 22: 5500 of 6400 complete\n","\n","Layer 4: 5500 of 6400 complete\n","\n","Layer 47: 5500 of 6400 complete\n","\n","Layer 23: 5500 of 6400 complete\n","\n","Layer 36: 5500 of 6400 complete\n","\n","Layer 32: 5500 of 6400 complete\n","Layer 27: 5450 of 6400 complete\n","\n","\n","Layer 46: 5500 of 6400 complete\n","\n","Layer 6: 5500 of 6400 complete\n","\n","Layer 35: 5450 of 6400 complete\n","\n","Layer 44: 5450 of 6400 complete\n","\n","Layer 7: 5500 of 6400 complete\n","\n","Layer 40: 5500 of 6400 complete\n","\n","Layer 37: 5450 of 6400 complete\n","\n","Layer 2: 5500 of 6400 complete\n","\n","Layer 30: 5500 of 6400 complete\n","\n","Layer 21: 5500 of 6400 complete\n","\n","Layer 26: 5500 of 6400 complete\n","\n","Layer 41: 5500 of 6400 complete\n","\n","Layer 29: 5500 of 6400 complete\n","\n","Layer 3: 5500 of 6400 complete\n","\n","Layer 24: 5500 of 6400 complete\n","\n","Layer 45: 5500 of 6400 complete\n","\n","Layer 0: 5550 of 6400 complete\n","\n","Layer 34: 5500 of 6400 complete\n","\n","Layer 33: 5500 of 6400 complete\n","\n","Layer 1: 5550 of 6400 complete\n","\n","Layer 31: 5550 of 6400 complete\n","\n","Layer 43: 5500 of 6400 complete\n","\n","Layer 18: 5550 of 6400 complete\n","\n","Layer 16: 5550 of 6400 complete\n","Layer 12: 5550 of 6400 complete\n","\n","\n","Layer 25: 5500 of 6400 complete\n","\n","Layer 9: 5550 of 6400 complete\n","\n","Layer 13: 5550 of 6400 complete\n","\n","Layer 20: 5550 of 6400 complete\n","\n","Layer 15: 5550 of 6400 complete\n","\n","Layer 39: 5500 of 6400 complete\n","\n","Layer 28: 5500 of 6400 complete\n","\n","Layer 42: 5500 of 6400 complete\n","\n","Layer 8: 5550 of 6400 complete\n","\n","Layer 10: 5550 of 6400 complete\n","\n","Layer 17: 5550 of 6400 complete\n","\n","Layer 19: 5550 of 6400 complete\n","\n","Layer 38: 5500 of 6400 complete\n","\n","Layer 5: 5550 of 6400 complete\n","\n","Layer 11: 5550 of 6400 complete\n","\n","Layer 14: 5550 of 6400 complete\n","\n","Layer 22: 5550 of 6400 complete\n","\n","Layer 27: 5500 of 6400 complete\n","\n","Layer 23: 5550 of 6400 complete\n","\n","Layer 36: 5550 of 6400 complete\n","\n","Layer 46: 5550 of 6400 complete\n","\n","Layer 6: 5550 of 6400 complete\n","Layer 4: 5550 of 6400 complete\n","\n","\n","Layer 47: 5550 of 6400 complete\n","\n","Layer 32: 5550 of 6400 complete\n","\n","Layer 44: 5500 of 6400 complete\n","\n","Layer 35: 5500 of 6400 complete\n","\n","Layer 40: 5550 of 6400 complete\n","\n","Layer 7: 5550 of 6400 complete\n","\n","Layer 2: 5550 of 6400 complete\n","\n","Layer 21: 5550 of 6400 complete\n","\n","Layer 30: 5550 of 6400 complete\n","\n","Layer 37: 5500 of 6400 complete\n","\n","Layer 41: 5550 of 6400 complete\n","\n","Layer 26: 5550 of 6400 complete\n","\n","Layer 29: 5550 of 6400 complete\n","\n","Layer 24: 5550 of 6400 complete\n","\n","Layer 3: 5550 of 6400 complete\n","\n","Layer 45: 5550 of 6400 complete\n","\n","Layer 0: 5600 of 6400 complete\n","\n","Layer 34: 5550 of 6400 complete\n","\n","Layer 1: 5600 of 6400 complete\n","\n","Layer 33: 5550 of 6400 complete\n","\n","Layer 18: 5600 of 6400 complete\n","\n","Layer 12: 5600 of 6400 complete\n","\n","Layer 16: 5600 of 6400 complete\n","\n","Layer 31: 5600 of 6400 complete\n","\n","Layer 15: 5600 of 6400 complete\n","\n","Layer 43: 5550 of 6400 complete\n","\n","Layer 25: 5550 of 6400 complete\n","\n","Layer 13: 5600 of 6400 complete\n","\n","Layer 9: 5600 of 6400 complete\n","\n","Layer 39: 5550 of 6400 complete\n","\n","Layer 42: 5550 of 6400 complete\n","\n","Layer 20: 5600 of 6400 complete\n","\n","Layer 28: 5550 of 6400 complete\n","Layer 10: 5600 of 6400 complete\n","\n","\n","Layer 17: 5600 of 6400 complete\n","\n","Layer 8: 5600 of 6400 complete\n","\n","Layer 38: 5550 of 6400 complete\n","Layer 19: 5600 of 6400 complete\n","\n","\n","Layer 11: 5600 of 6400 complete\n","\n","Layer 22: 5600 of 6400 complete\n","\n","Layer 27: 5550 of 6400 complete\n","\n","Layer 46: 5600 of 6400 complete\n","\n","Layer 5: 5600 of 6400 complete\n","\n","Layer 36: 5600 of 6400 complete\n","\n","Layer 4: 5600 of 6400 complete\n","\n","Layer 7: 5600 of 6400 complete\n","\n","Layer 6: 5600 of 6400 complete\n","\n","Layer 14: 5600 of 6400 complete\n","\n","Layer 32: 5600 of 6400 complete\n","\n","Layer 23: 5600 of 6400 complete\n","\n","Layer 47: 5600 of 6400 complete\n","\n","Layer 40: 5600 of 6400 complete\n","\n","Layer 35: 5550 of 6400 complete\n","\n","Layer 44: 5550 of 6400 complete\n","\n","Layer 2: 5600 of 6400 complete\n","\n","Layer 21: 5600 of 6400 complete\n","\n","Layer 30: 5600 of 6400 complete\n","\n","Layer 37: 5550 of 6400 complete\n","\n","Layer 26: 5600 of 6400 complete\n","Layer 41: 5600 of 6400 complete\n","\n","\n","Layer 24: 5600 of 6400 complete\n","\n","Layer 29: 5600 of 6400 complete\n","\n","Layer 3: 5600 of 6400 complete\n","\n","Layer 0: 5650 of 6400 complete\n","\n","Layer 45: 5600 of 6400 complete\n","\n","Layer 34: 5600 of 6400 complete\n","\n","Layer 1: 5650 of 6400 complete\n","\n","Layer 33: 5600 of 6400 complete\n","\n","Layer 12: 5650 of 6400 complete\n","\n","Layer 13: 5650 of 6400 complete\n","\n","Layer 31: 5650 of 6400 complete\n","Layer 15: 5650 of 6400 complete\n","\n","\n","Layer 18: 5650 of 6400 complete\n","\n","Layer 16: 5650 of 6400 complete\n","\n","Layer 25: 5600 of 6400 complete\n","\n","Layer 9: 5650 of 6400 complete\n","\n","Layer 43: 5600 of 6400 complete\n","\n","Layer 28: 5600 of 6400 complete\n","\n","Layer 42: 5600 of 6400 complete\n","\n","Layer 20: 5650 of 6400 complete\n","\n","Layer 8: 5650 of 6400 complete\n","\n","Layer 17: 5650 of 6400 complete\n","\n","Layer 10: 5650 of 6400 complete\n","\n","Layer 39: 5600 of 6400 complete\n","\n","Layer 19: 5650 of 6400 complete\n","\n","Layer 11: 5650 of 6400 complete\n","\n","Layer 27: 5600 of 6400 complete\n","\n","Layer 22: 5650 of 6400 complete\n","Layer 38: 5600 of 6400 complete\n","\n","\n","Layer 5: 5650 of 6400 complete\n","\n","Layer 32: 5650 of 6400 complete\n","\n","Layer 14: 5650 of 6400 complete\n","\n","Layer 46: 5650 of 6400 complete\n","Layer 6: 5650 of 6400 complete\n","\n","\n","Layer 23: 5650 of 6400 complete\n","\n","Layer 7: 5650 of 6400 complete\n","Layer 36: 5650 of 6400 complete\n","\n","\n","Layer 4: 5650 of 6400 complete\n","\n","Layer 47: 5650 of 6400 complete\n","\n","Layer 44: 5600 of 6400 complete\n","\n","Layer 40: 5650 of 6400 complete\n","\n","Layer 35: 5600 of 6400 complete\n","\n","Layer 30: 5650 of 6400 complete\n","\n","Layer 2: 5650 of 6400 complete\n","\n","Layer 21: 5650 of 6400 complete\n","\n","Layer 41: 5650 of 6400 complete\n","\n","Layer 26: 5650 of 6400 complete\n","\n","Layer 29: 5650 of 6400 complete\n","\n","Layer 37: 5600 of 6400 complete\n","\n","Layer 24: 5650 of 6400 complete\n","\n","Layer 0: 5700 of 6400 complete\n","\n","Layer 3: 5650 of 6400 complete\n","\n","Layer 45: 5650 of 6400 complete\n","\n","Layer 34: 5650 of 6400 complete\n","\n","Layer 1: 5700 of 6400 complete\n","\n","Layer 12: 5700 of 6400 complete\n","\n","Layer 13: 5700 of 6400 complete\n","\n","Layer 9: 5700 of 6400 complete\n","\n","Layer 15: 5700 of 6400 complete\n","\n","Layer 18: 5700 of 6400 complete\n","\n","Layer 31: 5700 of 6400 complete\n","\n","Layer 25: 5650 of 6400 complete\n","\n","Layer 16: 5700 of 6400 complete\n","\n","Layer 28: 5650 of 6400 complete\n","\n","Layer 43: 5650 of 6400 complete\n","\n","Layer 33: 5650 of 6400 complete\n","\n","Layer 20: 5700 of 6400 complete\n","\n","Layer 8: 5700 of 6400 complete\n","Layer 42: 5650 of 6400 complete\n","\n","\n","Layer 10: 5700 of 6400 complete\n","\n","Layer 17: 5700 of 6400 complete\n","\n","Layer 27: 5650 of 6400 complete\n","\n","Layer 11: 5700 of 6400 complete\n","\n","Layer 39: 5650 of 6400 complete\n","\n","Layer 19: 5700 of 6400 complete\n","\n","Layer 36: 5700 of 6400 complete\n","Layer 6: 5700 of 6400 complete\n","\n","\n","Layer 22: 5700 of 6400 complete\n","\n","Layer 14: 5700 of 6400 complete\n","\n","Layer 32: 5700 of 6400 complete\n","Layer 46: 5700 of 6400 complete\n","\n","\n","Layer 7: 5700 of 6400 complete\n","Layer 5: 5700 of 6400 complete\n","\n","\n","Layer 23: 5700 of 6400 complete\n","\n","Layer 4: 5700 of 6400 complete\n","\n","Layer 38: 5650 of 6400 complete\n","\n","Layer 44: 5650 of 6400 complete\n","\n","Layer 47: 5700 of 6400 complete\n","Layer 40: 5700 of 6400 complete\n","\n","\n","Layer 35: 5650 of 6400 complete\n","\n","Layer 2: 5700 of 6400 complete\n","\n","Layer 30: 5700 of 6400 complete\n","\n","Layer 21: 5700 of 6400 complete\n","\n","Layer 26: 5700 of 6400 complete\n","\n","Layer 41: 5700 of 6400 complete\n","\n","Layer 29: 5700 of 6400 complete\n","\n","Layer 0: 5750 of 6400 complete\n","\n","Layer 24: 5700 of 6400 complete\n","\n","Layer 3: 5700 of 6400 complete\n","\n","Layer 37: 5650 of 6400 complete\n","\n","Layer 34: 5700 of 6400 complete\n","\n","Layer 1: 5750 of 6400 complete\n","\n","Layer 45: 5700 of 6400 complete\n","\n","Layer 12: 5750 of 6400 complete\n","\n","Layer 9: 5750 of 6400 complete\n","\n","Layer 13: 5750 of 6400 complete\n","\n","Layer 18: 5750 of 6400 complete\n","\n","Layer 25: 5700 of 6400 complete\n","\n","Layer 43: 5700 of 6400 complete\n","\n","Layer 33: 5700 of 6400 complete\n","\n","Layer 15: 5750 of 6400 complete\n","\n","Layer 31: 5750 of 6400 complete\n","\n","Layer 16: 5750 of 6400 complete\n","\n","Layer 20: 5750 of 6400 complete\n","\n","Layer 17: 5750 of 6400 complete\n","\n","Layer 8: 5750 of 6400 complete\n","\n","Layer 28: 5700 of 6400 complete\n","\n","Layer 10: 5750 of 6400 complete\n","\n","Layer 42: 5700 of 6400 complete\n","\n","Layer 27: 5700 of 6400 complete\n","\n","Layer 39: 5700 of 6400 complete\n","\n","Layer 11: 5750 of 6400 complete\n","\n","Layer 36: 5750 of 6400 complete\n","\n","Layer 19: 5750 of 6400 complete\n","\n","Layer 6: 5750 of 6400 complete\n","\n","Layer 46: 5750 of 6400 complete\n","\n","Layer 22: 5750 of 6400 complete\n","\n","Layer 5: 5750 of 6400 complete\n","\n","Layer 14: 5750 of 6400 complete\n","\n","Layer 23: 5750 of 6400 complete\n","\n","Layer 38: 5700 of 6400 complete\n","\n","Layer 40: 5750 of 6400 complete\n","Layer 32: 5750 of 6400 complete\n","\n","\n","Layer 7: 5750 of 6400 complete\n","\n","Layer 4: 5750 of 6400 complete\n","Layer 44: 5700 of 6400 complete\n","\n","\n","Layer 47: 5750 of 6400 complete\n","\n","Layer 35: 5700 of 6400 complete\n","\n","Layer 2: 5750 of 6400 complete\n","\n","Layer 30: 5750 of 6400 complete\n","\n","Layer 21: 5750 of 6400 complete\n","\n","Layer 41: 5750 of 6400 complete\n","\n","Layer 29: 5750 of 6400 complete\n","Layer 0: 5800 of 6400 complete\n","\n","\n","Layer 26: 5750 of 6400 complete\n","Layer 24: 5750 of 6400 complete\n","\n","\n","Layer 3: 5750 of 6400 complete\n","\n","Layer 1: 5800 of 6400 complete\n","\n","Layer 37: 5700 of 6400 complete\n","\n","Layer 34: 5750 of 6400 complete\n","\n","Layer 12: 5800 of 6400 complete\n","\n","Layer 45: 5750 of 6400 complete\n","\n","Layer 9: 5800 of 6400 complete\n","\n","Layer 13: 5800 of 6400 complete\n","\n","Layer 25: 5750 of 6400 complete\n","\n","Layer 15: 5800 of 6400 complete\n","\n","Layer 33: 5750 of 6400 complete\n","\n","Layer 18: 5800 of 6400 complete\n","\n","Layer 16: 5800 of 6400 complete\n","\n","Layer 8: 5800 of 6400 complete\n","\n","Layer 17: 5800 of 6400 complete\n","\n","Layer 20: 5800 of 6400 complete\n","\n","Layer 43: 5750 of 6400 complete\n","Layer 31: 5800 of 6400 complete\n","\n","\n","Layer 11: 5800 of 6400 complete\n","\n","Layer 10: 5800 of 6400 complete\n","Layer 28: 5750 of 6400 complete\n","\n","\n","Layer 42: 5750 of 6400 complete\n","\n","Layer 27: 5750 of 6400 complete\n","\n","Layer 39: 5750 of 6400 complete\n","\n","Layer 36: 5800 of 6400 complete\n","\n","Layer 19: 5800 of 6400 complete\n","\n","Layer 5: 5800 of 6400 complete\n","\n","Layer 38: 5750 of 6400 complete\n","\n","Layer 46: 5800 of 6400 complete\n","\n","Layer 7: 5800 of 6400 complete\n","\n","Layer 22: 5800 of 6400 complete\n","\n","Layer 6: 5800 of 6400 complete\n","Layer 32: 5800 of 6400 complete\n","\n","\n","Layer 23: 5800 of 6400 complete\n","\n","Layer 14: 5800 of 6400 complete\n","\n","Layer 40: 5800 of 6400 complete\n","\n","Layer 47: 5800 of 6400 complete\n","\n","Layer 44: 5750 of 6400 complete\n","\n","Layer 4: 5800 of 6400 complete\n","Layer 35: 5750 of 6400 complete\n","\n","\n","Layer 2: 5800 of 6400 complete\n","\n","Layer 21: 5800 of 6400 complete\n","\n","Layer 30: 5800 of 6400 complete\n","\n","Layer 3: 5800 of 6400 complete\n","\n","Layer 41: 5800 of 6400 complete\n","\n","Layer 26: 5800 of 6400 complete\n","\n","Layer 29: 5800 of 6400 complete\n","\n","Layer 24: 5800 of 6400 complete\n","Layer 0: 5850 of 6400 complete\n","\n","\n","Layer 1: 5850 of 6400 complete\n","\n","Layer 37: 5750 of 6400 complete\n","\n","Layer 12: 5850 of 6400 complete\n","\n","Layer 34: 5800 of 6400 complete\n","\n","Layer 9: 5850 of 6400 complete\n","\n","Layer 45: 5800 of 6400 complete\n","\n","Layer 13: 5850 of 6400 complete\n","\n","Layer 15: 5850 of 6400 complete\n","\n","Layer 25: 5800 of 6400 complete\n","\n","Layer 18: 5850 of 6400 complete\n","\n","Layer 16: 5850 of 6400 complete\n","\n","Layer 8: 5850 of 6400 complete\n","Layer 33: 5800 of 6400 complete\n","\n","\n","Layer 20: 5850 of 6400 complete\n","\n","Layer 31: 5850 of 6400 complete\n","\n","Layer 17: 5850 of 6400 complete\n","\n","Layer 11: 5850 of 6400 complete\n","\n","Layer 43: 5800 of 6400 complete\n","\n","Layer 28: 5800 of 6400 complete\n","\n","Layer 27: 5800 of 6400 complete\n","\n","Layer 10: 5850 of 6400 complete\n","\n","Layer 39: 5800 of 6400 complete\n","\n","Layer 19: 5850 of 6400 complete\n","\n","Layer 42: 5800 of 6400 complete\n","Neuron 5823 in layer 34 failedNeuron 5828 in layer 24 failedNeuron 5828 in layer 41 failed\n","Neuron 5859 in layer 31 failed\n","\n","Neuron 5858 in layer 20 failed\n","\n","Neuron 5859 in layer 8 failed\n","\n","Layer 36: 5850 of 6400 complete\n","\n","Layer 7: 5850 of 6400 complete\n","\n","Layer 23: 5850 of 6400 complete\n","\n","Layer 38: 5800 of 6400 complete\n","Layer 6: 5850 of 6400 complete\n","\n","\n","Layer 5: 5850 of 6400 complete\n","\n","Layer 46: 5850 of 6400 complete\n","Layer 32: 5850 of 6400 complete\n","\n","\n","Layer 40: 5850 of 6400 complete\n","\n","Layer 22: 5850 of 6400 complete\n","\n","Layer 14: 5850 of 6400 complete\n","\n","Layer 35: 5800 of 6400 complete\n","\n","Layer 4: 5850 of 6400 complete\n","Layer 44: 5800 of 6400 complete\n","\n","\n","Layer 47: 5850 of 6400 complete\n","\n","Layer 30: 5850 of 6400 complete\n","\n","Layer 2: 5850 of 6400 complete\n","\n","Layer 21: 5850 of 6400 complete\n","\n","Layer 3: 5850 of 6400 complete\n","\n","Layer 29: 5850 of 6400 complete\n","\n","Layer 24: 5850 of 6400 complete\n","\n","Layer 0: 5900 of 6400 completeNeuron 5849 in layer 26 failed\n","Neuron 5874 in layer 19 failed\n","\n","Layer 26: 5850 of 6400 complete\n","\n","Layer 41: 5850 of 6400 complete\n","Neuron 5881 in layer 8 failed\n","\n","Layer 1: 5900 of 6400 complete\n","\n","\n","Layer 12: 5900 of 6400 complete\n","\n","Layer 37: 5800 of 6400 complete\n","\n","Layer 34: 5850 of 6400 complete\n","\n","Layer 9: 5900 of 6400 complete\n","\n","Layer 45: 5850 of 6400 complete\n","\n","Layer 13: 5900 of 6400 complete\n","\n","Layer 15: 5900 of 6400 complete\n","\n","Layer 18: 5900 of 6400 complete\n","\n","Layer 16: 5900 of 6400 complete\n","\n","Layer 25: 5850 of 6400 complete\n","Layer 31: 5900 of 6400 complete\n","\n","\n","Layer 8: 5900 of 6400 complete\n","\n","Layer 33: 5850 of 6400 complete\n","Layer 20: 5900 of 6400 complete\n","\n","\n","Layer 11: 5900 of 6400 complete\n","\n","Layer 28: 5850 of 6400 complete\n","\n","Layer 17: 5900 of 6400 complete\n","\n","Layer 39: 5850 of 6400 complete\n","\n","Layer 27: 5850 of 6400 complete\n","\n","Layer 10: 5900 of 6400 complete\n","\n","Layer 43: 5850 of 6400 complete\n","\n","Layer 19: 5900 of 6400 complete\n","\n","Layer 42: 5850 of 6400 complete\n","\n","Layer 6: 5900 of 6400 complete\n","\n","Layer 38: 5850 of 6400 complete\n","\n","Layer 36: 5900 of 6400 complete\n","\n","Layer 32: 5900 of 6400 complete\n","\n","Layer 46: 5900 of 6400 complete\n","\n","Layer 5: 5900 of 6400 complete\n","Layer 23: 5900 of 6400 complete\n","\n","\n","Layer 22: 5900 of 6400 complete\n","\n","Layer 14: 5900 of 6400 complete\n","\n","Layer 7: 5900 of 6400 complete\n","Layer 40: 5900 of 6400 complete\n","\n","\n","Layer 4: 5900 of 6400 complete\n","\n","Layer 47: 5900 of 6400 complete\n","\n","Layer 44: 5850 of 6400 complete\n","\n","Layer 30: 5900 of 6400 complete\n","\n","Layer 2: 5900 of 6400 complete\n","\n","Layer 35: 5850 of 6400 complete\n","\n","Layer 21: 5900 of 6400 complete\n","\n","Layer 26: 5900 of 6400 complete\n","\n","Layer 3: 5900 of 6400 complete\n","\n","Layer 0: 5950 of 6400 complete\n","\n","Layer 24: 5900 of 6400 complete\n","\n","Layer 1: 5950 of 6400 complete\n","Layer 41: 5900 of 6400 complete\n","\n","\n","Layer 12: 5950 of 6400 complete\n","\n","Layer 29: 5900 of 6400 complete\n","\n","Layer 37: 5850 of 6400 complete\n","\n","Layer 34: 5900 of 6400 complete\n","\n","Layer 9: 5950 of 6400 complete\n","\n","Layer 13: 5950 of 6400 complete\n","\n","Layer 45: 5900 of 6400 complete\n","\n","Layer 18: 5950 of 6400 complete\n","\n","Layer 15: 5950 of 6400 complete\n","\n","Layer 16: 5950 of 6400 complete\n","\n","Layer 20: 5950 of 6400 complete\n","\n","Layer 33: 5900 of 6400 complete\n","Layer 8: 5950 of 6400 complete\n","\n","\n","Layer 25: 5900 of 6400 complete\n","\n","Layer 31: 5950 of 6400 complete\n","\n","Layer 28: 5900 of 6400 complete\n","\n","Layer 11: 5950 of 6400 complete\n","\n","Layer 10: 5950 of 6400 complete\n","\n","Layer 17: 5950 of 6400 complete\n","Layer 27: 5900 of 6400 complete\n","\n","\n","Layer 43: 5900 of 6400 complete\n","\n","Layer 19: 5950 of 6400 complete\n","\n","Layer 42: 5900 of 6400 complete\n","\n","Layer 39: 5900 of 6400 complete\n","\n","Layer 38: 5900 of 6400 complete\n","\n","Layer 6: 5950 of 6400 complete\n","\n","Layer 36: 5950 of 6400 complete\n","\n","Layer 46: 5950 of 6400 complete\n","\n","Layer 22: 5950 of 6400 complete\n","\n","Layer 23: 5950 of 6400 complete\n","Layer 40: 5950 of 6400 complete\n","\n","\n","Layer 7: 5950 of 6400 complete\n","\n","Layer 5: 5950 of 6400 complete\n","\n","Layer 14: 5950 of 6400 complete\n","\n","Layer 32: 5950 of 6400 complete\n","\n","Layer 4: 5950 of 6400 complete\n","\n","Layer 44: 5900 of 6400 complete\n","\n","Layer 30: 5950 of 6400 complete\n","\n","Layer 2: 5950 of 6400 complete\n","\n","Layer 47: 5950 of 6400 complete\n","\n","Layer 21: 5950 of 6400 complete\n","\n","Layer 35: 5900 of 6400 complete\n","\n","Layer 0: 6000 of 6400 complete\n","\n","Layer 12: 6000 of 6400 complete\n","\n","Layer 3: 5950 of 6400 complete\n","\n","Layer 26: 5950 of 6400 complete\n","\n","Layer 24: 5950 of 6400 complete\n","\n","Layer 1: 6000 of 6400 complete\n","\n","Layer 41: 5950 of 6400 complete\n","\n","Layer 29: 5950 of 6400 complete\n","\n","Layer 34: 5950 of 6400 complete\n","\n","Layer 37: 5900 of 6400 complete\n","\n","Layer 13: 6000 of 6400 complete\n","\n","Layer 9: 6000 of 6400 complete\n","\n","Layer 45: 5950 of 6400 complete\n","\n","Layer 18: 6000 of 6400 complete\n","\n","Layer 16: 6000 of 6400 complete\n","\n","Layer 15: 6000 of 6400 complete\n","\n","Layer 20: 6000 of 6400 complete\n","\n","Layer 31: 6000 of 6400 complete\n","\n","Layer 8: 6000 of 6400 complete\n","\n","Layer 25: 5950 of 6400 complete\n","\n","Layer 10: 6000 of 6400 complete\n","\n","Layer 28: 5950 of 6400 complete\n","Layer 11: 6000 of 6400 complete\n","Layer 27: 5950 of 6400 complete\n","\n","\n","\n","Layer 17: 6000 of 6400 complete\n","\n","Layer 33: 5950 of 6400 complete\n","\n","Layer 43: 5950 of 6400 complete\n","\n","Layer 19: 6000 of 6400 complete\n","\n","Layer 39: 5950 of 6400 complete\n","\n","Layer 38: 5950 of 6400 complete\n","\n","Layer 42: 5950 of 6400 complete\n","\n","Layer 23: 6000 of 6400 complete\n","\n","Layer 6: 6000 of 6400 complete\n","\n","Layer 36: 6000 of 6400 complete\n","\n","Layer 46: 6000 of 6400 complete\n","\n","Layer 22: 6000 of 6400 complete\n","\n","Layer 40: 6000 of 6400 complete\n","\n","Layer 32: 6000 of 6400 complete\n","Layer 14: 6000 of 6400 complete\n","\n","Layer 5: 6000 of 6400 complete\n","Layer 7: 6000 of 6400 complete\n","\n","\n","\n","Layer 4: 6000 of 6400 complete\n","\n","Layer 2: 6000 of 6400 complete\n","\n","Layer 30: 6000 of 6400 complete\n","\n","Layer 44: 5950 of 6400 complete\n","\n","Layer 47: 6000 of 6400 complete\n","\n","Layer 21: 6000 of 6400 complete\n","\n","Layer 3: 6000 of 6400 complete\n","\n","Layer 24: 6000 of 6400 complete\n","\n","Layer 12: 6050 of 6400 complete\n","\n","Layer 35: 5950 of 6400 complete\n","\n","Layer 0: 6050 of 6400 complete\n","\n","Layer 26: 6000 of 6400 complete\n","\n","Layer 1: 6050 of 6400 complete\n","\n","Layer 41: 6000 of 6400 complete\n","\n","Layer 29: 6000 of 6400 complete\n","\n","Layer 37: 5950 of 6400 complete\n","\n","Layer 34: 6000 of 6400 complete\n","\n","Layer 13: 6050 of 6400 complete\n","\n","Layer 18: 6050 of 6400 complete\n","\n","Layer 45: 6000 of 6400 complete\n","\n","Layer 9: 6050 of 6400 complete\n","\n","Layer 16: 6050 of 6400 complete\n","\n","Layer 20: 6050 of 6400 complete\n","\n","Layer 8: 6050 of 6400 complete\n","\n","Layer 31: 6050 of 6400 complete\n","\n","Layer 15: 6050 of 6400 complete\n","\n","Layer 25: 6000 of 6400 complete\n","\n","Layer 10: 6050 of 6400 complete\n","\n","Layer 33: 6000 of 6400 complete\n","\n","Layer 19: 6050 of 6400 complete\n","\n","Layer 11: 6050 of 6400 complete\n","\n","Layer 28: 6000 of 6400 complete\n","\n","Layer 17: 6050 of 6400 complete\n","\n","Layer 27: 6000 of 6400 complete\n","\n","Layer 43: 6000 of 6400 complete\n","\n","Layer 42: 6000 of 6400 complete\n","\n","Layer 36: 6050 of 6400 complete\n","\n","Layer 39: 6000 of 6400 complete\n","\n","Layer 23: 6050 of 6400 complete\n","\n","Layer 38: 6000 of 6400 complete\n","Layer 46: 6050 of 6400 complete\n","\n","\n","Layer 6: 6050 of 6400 complete\n","\n","Layer 7: 6050 of 6400 complete\n","\n","Layer 32: 6050 of 6400 complete\n","\n","Layer 22: 6050 of 6400 complete\n","\n","Layer 5: 6050 of 6400 complete\n","Layer 14: 6050 of 6400 complete\n","\n","\n","Layer 40: 6050 of 6400 complete\n","\n","Layer 4: 6050 of 6400 complete\n","\n","Layer 30: 6050 of 6400 complete\n","\n","Layer 2: 6050 of 6400 complete\n","\n","Layer 44: 6000 of 6400 complete\n","\n","Layer 21: 6050 of 6400 complete\n","\n","Layer 47: 6050 of 6400 complete\n","\n","Layer 3: 6050 of 6400 complete\n","\n","Layer 26: 6050 of 6400 complete\n","\n","Layer 35: 6000 of 6400 complete\n","\n","Layer 24: 6050 of 6400 complete\n","\n","Layer 1: 6100 of 6400 complete\n","Layer 0: 6100 of 6400 complete\n","\n","\n","Layer 12: 6100 of 6400 complete\n","\n","Layer 41: 6050 of 6400 complete\n","\n","Layer 29: 6050 of 6400 complete\n","\n","Layer 34: 6050 of 6400 complete\n","\n","Layer 37: 6000 of 6400 complete\n","\n","Layer 18: 6100 of 6400 complete\n","\n","Layer 13: 6100 of 6400 complete\n","\n","Layer 9: 6100 of 6400 complete\n","\n","Layer 20: 6100 of 6400 complete\n","Layer 8: 6100 of 6400 complete\n","\n","\n","Layer 45: 6050 of 6400 complete\n","\n","Layer 16: 6100 of 6400 complete\n","\n","Layer 11: 6100 of 6400 complete\n","\n","Layer 31: 6100 of 6400 complete\n","\n","Layer 15: 6100 of 6400 complete\n","\n","Layer 10: 6100 of 6400 complete\n","\n","Layer 17: 6100 of 6400 complete\n","Layer 33: 6050 of 6400 complete\n","\n","\n","Layer 27: 6050 of 6400 complete\n","\n","Layer 25: 6050 of 6400 complete\n","\n","Layer 19: 6100 of 6400 complete\n","\n","Layer 28: 6050 of 6400 complete\n","\n","Layer 43: 6050 of 6400 complete\n","\n","Layer 42: 6050 of 6400 complete\n","\n","Layer 39: 6050 of 6400 complete\n","Layer 36: 6100 of 6400 complete\n","\n","\n","Layer 7: 6100 of 6400 complete\n","\n","Layer 38: 6050 of 6400 complete\n","\n","Layer 23: 6100 of 6400 complete\n","\n","Layer 46: 6100 of 6400 complete\n","\n","Layer 6: 6100 of 6400 complete\n","\n","Layer 5: 6100 of 6400 complete\n","\n","Layer 14: 6100 of 6400 complete\n","\n","Layer 22: 6100 of 6400 complete\n","\n","Layer 30: 6100 of 6400 complete\n","\n","Layer 32: 6100 of 6400 complete\n","\n","Layer 40: 6100 of 6400 complete\n","\n","Layer 4: 6100 of 6400 complete\n","\n","Layer 2: 6100 of 6400 complete\n","\n","Layer 44: 6050 of 6400 complete\n","\n","Layer 47: 6100 of 6400 complete\n","\n","Layer 21: 6100 of 6400 complete\n","\n","Layer 3: 6100 of 6400 complete\n","\n","Layer 26: 6100 of 6400 complete\n","\n","Layer 35: 6050 of 6400 complete\n","\n","Layer 24: 6100 of 6400 complete\n","\n","Layer 0: 6150 of 6400 complete\n","\n","Layer 1: 6150 of 6400 complete\n","\n","Layer 12: 6150 of 6400 complete\n","\n","Layer 29: 6100 of 6400 complete\n","Layer 41: 6100 of 6400 complete\n","\n","\n","Layer 34: 6100 of 6400 complete\n","\n","Layer 13: 6150 of 6400 complete\n","\n","Layer 18: 6150 of 6400 complete\n","\n","Layer 37: 6050 of 6400 complete\n","\n","Layer 20: 6150 of 6400 complete\n","\n","Layer 9: 6150 of 6400 complete\n","\n","Layer 8: 6150 of 6400 complete\n","\n","Layer 11: 6150 of 6400 complete\n","\n","Layer 45: 6100 of 6400 complete\n","\n","Layer 15: 6150 of 6400 complete\n","\n","Layer 16: 6150 of 6400 complete\n","\n","Layer 25: 6100 of 6400 complete\n","\n","Layer 10: 6150 of 6400 complete\n","\n","Layer 17: 6150 of 6400 complete\n","\n","Layer 31: 6150 of 6400 complete\n","\n","Layer 27: 6100 of 6400 complete\n","\n","Layer 33: 6100 of 6400 complete\n","\n","Layer 19: 6150 of 6400 complete\n","\n","Layer 28: 6100 of 6400 complete\n","\n","Layer 43: 6100 of 6400 complete\n","\n","Layer 42: 6100 of 6400 complete\n","\n","Layer 39: 6100 of 6400 complete\n","\n","Layer 14: 6150 of 6400 complete\n","\n","Layer 23: 6150 of 6400 complete\n","\n","Layer 7: 6150 of 6400 complete\n","\n","Layer 6: 6150 of 6400 complete\n","\n","Layer 22: 6150 of 6400 complete\n","\n","Layer 36: 6150 of 6400 complete\n","\n","Layer 46: 6150 of 6400 complete\n","\n","Layer 38: 6100 of 6400 complete\n","\n","Layer 5: 6150 of 6400 complete\n","\n","Layer 32: 6150 of 6400 complete\n","\n","Layer 30: 6150 of 6400 complete\n","\n","Layer 4: 6150 of 6400 complete\n","\n","Layer 2: 6150 of 6400 complete\n","\n","Layer 40: 6150 of 6400 complete\n","\n","Layer 21: 6150 of 6400 complete\n","\n","Layer 44: 6100 of 6400 complete\n","\n","Layer 3: 6150 of 6400 complete\n","\n","Layer 26: 6150 of 6400 complete\n","\n","Layer 47: 6150 of 6400 complete\n","\n","Layer 35: 6100 of 6400 complete\n","\n","Layer 24: 6150 of 6400 complete\n","\n","Layer 0: 6200 of 6400 complete\n","\n","Layer 1: 6200 of 6400 complete\n","\n","Layer 12: 6200 of 6400 complete\n","\n","Layer 41: 6150 of 6400 complete\n","\n","Layer 29: 6150 of 6400 complete\n","\n","Layer 13: 6200 of 6400 complete\n","\n","Layer 18: 6200 of 6400 complete\n","\n","Layer 34: 6150 of 6400 complete\n","\n","Layer 37: 6100 of 6400 complete\n","\n","Layer 20: 6200 of 6400 complete\n","\n","Layer 11: 6200 of 6400 complete\n","\n","Layer 8: 6200 of 6400 complete\n","\n","Layer 25: 6150 of 6400 complete\n","\n","Layer 16: 6200 of 6400 complete\n","\n","Layer 9: 6200 of 6400 complete\n","\n","Layer 17: 6200 of 6400 complete\n","\n","Layer 15: 6200 of 6400 complete\n","\n","Layer 45: 6150 of 6400 complete\n","Layer 10: 6200 of 6400 complete\n","\n","\n","Layer 33: 6150 of 6400 complete\n","\n","Layer 31: 6200 of 6400 complete\n","\n","Layer 19: 6200 of 6400 complete\n","\n","Layer 28: 6150 of 6400 complete\n","\n","Layer 27: 6150 of 6400 complete\n","\n","Layer 42: 6150 of 6400 complete\n","\n","Layer 43: 6150 of 6400 complete\n","\n","Layer 22: 6200 of 6400 complete\n","\n","Layer 23: 6200 of 6400 complete\n","\n","Layer 6: 6200 of 6400 complete\n","\n","Layer 39: 6150 of 6400 complete\n","\n","Layer 7: 6200 of 6400 complete\n","\n","Layer 14: 6200 of 6400 complete\n","\n","Layer 36: 6200 of 6400 complete\n","\n","Layer 38: 6150 of 6400 complete\n","\n","Layer 46: 6200 of 6400 complete\n","\n","Layer 5: 6200 of 6400 complete\n","\n","Layer 2: 6200 of 6400 complete\n","\n","Layer 32: 6200 of 6400 complete\n","\n","Layer 30: 6200 of 6400 complete\n","\n","Layer 4: 6200 of 6400 complete\n","\n","Layer 40: 6200 of 6400 complete\n","\n","Layer 3: 6200 of 6400 complete\n","\n","Layer 21: 6200 of 6400 complete\n","Layer 47: 6200 of 6400 complete\n","\n","\n","Layer 44: 6150 of 6400 complete\n","\n","Layer 26: 6200 of 6400 complete\n","\n","Layer 24: 6200 of 6400 complete\n","\n","Layer 12: 6250 of 6400 complete\n","\n","Layer 41: 6200 of 6400 complete\n","\n","Layer 0: 6250 of 6400 complete\n","\n","Layer 1: 6250 of 6400 complete\n","\n","Layer 35: 6150 of 6400 complete\n","\n","Layer 29: 6200 of 6400 complete\n","\n","Layer 13: 6250 of 6400 complete\n","\n","Layer 18: 6250 of 6400 complete\n","\n","Layer 34: 6200 of 6400 complete\n","\n","Layer 20: 6250 of 6400 complete\n","\n","Layer 11: 6250 of 6400 complete\n","\n","Layer 37: 6150 of 6400 complete\n","\n","Layer 8: 6250 of 6400 complete\n","Layer 25: 6200 of 6400 complete\n","\n","\n","Layer 17: 6250 of 6400 complete\n","\n","Layer 15: 6250 of 6400 complete\n","\n","Layer 9: 6250 of 6400 complete\n","Layer 10: 6250 of 6400 complete\n","\n","\n","Layer 16: 6250 of 6400 complete\n","\n","Layer 45: 6200 of 6400 complete\n","\n","Layer 31: 6250 of 6400 complete\n","\n","Layer 33: 6200 of 6400 complete\n","\n","Layer 19: 6250 of 6400 complete\n","\n","Layer 27: 6200 of 6400 complete\n","Layer 43: 6200 of 6400 complete\n","\n","\n","Layer 42: 6200 of 6400 complete\n","\n","Layer 28: 6200 of 6400 complete\n","\n","Layer 14: 6250 of 6400 complete\n","\n","Layer 22: 6250 of 6400 complete\n","Layer 6: 6250 of 6400 complete\n","\n","\n","Layer 38: 6200 of 6400 complete\n","Layer 39: 6200 of 6400 complete\n","\n","\n","Layer 23: 6250 of 6400 complete\n","\n","Layer 46: 6250 of 6400 complete\n","\n","Layer 36: 6250 of 6400 complete\n","\n","Layer 2: 6250 of 6400 complete\n","\n","Layer 7: 6250 of 6400 complete\n","\n","Layer 40: 6250 of 6400 complete\n","\n","Layer 32: 6250 of 6400 complete\n","\n","Layer 5: 6250 of 6400 complete\n","\n","Layer 4: 6250 of 6400 complete\n","\n","Layer 30: 6250 of 6400 complete\n","\n","Layer 47: 6250 of 6400 complete\n","\n","Layer 3: 6250 of 6400 complete\n","\n","Layer 21: 6250 of 6400 complete\n","\n","Layer 12: 6300 of 6400 complete\n","Layer 26: 6250 of 6400 complete\n","Layer 44: 6200 of 6400 complete\n","\n","\n","\n","Layer 41: 6250 of 6400 complete\n","\n","Layer 24: 6250 of 6400 complete\n","\n","Layer 0: 6300 of 6400 complete\n","\n","Layer 1: 6300 of 6400 complete\n","\n","Layer 35: 6200 of 6400 complete\n","\n","Layer 13: 6300 of 6400 complete\n","\n","Layer 18: 6300 of 6400 complete\n","\n","Layer 29: 6250 of 6400 complete\n","\n","Layer 34: 6250 of 6400 complete\n","\n","Layer 20: 6300 of 6400 complete\n","\n","Layer 37: 6200 of 6400 complete\n","\n","Layer 11: 6300 of 6400 complete\n","\n","Layer 15: 6300 of 6400 complete\n","\n","Layer 16: 6300 of 6400 complete\n","\n","Layer 17: 6300 of 6400 complete\n","Layer 8: 6300 of 6400 complete\n","\n","Layer 31: 6300 of 6400 complete\n","Layer 25: 6250 of 6400 complete\n","\n","\n","\n","Layer 45: 6250 of 6400 complete\n","\n","Layer 9: 6300 of 6400 complete\n","\n","Layer 10: 6300 of 6400 complete\n","\n","Layer 33: 6250 of 6400 complete\n","\n","Layer 19: 6300 of 6400 complete\n","\n","Layer 27: 6250 of 6400 complete\n","\n","Layer 42: 6250 of 6400 complete\n","Layer 43: 6250 of 6400 complete\n","\n","\n","Layer 28: 6250 of 6400 complete\n","\n","Layer 14: 6300 of 6400 complete\n","\n","Layer 7: 6300 of 6400 complete\n","\n","Layer 22: 6300 of 6400 complete\n","Layer 38: 6250 of 6400 complete\n","Layer 39: 6250 of 6400 complete\n","\n","\n","\n","Layer 46: 6300 of 6400 complete\n","Layer 40: 6300 of 6400 complete\n","\n","\n","Layer 36: 6300 of 6400 complete\n","\n","Layer 23: 6300 of 6400 complete\n","\n","Layer 2: 6300 of 6400 complete\n","\n","Layer 6: 6300 of 6400 complete\n","Layer 32: 6300 of 6400 complete\n","Layer 5: 6300 of 6400 complete\n","\n","\n","\n","Layer 4: 6300 of 6400 complete\n","\n","Layer 30: 6300 of 6400 complete\n","\n","Layer 3: 6300 of 6400 complete\n","\n","Layer 21: 6300 of 6400 complete\n","\n","Layer 44: 6250 of 6400 complete\n","\n","Layer 12: 6350 of 6400 complete\n","\n","Layer 47: 6300 of 6400 complete\n","\n","Layer 26: 6300 of 6400 complete\n","\n","Layer 41: 6300 of 6400 complete\n","\n","Layer 24: 6300 of 6400 complete\n","\n","Layer 1: 6350 of 6400 complete\n","\n","Layer 0: 6350 of 6400 complete\n","\n","Layer 13: 6350 of 6400 complete\n","\n","Layer 29: 6300 of 6400 complete\n","\n","Layer 35: 6250 of 6400 complete\n","\n","Layer 20: 6350 of 6400 complete\n","\n","Layer 18: 6350 of 6400 complete\n","\n","Layer 34: 6300 of 6400 complete\n","\n","Layer 37: 6250 of 6400 complete\n","\n","Layer 11: 6350 of 6400 complete\n","\n","Layer 15: 6350 of 6400 complete\n","\n","Layer 31: 6350 of 6400 complete\n","\n","Layer 16: 6350 of 6400 complete\n","\n","Layer 17: 6350 of 6400 complete\n","\n","Layer 25: 6300 of 6400 complete\n","\n","Layer 8: 6350 of 6400 complete\n","\n","Layer 45: 6300 of 6400 complete\n","\n","Layer 10: 6350 of 6400 complete\n","\n","Layer 9: 6350 of 6400 complete\n","\n","Layer 19: 6350 of 6400 complete\n","\n","Layer 27: 6300 of 6400 complete\n","\n","Layer 33: 6300 of 6400 complete\n","\n","Layer 43: 6300 of 6400 complete\n","\n","Layer 14: 6350 of 6400 complete\n","\n","Layer 42: 6300 of 6400 complete\n","\n","Layer 38: 6300 of 6400 complete\n","\n","Layer 28: 6300 of 6400 complete\n","\n","Layer 22: 6350 of 6400 complete\n","\n","Layer 7: 6350 of 6400 complete\n","\n","Layer 39: 6300 of 6400 complete\n","\n","Layer 36: 6350 of 6400 complete\n","\n","Layer 40: 6350 of 6400 complete\n","\n","Layer 2: 6350 of 6400 complete\n","Layer 6: 6350 of 6400 complete\n","\n","\n","Layer 32: 6350 of 6400 complete\n","\n","Layer 46: 6350 of 6400 complete\n","\n","Layer 5: 6350 of 6400 complete\n","\n","Layer 23: 6350 of 6400 complete\n","\n","Layer 4: 6350 of 6400 complete\n","\n","Layer 30: 6350 of 6400 complete\n","\n","Layer 21: 6350 of 6400 complete\n","\n","Layer 44: 6300 of 6400 complete\n","\n","Layer 47: 6350 of 6400 complete\n","\n","Layer 3: 6350 of 6400 complete\n","\n","Layer 26: 6350 of 6400 complete\n","\n","Layer 24: 6350 of 6400 complete\n","\n","Layer 41: 6350 of 6400 complete\n","\n","Layer 29: 6350 of 6400 complete\n","\n","Layer 35: 6300 of 6400 complete\n","\n","Layer 34: 6350 of 6400 complete\n","\n","Layer 37: 6300 of 6400 complete\n","\n","Layer 25: 6350 of 6400 complete\n","\n","Layer 45: 6350 of 6400 complete\n","\n","Layer 27: 6350 of 6400 complete\n","\n","Layer 33: 6350 of 6400 complete\n","\n","Layer 43: 6350 of 6400 complete\n","\n","Layer 42: 6350 of 6400 complete\n","\n","Layer 38: 6350 of 6400 complete\n","\n","Layer 28: 6350 of 6400 complete\n","\n","Layer 39: 6350 of 6400 complete\n","\n","Layer 44: 6350 of 6400 complete\n","\n","Layer 35: 6350 of 6400 complete\n","\n","Layer 37: 6350 of 6400 complete\n","CPU times: user 24.4 s, sys: 5.95 s, total: 30.3 s\n","Wall time: 40min 3s\n"]}]},{"cell_type":"code","source":["activation_matrix_np = np.array(activation_matrix)\n","activation_matrix_np.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vcDoH0usVnji","executionInfo":{"status":"ok","timestamp":1683887364445,"user_tz":-60,"elapsed":26,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"a181520f-20ea-4f1b-9f8d-8753eaa0a314"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(48, 6400)"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["import json\n","\n","if True:\n","  with open(os.path.join(base_path, f\"data/activation_matrix-{model_name}.json\"), \"w\") as ofh:\n","    json.dump(activation_matrix, ofh, indent=2, ensure_ascii=False)"],"metadata":{"id":"9UQhQBXsUwx9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Create dataset"],"metadata":{"id":"1vbKNMFJUyh7"}},{"cell_type":"code","source":["!pip install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h8sdvXpb6SMm","executionInfo":{"status":"ok","timestamp":1675626754091,"user_tz":0,"elapsed":3906,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"58e911d0-62f5-4704-8ba3-45703ddfb40e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.9.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.12.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.2.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n","Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (23.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.26.14)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"]}]},{"cell_type":"code","source":["import math\n","\n","\n","def batch(arr, n=None, batch_size=None):\n","    if n is None and batch_size is None:\n","        raise ValueError(\"Either n or batch_size must be provided\")\n","    if n is not None and batch_size is not None:\n","        raise ValueError(\"Either n or batch_size must be provided, not both\")\n","\n","    if n is not None:\n","        batch_size = math.floor(len(arr) / n)\n","    elif batch_size is not None:\n","        n = math.ceil(len(arr) / batch_size)\n","\n","    extras = len(arr) - (batch_size * n)\n","    groups = []\n","    group = []\n","    added_extra = False\n","    for element in arr:\n","        group.append(element)\n","        if len(group) >= batch_size:\n","            if extras and not added_extra:\n","                extras -= 1\n","                added_extra = True\n","                continue\n","            groups.append(group)\n","            group = []\n","            added_extra = False\n","\n","    if group:\n","        groups.append(group)\n","\n","    return groups"],"metadata":{"id":"51VhFGJxCbUb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import load_dataset\n","\n","data_files = {\"validation\": \"en/c4-validation.*.json.gz\"}\n","c4_validation = load_dataset(\"allenai/c4\", data_files=data_files, split=\"validation\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7QkfBFja5YFL","executionInfo":{"status":"ok","timestamp":1675626760125,"user_tz":0,"elapsed":6048,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"8ce016c0-6bf3-486d-9c4a-650248db5423"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:Using custom data configuration allenai--c4-181ebbe6122ca37f\n","WARNING:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/allenai___json/allenai--c4-181ebbe6122ca37f/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"]}]},{"cell_type":"code","source":["print(c4_validation)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yPFIx-meCOgr","executionInfo":{"status":"ok","timestamp":1675626760447,"user_tz":0,"elapsed":3,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"9520fcee-0e1d-4c6d-bcc6-c58dd1943088"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['text', 'timestamp', 'url'],\n","    num_rows: 364608\n","})\n"]}]},{"cell_type":"code","source":["data = [row[\"text\"] for row in c4_validation]"],"metadata":{"id":"MheQ2KXsCQ1H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print([len(row) for row in data[:10]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EcJJB5D7G-5S","executionInfo":{"status":"ok","timestamp":1675626777727,"user_tz":0,"elapsed":22,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"72772eb8-c30d-4069-8586-b8a383035219"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1625, 2702, 3027, 1018, 793, 364, 1113, 268, 1522, 2165]\n"]}]},{"cell_type":"code","source":["batch_size = 2\n","batched = batch(data, batch_size=batch_size)"],"metadata":{"id":"vtfCPDKCDHFB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Method\n","- Scrape max activation of neuron on any token from lexoscope\n","- Create layer x neuron matrix of max activations * scale to get activation thresholds\n","- Threshold the activation matrix for a given example with the threshold matrix\n","- Create a dict/matrix where, for each neuron in the model, there is an array containing a tokenized text example and the actvation of the neuron on each token. If this takes too much space, could just store the activations and the index of the text example, and separately store the tokenized text examples by index\n","- (Store the non-zero entries in a dict, where each key is the index of an example, and each value is a tuple with the example text and an array of dicts mapping (layer, neuron) indices to the activation for each token in the text) - old idea"],"metadata":{"id":"2an9trraN1N3"}},{"cell_type":"code","source":["with open(os.path.join(base_path, f\"data/activation_matrix-{model_name}.json\")) as ifh:\n","    activation_matrix = json.load(ifh)\n","    activation_matrix = np.array(activation_matrix)"],"metadata":{"id":"r8kFxF6GioOj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scale = 0.2\n","threshold_matrix = activation_matrix * scale"],"metadata":{"id":"J6fl-iQEivYz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","from tqdm.autonotebook import tqdm\n","import gzip    \n","\n","layer_indices = [i for i in range(6)]\n","\n","all_activation_groups = []\n","prompts = []\n","prompt_count = 0\n","\n","process_data = batched[:50000]\n","\n","if False:\n","  with gzip.open(os.path.join(base_path, \"data/activation_data.jsonl.gz\"), \"wb\") as ofh1, open(os.path.join(base_path, \"data/prompts.jsonl\"), \"w\") as ofh2:\n","    for i, data_batch in tqdm(enumerate(process_data), total=len(process_data), desc=\"Progress\"):\n","      tokens = model.to_tokens(data_batch)\n","      str_tokens = model.to_str_tokens(data_batch)\n","      logits, cache = model.run_with_cache(tokens)\n","      layer_activations = torch.stack([cache[f\"blocks.{layer_index}.mlp.hook_mid\"] for layer_index in layer_indices]).permute(1, 2, 0, 3).cpu().numpy()\n","      # print(layer_activations)\n","      # print(threshold_matrix)\n","      thresholded = layer_activations > threshold_matrix\n","      strong_activations = np.where(layer_activations > threshold_matrix, layer_activations, 0)\n","      strong_activations /= activation_matrix\n","      strong_activations = strong_activations.transpose(0, 2, 3, 1)\n","\n","      for j, batch_activations in enumerate(strong_activations):\n","        layer_groups = []\n","        for k, layer_activations in enumerate(batch_activations):\n","          neuron_groups = {}\n","          for l, neuron_activations in enumerate(layer_activations):  \n","            non_zero_indices = np.nonzero(neuron_activations)[0]\n","            if len(non_zero_indices) == 0:\n","              continue\n","            token_activations = {int(index): float(neuron_activations[index]) for index in non_zero_indices}\n","            group = {\"prompt_index\": prompt_count, \"token_activations\": token_activations}\n","            # print(len(group))\n","            neuron_groups[l] = group\n","          # print(len(neuron_groups))\n","          layer_groups.append(neuron_groups)\n","        # print(len(layer_groups))\n","        ofh1.write(f\"{json.dumps(layer_groups)}\\n\".encode())\n","        ofh2.write(f\"{json.dumps(str_tokens[j])}\\n\")\n","        prompt_count += 1\n","\n","      # print(len(all_activation_groups))\n","      # print(tokens.shape)\n","      # print(layer_activations.shape)\n","      # print(threshold_matrix.shape)\n","      # print(thresholded.shape)\n","      # print(strong_activations.shape)\n","      # print(np.count_nonzero(strong_activations))\n","      # break\n","\n","  with open(os.path.join(base_path, \"data/prompts.json\"), \"w\") as ofh:\n","    json.dump(prompts, ofh, ensure_ascii=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":149},"id":"XR1LjfxlDU1h","executionInfo":{"status":"ok","timestamp":1683920198157,"user_tz":-60,"elapsed":3184,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"4ad42842-bd22-4126-89e1-eb57a8e9011d"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'batched' is not defined"]}]},{"cell_type":"code","source":["print(len(prompts))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3c2-oalQgeOP","executionInfo":{"status":"ok","timestamp":1675633322176,"user_tz":0,"elapsed":535,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"d022759f-74d8-43b7-bfba-6f67fbaa6947"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["200\n"]}]},{"cell_type":"code","source":["with gzip.open(os.path.join(base_path, \"data/activation_data.jsonl.gz\")) as ifh:\n","  for line in ifh:\n","    activation_group = json.loads(line)\n","    print(len(activation_group))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xHy8cYbSYRM5","executionInfo":{"status":"ok","timestamp":1675631592356,"user_tz":0,"elapsed":2266,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"34a5c93d-8640-4d7f-ba9f-32e2e943bff1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["6\n","6\n","6\n","6\n","6\n","6\n","6\n","6\n","6\n","6\n","6\n","6\n","6\n","6\n","6\n","6\n","6\n","6\n","6\n","6\n","6\n","6\n","6\n","6\n"]}]},{"cell_type":"code","source":["def layer_and_neuron_to_index(layer, neuron, width=3072, block_size=None):\n","  index = (layer * width) + neuron\n","  if block_size is None:\n","    return index\n","  return divmod(index, block_size)\n","\n","def index_to_layer_and_neuron(index, width=3072):\n","  return divmod(index, width)"],"metadata":{"id":"DccAwZD1hJ_8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["index_to_layer_and_neuron(layer_and_neuron_to_index(4, 372))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IKcK0Q0bjk7j","executionInfo":{"status":"ok","timestamp":1676318190547,"user_tz":0,"elapsed":2,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"aa985642-5b41-4c95-9335-54607cc17929"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4, 372)"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["print(layer_and_neuron_to_index(5, 3071))\n","print(layer_and_neuron_to_index(3, 6, block_size=1000))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q4jPg0WSWbK-","executionInfo":{"status":"ok","timestamp":1676319813361,"user_tz":0,"elapsed":245,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"d309cb45-3b99-48dc-9301-cb8cd0d3b721"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["18431\n","(9, 222)\n"]}]},{"cell_type":"code","source":["block_size = 1000\n","neuron_blocks = batch([i for i in range(3072 * 6)], batch_size=block_size)"],"metadata":{"id":"vCK7ZIAVoZbH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(neuron_blocks[-1][-1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zd5G2buecn6F","executionInfo":{"status":"ok","timestamp":1676319871265,"user_tz":0,"elapsed":317,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"9e1586f3-711f-4e3b-9478-866790028329"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["18431\n"]}]},{"cell_type":"code","source":["import json\n","import gzip\n","from tqdm.autonotebook import tqdm\n","\n","n = 100000\n","\n","if False:\n","  for block_index, neuron_block in enumerate(neuron_blocks):\n","    print(f\"Processing block {block_index + 1} of {len(neuron_blocks)}\")\n","    neuron_block_set = set(neuron_block)\n","    activation_data_by_neuron = [[] for _ in neuron_block]\n","    offset = neuron_block[0]\n","\n","    with gzip.open(os.path.join(base_path, \"data/activation_data.jsonl.gz\")) as ifh:\n","      for i, line in tqdm(enumerate(ifh), total=n, desc=\"Processing Progress\"):\n","        activation_info = json.loads(line)\n","        for layer, layer_info in enumerate(activation_info):\n","          for neuron, neuron_info in layer_info.items():\n","            neuron = int(neuron)\n","            index = layer_and_neuron_to_index(layer, neuron)\n","            if index in neuron_block_set:\n","              activation_data_by_neuron[index - offset].append(neuron_info)\n","\n","        # if i > 20:\n","        #   break\n","\n","    with gzip.open(os.path.join(base_path, f\"data/activation_data_by_neuron_block_{block_index}.jsonl.gz\"), \"w\") as ofh:\n","      for neuron_info in tqdm(activation_data_by_neuron, total=block_size, desc=\"Write Progress\"):\n","        ofh.write(f\"{json.dumps(neuron_info)}\\n\".encode())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["8856e0244c7a4a278c70af17ba222aec","6a2a4ab75ad443d49a3638f29827303b","fa9c69a78a084663bc3f9e30b75d4473","68031e477f7048408260185dbe78d21a","47313e0dff814d9882171837dd562d3f","69d45bd2ca294752aeb6f38155333c2d","6ee00ad75ecf4719b0bc2d286b022fe3","5269b2001b3e4652ac45a494d5197855","ac22784a5d0c47138b51819090230953","fa329694c0d94a349c1c8ba89693d0e3","c38fcff54d36456fa367c8bd07821261","141a8321993d4b6497e945d5cae1f2bd","06efa173c613478ea3f12997f2a48e14","f943ac4144864c18bae86a600aa5f559","c0e9a183cc954b8c9e3c3db47ef9c611","c41f1b39cff24f72bd0e7b60d5423d83","84ffefbf17b54ef4a4afd3acd43d9486","aca99de89b9f4838aa3ce85e706b95d3","4ff69842a1c24792a6cd4f42db45fdcd","d2786ffbbcd14ca5b0af3bfaa35e2f53","cf0eee0cf56c4402a35b2683f5f3ea01","f1610f90fd004a38b194ae4859f25426","7c44037262314e129fb33e267244034a","f2ea0e5a173a4cf2a87dfc6224aa20c4","f15f430308024941b3bbcbe425aea8a3","da98fa9396fd4bb68214e4e7b2ac4879","689719364ce5494a9df3a158db256f45","885edba6ac9946e58af4d42945fb1ad4","ae96cdd390114581a4df661d839d36e1","4084c6e9d79e430c8e0bebec6af2a1bc","de61536a2856409b830cf25d7810faa9","8d5ff26f66184d438d27e5ea907d2143","b7f7bfd2f8124c7a8ba9ec009985dbbc","c8eec8906a0b4f7086f3a1cc49a0e391","ed3e6458d8f4418092700e8d3d227890","68060fb0b5ef4092b09b1d1d3746cc7c","8cc7b11c6e204d36b63ca4b6498c9694","9f17e367d76242398756365022f3bcd5","349bf3f1097941c0a2e3ee575a02a18a","5e8d0d8ecf4447d793e8f854941688c8","05b8ef0a6a504e95b652703399b846b3","80b4e3e1c1df44dbbcbd406f31e62002","980b64206d944b6795bb8f0ced2e3c04","f8026818bbb84b608d859f3e60659ad4","0fc03a616766446c8e1fc181f7ad7e53","f96e425cf65948e2bec3303250750109","358b61297fbd4d498d83e37bcf1f5020","cdc28a7e756846f8b3a4f1309c7b2c28","670ac2254b58499085469892297a829e","b21d3a2c4d11440b82f34956ddc42e99","a1fb0f22d387494787f5a8b7fe804e97","e255cc2176b2408fb3db966f0042208f","7cdd6c0ae0154f97b383334bebfcccc5","c7504afd683f485c94db3464d3a6de29","ff832b02902447779e919cfd9d00fbdb","df9c3d40c4e24aadbf4e27f91c6ef528","ff03379fd03a48a8b19da5a6c12ed513","c73273b93cb6446d92f77b6c4f8e6164","ba98c5b0d25142c2a25be9ffdce15415","9286935a0dca499d9f8e79dc3c2eaa30","d028e060162141f894b034e1dfb5be14","b7631692d1c54528aa8500ea60c40c8a","482cde19ffad4bb2bd52aac7aa0aa787","ee99866a961d4a8e99ec73ad5ab5c343","a91a784424284f9fa7179533431537d9","9d11afeda80845ad903082b0c8be098f","2f1c2622d28c48e4abedc0432746fb59","1f94b2d9dfcf4484bbebcfe733ac0c52","ade0fe2ecacc406195f600fb23f5cc11","f260d0ed5bbf43578f0050e66f45ff6d","841684594a2c40e28f5cdb67b09ab276","b1affe0f2fa240a180589820485a9f37","07b97bf60f754c17aa3d5ddcec013aba","07c0c331706d42239e3354aecd2f4b4e","d1ae18b5c9164ce4ac060e384b7f3392","1da643bcb379450e9e0c6e89e30b6020","9fd933f2247b4dd7b7e807672ba78510","30b674c683334dc5a886085bc5da7dd1","226ef69ded694399ac823b459e889fed","df1d26813baa4a0597b9bdb5af3bd13f","24682bd6941d4aa4b6e07d63ab60545d","51da0ed9171b4ad3a3c765564893863c","04c43fbbb50145018762cc798c2d9f85","9081f193c5c1478686b33ac298646938","b38c92b86ea54e7cb1d2c996bff4801d","5a32fe5b7d9544fd859b29d8357a7cf6","d3d757fa65994b479ce9c3351f931d9c","92abb3ee1b5642a0a63b5b0791a45294","5eeb380e3e1146b38f3dd90642344e84","d181067b4f2a43bb8cdf021c8bf12a73","06e0abef7de14b5d82e64f3a9d24759e","83567640b3ca4a0aa50043dc66738afe","ee49a484649a4314b018d7110f09a204","dda1984cb671441d9e98b97b7417bf3f","7de4ee8644d64df6b0ede1017f51c447","7070f9ea2e744f4caafb634617e519c9","2ac5d70712474ece9b2c254794a30e02","b120872a03ee4d3cb8ea298ec59767d3","cc7fa056ca584b0bb9e929fff48e0e33","4497b28d9a804c498b3f0ae8d062cfb4","73033b7c63c7460fbecd9920aeb62bd0","e376350679d24ba49ca3a66aa2daeae7","36bab4f238e141dc94f065d8efdc3e07","3db122836c6442628cdb5b9aa5b80375","3bc584cfaec74aec8d9d9e4c1a002d77","f9d8525f21c14911911f2799c8d50e0f","82304c5496994199ab0ba4b92f8f048e","073cf41004eb4711b9ce77703ffe63fa","477d788db9394ba7ad2002c0f150006b","d247008e92644b55bc6971ba69fc630d","8898fe84ab1b429e88a5a609b8b270fe","2dd301500e7c4cfea9c25629764caab1","a35f832bc8c44d829dc5f4a4a52d6edf","e8dc90df222f4de3aa5a40b976148069","f7d5fb6fd03e41bf85e2d15cae5d0e4b","2ae24993b3344dd6b91e61c4ec915b83","fb56d8c8925d4e48b2e849cb6f9ee00d","3352751c1b704215ab1fea989d048e56","f3eedf8092a54754bdf664c66241c4c2","a746d3da20eb4725ba583a56ac623538","e03e828cc24e4d4bad5238a6bb809161","31904fe7b4dd482ba8d3d964452a3424","740d72c1b342429db6e3fb0dc4324916","b1055304aa9c4398bfe1e7b04232c82f","1c92b7598d2d45ebbd6c1dd5f0e593f6","097d8e83002b4dbc83ee14a153502f41","29ac7667469c464eba98b8c0651d0bdb","113e2fb288b34c95a6d034dcd58bf0b9","5efc9d376cab49e393a74dc58bdcfd85","65abd516ec2b44bd99aa2f4790143124","8e2d66dcd8ee463aaa6fc317d7a80d8a","41b42b7ec7774683a24e26f7c7fd8d5a","1e6a2b17f46b4778b2566537b62c20a8","517e904d47c54eacb943faf2e6bbc8aa","24a2132bfac64fb1b8252c76dab60ba9","d55a967071d8483688041fd5b44f8c0a","3cf3860a67f54773867b88639277e96d","5f50e10500684e0687ce3b9caf035351","bd7de79a8fac49de9e0e34cd5fa75810","cb12d7c0ccc14b9f80486805eb4c1091","659523e3dd9a44d7b8c0b221f71e7a4e","5dec1fea15594c9285bf8970e817b25c","1b8e35d3dae840f3a115903a6653cc92","1b0b3dceb04d41b49ad0a9030ecd87de","7c7e2f248e5d48319c059d4a216e6547","bb1dddf496144561967823b73e070a39","5a9de94ddc6147239a21cab578d44626","3772e775a84e45f6b069ac81c38d4805","7db64f6d3cf44744ae0a0cfba32b6e06","fae6a3c4b6094fadae8f0db700595fd4","5270f13681e44ac88ca295e2550fac1c","1ee540a502d042bfbda71adb2eeabfd2","e8716c0d7b0946a2bdc23ceb92616b85","7931baa091c24e91af39cb4f33a237bc","3eb8b0db1f9644fb9af6fb10f026b1ca","8eb2e0617e4341819fd08002ffd9f26a","402b5f592e864be498742dcf9ce274b9","5e9e9ad0dc4f4d688a5db26726119178","c32a5b09e8c14f6492eb05496dacf5af","548bf7c7ae3f45c2a8e2a912cc6067b8","24991884345847668757523dc811c0ed","2e1fcc80a5194995aa0cc57e18e70e2f","ea015c3d01784854b5a0f91bb2846340","18baafbd13734a65936797ca25b6d375","e10996b57f9a4281a8a5cbf622610962","7db1d391a762430caab84dc1f222cb7f","9e51f74d10ea4546b1f0db1795cf478d","e9cf3978f0bc47d68c6489dbb6b77444","6e20865484ec449599a46a08e43cd660","27feb45f2f3242659d442318d2d5d430","3e05f38a8061441fae8e6217ea6edf5f","19e88ad6fd45468395391ee3cc7315cd","6be20f53a3b942079602f3b397852db0","92a8ef75c4c64252a11cb0c7c8ceecdd","447c83d95ffc4844a9de2b5b990ff32d","2fa272c2eeb8471996509d5c3f85bb48","ce4dd1bb215040728744ceb6394211d6","ce01f958c64d471490023ce5d030a4b6","5a898b649ecc4802bf8cb868d82d00c3","abadf98563784d53921a059af10c3ba6","7beadfa5d1fa477d84434f26f80c57bb","3245ea3e1d024b5e9c69de41a963dc98","ff630956dae64d829f9995196dc0071f","6390e6b786ee46c8baaa65f44a5bcc5d","a10ead483edb4af3a411c364b70430c5","a98e4dace8df4176951ecafe8f5250f4","12d2e96145574682965e611ce8ade2be","fef99d16fd404251bc464ef81d8d99ca","9d5ea4818d0845bb8a0286f4d2cfba34","4a9a2e78902b4317b040146055fa8ba9","b1e61cbcd0e34c0a9ea9b9d436f2025b","02d922ef867f47a790a320e9bcafa2c5","51aaf42a67b348d6a12fa037f4d4e4a0","ba38aa1a7913495085cfc4dc1f74365a","55b1ce84b49f4bca8b18c7b46df6c82d","c0c3053a14d94883883ad87acff92952","c5fe2e82dbae4b028dc87c78e717525b","af7100a6a4f841f487b72c67f9d42a98","56ca7045080d43fb88ac1773cd096728","159391f2a2964586836614a91afd08ef","c6509b9789624a24ba30ab6f31c77dd9","0ad0e54195564def90dd199c297b89fd","c551e40ea1ea4bc1b930cdbb2b62bab4","2909d85fcbc84e14bd8e803bfd2c1552","4e976439b3174be095e0a31a6183d4cf","9dd93efc80984b9b92055e3c9dbba754","48d30ab8d5a0440ea28ae4c9e9940a3f","d223be80583c4c36bd1f323aac56038a","57f30c610f2b42f48708cf2e9d73e090","771faebabf584cb0a336140d828f157a","d3c4ec7ef8634763906946e895cf7e6d","ab94adf8923e42fb8872d45e544303d6","e0dce679842649399d62ed64e378e4f4","3ba3d7a1d2824c7fbcb9fb61683e69ab","976dbfccce5944d9a68923061986fc0e","9cc81994c9bf44849476b92fe7b0d213","77408a5de91f472bacb5ee51a33093bb","5d84029f0b2f4b689da27d05a08cd23c","bb70b21152074190b4686c277a82598b","8d2b53184bac4103b50cda8db4667c59","b4221863abc44d2fbed2a02245e7f109","49e507c187ef4f288a16a86e43a1f5a3","bbb9fc067ff94b429806336d1beb83bc","83487565432c48f788fb431fb5abbb18","d447abbbb8c24b3ab42f9bbe8c441948","e171cf83a33643ea81682d39289fba69","4291101367b84ff48286e7214880e762","3eaabda6f64b47b187dc498ad8f9d5f2","05a132924d9a43c7a49660cdcf8de327","29d81c953fd64e54bb68a7754503b859","c1e40d08be6e4426aea7257d7b284ed9","24e8c5a5fc17430fbd78653da9ba53d4","773efd4fc4e7409e8b4fd539fdefe56a","16fd458d2ee9454a9c452c1172a5a86b","21a57124b4004a4caf6f116be6e6691d","3e41b93f74ba4c0eb27af0fc60512989","3b74712a797e4bdaac282dcbde21328d","2658b8fdf7444526860a86074c576249","d9c959d33193464e975d3e919e3a56f1","05e75a2009254f02bc8e9d03d300e6bf","aa65f4c255854243974c0b43ff2f9bed","4baa8f29b4164786ac2853d2045afb39","7d7aade26bbb4010910faca1a9ce9c86","754ffbc812744efe8eb54741a94b7cc1","35f9f19ca8cb4a2992423f6094b7f8c3","bef28b22c3764b8db40cf1db8d8ceaba","bea006a710154dcbb3de85e499e25353","d3f048830c5742e58e3d505f18c7ced4","51e61eb58d814701b673f90ab76cf84a","f337c9c38244408b8c1782c60b5ec1f8","986681cbcefe468784e75efec5c76c8d","da527fd6e91c454599ac0434a49e4f89","3c23fa4628be4da8ae56e10f607a267c","dc6412a522444ee7b7a5dd89f092824c","d27b8d9217ac4495bb0fb7d0b0e8c62e","959d1a8fdfdd40eaa2c5d8ae4694144f","30f88682b78a4d149471a1b2c8023d82","77cfa26139864764a71636e39d17b45a","4483016842e246768cb2352b68e268e7","b5b333c9ac254d838db7d2d457578af4","10c2b9e55141456abc1debc2b1538707","efaee6030f254d619c939cc2933f247f","9ec24e1975614ef2b78365d581b93ca2","4df9dc2c04904e11b059a5f0de61582e","2b7a61bef9b84114ac9239ebd140849f","e746c36faea545869359daf258c82185","6d49bec9a491469db4aea6f2b9f1669b","a4e59f9582bc4732b96955a6ae06a598","31d73696bf444b8a8616291125ade4b9","9b4e3314edd04edea7be5d7ff507a04a","673db829be704a4486de1b749e539066","de32d7c147dd4daa9975e9ea9215a461","ba3439e630eb411e9a93d6b96fdad661","91869cb63804414382d953a30579acd1","eee42fd2aa6c4808b8916ee39536991f","f33575dce314412f880122b9d9656c5e","4a2d9a90e99f41498871826386bb985e","204d1cefcd0b45f9879b892e5f12a109","7c7b3a4abb484676ae3de1b495a8663a","42616641c4db4f219b3e488385ece72f","4312d09da4e44816904ba974aa1b4cb5","5713115f4fa7447daef785af7513ad89","b318e331eb424bd9824cde45166bfee0","1840b8e2baff4252bcf73a4e4cfc9cc6","b85416a0512948e1947aaa285d8c98ed","7008ac52529349f4b505dac17dbcc8c5","ce9e7f335bd1460fbfbd2280bb449b7b","b354c35f790b4d789c85ee773ebc9977","f5094ede598c4489bac074018fc232d9","edec6c72dee3443caa03d539fac5a6f0","25d5a4a00f124d3e9fa92fc3de0b342f","192a121860df4b019dde57e049088ef8","9974a2a7a96e4fb5803e71329de9631e","15e818e3a50e49fc874bf1c18975f656","771463824c414434ae7808cc4d1c077d","b74d255f28694e12ac0d0c72f242f3c0","05ae9ae7afb6489c87d6117150fe6946","d62c07c4d017435f9937c3dd2331f1bf","03eaec383d354f919f8a0e7497c6b549","eaa10361934345bca6be567384cf6ffe","ecab84f4a1644eeca40f122c3b45d83a","dcc11692eea44c79a44b46e0b7fce721","0d34ff74f6e947d9b5dc7534048449bc","c8b5f8da0e684adbbb35056e8b5a130a","790d01265c3f4ed78f343aee27351efe","fea7b165eda2471182ea3058a460540e","dd089ab8a4bc458188d2df5ed7061b93","39cf634df52b4edbb56af296537931c1","cdf18fedbe8a495cba1fa11a35a3638f","535ac72b11624f2d933c4adc86072cfd","141dab626bc44438868d4e4bbad43e05","49faadbdfb234bb2930bf0a1fce4c2a1","add888a35c4d45f2a6e4db90ba00d4dc","8c28816391d9489d964ca0eb93bf2468","ec45024e31f1414eb6eaa52a869efda0","f299b79578c24cd09617922e409e8331","d0fa0482e7114c7286d73434fec925d8","a9aba61e3d064a2eb373215c63b67243","698fe2aa854c42f7bb21deaffdd4ae81","7763e013592c481692c8631e5cb3b757","08927959ba6b41cd954e67b6ec527657","5852db60d352431194ac86b01c73a1b4","5c40e55b22804d1dbc6c6138f0e7e14c","08e1c152cb494619b4354a41efe123ca","d58fc2f247b248e98a736e892cbde9e5","cfd85b5704e14423a65a0c1ba5db1c16","c232ab16a95f42c8a97a3976a89b2df3","5aa6a14fbc2f4b029affee3a892ad497","b1fc5919a497484ca064f2500cb78964","27d1f5f0aa15481bb6c53390f1e0b365","34279a8fe16e4e94a91e3fb816484345","46b454518eae49b1bd2ee45494e0b6c7","0aad49ce4c8042e39b15fbf04ef47ca8","601e1041f3374aba87f325b9c4ec4812","2d724dd248fb4ab0a1af873b78d3a353","eabeedc878fa4a0e9a4360b2a5514a76","3d89dfd19dfa473ab5f14862c8864706","9993a674c4aa47a4aa2ff2a2d7731f22","24bff944845541e2a107de58f26158ce","74c4d0f8ea18444b80abb0b0ad7c8c99","a5f64bf184594b58b5c152b73a9bae56","5657ce7e40414921a34fc1897fe47ff3","39076c8dc2fa4282b302f549a1983317","022369ba384a4f50a6adaca52b3e1ddf","ebee06b107f1463198d596136f460715","37f9512c377c425c943d13d4fd4055f5","e74ff1bcaba74b3ea9823aa6c1eedc89","004a012697c14103aa8800982030650a","180a0a7b41234996bbe6b1bc1c272d7d","53ceb3c87e754931927976c16a090fba","1861512ef08c4c6b925b55a0940d4fc7","6cd505d1382a4d2a9bd33a9355c34294","d7ebaadc6b2945f69b17a46e83ac1ae1","b103c4367fd9487aa9071e0c91838d02","0e4def368211419fba181282417920fb","fc0eb78224654e2498f92e536279a496","3089d14a33134f28a95eecd5ef287fac","6aba5071771d444f93685c94ff75c245","bae8a851ca1a4c029d823f8e1babb915","6742d4617f8d4cd2bc11467319ce2a28","62c3c7de7e3d42e788394e4fbfb9580a","37304c891eb142309c6b387b9da6146e","f88539e0fd5e42acb7bb1929322f6513","eb00ca4c15b04b6da53ed37b24ec9ece","66ebc58fcaa8468ea9232e91096799a3","3fde07030ecc4c7baa3b80ad6056a169","a91d483580ab485398ef793ca3e91299","75e4302f6c814435b1f782252910234c","94865dab54a0450382a499dfd0ea1156","9c1d30a1ca52427a9c78788e73024d9e","5b83273e88f8400a992a06b4ee77574e","1c77892c9d0e4e28bd9771b9a9decebb","65101fb186a944589fa58be452fd51c3","c3085b8e71bf4a86924d0c4285bfe80d","0bc7001a1a734188832ca2fba148e9a0","e8c6576ca2f2445ab9a4ab518e31535b","ab9191cb8cae4ef4abc3114e98241459","5cb2d8b8a1674dfd8d12c6e4592f7b26","d6829f3452174f2ea172a4405befb896","8ef17d1902ba4082a51dd2c1cec9b5b4","6c126918f9304ad2b798543157caf396","064ace65ee8a4d579ab6d80f2266fc77","218a41f3d13442c28f59ca2d05e4d721","06e17eb713094b71ba06fd93b4e6743c","a00f1c4d0efc43e281a5f63ce37f31a3","45013ac717ae40f78a3bf77771c1a237","b4a724b796b2455d998074418205d797","d2397b421f834ce9b7556409bc88f5cd","ef4294c797c0459ca95cd0492a70e791","80a42055ec4e40b88b73b5667167bcee","43b933ab79e14558bdc986fb203ef14a","db66dbfe60714d4b82925def69533dba","faf3cbb14d8c46a3b5a420398ffda3e7","cce6aafec7f441149ff16f11454b883b","1e77108222544d53bee33a47dcffb7cd","0306d8beca94492aa2a9111b248eafde","9e3e2544df434d47b91ef7c242c4a869","c767082e1a8c4a20ab75fc5481f907ea","4c3b6e0db4854cffbe9ab799e9d8079c","5e845a1e30594a44b18b3478a784e110","6eab5b0ab49c48ca9c38f82b02db8f4f","e81491e8a76c45d8a1e5690533dbd32e","1e16cbd15aaf41eda727ade5814c37fa","e29a66ba74134f50a7502f674abd3a1b","cde68b99a93241e485dee1ea30ac3538","239d4b45c65440df957cc9ef64541081","3c1edfa58683498a84e7c03f6b07fe1b","e049623d38394120834caea21e2c97c9","acd3a6626ced432d836b8993753cb3a0","83d789f3289b4088a26fafd77fddd2ec","bea3112b8f38401aa25c2625596d2db2","d3c35732159e4737a3288a3fd68373c2","e38d99767c414099b740c969fcc6c144","9b3c9f89d3fc4fa396a54b749926c528","d20daf109d304b658ff7ec745a100959","c3e149b8faed401083a6fedaa3cecd13","438be166e67741d6ab32d9fc81d60525","2221d92c88e94b51ab9b264e320d76e8"]},"id":"x39FzbqXh3ku","executionInfo":{"status":"ok","timestamp":1676258445486,"user_tz":0,"elapsed":16278291,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"1012d774-635f-4445-f1e3-12e920faec59"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing block 1 of 19\n"]},{"output_type":"display_data","data":{"text/plain":["Processing Progress:   0%|          | 0/100000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8856e0244c7a4a278c70af17ba222aec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Write Progress:   0%|          | 0/1000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"141a8321993d4b6497e945d5cae1f2bd"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing block 2 of 19\n"]},{"output_type":"display_data","data":{"text/plain":["Processing Progress:   0%|          | 0/100000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c44037262314e129fb33e267244034a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Write Progress:   0%|          | 0/1000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8eec8906a0b4f7086f3a1cc49a0e391"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing block 3 of 19\n"]},{"output_type":"display_data","data":{"text/plain":["Processing Progress:   0%|          | 0/100000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fc03a616766446c8e1fc181f7ad7e53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Write Progress:   0%|          | 0/1000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df9c3d40c4e24aadbf4e27f91c6ef528"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing block 4 of 19\n"]},{"output_type":"display_data","data":{"text/plain":["Processing Progress:   0%|          | 0/100000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f1c2622d28c48e4abedc0432746fb59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Write Progress:   0%|          | 0/1000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30b674c683334dc5a886085bc5da7dd1"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing block 5 of 19\n"]},{"output_type":"display_data","data":{"text/plain":["Processing Progress:   0%|          | 0/100000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5eeb380e3e1146b38f3dd90642344e84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Write Progress:   0%|          | 0/1000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4497b28d9a804c498b3f0ae8d062cfb4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing block 6 of 19\n"]},{"output_type":"display_data","data":{"text/plain":["Processing Progress:   0%|          | 0/100000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8898fe84ab1b429e88a5a609b8b270fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Write Progress:   0%|          | 0/1000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31904fe7b4dd482ba8d3d964452a3424"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing block 7 of 19\n"]},{"output_type":"display_data","data":{"text/plain":["Processing Progress:   0%|          | 0/100000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e6a2b17f46b4778b2566537b62c20a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Write Progress:   0%|          | 0/1000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b0b3dceb04d41b49ad0a9030ecd87de"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing block 8 of 19\n"]},{"output_type":"display_data","data":{"text/plain":["Processing Progress:   0%|          | 0/100000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3eb8b0db1f9644fb9af6fb10f026b1ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Write Progress:   0%|          | 0/1000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7db1d391a762430caab84dc1f222cb7f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing block 9 of 19\n"]},{"output_type":"display_data","data":{"text/plain":["Processing Progress:   0%|          | 0/100000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce4dd1bb215040728744ceb6394211d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Write Progress:   0%|          | 0/1000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fef99d16fd404251bc464ef81d8d99ca"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing block 10 of 19\n"]},{"output_type":"display_data","data":{"text/plain":["Processing Progress:   0%|          | 0/100000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56ca7045080d43fb88ac1773cd096728"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Write Progress:   0%|          | 0/1000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"771faebabf584cb0a336140d828f157a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing block 11 of 19\n"]},{"output_type":"display_data","data":{"text/plain":["Processing Progress:   0%|          | 0/100000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4221863abc44d2fbed2a02245e7f109"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Write Progress:   0%|          | 0/1000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24e8c5a5fc17430fbd78653da9ba53d4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing block 12 of 19\n"]},{"output_type":"display_data","data":{"text/plain":["Processing Progress:   0%|          | 0/100000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d7aade26bbb4010910faca1a9ce9c86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Write Progress:   0%|          | 0/1000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc6412a522444ee7b7a5dd89f092824c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing block 13 of 19\n"]},{"output_type":"display_data","data":{"text/plain":["Processing Progress:   0%|          | 0/100000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b7a61bef9b84114ac9239ebd140849f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Write Progress:   0%|          | 0/1000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f33575dce314412f880122b9d9656c5e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing block 14 of 19\n"]},{"output_type":"display_data","data":{"text/plain":["Processing Progress:   0%|          | 0/100000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce9e7f335bd1460fbfbd2280bb449b7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Write Progress:   0%|          | 0/1000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d62c07c4d017435f9937c3dd2331f1bf"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing block 15 of 19\n"]},{"output_type":"display_data","data":{"text/plain":["Processing Progress:   0%|          | 0/100000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdf18fedbe8a495cba1fa11a35a3638f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Write Progress:   0%|          | 0/1000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7763e013592c481692c8631e5cb3b757"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing block 16 of 19\n"]},{"output_type":"display_data","data":{"text/plain":["Processing Progress:   0%|          | 0/100000 [00:02<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34279a8fe16e4e94a91e3fb816484345"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Write Progress:   0%|          | 0/1000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5657ce7e40414921a34fc1897fe47ff3"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing block 17 of 19\n"]},{"output_type":"display_data","data":{"text/plain":["Processing Progress:   0%|          | 0/100000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7ebaadc6b2945f69b17a46e83ac1ae1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Write Progress:   0%|          | 0/1000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb00ca4c15b04b6da53ed37b24ec9ece"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing block 18 of 19\n"]},{"output_type":"display_data","data":{"text/plain":["Processing Progress:   0%|          | 0/100000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bc7001a1a734188832ca2fba148e9a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Write Progress:   0%|          | 0/1000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45013ac717ae40f78a3bf77771c1a237"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Processing block 19 of 19\n"]},{"output_type":"display_data","data":{"text/plain":["Processing Progress:   0%|          | 0/100000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e3e2544df434d47b91ef7c242c4a869"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Write Progress:   0%|          | 0/1000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e049623d38394120834caea21e2c97c9"}},"metadata":{}}]},{"cell_type":"markdown","source":["## Old"],"metadata":{"id":"7gRiG8Eo0eKx"}},{"cell_type":"code","source":["import json\n","import gzip\n","from tqdm.autonotebook import tqdm\n","\n","\n","def get_data_old(layer, neuron, n=10000):\n","  if n is None:\n","    n = 200000\n","\n","  neuron = str(neuron)\n","  prompt_indices = set()\n","  prompt_index_to_activation_dict = {}\n","\n","  with gzip.open(os.path.join(base_path, \"data/activation_data.jsonl.gz\")) as ifh:\n","    for i, line in tqdm(enumerate(ifh), total=n, desc=\"Progress\"):\n","      activation_info = json.loads(line)\n","      layer_activations = activation_info[layer]\n","      # print(list(layer_activations.keys()))\n","      if neuron in layer_activations:\n","        neuron_activation_info = layer_activations[neuron]\n","        # print(layer_activations[neuron])\n","        prompt_index = neuron_activation_info[\"prompt_index\"]\n","        prompt_indices.add(prompt_index)\n","        prompt_index_to_activation_dict[prompt_index] = neuron_activation_info[\"token_activations\"]\n","        # break\n","\n","      # pprint(activation_info[0])\n","\n","      if i >= n:\n","        break\n","  \n","  all_prompts_and_activations = []\n","  with open(os.path.join(base_path, \"data/prompts.jsonl\")) as ifh:\n","    for i, line in enumerate(ifh):\n","      if i in prompt_indices:\n","        prompt_tokens = json.loads(line)\n","        # print(len(prompt_tokens))\n","        prompt_activation_dict = prompt_index_to_activation_dict[i]\n","        prompt_activations = [prompt_activation_dict.get(str(j), 0) for j, _ in enumerate(prompt_tokens)]\n","        non_zero_indices = [j for j, activation in enumerate(prompt_activations) if activation > 0]\n","        # print([activation for activation in prompt_activations if activation > 0])\n","        # print(list(zip(prompt_tokens, prompt_activations))[max(0, non_zero_indices[0] - 10):min(len(prompt_tokens) - 1, non_zero_indices[0] + 10)])\n","        all_prompts_and_activations.append((prompt_tokens, prompt_activations))\n","\n","  return all_prompts_and_activations"],"metadata":{"id":"Pt0QsefrvKn7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title\n","# Old build using pyvis\n","\n","\n","  # def build(self):\n","  #   print(\"\\n\\n******BUILDING*******\")\n","  #   visited = set() # List to keep track of visited nodes.\n","  #   queue = []     #Initialize a queue\n","\n","  #   visited.add(self.root[0].id_)\n","  #   queue.append(self.root)\n","\n","  #   tokens_by_layer = {}\n","  #   node_id_to_graph_id = {}\n","  #   added_ids = set()\n","  #   node_count = 0\n","\n","  #   while queue:\n","  #     node, edge = queue.pop(0) \n","\n","  #     token = node.value[\"token\"]\n","  #     depth = node.depth\n","\n","  #     if depth not in tokens_by_layer:\n","  #       tokens_by_layer[depth] = {}\n","\n","  #     if token not in tokens_by_layer[depth]:\n","  #       tokens_by_layer[depth][token] = node_count        \n","  #       node_count += 1\n","\n","  #     graph_node_id = tokens_by_layer[depth][token]\n","  #     node_id_to_graph_id[node.id_] = graph_node_id\n","\n","  #     scaled_act = int(node.value.get(\"activation\", 0) * 255)\n","  #     rgb = (255, 255 - scaled_act, 255 - scaled_act)\n","  #     hex = \"#{0:02x}{1:02x}{2:02x}\".format(*self.clamp(rgb))\n","\n","  #     # self.net.add_node(node.id_, label=node.value[\"token\"], color=hex)\n","\n","  #     if graph_node_id not in added_ids:\n","  #       self.net.add_node(graph_node_id, label=node.value[\"token\"], color=hex)\n","      \n","  #     if edge.parent is not None and edge.parent.id_ in visited and edge.parent.id_ != -1:\n","  #       # self.net.add_edge(node.id_, edge.parent.id_, value=edge.weight, title=round(edge.weight, 2))\n","  #       graph_parent_id = node_id_to_graph_id[edge.parent.id_]\n","  #       self.net.add_edge(graph_node_id, graph_parent_id, value=edge.weight, title=round(edge.weight, 2))\n","\n","  #     print(node) \n","  #     print(edge)\n","\n","  #     for token, neighbour in node.children.items():\n","  #       new_node, new_edge = neighbour\n","  #       if new_node.id_ not in visited:\n","  #         visited.add(new_node.id_)\n","  #         queue.append(neighbour)\n","\n","    # self.net.show('nodes.html')"],"metadata":{"id":"jpu3wuDM1DdM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Compute Statistics"],"metadata":{"id":"Qrxz6p4jDJPI"}},{"cell_type":"markdown","source":["### Save dataset examples from each layer"],"metadata":{"id":"ZerY2i-bDAR9"}},{"cell_type":"code","source":["def get_examples(model_name, layer_and_neurons):\n","  layer, neurons = layer_and_neurons\n","  neuron_to_snippets = {}\n","  for neuron in neurons:\n","    try:\n","      snippets = get_snippets(model_name, layer, neuron)\n","      neuron_to_snippets[neuron] = snippets\n","    except:\n","      print(f\"Neuron {neuron} in layer {layer} failed\")    \n","  return neuron_to_snippets"],"metadata":{"id":"K6p8mFTzD8Tj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import multiprocessing as mp\n","import random\n","\n","random.seed(0)\n","\n","layers = 8\n","neurons = 1024\n","model_name = \"solu-8l-old\"\n","\n","info = [(layer, random.sample([neuron for neuron in range(neurons)], 200)) for layer in range(layers)]"],"metadata":{"id":"9iGF-mJQC_nw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","\n","with mp.Pool(layers) as p:\n","    snippet_dicts = p.map(partial(get_examples, model_name), info)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MTySFh8ZJsza","executionInfo":{"status":"ok","timestamp":1673114426258,"user_tz":0,"elapsed":292795,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"df693e5f-3dc9-40c1-c695-d0acaafc0953"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Neuron 720 in layer 0 failed\n","CPU times: user 1.39 s, sys: 955 ms, total: 2.35 s\n","Wall time: 4min 52s\n"]}]},{"cell_type":"code","source":["print(len(snippet_dicts))\n","print(len(snippet_dicts[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LmEql_QjS7zv","executionInfo":{"status":"ok","timestamp":1673115826629,"user_tz":0,"elapsed":396,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"b9be38f4-5902-43de-c01f-243192905596"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["8\n","199\n"]}]},{"cell_type":"code","source":["import json\n","\n","if False:\n","  with open(os.path.join(base_path, \"data/snippets.json\"), \"w\") as ofh:\n","    json.dump(snippet_dicts, ofh, indent=2, ensure_ascii=False)"],"metadata":{"id":"ManFMjvmK9q7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i, snippet_dict in enumerate(snippet_dicts):\n","  print(\"layer\", i)\n","  for neuron, snippet in snippet_dict.items():\n","    print(neuron, snippet[:50])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B8V4DavIKYs4","executionInfo":{"status":"ok","timestamp":1673110710270,"user_tz":0,"elapsed":80,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"f2b6f9bb-f843-4325-b662-fe4a4975ed8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["layer 0\n","788 ['<|endoftext|> 1 ½ minutes or until melted, stirring at 30-second intervals.\\n\\n3. Stir together flour, salt, and baking powder in a large bowl.\\n\\n4. Beat eggs and brown sugar in a large bowl with a mixer at medium-high speed 3 to 4 minutes or until batter forms thin ribbons when beaters are lifted.\\n\\n5. Add vanilla, bittersweet chocolate, and melted chocolate mixture. Beat only until blended.\\n\\n6. Stir in flour mixture just until combined. Spread 1 cup crust mixture on bottom of prepared pan.\\n\\n7. Bake at 350°F on center oven rack 13 to 15 minutes or until set. Cool on a wire rack 10 minutes; freeze 15 minutes. Remove from freezer; spread remaining batter up sides of pan to ¼ inch from top, sealing batter to bottom crust.\\n\\n8. Prepare the Cheesecake Filling: Beat cream cheese and brown sugar with a stand mixer at medium speed until blended. Add eggs, 1 at a time, beating only until yellow yolk disappears after each addition. Beat in sour cream only until blended. Beat in peanut butter until blended.\\n\\n9. Pour filling into prepared crust. (Mixture will not completely fill crust.)\\n\\n10. Bake at 350°F for 35 minutes or until center is almost set. A 2-inch circle in center of filling should jiggle slightly when pan is shaken gently. Meanwhile, prepare the Topping. Stir together sour cream and sugar in a small bowl until smooth.\\n\\n11. Remove cheesecake from oven. Spread Topping over center of cheesecake, leaving a 2-inch border around edge. Bake for 1 more minute.\\n\\n12. Remove from oven; gently run a knife around outer edge of cheesecake to loosen from sides of pan. Cool completely on a wire rack.\\n\\n13. Cover and chill 8 to 12 hours. Remove sides of pan. Top with chocolate curls.Eggnog Cheesecake with Bourbon Caramel\\n\\nEggnog Cheesecake with Bourbon Caramel\\n\\nYou can also use high-quality prepared caramel sauce. Warm it in a saucepan over low heat, then gradually stir in bourbon to taste.\\n\\nActive 15 min. - Total 11 hours, 36 min.\\n\\nServes 10\\n\\nCRUST\\n\\n2 cups graham cracker crumbs (about 15 whole crackers)\\n\\n½ cup butter, melted\\n\\n½ cup finely chopped pecans\\n\\n2 Tbsp. granulated sugar\\n\\nFILLING\\n\\n3 (8-oz.) pkg. cream cheese, softened\\n\\n1 �� cups granulated sugar, divided\\n\\n2 Tbsp. all-purpose flour\\n\\n½ tsp. freshly grated nutmeg\\n\\n4 large eggs\\n\\n1 cup refrigerated eggnog\\n\\n1 tsp. vanilla extract\\n\\nCARAMEL TOPPING\\n\\n¼ cup light corn syrup\\n\\n¼ cup water\\n\\n¾ cup heavy whipping cream\\n\\n2 Tbsp. bourbon\\n\\nSweetened whipped cream\\n\\nFreshly grated nutmeg\\n\\n1. Preheat oven to 325°F. Prepare the Crust: Stir together first 4 ingredients in a medium bowl until well blended. Press mixture on bottom and 2 inches up sides of a 9-inch springform pan. Bake for 10 to 12 minutes or until lightly browned. Remove crust to a wire rack, and cool completely, about 30 minutes.\\n\\n2. Meanwhile, prepare the Filling: Beat cream cheese and 1 cup of the sugar with a stand mixer at medium speed until blended and smooth. Beat in flour and nutmeg. Add eggs, 1 at a time, beating just until blended after each addition. Add eggnog and vanilla, beating until blended. Pour batter into prepared crust.\\n\\n3. Bake at 325°F for 1 hour and 5 minutes or until almost set. Turn off oven. Let cheesecake stand in oven, with door closed, 15 minutes. Remove cheesecake from oven, and gently run a knife around outer edge of cheesecake to loosen from sides of pan. (Do not remove sides of pan.) Cool completely on a wire rack, about 1 hour. Cover and chill 8 to 24 hours.\\n\\n4. Prepare the Caramel Topping: Bring corn syrup, ¼ cup water, and remaining �� cup sugar to a boil in a medium saucepan over medium-high. (Do not stir.) Boil, swirling occasionally after sugar begins to change color, 7 minutes or until dark amber. (Do not walk away from the pan because sugar will burn quickly once it begins to change color.) Remove from heat. Carefully whisk in cream (mixture will bubble and spatter). Whisk constantly until bubbling stops and caramel dissolves. Whisk in bourbon. Cover and refrigerate until ready to use or up to 2 weeks.\\n', '<|endoftext|>. Roll the braciole tightly and secure with toothpick. Season with salt and pepper.\\n\\n**4**.Warm oil in skillet over medium heat. Add onions, and cook until translucent.\\n\\n**5**.Add braciole to skillet and cook for approx. 1 minute per side, then add wine and allow alcohol to evaporate (approx. 3 minutes).\\n\\n**6**.Add tomato sauce and basil, reduce heat to low and cook for another 7 to 10 minutes. Season to taste.\\n\\n**7**.Transfer braciole to serving plate, increase heat to medium, and cook till liquid is reduced by half. Pour liquid onto plated braciole.\\n\\n_Serve immediately._\\n\\n### Patate e Baccalà al Forno\\n\\n### (Oven-baked Cod and Potatoes)\\n\\nLucia (Grilli) Otello, Foggia\\n\\n**(Yield: 4 servings)**\\n\\n**1½ pounds baccalà (cod fillets)**\\n\\n**5 teaspoons extra-virgin olive oil (plus extra)**\\n\\n**1 cup water (optional white wine)**\\n\\n**1 cup breadcrumbs**\\n\\n**1 garlic clove (minced)**\\n\\n**1 teaspoon freshly ground black pepper**\\n\\n**¼ cup parsley (chopped fine)**\\n\\n**6 potatoes (cleaned, cut into wedges, skin on)**\\n\\n**1**. Lightly grease bottom of oven pan with 2 teaspoons of oil, layer in cod fillets, and pour in water (or wine).\\n\\n**2**.In bowl combine breadcrumbs, garlic, pepper, parsley and remaining oil. Mix well. Add cut potatoes and toss.\\n\\n**3**.Add potatoes to pan and drizzle lightly with more oil.\\n\\n**4**.Seal pan with aluminum foil and bake in oven preheated to 350°F for 1½ hours, removing foil for last 30 minutes.\\n\\n_Serve plated with pan juices._\\n\\n_Traditionally this recipe is made using dry salted cod, giving it a slightly different flavour. Refer topage 306 for preparation of salted cod._\\n\\n### Spaghetti con Seppie e Piselli\\n\\n### (Spaghetti, Cuttlefish and Peas)\\n\\nRosa (Calamita) Silvestri, Bari\\n\\n**(Yield: 4 servings)**\\n\\n**1 pound spaghetti**\\n\\n**1 pound cuttlefish (cut into strips)**\\n\\n**2 teaspoons extra-virgin olive oil**\\n\\n**2 garlic cloves (minced)**\\n\\n**1 onion (diced)**\\n\\n**½ cup white wine**\\n\\n**16 ounces crushed tomatoes**\\n\\n**1 cup peas (fresh or frozen)**\\n\\n**2 teaspoons finely chopped parsley**\\n\\n**salt and freshly ground pepper**\\n\\n**1**. Warm oil in large skillet over low heat and sauté garlic and onions until onions are translucent.\\n\\n**2**.Add strips of cuttlefish. Stir well and continue cooking for 5 minutes. Add wine, cook for 5 minutes, and then add tomatoes. Salt and pepper to taste. Increase heat to medium and once boiling, reduce to low and allow sauce to simmer partially covered for approx. 30 minutes.\\n\\n**3**.Add peas in last 10 minutes. Sprinkle half the parsley in last 5 minutes. Stir well.\\n\\n**4**.While sauce is cooking, bring pot of salted water to boil, add spaghetti and cook until al dente.\\n\\n**5**.Drain, add spaghetti to sauce, mix thoroughly, and cook for another minute. Remove from heat and sprinkle remaining parsley.\\n\\n_Serve immediately._\\n\\n### Zuppa di Cozze alla Tarantina\\n\\n### (Mussel Soup)\\n\\nLeonarda (Notarangelo) Guerra, Manfredonia, Foggia\\n\\n**(Yield: 4 servings)**\\n\\n**2 pounds mussels (scrubbed and cleaned)**\\n\\n**2 tablespoons extra-virgin olive oil**\\n\\n**2 garlic cloves (smashed)**\\n\\n**½ teaspoon chili flakes**\\n\\n**12 ounces tomato sauce**\\n\\n**1 teaspoon salt**\\n\\n**2 tablespoons finely chopped parsley**\\n\\n**toasted bread**\\n\\n**1**. Warm oil in deep saucepan over medium heat. Add garlic and sauté until garlic is golden, then remove and discard garlic.\\n\\n**2**.Add chili flakes, tomato sauce, and salt; reduce heat to low and cook for approx. 10 minutes.\\n\\n**3**.Add cleaned mussels and parsley. Stir well. Cook covered until the mussels have opened (10 minutes). Discard any that have not opened.\\n\\n_Serve immediately with the', '<|endoftext|> 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 </vcount>\\n          <p>1 0 0 0 32 0 32 1 2 1 1 1 32 2 3 2 2 2 32 3 4 3 3 3 32 4 5 4 4 4 32 5 6 5 5 5 32 6 7 6 6 6 32 7 8 7 7 7 32 8 9 8 8 8 32 9 10 9 9 9 32 10 11 10 10 10 32 11 12 11 11 11 32 12 13 12 12 12 32 13 14 13 13 13 32 14 15 14 14 14 32 15 16 15 15 15 32 16 17 16 16 16 32 17 18 17 17 17 32 18 19 18 18 18 32 19 20 19 19 19 32 20 21 20 20 20 32 21 22 21 21 21 32 22 23 22 22 22 32 23 24 23 23 23 32 24 25 24 24 24 32 25 26 25 25 25 32 26 27 26 26 26 32 27 28 27 27 27 32 28 29 28 28 28 32 29 30 29 29 29 32 30 31 30 30 30 32 31 0 31 31 31 33 32 0 32 1 32 33 33 1 33 2 33 33 34 2 34 3 34 33 35 3 35 4 35 33 36 4 36 5 36 33 37 5 37 6 37 33 38 6 38 7 38 33 39 7 39 8 39 33 40 8 40 9 40 33 41 9 41 10 41 33 42 10 42 11 42 33 43 11 43 12 43 33 44 12 44 13 44 33 45 13 45 14 45 33 46 14 46 15 46 33 47 15 47 16 47 33 48 16 48 17 48 33 49 17 49 18 49 33 50 18 50 19 50 33 51 19 51 20 51 33 52 20 52 21 52 33 53 21 53 22 53 33 54 22 54 23 54 33 55 23 55 24 55 33 56 24 56 25 56 33 57 25 57 26 57 33 58 26 58 27 58 33 59 27 59 28 59 33 60 28 60 29 60 33 61 29 61 30 61 33 62 30 62 31 62 31 63 0 63 33 63 35 64 67 64 66 64 66 65 65 65 35 65 65 66 64 66 35 66 64 67 63 67 35 67 63 68 62 68 35 68 62 69 61 69 35 69 61 70 60 70 35 70 60 71 59 71 35 71 59 72 58 72 35 72 58 73 57 73 35 73 57 74 56 74 35 74 56 75 55 75 35 75 55 76 54 76 35 76 54 77 53 77 35 77 53 78 52 78 35 78 52 79 51 79 35 79 51 80 50 80 35 80 50 81 49 81 35 81 49 82 48 82 35 82 48 83 47 83 35 83 47 84 46 84 35 84 46 85 45 85 35 85 45 86 44 86 35 86 44 87 43 87 35 87 43 88 42 88 35 88 42 89 41 89 35 89 41 90 40 90 35 90 40 91 39 91 35 91 39 92 38 92 35 92 38 93 37 93 35 93 37 94 36 94 35 94 36 95 67 95 35 95 66 96 67 96 34 96 65 97 66 97 34 97 64 98 65 98 34 98 63 99 64 99 34 99 62 100 63 100 34 100 61 101 62 101 34 101 60 102 61 102 34 102 59 103 60 103 34 103 58 104 59 104 34 104 57 105 58 105 34 105 56 106 57 106 34 106 55 107 56 107 34 107 54 108 55 108 34 108 53 109 54 109 34 109 52 110 53 110 34 110 51 111 52 111 34 111 50 112 51 112 34 112 49 113 50 113 34 113 48 114 49 114 34 114 47 115 48 115 34 115 46 116 47 116 34 116 45 117 46 117 34 117 44 118 45 118 34 118 43 119 44 119 34 119 42 120 43 120 34 120 41 121 42 121 34 121 40 122 41 122 34 122 39 123 40 123 34 123 38 124 39 124 34 124 37 125 38 125 34 125 36 126 37 126 34 126 34 127 67 127 36 127 69 128 68 128 100 128 100 129 70 129 69 129 100 130 71 130 70 130 100 131 72 131 71 131 100 132 73 132 72 132 100 133 74 133 73 133 100 134 75 134 74 134 100 135 76 135 75 135 100 136 77 136 76 136 100 137 78 137 77 137 100 138 79 138 78 138 100 139 80 139 79 139 100 140 81 140 80 140 100 141 82 141 81 141 100 142 83 142 82 142 100 143 84 143 83 143 100 144 85 144 84 144 100 145 86 145 85 145 100 146 87 146 86 146 100 147 88 147 87 147 100 148 89 148 88 148 100 149 90 149 89 149 100 150 91 150 90 150 100 151 92 151 91 151 100', \"<|endoftext|> and garlic until meat is browned and onion is tender. Drain off fat.\\n\\n2 Stir water, chili powder, cumin, and salt into meat mixture in skillet. Cook about 5 minutes or until most of the water has evaporated. Remove from heat. Stir in cooked rice and chiles.\\n\\n3 Spoon ½ cup filling onto each tortilla (see photo 1, below). Top with cheese and tomato. Fold bottom edge of tortillas over filling. Fold in opposite sides and roll up (see photo 2, below). Secure with wooden toothpicks.\\n\\n4 Arrange burritos, seam sides down, on a baking sheet. Bake for 10 to 12 minutes or until heated through. Serve warm burritos on lettuce with Guacamole.\\n\\nPER burrito: 449 cal., 25 g fat (9 g sat. fat), 63 mg chol., 528 mg sodium, 37 g carb., 5 g fiber, 21 g pro. EXCHANGES: ½ Vegetable, 2½ Starch, 2 Lean Meat, 3 Fat\\n\\nCHICKEN OR STEAK BURRITOS: Omit the ground beef. Partially freeze 1 pound skinless, boneless chicken breast halves or 1 pound beef flank steak for easier slicing. Cut chicken into thin bite-size strips or cut beef across the grain into thin, bite-size strips. For filling, in a large skillet cook chicken or beef, onion, sweet pepper, and garlic in 1 tablespoon hot vegetable oil until chicken is no longer pink or beef is desired doneness. Stir in water, chili powder, cumin, and salt. Cook about 5 minutes or until most of the water has evaporated. Remove from heat. Stir in rice and chiles. Continue as directed.\\n\\nPER BURRITO: 415 cal., 20 g total fat (6 g sat. fat), 52 mg chol., 472 mg sodium, 37 g carb., 5 g fiber, 24 g pro. EXCHANGES: ½ Vegetable, 2 Starch, 1 Lean Meat, 1 High-Fat Meat, 2 Fat\\n\\n* * *\\n\\n## super burritos step-by-step\\n\\n**1.** Spread about ½ cup of filling on a warmed tortilla so it's just below the center. Top the filling with cheese and tomato. Fold the bottom of the tortilla up and over the filling.\\n\\n**2.** Fold the ends of the tortilla in and over the filling. Roll up from the bottom, completely enclosing the filling. Secure with wooden toothpicks.\\n\\nChapter Contents | Charts |Metric Information | Emergency Substitutions | Index\\nMeat\\n\\nBEST-LOVED\\n\\n## Steak and Tomatoes on Toast\\n\\nPREP: 20 MINUTES COOK: 17 MINUTES MAKES: 6 open-face sandwiches\\n\\n  * 2 tablespoons butter, softened\\n  * 2 tablespoons olive oil\\n  * 1 tablespoon snipped fresh oregano\\n  * 1 tablespoon snipped fresh rosemary\\n  * 2 cloves garlic, minced\\n  * 1 teaspoon smoked paprika\\n  * ½ teaspoon salt\\n  * ½ teaspoon cracked black pepper\\n  * 1 1-pound ciabatta loaf\\n  * 1½ pounds beef flank steak\\n  * Salt and cracked black pepper\\n  * 3 cups cherry or grape tomatoes\\n\\n1 In a small bowl combine butter, oil, oregano, rosemary, garlic, paprika, ½ teaspoon salt, and cracked black pepper. Cut ciabatta loaf in half horizontally; cut each half crosswise into thirds to make six pieces. Very lightly brush cut sides of bread with some of the herb mixture. Set remaining herb mixture aside.\\n\\n2 Score flank steak on both sides, making shallow cuts at 1-inch intervals diagonally across steak in a diamond pattern. Heat a very large skillet over medium-high heat until very hot. Sprinkle both sides of steak with additional salt and pepper.\\n\\n3 Cook steak in hot skillet, uncovered, for 12 to 15 minutes or until medium rare (145°F), turning once halfway through cooking. Transfer steak to a plate. Cover; let stand for 5 minutes.\\n\\n4 Meanwhile, place half of the bread, cut sides down, in the skillet; cook about 1 minute or until toasted. Remove from skillet. Repeat with remaining bread. Add remaining herb mixture to skillet. When mixture begins to bubble, add tomatoes for 4 to 6 minutes or until skins split. Remove from heat.\\n\\n5 Thinly slice steak across the grain. Arrange thinly sliced steak on toasted bread; top with tomatoes. Serve immediately.\\n\\nPER open-face sandwich: 417 cal., 15 g total (6 g sat. fat), 88 mg chol., 723 mg sodium, 36 g carb., 3 g fiber, 32 g pro. EXCHANGES: 1 Vegetable, 2 Starch, 3½ Lean Meat\", '<|endoftext|> 4 hours or up to 2 days.\\n\\n4 To serve, let cake stand at room temperature 5 minutes. Remove plastic wrap. Place serving plate upside down over pan; turn plate and pan over. Remove pan and foil. Break remaining granola bar into pieces; sprinkle over top. With sharp knife, cut crosswise into 1-inch-thick slices.\\n\\n1 Serving: Calories 350; Total Fat 26g (Saturated Fat 15g, Trans Fat 1g); Cholesterol 80mg; Sodium 120mg; Total Carbohydrate 26g (Dietary Fiber 2g); Protein 3g Exchanges: 1 Starch, ½ Other Carbohydrate, 5 Fat Carbohydrate Choices: 2\\n\\n## Mud Slide Ice Cream Cake\\n\\n15 servings | Prep Time: 30 Minutes | Start to Finish: 6 Hours\\n\\n•••\\n\\n  * 1 box (15.25 oz) chocolate fudge cake mix with pudding\\n  * ½ cup butter, softened\\n  * 1 egg\\n  * 2 tablespoons milk\\n  * 2 tablespoons coffee-flavored liqueur or cold strong brewed coffee\\n  * 1 quart (4 cups) vanilla ice cream\\n  * 1 container (12 oz) chocolate whipped ready-to-spread frosting\\n  * 2 tablespoons coffee-flavored liqueur, if desired\\n\\n1 Heat oven to 350°F (325°F for dark or nonstick pan). Grease bottom only of 13x9-inch pan with shortening or cooking spray. In large bowl, beat cake mix, butter, egg and milk with spoon or electric mixer on low speed until well blended. Spread batter in pan.\\n\\n2 Bake 16 to 18 minutes or until center is set (top may appear dry and cracked). Cool completely on cooling rack, about 1 hour.\\n\\n3 Brush 2 tablespoons liqueur over cake. Let ice cream stand about 15 minutes at room temperature to soften. Spread ice cream over cake. Freeze about 3 hours or until firm.\\n\\n4 In medium bowl, mix frosting and 2 tablespoons liqueur; spread over ice cream. Freeze at least 1 hour. Store covered in freezer up to 3 months.\\n\\n1 Serving: Calories 340; Total Fat 16g (Saturated Fat 8g, Trans Fat 1.5g); Cholesterol 45mg; Sodium 390mg; Total Carbohydrate 46g (Dietary Fiber 1g); Protein 3g Exchanges: 1 Starch, 2 Other Carbohydrate, 3 Fat Carbohydrate Choices: 3\\n\\nFresh Idea Coffee lovers, substitute coffee-flavored ice cream for the vanilla!\\n\\nMud Slide Ice Cream Cake\\n\\nRainbow Sherbet Roll\\n\\n## Rainbow Sherbet Roll\\n\\n12 servings | Prep Time: 20 Minutes | Start to Finish: 8 Hours 15 Minutes\\n\\n•••\\n\\n  * 1 box (16 oz) white angel food cake mix\\n  * 1¼ cups cold water\\n  * Powdered sugar\\n  * 1½ cups raspberry sherbet, softened\\n  * 1½ cups orange sherbet, softened\\n  * 1½ cups lime sherbet, softened\\n\\n1 Heat oven to 350°F. Line 15x10x1-inch pan with waxed paper.\\n\\n2 In extra-large glass or metal bowl, beat cake mix and cold water with electric mixer on low speed 30 seconds; beat on medium speed 1 minute. Spread half of the batter in pan. Spread remaining batter in ungreased 9x5-inch loaf pan.\\n\\n3 Bake 15x10 pan 20 to 25 minutes, loaf pan 35 to 45 minutes, or until top springs back when touched lightly in center. Cool 10 minutes; remove cake from loaf pan and reserve for another use. Loosen cake from edges of 15x10 pan; turn upside down onto towel sprinkled with powdered sugar. Carefully remove waxed paper. Trim off stiff edges of cake if necessary. Carefully roll hot cake and towel from narrow end. Cool completely on cooling rack, about 1 hour.\\n\\n4 Unroll cake; remove towel. Beginning at a narrow end, spread raspberry sherbet on one-third of cake, orange sherbet on next third of cake and lime sherbet on remaining cake. Roll up carefully. Place roll, seam side down, on 18x12-inch piece of foil; wrap in foil.\\n\\n5 Freeze at least 6 hours or until firm. Remove from freezer 15 minutes before serving. Cut roll into ��-inch slices. Store tightly wrapped in freezer up to 3 months.\\n\\n1 Serving: Calories 220; Total Fat 1g (Saturated Fat 0.5g, Trans Fat 0g); Cholesterol 0mg; Sodium 350mg; Total Carbohydrate 50g (Dietary Fiber 0g); Protein 3g Exchanges:', '<|endoftext|> combined. Add eggs, 1 at a time, beating well after each addition.\\n\\n5. Add sour cream, zest, and juice; beat until combined. Pour mixture on top of cooled crust.\\n\\n6. Bake at 325°F for 30 minutes or until almost set in the middle. Remove pan from oven; place on a wire rack.\\n\\n7. Prepare the Topping: Combine sugar, zest, juice, cornstarch, and yolks in a small saucepan, stirring with a whisk until smooth.\\n\\n8. Place pan over medium-low; cook 5 minutes or until mixture thickens, stirring constantly. Remove pan from heat; add butter, stirring until butter melts. Spread Topping over warm cheesecake. Cool completely on wire rack. Cover and refrigerate overnight. Cut into 16 bars.\\n\\nRed Velvet-White Chocolate Cheesecake\\n\\nWhimsy meets elegance in all five layers of this red velvet-white chocolate wonder.\\n\\nActive 45 min. - Total 13 hours, 45 min.\\n\\nServes 10 to 12\\n\\nCHEESECAKE LAYERS\\n\\n2 (8-inch) round disposable aluminum foil cake pans\\n\\n1 (12-oz.) pkg. white chocolate chips\\n\\n5 (8-oz.) pkg. cream cheese, softened\\n\\n1 cup granulated sugar\\n\\n2 large eggs\\n\\n1 Tbsp. vanilla extract\\n\\nRED VELVET LAYERS\\n\\n3 (8-inch) round disposable aluminum foil cake pans\\n\\n1 cup butter, softened\\n\\n2 ½ cups granulated sugar\\n\\n6 large eggs\\n\\n3 cups all-purpose flour\\n\\n3 Tbsp. unsweetened cocoa\\n\\n¼ tsp. baking soda\\n\\n1 (8-oz.) container sour cream\\n\\n2 tsp. vanilla extract\\n\\n2 (1-oz.) bottles red liquid food coloring\\n\\nWHITE CHOCOLATE FROSTING\\n\\n2 (4-oz.) white chocolate baking bars, chopped\\n\\n½ cup boiling water\\n\\n1 cup butter, softened\\n\\n1 (32-oz.) pkg. powdered sugar, sifted\\n\\n��� tsp. table salt\\n\\nGarnishes: store-bought coconut candies, White Candy Leaves (recipe follows)\\n\\n1. Preheat oven to 300°F. Prepare the Cheesecake Layers: Line bottom and sides of 2 disposable cake pans with aluminum foil, allowing 2 to 3 inches to extend over sides; lightly grease foil.\\n\\n2. Microwave white chocolate chips in a microwave-safe bowl according to package directions; cool 10 minutes.\\n\\n3. Beat cream cheese and melted chocolate with a mixer at medium speed until creamy; gradually add 1 cup sugar, beating well. Add 2 eggs, 1 at a time, beating just until yellow disappears after each addition. Stir in 1 tablespoon vanilla. Pour into prepared pans.\\n\\n4. Bake at 300°F for 30 to 35 minutes or until almost set. Turn off oven. Let cheesecakes stand in oven, with door closed, 30 minutes. Remove from oven to wire racks; cool completely, about 1 ½ hours.\\n\\n5. Cover and chill 8 hours, or freeze 24 hours to 2 days.\\n\\n6. Preheat oven to 350°F. Prepare the Red Velvet Layers: Grease and flour 3 (8-inch) disposable cake pans. Beat 1 cup butter with a stand mixer at medium speed until creamy. Gradually add 2 ½ cups sugar, beating until light and fluffy. Add 6 eggs, 1 at a time, beating just until blended after each addition.\\n\\n7. Stir together flour and next 2 ingredients; add to butter mixture alternately with sour cream, beginning and ending with flour mixture. Beat at low speed just until blended after each addition. Stir in 2 teaspoons vanilla; stir in food coloring. Spoon batter into prepared pans.\\n\\n8. Bake at 350°F for 20 to 24 minutes or until a wooden pick inserted in center comes out clean. Cool in pans on wire racks 10 minutes. Remove from pans to wire racks; cool completely, about 1 hour.\\n\\n9. Prepare the White Chocolate Frosting: Whisk together chocolate and ½ cup boiling water until chocolate melts. Cool 20 minutes; chill 30 minutes.\\n\\n10. Beat 1 cup butter and chilled chocolate mixture at low speed until blended. Beat at medium speed 1 minute. Increase speed to high; beat 2 to 3 minutes or until fluffy. Gradually add powdered sugar and salt, beating at low speed until blended. Increase speed to high; beat 1 to 2 minutes or until smooth and fluffy.\\n\\n11. Assemble cake: Place 1 red velvet layer on a serving platter. Top with 1 cheesecake layer. Repeat with remaining layers of red velvet and cheesecake, alternating', '<|endoftext|> the two-piece lids and secure snugly.\\n\\nPlace jars in prepared pressure cooker and process at 10 pounds pressure, or at 240°F (for pint jars this will take 75 minutes and for quart jars it will take 90 minutes).\\n\\n## **Garlic Bean Soup**\\n\\nServes 8\\n\\n### **Ingredients:**\\n\\n1 pound dry Great Northern beans\\n\\n1 quart water\\n\\n1 quart low-sodium vegetable broth\\n\\n3 tablespoons olive oil\\n\\n2 garlic cloves, minced\\n\\n4 tablespoons chopped parsley\\n\\n### **Directions:**\\n\\nPlace beans in large soup pot, cover with water and bring to boil. Cook 2 minutes, remove from heat. Cover pot and allow to stand for 1 hour. Drain, discarding the water. Combine beans, 1 quart fresh water, and vegetable broth in slow cooker. Sauté garlic and parsley in olive oil in skillet. Stir into slow cooker. Cover and cook on low for 8-10 hours or until beans are tender.\\n\\n## **Creamy Squash Soup with Shredded Apples**\\n\\nCourtesy of NHLBI, part of NIH and HHS\\n\\n### **Ingredients:**\\n\\n32 ounces puréed winter (butternut) squash\\n\\n2 medium apples (try Golden Delicious or Gala)\\n\\n1 tablespoon olive oil\\n\\n½ teaspoon pumpkin pie spice\\n\\n2 (12 oz.) cans fat-free evaporated milk\\n\\n¼ teaspoon salt\\n\\n��� teaspoon ground black pepper\\n\\n### **Directions:**\\n\\nPeel then shred the apples using a grater or food processor, or peel and finely chop apples into thin strips. Set aside ¼ cup. Warm oil in a 4-quart saucepan over medium heat. Add all but ¼ cup of the apples. Cook and stir until apples soften, about 5 minutes. Stir in squash and pumpkin pie spice. Add the evaporated milk about ½ cup at a time, stirring after each addition.\\n\\nSeason with salt and pepper. Cook and stir over high heat just until soup is about to boil. Ladle into individual soup bowls. Top each with a tablespoon of the unused apples. Sprinkle with additional pumpkin pie spice, if desired.\\n\\n## **Chayote Squash Soup with Cilantro Sour Cream**\\n\\nServes 6\\n\\n### **Ingredients:**\\n\\n1 large onion, chopped\\n\\n2 garlic cloves, minced\\n\\n1 tablespoon fresh ginger, minced\\n\\n4 tablespoons flour\\n\\n1 medium yellow pepper, sliced\\n\\n3 large chayote squash, peeled, pitted, sliced\\n\\n6 cups vegetable broth, divided\\n\\n½ cup water\\n\\nCilantro, coarsely chopped, for garnish\\n\\nCooking spray\\n\\n### **Cilantro Sour Cream**\\n\\n��� cup fat-free sour cream\\n\\n1 tablespoon finely chopped cilantro\\n\\n��� cup skim milk\\n\\n### **Directions:**\\n\\nSpray large saucepan with cooking spray; heat over medium heat until hot. Sauté onion and garlic until tender; about 5 minutes. Stir in ginger and flour and cook over medium heat for 2 minutes, stirring constantly. Add pepper, squash, and 2 cups broth to saucepan; heat to boiling. Reduce heat to simmer until squash is tender, 15 to 20 minutes. Process mixture in food processor or blender until smooth; return to saucepan. Add remaining broth and water while continuing to heat; serve warm or cool to serve chilled. Drizzle with Cilantro Sour Cream and sprinkle of cilantro.\\n\\n## **Roasted Acorn Squash and Apple Soup**\\n\\nCourtesy of the New York State Maple Producers Association\\n\\n(www.nysmaple.com)\\n\\n### **Ingredients:**\\n\\n1 medium acorn squash, quartered, seeds removed (see note below)\\n\\n1 cup onions, peeled and diced\\n\\n1 cup carrots, peeled and diced\\n\\n1 cup celery, diced\\n\\n3 apples (such as Cortland or McIntosh), peeled, cored and diced small\\n\\n3 cloves garlic, minced\\n\\n2 cups sherry wine\\n\\n1 quart low-sodium chicken stock or chicken broth\\n\\n1 cup heavy cream\\n\\n1 cup pure maple syrup\\n\\nCider vinegar, to taste\\n\\nPure maple sugar, for garnish\\n\\nOil, as needed\\n\\nSalt and pepper, to taste\\n\\n### **Directions:**\\n\\nPlace the acorn squash quarters on an oiled sheet tray, drizzle squash with oil and sprinkle with salt and pepper. Cover the entire tray with foil and bake in a 425°F oven for about 30 minutes or until starting to turn tender. Remove foil and bake an additional 30 minutes or until fork tender. Remove from oven. When cool enough to handle, scoop out flesh from squash skin. Disc', '<|endoftext|>, Trans Fat 1g); Cholesterol 55mg; Sodium 240mg; Total Carbohydrate 45g (Dietary Fiber 0g); Protein 2g Exchanges: 1 Starch, 2 Other Carbohydrate, 3 Fat Carbohydrate Choices: 3\\n\\nMini Cupcakes: To make mini cupcakes, place mini paper baking cup in each of 24 mini muffin cups. Make batter as directed in recipe. Fill each cup with about 1 tablespoon plus 1 teaspoon batter or until about two-thirds full. (Cover and refrigerate remaining batter until ready to bake; cool pan 15 minutes before reusing.) Bake 17 to 20 minutes or until golden brown and toothpick inserted in center comes out clean. Cool 5 minutes. Remove cupcakes from pans; place on cooling racks. Cool completely, about 15 minutes. Repeat with remaining batter to make an additional 48 mini cupcakes. Frost as directed. Makes 72 mini cupcakes.\\n\\nTip When mixing the green frosting, don\\'t completely mix in the green food color so that the frosting remains white in some parts. Then, when it\\'s piped onto the cupcakes, it will more accurately resemble the rind of a watermelon.\\n\\n## Sunnyside-Up Bacon Cupcakes\\n\\nPrep Time: 50 Minutes • Start to Finish: 1 Hour 50 Minutes • Makes 24 cupcakes\\n\\n  * Cupcakes\\n  * 2��� cups Gold Medal all-purpose flour\\n  * 2½ teaspoons baking powder\\n  * ½ teaspoon salt\\n  * ½ teaspoon ground cinnamon\\n  * 1 cup butter or margarine, softened\\n  * 1 cup granulated sugar\\n  * 3 eggs\\n  * 2 tablespoons maple-flavored syrup\\n  * 1 teaspoon vanilla\\n  * 1 cup milk\\n  * �� cup crumbled crisply cooked maple-flavored bacon (9 slices)\\n  * Frosting\\n  * 6 cups powdered sugar\\n  * ��� cup butter or margarine, softened\\n  * 1 tablespoon vanilla\\n  * 3 to 4 tablespoons milk\\n  * Decorations\\n  * 24 butterscotch candies, unwrapped\\n  * Black decorator sugar, if desired\\n\\n1 Heat oven to 350°F. Place paper baking cup in each of 24 regular-size muffin cups.\\n\\n2 In medium bowl, mix flour, baking powder, salt and cinnamon; set aside. In large bowl, beat 1 cup butter with electric mixer on medium speed 30 seconds. Gradually add granulated sugar, about ¼ cup at a time, beating well after each addition. Beat 2 minutes longer. Add eggs, one at a time, beating well after each addition. Beat in syrup and 1 teaspoon vanilla. On low speed, alternately add flour mixture, about one-third at a time, and milk, about half at a time, beating just until blended.\\n\\n3 Fold in bacon. Divide batter evenly among muffin cups, filling each about two-thirds full.\\n\\n4 Bake 20 to 25 minutes or until golden brown and toothpick inserted in center comes out clean. Cool 5 minutes. Remove cupcakes from pans; place on cooling racks. Cool completely, about 30 minutes.\\n\\n5 In large bowl, beat powdered sugar and ��� cup butter with spoon or electric mixer on low speed. Stir in 1 tablespoon vanilla and 3 tablespoons milk. Gradually beat in just enough remaining milk to make frosting smooth and spreadable.\\n\\n6 Frost cupcakes to look like the white of a sunnyside-up egg. For \"yolk,\" press 1 butterscotch candy in center of each cupcake. Sprinkle with black decorator sugar for \"pepper.\"\\n\\n1 Cupcake: Calories 370; Total Fat 15g (Saturated Fat 9g, Trans Fat 0.5g); Cholesterol 65mg; Sodium 300mg; Total Carbohydrate 55g (Dietary Fiber 0g); Protein 3g Exchanges: 1 Starch, 2½ Other Carbohydrate, 3 Fat Carbohydrate Choices: 3½\\n\\nTip Short on time? Use 1 container (1 lb) Betty Crocker Rich & Creamy vanilla frosting instead of the vanilla buttercream frosting.\\n\\n## Cupcake Sliders\\n\\nPrep Time: 1 Hour 40 Minutes • Start to Finish: 3 Hours 20 Minutes • Makes 64 cupcake sliders\\n\\n  * Cupcakes\\n  * 2��� cups Gold Medal all-purpose flour\\n  * 2½ teaspoons baking powder\\n  * ½ teaspoon salt\\n  * 1 cup butter or margarine, softened\\n  * 1¼ cups sugar\\n  * 3 eggs\\n  * 1 teaspoon vanilla\\n  * ��� cup milk\\n  * Brownies\\n  * 1 box (1 lb 2.3 oz) Betty Crocker fudge', \"<|endoftext|> The olefin polymerization activity in these catalyst systems, however, has been less than adequate.\\nAlso, Japanese Unexamined Patent Publication No. 7-224106 teaches that a high activity catalyst system can be obtained by using an interlayer cation modified clay prepared by reacting clay with an organic cation, for the purpose of actively utilizing the surface negative charge of the clay minerals as a promoting catalyst; however, in terms of ash content or process applicability when considering actual production, it has been desirable to develop catalyst systems with even higher activity and better polymerization behavior, which can be used at high temperature and in solution polymerization processes wherein the residence time of catalysts is longer. It has also been desired for the interlayer cation-modified clay in such catalysts to have better storage stability.<|endoftext|>You'll Turn Your Back on Beef After Making These Beet Burgers\\n\\nI Can't Believe It's Not Beef!\\n\\nGet Spoon University delivered to you\\n\\nYou tryna be tricky? That email doesn't look right.\\n\\nBy adding your email you agree to get updates about Spoon University Healthier\\n\\nIf Leonardo DiCaprio taught us anything in Before the Flood, it's that beef burgers require a substantial amount of water. Want to try a more sustainable option? These beet burgers may look intimidating, but they are delicious and a much healthier, and more environmentally friendly substitute for beef.\\n\\nBeet Burgers\\n\\nPrep Time:20 mins\\n\\nCook Time:13 mins\\n\\nTotal Time:33 mins\\n\\nServings:4\\n\\nMedium\\n\\nIngredients\\n\\n1 tablespoon ground flax seed\\n\\n3 tablespoon water\\n\\n1/2 cup diced red onion\\n\\n1/2 cup walnuts\\n\\n1 cup roasted beet about 1 medium\\n\\n1 cup cooked and cooled brown rice\\n\\n1/2 cup brown rice flour\\n\\n1/2 cup chopped fresh cilantro\\n\\n2 tablespoon mustard\\n\\n1 teaspoon cumin\\n\\n1 teaspoon paprika\\n\\n1/2 teaspoon salt\\n\\n1/2 teaspoon black pepper\\n\\nToppings\\n\\nAvocado\\n\\nTomato\\n\\nArugula\\n\\nAlexis Clark\\n\\nStep 1\\n\\nCombine flax and water in a small bowl, set aside.\\n\\nGIF by Alexis Clark\\n\\nStep 2\\n\\nChop onions.\\n\\nGIF by Alexis Clark\\n\\nStep 3\\n\\nSauté onions on medium heat, until translucent.\\n\\nGIF by Alexis Clark\\n\\nStep 4\\n\\nThrow walnuts into a blender or food processor, and process just a few seconds until they become like a powder. Remove and place in a large bowl.\\n\\nGIF by Alexis Clark\\n\\nStep 5\\n\\nPulse beets in blender, just a few seconds, until it is puréed. Pour into that same bowl.\\n\\nGIF by Alexis Clark\\n\\nStep 6\\n\\nAdd chopped walnuts, puréed beets, onions, brown rice, brown rice flower, parsley, and spices. Stir until all ingredients are well combined. Next, stir the mustard into the flax mixture, and then add that to the beet/brown rice mixture. Mix until combined.\\n\\nGIF by Alexis Clark\\n\\nStep 7\\n\\nUsing your hands, roll a scoop of the mixture into a ball between your hands, then press into a patty, and 2 ½ inches across and 1 cm or so high. Repeat 7 times, to make 8 patties. Use gloves if you have them, to avoid getting beet juice on your hands.\\n\\nHeat a large skillet over medium-low heat. Add oil to pan; swirl to coat. Carefully add 4 patties to pan and cook 2 minutes. Flip and cook other side for 2 minutes. Transfer patties to baking sheet. Repeat procedure with remaining 4 patties. Place baking sheet in oven; bake patties at 400° for 5 minutes.\\n\\nAlexis Clark\\n\\nStep 8\\n\\nPlace bottoms of bun on a flat surface. Top each with arugula, a beet burger, avocado, sprouts, and the top of the bun.<|endoftext|>\\nShow HN: Solitext. Send yourself text message reminders throughout the day - travisjungroth\\nhttps://www.solitext.com/\\n======\\ntravisjungroth\\nLast night I finished a project I’ve been working on in my spare time. It’s a\\nweb app where you can set up a group of messages, and get one of those\\nmessages texted to you at scheduled times. I use it to remind myself of things\\nthat are important but I tend to forget throughout the day.\\n\\nWhile at work, I might get “Writes lots of tests” or “Go for short walks”.\\nEvery night at 11, my phone buzzes with “Get lots of sleep”.\", \"<|endoftext|>\\n¼ cup bagged sun-dried tomatoes (not packed in oil), thinly sliced   \\n1 teaspoon chopped garlic   \\n1 tablespoon light whipped butter or light buttery spread   \\n1 tablespoon reduced-fat Parmesan-style grated topping\\n\\nDIRECTIONS\\n\\nUse a strainer to rinse and drain noodles. Thoroughly pat dry. Roughly cut noodles.\\n\\nBring a skillet sprayed with nonstick spray to medium-high heat. Add chicken and season with Italian seasoning, 1/8 teaspoon salt, and pepper. Cook for about 4 minutes per side, until fully cooked.\\n\\nRemove chicken and set aside. If needed, clean skillet. Remove from heat, re-spray, and return to medium-high heat. Add asparagus and 2 tablespoons water. Cover and cook for 4 minutes. Meanwhile, slice chicken.\\n\\nUncover skillet and add mushrooms, tomatoes, and garlic. Cook and stir until tender, about 4 more minutes.\\n\\nAdd noodles and cook and stir until hot, about 2 minutes. Add butter, remaining 1/8 teaspoon salt, and sliced chicken. Cook and stir until butter has melted and ingredients are well mixed, about 1 minute.\\n\\nStir in Parm-style topping and serve!\\n\\nMAKES 2 SERVINGS\\n\\n Pasta swappin' with SPAGHETTI SQUASH is a no-brainer! It's a fantastic and delicious pasta alternative that's 100 percent natural and SO low in calories...\\n\\nSPAGHETTI SWAP & MEATBALLS\\n\\n You'll Need: large baking pan, baking sheet, nonstick spray, 2 large bowls, strainer, medium pot   \\nPrep: 20 minutes  \\nCook: 1 hour and 10 minutes\\n\\n1/2 of recipe (2 cups squash with about �� cup sauce and 3 meatballs):   \\n327 calories, 6g fat, 775mg sodium, 45g carbs, 9g fiber, 19g sugars, 26g protein\\n\\nINGREDIENTS\\n\\nSpaghetti\\n\\n1 spaghetti squash (about 41/2 pounds)\\n\\nMeatballs\\n\\n6 ounces raw extra-lean ground beef   \\n2 tablespoons fat-free liquid egg substitute   \\n1 teaspoon dried parsley   \\n1/2 teaspoon chopped garlic   \\n1/8 teaspoon each salt and black pepper\\n\\nSauce\\n\\n1/2 cup finely diced onion   \\n1/2 cup finely diced carrot   \\n1 teaspoon chopped garlic   \\n11/2 cups canned crushed tomatoes   \\n¼ cup chopped fresh basil   \\n2 tablespoons tomato paste   \\n1 teaspoon Italian seasoning   \\n¼ teaspoon red pepper flakes, or more to taste   \\n¼ teaspoon ground cumin   \\n4 teaspoons reduced-fat Parmesan-style grated topping\\n\\nDIRECTIONS\\n\\nPreheat oven to 400 degrees.\\n\\nMicrowave squash for 3 to 4 minutes, until soft enough to cut. Halve lengthwise; scoop out and discard seeds. Fill a large baking pan with 1/2 inch water and place squash halves in the pan, cut sides down. Bake until tender, about 40 minutes.\\n\\nSpray a baking sheet with nonstick spray.\\n\\nThoroughly mix meatball ingredients in a large bowl. Evenly form into 6 meatballs and place on the baking sheet, evenly spaced. Bake until just cooked through, about 10 minutes.\\n\\nUse a fork to scrape out squash strands. Place in a strainer to drain excess moisture. Blot dry, if needed. Transfer to another large bowl and cover to keep warm.\\n\\nBring a medium pot sprayed with nonstick spray to medium-high heat. Cook and stir onion and carrot until slightly softened, 6 to 8 minutes. Add garlic and cook until fragrant, 1 to 2 minutes. Add all remaining sauce ingredients except Parm-style topping; stir to combine. Add meatballs and bring sauce to a low boil. Reduce heat to low. Gently stirring occasionally, simmer until veggies have softened and meatballs are hot, about 8 minutes.\\n\\nAdd sauce to spaghetti strands and stir to coat. Serve topped with meatballs and Parm-style topping!\\n\\nMAKES 2 SERVINGS\\n\\nHG ALTERNATIVE!\\n\\nThis recipe can also be made with 11/2 cups of jarred low-fat marinara sauce... But our sauce is reeeeallly good!\\n\\nCHEESY-PEASY SPAGHETTI SQUASH\\n\\n You'll Need: large baking pan, blender or food processor (optional), strainer, large bowl, microwave-safe bowl, small microwave-safe dish   \\nPrep: 10 minutes   \\nCook: 50 minutes\\n\\n¼th of recipe (about 11/2 cups): 171 calories, 3.5g fat, 429mg sodium, 25.5g carbs, 5g fiber, 10g\", \"<|endoftext|> oil in large nonstick skillet over medium-high heat until hot. Add 1/2 of beef; stir-fry 2 to 3 minutes or until outside surface of beef is no longer pink. Remove. Repeat with remaining beef. Season with salt and pepper.\\n\\nToss greens with 1/2 cup dressing in large bowl; place on platter. Top with beef and croutons. Serve with remaining dressing.<|endoftext|>The present invention relates to packaging products into containers. In particular, the invention relates to an operative unit for advancing containers along a conveying line and for transferring the containers from the conveying line to a weighing station and vice-versa.\\nThe proposed invention concerns also packaging of pharmaceutical products, in particular within a sterile environment, so that the articles introduced into containers are not contaminated\\nGenerally, considering sterile working environments, problems have been encountered in avoiding, as much as possible, the presence of sources of pollution.\\nIn particular, it is required that machines working in sterile environments, during normal operation, have no elements which move along prismatic coupling. For this purpose, the power means are generally contained in a hermetic structure, called xe2x80x9cgray areaxe2x80x9d, separated from the sterile environment.\\nIn specific case of machines for packaging liquid or powder pharmaceuticals into containers, such as bottles and the like, transferring the containers from and to a weighing station is a particularly critical operation.\\nActually the transfer operation of the containers to be weighed to the weighing means, which requires moving elements, must not constitute a source of electrostatic pollution, so that the precision of the measurements performed by the weighing means is not compromised.\\nTherefore, the object of the present invention is to propose a operative unit, in particular for stepwise working machines for packaging products into containers, which allows to feed containers along a conveying line and to transfer the containers from the conveying line to a weighing station, situated therealong, and vice-versa, so that the weighing is in no way affected by possible electrostatic loads generated by the elements of the unit which move the containers.\\nAnother object of the present invention is to propose a operative unit which operates effectively no matter of the containers size.\\nA further object of the present invention is to propose a operative unit which does not constitute a source of pollution for the surrounding environment.\\nStill another object of the present invention is to propose a operative unit, which, beside the previous objects, maintains unchanged the orientation of the containers and moves them in a constant way.\\nYet another object of the present invention is to propose a operative unit which achieves the above objects and allows to transfer the containers to a weighing station, so as to allow weighing of all the containers, as well as a statistic weighing.\\nThe above mentioned objects are obtained in accordance with the content of the claims, by means of an operative unit for advancing containers along a conveying line and for transferring the containers from the conveying line to at least one weighing station and vice-versa, the operative unit including:\\nan endless conveyor passing through the weighing station;\\na sliding track on which said containers move, said sliding track being parallel to said conveyor;\\nsaid unit being characterized in that it further includes:\\nmoving means for moving said containers on said sliding track, said moving means being removably fastened to said conveyor;\\na platform forming a portion of said sliding track situated in the region of said weighing station\\ndriving means connected to said platform for temporarily disengaging said containers supported by the platform from said moving means and for placing said containers in engagement with weighing means of said weighing station.<|endoftext|>Q:\\n\\nLockless queue implementation ends up having a loop under stress\\n\\nI have lockless queues written in C in form of a linked list that contains requests from several threads posted to and handled in a single thread. After a few hours of stress I end up having the last request's next pointer pointing to itself, which creates an endless loop and locks up the handling thread.\\nThe application runs (and fails) on both Linux and Windows. I'm debugging on Windows, where my COMPARE_EXCHANGE_PTR maps to InterlockedCompareExchangePointer. \\nThis is the code that pushes a request to the head of the list, and is called from several threads:\\nvoid push_request(struct request * volatile * root, struct request * request)\\n{\\n    assert(request);\\n\\n    do {\\n        request->next = *root;\\n    } while(COMPARE_EXCHANGE_PTR(root, request, request->next) != request->next);\\n}\\n\\nThis is the code that gets a request from the end of the list, and is only called by a single thread that is handling them:\\nstruct request * pop_request(struct request * volatile * root)\\n{\\n    struct request * volatile * p;\\n    struct request * request;\\n\\n    do {\\n        p = root;\\n        while(*p\", \"<|endoftext|>\\n1 c. chicken broth\\n\\nIn a bowl, whisk together soy sauce, juice and seasonings. Add chicken and turn to coat; let marinate 5 minutes. Heat 2 tablespoons oil in a large skillet over high heat. Stirring constantly, cook chicken mixture in oil for 5 minutes, or until cooked through. Remove chicken mixture and keep warm. Add remaining oil to skillet; stir in vegetables and broth. Cook over high heat for 5 minutes, stirring constantly. Add chicken mixture to skillet and cook an additional 5 minutes, stirring constantly.\\n\\nSkillet stir-fries are a versatile way to prepare a healthy veggie-packed meal. Try using sliced pork, beef or chicken, or make it a meatless meal. Add any fresh vegetables you have on hand...tomato, green pepper and celery are tasty!\\n\\n# Rosemary Pork Loin\\n\\nMakes 4 servings at  \\n160 calories each\\n\\n1 T. butter\\n\\n1-lb. pork tenderloin, sliced one-inch thick\\n\\n1 c. sliced mushrooms\\n\\n2 T. onion, finely chopped\\n\\n1-1/2 T. fresh rosemary, chopped\\n\\n1 clove garlic, minced\\n\\nsalt and pepper to taste\\n\\n1 T. apple juice\\n\\nGarnish: fresh rosemary sprigs\\n\\nMelt butter in a heavy skillet over medium-high heat. Brown pork slices quickly, about one minute on each side. Remove pork to a serving plate, reserving drippings in skillet. Add remaining ingredients except juice and garnish to skillet. Cook and stir over low heat for several minutes, or until mushrooms and onion are almost tender. Stir in juice. Return pork to skillet; spoon mushroom mixture over pork. Cover; simmer 3 to 4 more minutes. Garnish with sprigs of rosemary.\\n\\nIf you have formed the habit of checking on every new diet that comes along, you will find that, mercifully, they all blur together, leaving you with only one definite piece of information: French-fried potatoes are out.\\n\\n– Jean Kerr\\n\\n# Pasta Primavera Even Kids Like\\n\\nMakes 6 servings at  \\n290 calories each\\n\\n12-oz. pkg. whole-wheat linguine pasta, uncooked\\n\\n1 T. olive oil\\n\\n3 cloves garlic, minced\\n\\n1 red pepper, cut into strips\\n\\n1/2 lb. asparagus, trimmed and sliced\\n\\n1 c. cherry tomatoes, halved\\n\\n1 c. sliced mushrooms\\n\\n1 T. all-purpose flour\\n\\n1 c. chicken broth\\n\\n1/2 c. low-fat milk\\n\\n1/2 t. salt\\n\\n1/2 t. pepper\\n\\n2 carrots, peeled and cut into ribbons with peeler\\n\\nGarnish: 2 T. grated Parmesan cheese\\n\\nCook pasta according to package directions. Drain, reserving 1/2 cup of pasta water. Meanwhile, heat oil in a large skillet over medium-high heat. Add garlic; cook and stir for one minute. Add red pepper; cook and stir until it begins to soften, about 3 minutes. Add asparagus, tomatoes and mushrooms; cook until tender. Stir in flour; cook and stir for one minute. Add broth, milk, salt and pepper; bring to a boil. Reduce heat. Cook until liquid thickens slightly, about 5 minutes. Stir in carrots. Toss pasta with sauce and vegetables, adding reserved water as necessary to moisten. Sprinkle with cheese.\\n\\nFor hearty salads in a snap, keep unopened cans of diced tomatoes, black olives, white beans and artichoke hearts in the fridge. They'll be chilled and ready to toss with fresh greens at a moment's notice.\\n\\n# Spicy Pork Noodle Bowls\\n\\nMakes 4 servings at  \\n300 calories each\\n\\n8-oz. pkg. whole-wheat linguine pasta, uncooked and divided\\n\\n2 T. canola oil, divided\\n\\n1 lb. boneless pork shoulder, sliced into strips\\n\\n1 onion, thinly sliced\\n\\n1/2 lb. broccoli flowerets\\n\\n2 T. Worcestershire sauce\\n\\n1 T. soy sauce\\n\\n2 t. cornstarch\\n\\n1/2 t. curry powder\\n\\n1 tomato, chopped\\n\\nCook half of pasta according to package directions; set aside. Reserve remaining pasta for another recipe. Meanwhile, heat one tablespoon oil in a large skillet over high heat. Add pork; cook and stir until golden, about 7 minutes. Remove pork; set aside. Heat remaining oil in skillet; add onion and broccoli. Cook and stir until tender, about 5 minutes. Mix together sauces, cornstarch and curry powder in a cup; stir into skillet. Cook and stir until slightly thickened. Return pork to pan;\", \"<|endoftext|> bottom of a hot frying pan, pour in a large ladleful of batter, and fry quickly. Serve with pure maple syrup.\\n\\n## **Cornmeal Pancakes with Honey Fruit Sauce**\\n\\nCourtesy of the National Honey Board\\n\\n(www.honey.com)  \\nMakes 8 pancakes\\n\\n### **Ingredients:**  \\n **Fruit Sauce**\\n\\n1 cup orange juice\\n\\n1 apple, pared, cored and diced\\n\\n1 pear, pared, cored and diced\\n\\n��� cup honey\\n\\n1 teaspoon grated orange peel\\n\\n1 tablespoon cornstarch\\n\\n¼ cup water\\n\\n### **Cornmeal Pancakes**\\n\\n½ cup flour\\n\\n½ cup cornmeal\\n\\n3 teaspoons baking powder\\n\\n½ teaspoon salt\\n\\n1 cup milk\\n\\n1 egg\\n\\n3 tablespoons honey\\n\\n3 tablespoons butter or margarine, melted\\n\\n### **Directions:**  \\n **Fruit Sauce**\\n\\nCombine orange juice, apple, pear, honey and orange peel in medium saucepan. Bring mixture to boil, reduce heat, and simmer 8 to 10 minutes or until fruits are tender. Dissolve cornstarch in water. Stir into hot mixture; cook and stir until mixture comes to a boil; simmer 1 minute. Makes 2��� cups.\\n\\n### **Cornmeal Pancakes**\\n\\nCombine flour, cornmeal, baking powder, and salt in medium bowl; mix well and set aside. Combine milk, egg, honey, and melted butter in small bowl; mix well. Pour liquid mixture into flour mixture; stir only until moistened (batter will be lumpy). Pour about ¼ cup batter for each pancake in hot skillet or on griddle over medium-low heat; cook until bubbles form on surface and edges become dry. Turn and cook 2 minutes longer or until golden. Serve with Fruit Sauce.\\n\\n## **Pumpkin Pancakes**\\n\\n### **Ingredients:**\\n\\n1 cup cooked pumpkin\\n\\n2 eggs\\n\\n1½ pints milk\\n\\n2 teaspoons baking powder\\n\\nSalt\\n\\nFlour (enough to make a good batter, about 2 cups)\\n\\n### **Directions:**\\n\\nMix together the cooked and cooled pumpkin, eggs, milk, baking powder, a little salt, and flour to make good batter. Beat until smooth and cook on the griddle.\\n\\n## **Pumpkin Waffles with Blueberries and Pomegranate Coulis**\\n\\nMakes 8 waffles\\n\\n### **Ingredients:**\\n\\n2 cups flour, sifted\\n\\n4 tablespoons turbinado sugar (or light brown sugar)\\n\\n1 tablespoon baking powder\\n\\n1 teaspoon baking soda\\n\\n¼ teaspoon salt\\n\\n1 tablespoon pumpkin pie spice\\n\\n2 extra-large eggs, separated\\n\\n1¾ cups buttermilk\\n\\n½ cup pumpkin puree\\n\\n2 tablespoons melted butter\\n\\n1¼ cup blueberry juice (no sugar added)\\n\\n1¼ cup pomegranate juice (no sugar added)\\n\\n### **Directions:**\\n\\nPlace the juices and 1 tablespoon sugar in a pan. Bring to simmer over medium heat and reduce to 1 cup. Remove from heat and set aside to cool. Mix the flour, remaining 3 tablespoons sugar, baking powder, baking soda, salt, and pumpkin pie spice together in a large bowl. In another bowl, whisk the egg yolks and buttermilk until frothy. Blend in the pumpkin puree and melted butter. Pour the mixture over the dry ingredients and mix until incorporated. Whisk the egg whites until set and gently fold into the prepared mixture. Preheat a waffle iron, according to manufacturer's recommendations. Quickly spread batter to the rim and cook until the steaming stops and until the waffle is golden brown. Repeat with the remaining batter. Serve each waffle with 2 tablespoons of coulis.\\n\\n**Note:** While making a large portion of waffles, you can keep them warm in a 270°F preheated oven.\\n\\nCoulis is typically a thick fruit sauce, but in this recipe we are using a no-sugar-added juice as a healthier alternative.\\n\\n## **Spiced Egg Nog French Toast**\\n\\nCourtesy of Garelick Farms\\n\\n(www.garelickfarms.com)\\n\\n### **Ingredients:**\\n\\n2 cups egg nog\\n\\n½ teaspoon cinnamon\\n\\n½ teaspoon nutmeg\\n\\n¼ teaspoon cloves\\n\\n2 eggs\\n\\n12 slices firm (day-old) white bread\\n\\n4 tablespoons butter or margarine\\n\\n### **Directions:**\\n\\nCombine egg nog, spices, and eggs; beat with a wire whisk for 1-2 minutes. Melt butter or margarine in a non-stick skillet over medium heat. Dip slice of\", \"<|endoftext|>, sugar, and edible gums. It makes Royal Icing dry quickly with a smooth, hard finish. Look for it in the baking aisle of large supermarkets or in the cake decorating department of hobby and crafts stores.\\n\\nPaste Food Coloring: Paste food coloring creates bright colors and doesn't thin icing like liquid coloring does. Use a clean toothpick to add coloring to icing until it's the desired color.\\n\\nChapter Contents | Metric Information | Emergency Substitutions | Index\\nHoliday Favorites\\n\\n## Goat Cheese, Artichoke, and Smoked Ham Strata\\n\\nPrep: 30 minutes Stand: 20 minutes Chill: 2 to 24 hourS Bake: 60 minutes at 350°F Makes: 8 servings\\n\\n  * 2 cups whole milk\\n  * 2 tablespoons olive oil\\n  * 1 1-pound loaf sourdough bread, cut into 1-inch cubes (about 12 cups)\\n  * 5 eggs\\n  * 1½ cups half-and-half or light cream\\n  * 1 tablespoon minced garlic\\n  * 1½ teaspoons herbes de Provence\\n  * �� teaspoon black pepper\\n  * ½ teaspoon freshly ground nutmeg\\n  * ½ teaspoon dried sage, crushed\\n  * ½ teaspoon dried thyme, crushed\\n  * 8 ounces goat cheese (chèvre), crumbled\\n  * 12 ounces smoked ham, chopped\\n  * 3 6-ounce jars marinated artichoke hearts, drained and halved lengthwise\\n  * 6 ounces Parmesan cheese, finely shredded (1½ cups)\\n  * 4 ounces Fontina cheese, shredded (1 cup)\\n\\n1 Grease a 3-quart rectangular baking dish; set aside. In a very large bowl combine milk and olive oil. Add bread cubes, stirring to coat. Let stand for 10 minutes.\\n\\n2 In a large bowl whisk together eggs, half-and-half, garlic, herbes de Provence, pepper, nutmeg, sage, and thyme. Whisk in goat cheese until combined; set aside.\\n\\n3 Spread half of the bread cube mixture in the bottom of the prepared dish. Top with half each of the ham, artichoke hearts, and cheeses. Repeat layers. Drizzle egg mixture over all. Cover and chill for 2 to 24 hours.\\n\\n4 Preheat oven to 350°F. Uncover and bake about 60 minutes or until set in the center and edges are browned. Let stand for 10 minutes before serving.\\n\\nPer Serving: 674 cal., 37 g fat (19 g sat. fat), 203 mg chol., 2,013 mg sodium, 45 g carb., 2 g fiber, 40 g pro. EXCHANGES: ½ Vegetable, 3 Starch, 4 High-Fat Meat\\n\\nChapter Contents | Metric Information | Emergency Substitutions | Index\\nBEST-LOVED\\n\\n## Fruit Coffee Cake\\n\\nPrep: 30 minutes Bake: 45 minutes at 350°F Makes: 9 servings\\n\\n  * 2 cups blueberries and/or red raspberries; sliced, peeled apricots or peaches; or chopped, peeled apples\\n  * ��� cup water\\n  * ��� cup sugar\\n  * 2 tablespoons cornstarch\\n  * ¼ teaspoon ground cinnamon\\n  * 1¾ cups all-purpose flour\\n  * �� cup sugar\\n  * �� teaspoon baking powder\\n  * ¼ teaspoon baking soda\\n  * 5 tablespoons butter, cut up\\n  * 1 egg, lightly beaten\\n  * �� cup buttermilk or sour milk (see tip)\\n  * 1 teaspoon vanilla\\n  * ��� cup all-purpose flour\\n  * ��� cup sugar\\n  * 3 tablespoons butter, cut up\\n\\n1 For filling, in a medium saucepan combine fruit and water. Bring to boiling; reduce heat. Simmer (do not simmer if using all raspberries), covered, about 5 minutes or until fruit is tender. In a small bowl stir together the ��� cup sugar, the cornstarch, and cinnamon; stir into fruit. Cook and stir over medium heat until thickened and bubbly; set filling aside.\\n\\n2 Preheat oven to 350°F. In a large bowl combine the 1¾ cups flour, the �� cup sugar, baking powder, and baking soda. Using a pastry blender, cut in the 5 tablespoons butter until mixture resembles coarse crumbs. Make a well in the center of the flour mixture; set aside.\\n\\n3 In a medium bowl combine egg, buttermilk, and vanilla. Add egg mixture all at once to flour mixture. Stir just until moistened (batter should be lumpy). Remove 1 cup batter; set aside. Spread the remaining batter into an ungreased 9×9×2-inch or 8×8×2-inch baking pan\", \"<|endoftext|>AD\\n\\nA half-hour is all you need to mix up this colorful crowd-pleaser. With plenty of shrimp, artichoke hearts, olives, peppers and a host of herbs, it's a tasty change of pace from the usual pasta salad. The dish completes any buffet.\\n\\n—GINGER JOHNSON POTTSTOWN, PA\\n\\n* * *\\n\\n* * *\\n\\nSTART TO FINISH: 30 MIN. • MAKES: 16 SERVINGS\\n\\n* * *\\n\\n1 package (16 ounces) orzo pasta\\n\\n3/4 pound cooked medium shrimp, peeled, deveined and cut into thirds\\n\\n1 cup finely chopped green pepper\\n\\n1 cup finely chopped sweet red pepper\\n\\n1 can (14 ounces) water-packed artichoke hearts, rinsed, drained and quartered\\n\\n3/4 cup finely chopped red onion\\n\\n1/2 cup minced fresh parsley\\n\\n1/3 cup chopped fresh dill\\n\\n1/3 cup chopped pimiento-stuffed olives\\n\\n1/2 cup white wine vinegar\\n\\n3 garlic cloves, minced\\n\\n1 teaspoon salt\\n\\n1/2 teaspoon dried basil\\n\\n1/2 teaspoon dried oregano\\n\\n1/2 teaspoon pepper\\n\\n1/4 cup olive oil\\n\\n1. Cook pasta according to package directions; drain and rinse in cold water. Place in a large bowl; add the shrimp, peppers, artichokes, onion, parsley, dill and olives.\\n\\n2. In a small bowl, combine the vinegar, garlic, salt, basil, oregano and pepper. Slowly whisk in oil. Pour over the pasta mixture and toss to coat. Refrigerate until serving.\\n\\n### GARDEN BOUNTY PANZANELLA SALAD\\n\\nWhen my sister gave me fresh tomatoes and basil, I made this traditional bread salad. The longer it sits, the more the bread soaks up the seasonings.\\n\\n—JANNINE FISK MALDEN, MA\\n\\n* * *\\n\\n* * *\\n\\nPREP: 15 MIN. • COOK: 20 MIN. • MAKES: 16 SERVINGS\\n\\n* * *\\n\\n1/4 cup olive oil\\n\\n12 ounces French or ciabatta bread, cut into 1-inch cubes (about 12 cups)\\n\\n4 large tomatoes, coarsely chopped\\n\\n1 English cucumber, coarsely chopped\\n\\n1 medium green pepper, cut into 1-inch pieces\\n\\n1 medium sweet yellow pepper, cut into 1-inch pieces\\n\\n1 small red onion, halved and thinly sliced\\n\\n1/2 cup coarsely chopped fresh basil\\n\\n1/4 cup grated Parmesan cheese\\n\\n3/4 teaspoon kosher salt\\n\\n1/4 teaspoon coarsely ground pepper\\n\\n1/2 cup Italian salad dressing\\n\\n1. In a large skillet, heat 2 tablespoons oil over medium heat. Add half of the bread cubes; cook and stir until toasted, about 8 minutes. Remove from the pan. Repeat with the remaining oil and bread cubes.\\n\\n2. Combine the bread cubes, tomatoes, cucumber, peppers, onion, basil, cheese, salt and pepper. Toss with dressing.\\n\\n### BALSAMIC THREE-BEAN SALAD\\n\\nHere's my little girl's favorite salad. She eats it just about as fast as I can make it. Make it ahead so the flavors have plenty of time to get to know one another.\\n\\n—STACEY FEATHER JAY, OK\\n\\n* * *\\n\\n* * *\\n\\nPREP: 25 MIN. + CHILLING • MAKES: 12 SERVINGS\\n\\n* * *\\n\\n2 pounds fresh green beans, trimmed and cut into 2-inch pieces\\n\\n1/2 cup balsamic vinaigrette\\n\\n1/4 cup sugar\\n\\n1 garlic clove, minced\\n\\n3/4 teaspoon salt\\n\\n2 cans (16 ounces each) kidney beans, rinsed and drained\\n\\n2 cans (15 ounces each) cannellini beans, rinsed and drained\\n\\n4 fresh basil leaves, torn\\n\\n1. Fill a Dutch oven three-fourths full with water; bring to a boil. Add green beans; cook, uncovered, for 3-6 minutes or until crisp-tender. Drain and immediately drop into ice water. Drain and pat dry.\\n\\n2. In a large bowl, whisk vinaigrette, sugar, garlic and salt until sugar is dissolved. Add canned beans and green beans; toss to coat. Refrigerate, covered, at least 4 hours. Stir in basil just before serving.\\n\\n### FAST FIX\\n\\n### CREAMY GRAPE SALAD\\n\\nEveryone raves when I bring this refreshing, creamy salad to potlucks. It\", '<|endoftext|> strips bacon, diced\\n\\n1 small stalk celery, finely diced\\n\\n1 small onion, peeled and diced\\n\\n1 cup cornbread stuffing mix\\n\\n2 tablespoons pecans, toasted and chopped\\n\\n1 large egg, beaten\\n\\nPinch nutmeg, freshly grated\\n\\nSalt and freshly ground black pepper, to taste\\n\\n4 1-inch-thick pork chops\\n\\n1 tablespoon olive or vegetable oil\\n\\n1 tablespoon butter\\n\\n1⁄2 cup chicken broth\\n\\n1. Put the dried cranberries and apple juice in a microwave-safe bowl. Cover and microwave on high for 1 minute to soften the cranberries. Set aside.\\n\\n2. Fry the bacon in the pressure cooker over medium-high heat until it begins to render its fat. Add the celery; sauté for 2 minutes. Add the onion; sauté for 3 minutes. Pour the contents of the pressure cooker into a bowl.\\n\\n3. Use a paper towel to blot up some of the excess bacon fat. Mix in the cranberries and apple juice, cornbread stuffing mix, pecans, egg, nutmeg, salt, and pepper. The cornbread stuffing mixture should be moist, but not wet. If some of the stuffing mix is still dry, add apple juice or water a teaspoon at a time until moistened.\\n\\n4. Trim and discard any excess fat from the pork chops. Cut a pocket into each one, slicing from the outside edge to the bone. Fill each pork chop with a fourth of the stuffing mixture. Press to close. Season each side of the pork chops with salt and pepper.\\n\\n5. Bring the oil and butter to temperature over medium heat in the pressure cooker. Add the pork chops and brown well on both sides. Pour the broth into the bottom of the pan.\\n\\n6. Lock the lid into place and bring to high pressure; maintain pressure for 15 minutes. Remove the pressure cooker from the heat, quick-release the pressure, and remove the lid. Serve.\\n\\n# PORK ROAST WITH ROOT BEER GRAVY\\n\\n_Only use regular (not diet) root beer in this recipe. Soft drinks made with artificial sweeteners cannot withstand the heat of the pressure cooker_.\\n\\nINGREDIENTS\\n\\n**Serves 6**\\n\\n1 10-ounce can golden cream of mushroom soup\\n\\n1 12-ounce can root beer\\n\\n1 1-ounce envelope dry onion soup mix\\n\\n1 3-pound pork roast\\n\\n1. Add the soup, root beer, and onion soup mix to the pressure cooker. Stir to mix. Add the pork roast.\\n\\n2. Lock the lid in place. Bring to low pressure; maintain pressure for 45 minutes. Remove from the heat and allow pressure to release naturally.\\n\\n3. Transfer the roast to a serving platter; let rest for 5 minutes before slicing.\\n\\n4. Skim any fat from the gravy in the pressure cooker. Stir to mix and then transfer to a gravy boat or pour over the sliced meat.\\n\\n# PORK SAUSAGE WITH BELL PEPPERS AND ONIONS\\n\\n_Use a combination of spicy Italian sausage, bratwurst, or mild sausage links, if desired_.\\n\\nINGREDIENTS\\n\\n**Serves 6**\\n\\n6 pork sausages\\n\\n1⁄2 tablespoon vegetable oil\\n\\n1 large green bell pepper, seeded and sliced\\n\\n1 large red bell pepper, seeded and sliced\\n\\n1 large yellow bell pepper, seeded and sliced\\n\\n1 large onion, sliced\\n\\n2 cloves garlic, minced\\n\\n1⁄3 cup chicken stock\\n\\n1. Poke each sausage several times with a fork.\\n\\n2. Heat oil in an uncovered pressure cooker over medium heat. Add half the sausages to the pressure cooker and brown for about 5 minutes. Remove to a plate and brown the remaining sausages. Discard all but one tablespoon of rendered fat in the pressure cooker. Add the peppers and onion and sauté for about 3 minutes or until they begin to soften. Add garlic and return the sausages to the pressure cooker, pushing them down into the peppers and onions. Pour in the stock. Close and lock the lid.\\n\\n2. Turn the heat up to high and when the cooker reaches pressure, lower the heat to the minimum needed to maintain pressure. Cook for 5–8 minutes at high pressure.\\n\\n3. When time is up, open the pressure cooker by releasing pressure.\\n\\n4. Serve with a slotted spoon.\\n\\n# PORK STEAK IN FRUIT SAUCE\\n\\n_Serve this dish over some mashed potatoes and alongside some steam-in-the-bag green beans_.\\n\\nINGREDIENTS\\n\\n**Serves 6**\\n\\n8 pitted prunes\\n\\n', '<|endoftext|> oil. Heat on medium-high heat. Add mushrooms and fry for 2 to 3 minutes until the mushrooms are cooked. Add the onion mixture, turmeric, salt, and cayenne pepper. Stir and cook for 2 to 3 minutes, coating the mushrooms. Add remaining 1½ cups water, bring to a boil, cover with lid, and simmer for 5 minutes.\\n\\n4. Transfer to a serving dish and serve hot.\\n\\nNUTRITION INFORMATION PER SERVING:\\n\\n**Calories: 175; Total Fat: 15 g (Saturated**   \\n**Fat: 2 g); Carbohydrate: 8 g; Protein: 5 g;**   \\n**Fiber: 2 g; Sodium: 443 mg**\\n\\n**GF**\\n\\n#  **Curried Mushrooms and Peas**\\n\\n**_Khumb-Matar_**\\n\\nPREP: **10 minutes**   \\nCOOK : **10 minutes**   \\nMAKES : **4 servings**   \\nSERVING SIZE : ½ cup\\n\\n**M** **ushrooms and peas are a winning combination. Serve this easy-to-prepare dish alongside any meal. If desired, add slivered almonds for a nutty texture.**\\n\\n**2 tablespoons canola or vegetable oil**   \\n**½ teaspoon brown mustard seeds**   \\n**1 cup red onion, thinly sliced**   \\n**1 teaspoon ginger, peeled and finely grated**   \\n**2 cups (12 ounces) mushrooms, sliced**   \\n**1 cup frozen peas, thawed**   \\n**½ teaspoon turmeric**   \\n**½ teaspoon salt**   \\n**1 teaspoon ground coriander**   \\n**¼ teaspoon cayenne pepper, or to taste**   \\n**½ cup water**   \\n**¼ teaspoon garam masala (page 24)**\\n\\n**2 tablespoons slivered almonds, lightly roasted, optional**\\n\\n1. Heat oil in a nonstick fry pan on medium-high heat. Add mustard seeds, cover with lid, and cook for a few seconds, until the seeds stop popping. Add onion and fry 1 to 2 minutes until transparent. Add ginger and stir.\\n\\n2. Add mushrooms and stir-fry for 2 to 3 minutes. Add peas, turmeric, salt, coriander, and cayenne pepper. Add the water, bring to a boil, cover with lid, and cook for 5 to 7 minutes, or until the peas are cooked.\\n\\n3. Sprinkle garam masala over mushroom mixture. Transfer to a serving dish and garnish with almonds, if desired.\\n\\nNUTRITION INFORMATION PER SERVING:\\n\\n**Calories: 107; Total Fat: 7 g (Saturated Fat: 0.5 g); Carbohydrate: 8 g; Protein: 3 g; Fiber: 2 g;**\\n\\n**Sodium: 330 mg**\\n\\n**GF, LF**\\n\\n#  **Plantain Stew**\\n\\n**_Kele Ka Kootu_**\\n\\nPREP : **10 minutes**   \\nCOOK : **40 minutes**   \\nMAKES: **12 servings**   \\nSERVING SIZE : **½ cup**\\n\\n**I** **n southern India, banana trees and coconut trees are everywhere. Plantains (raw bananas) are used to make a variety of dishes. Before bananas ripen, they have a unique taste and texture, and are cooked as a vegetable. Once ripe, they become sweet and soft and are eaten as a fruit.**\\n\\n_Kootu_ is a vegetable dish with a stew-like consistency and a coconut base. You can use fresh coconut, but for convenience I use the frozen grated coconut available in Indian grocery stores.\\n\\n**1 pound plantains**   \\n**1 tablespoon canola or vegetable oil**   \\n**½ teaspoon brown mustard seeds**   \\n**��� teaspoon asafetida powder**   \\n**8-10 curry leaves**   \\n**1 cup carrot, cut into 1-inch strips**   \\n**1 cup green beans, cut into 1-inch pieces**   \\n**½ teaspoon turmeric**   \\n**1½ teaspoons salt**   \\n**2 cups water**\\n\\n**KOOTU MASALA**\\n\\n**1 teaspoon canola or vegetable oil**   \\n**2-3 dried red chiles, or to taste**   \\n**2 teaspoons cumin seeds**   \\n**1 tablespoon coriander seeds**   \\n**½ teaspoon black peppercorns**   \\n**1 cup fresh or frozen grated coconut**   \\n**1 cup warm water**   \\n**1 teaspoon brown sugar**   \\n**2 teaspoons tamarind paste or 2 tablespoons**   \\n**lemon juice**\\n\\n1. Peel plantains with a peeler, removing just the thin green outer layer. In a medium', \"<|endoftext|> drain it well.\\n\\n3. Heat 2 tablespoons oil in a large skillet, add onions, and sauté over medium heat until golden brown, about 20 minutes. Remove 1⁄2 cup sautéed onions for mixing with potatoes. To onions in skillet add asparagus, sprinkle with salt and pepper, and toss over low heat 2 minutes.\\n\\n4. Preheat oven to 350°F. Peel potatoes while still fairly hot. Mash them with a potato masher or food mill, not in a food processor. Add remaining oil and stir until blended. Add reserved 1⁄2 cup of fried onion. If using the smaller amount of fat, add 2 tablespoons of the reserved asparagus cooking liquid. Add salt and pepper; mixture should be seasoned generously. Add egg and mix well.\\n\\n5. In a greased 2-quart casserole dish, layer half of potato mixture (about 21⁄2 cups), top with all of asparagus mixture, then with remaining potatoes. Smooth top.\\n\\n6. Sprinkle casserole lightly with paprika and bake uncovered about 50 minutes or until top is firm and lightly golden at edges. Let stand about 10 minutes before serving. Use a spoon to serve.\\n\\n# Cauliflower Kugel with Sautéed Onions\\n\\nMakes 4 to 6 servings\\n\\nThis is a favorite of my mother's and mine for Shabbat. It's great with chicken prepared any way, whether poached, braised, or roasted. Since Shabbat meals can be rich and fattening (although always delicious), we sometimes use egg substitute in this dish for a more healthful twist.\\n\\n1 large head cauliflower (2 pounds), divided into medium florets, stalks peeled and sliced\\n\\n2 to 3 tablespoons vegetable oil\\n\\n1 medium onion, chopped\\n\\n2 large eggs, or 1 large egg and equivalent of 1 egg in egg substitute\\n\\n1 tablespoon matzo meal\\n\\nSalt and freshly ground pepper, to taste\\n\\nAbout 1⁄2 teaspoon paprika (optional)\\n\\n1. Place rack in the upper third of the oven and preheat oven to 375°F. Boil cauliflower in a large saucepan of boiling salted water 8 to 10 minutes or until stalk slices are very tender. Drain well and cool. Mash with potato masher, leaving a few small chunks. Transfer to a bowl.\\n\\n2. Heat 1 to 2 tablespoons oil in medium nonstick skillet, add onion and sauté over medium-low heat 7 minutes or until onion begins to turn golden.\\n\\n3. Add eggs and matzo meal to cauliflower mixture. Season well with salt and pepper. Lightly stir in onion mixture and any oil in pan.\\n\\n4. Grease a shallow 8-inch square baking dish. Add cauliflower mixture. Sprinkle 1 tablespoon oil over top. Sprinkle with paprika, if using. Bake 40 minutes or until set and very lightly browned on top. Remove from oven and run a knife around edges. Let stand about 5 minutes before serving. Serve hot, cut carefully into squares. Use a spoon to remove portions.\\n\\n# Savory Zucchini Kugel\\n\\nMakes 6 to 8 servings\\n\\nThis kugel makes a good accompaniment for a Shabbat roast chicken or for baked or grilled fish. For a meatless meal you can serve it as a light entree and top each serving with a dollop of Garlic-Yogurt Sauce.\\n\\n2 pounds medium zucchini\\n\\n4 tablespoons olive oil\\n\\n1 large onion, chopped\\n\\n4 large cloves garlic, minced\\n\\n1⁄4 cup chopped fresh Italian parsley\\n\\n1⁄4 cup dry bread crumbs\\n\\nSalt and freshly ground pepper, to taste\\n\\nCayenne pepper, to taste\\n\\n4 large eggs, beaten\\n\\n1. Preheat oven to 375°F. Grate zucchini on large holes of grater. Put in a strainer and squeeze firmly to remove excess liquid. Transfer zucchini to a bowl.\\n\\n2. Heat 2 tablespoons oil in a medium skillet. Add onion and sauté over medium heat, stirring often, about 7 minutes or until onion begins to turn golden. Remove from heat and stir in garlic. Cool slightly, then add mixture to zucchini. Let cool.\\n\\n3. Add parsley and bread crumbs to zucchini mixture. Season well with salt, pepper, and cayenne so mixture will not be bland. Add eggs and mix well.\\n\\n4. Heat 1 tablespoon oil in a shallow 8-inch square baking dish in oven for about 3 minutes. Add zucchini mixture to hot dish. Sprinkle with remaining tablespoon oil. Bake about 50 minutes or until set. Remove from oven and run a knife around edges. Let stand about 5 minutes before serving.\", \"<|endoftext|>9781250029225_toc01.html#toctitle314)\\n\\n You'll Need: 8-inch by 8-inch baking pan, nonstick spray, grill pan, 2 large bowls   \\nPrep: 20 minutes  \\nCook: 1 hour\\n\\n¼th of lasagna:   \\n265 calories, 4.5g fat, 926mg sodium, 32.5g carbs, 11g fiber, 13.5g sugars, 24g protein\\n\\nINGREDIENTS\\n\\n3 medium zucchini, ends removed, sliced lengthwise   \\n1 large portabella mushroom, sliced into strips   \\n1 large eggplant, ends removed, sliced lengthwise   \\n2 cups canned crushed tomatoes   \\n¼ teaspoon garlic powder   \\n¼ teaspoon onion powder   \\n¼ teaspoon Italian seasoning   \\nOne 16-ounce package frozen chopped spinach, thawed and squeezed dry   \\n1 cup fat-free ricotta cheese   \\n2 tablespoons fat-free liquid egg substitute   \\n1 tablespoon chopped fresh basil   \\n¼ teaspoon salt   \\nDash ground nutmeg   \\n1 cup frozen ground-beef-style soy crumbles, thawed   \\n1/2 cup shredded part-skim mozzarella cheese   \\n1 tablespoon reduced-fat Parmesan-style grated topping\\n\\nDIRECTIONS\\n\\nPreheat oven to 425 degrees. Spray an 8-inch by 8-inch baking pan with nonstick spray.\\n\\nLay paper towels next to the stove, to drain veggies during the next step.\\n\\nBring a grill pan sprayed with nonstick spray to medium-high heat. Working in batches as needed, lay zucchini, mushroom, and eggplant slices in the pan and cook until softened, about 2 minutes per side. Transfer cooked veggies to the paper towels.\\n\\nIn a large bowl, mix crushed tomatoes, garlic powder, onion powder, and Italian seasoning.\\n\\nIn another large bowl, mix spinach, ricotta cheese, egg substitute, basil, salt, and nutmeg.\\n\\nEvenly layer ingredients in the baking pan: half of the seasoned tomatoes, half of the sliced veggies, half of the spinach mixture, and all of the soy crumbles.\\n\\nEvenly layer remaining veggies, in the opposite direction of the first layer, followed by remaining spinach mixture and remaining seasoned tomatoes. Top with mozzarella cheese and Parm-style topping.\\n\\nBake until cheese has lightly browned, about 30 minutes. Mmmmm!\\n\\nMAKES 4 SERVINGS\\n\\nPUMPKIN LASAGNA\\n\\nYou'll Need: 8-inch by 8-inch baking pan, nonstick spray, large skillet, medium bowl   \\nPrep: 15 minutes  \\nCook: 45 minutes\\n\\n¼th of lasagna:   \\n343 calories, 9.5g fat, 803mg sodium, 32.5g carbs, 5.5g fiber, 8g sugars, 27.5g protein\\n\\nINGREDIENTS\\n\\nFour ¼-inch-thick eggplant slices (cut lengthwise from a long eggplant), patted dry   \\n10 ounces raw extra-lean ground beef   \\n1 tablespoon dried minced onion   \\n1/2 teaspoon each salt and black pepper   \\n1/2 cup fat-free sour cream   \\n4 wedges The Laughing Cow Light Creamy Swiss cheese   \\nOne 15-ounce can pure pumpkin   \\n¼ cup light plain soymilk   \\n1 teaspoon chopped garlic   \\n1/2 teaspoon ground nutmeg   \\n4 sheets oven-ready lasagna noodles   \\n1/2 cup shredded part-skim mozzarella cheese   \\n¼ cup reduced-fat Parmesan-style grated topping\\n\\nDIRECTIONS\\n\\nPreheat oven to 425 degrees. Spray an 8-inch by 8-inch baking pan with nonstick spray.\\n\\nBring a large skillet sprayed with nonstick spray to medium-high heat. Cook eggplant until softened, about 2 minutes per side. (Work in batches as needed.)\\n\\nRemove eggplant and blot away excess moisture. Remove skillet from heat, re-spray, and return to medium-high heat. Add beef and sprinkle with minced onion and ¼ teaspoon each salt and pepper. Cook and crumble for 5 minutes, or until fully cooked.\\n\\nAdd sour cream and cheese wedges, breaking wedges into pieces. Cook and stir until cheese has melted, mixed with sour cream, and coated beef, 2 to 3 minutes. Remove from heat.\\n\\nIn a medium bowl, mix pumpkin, soymilk, garlic, nutmeg, and remaining ¼ teaspoon each salt and black pepper.\\n\\nSpread 1/3rd of the pumpkin mixture (about 2/3 cup) into the baking pan. Evenly layer with half of each ingredient: lasagna sheets, beef mixture, eggplant slices, remaining pumpkin mixture\", \"<|endoftext|> to taste\\n\\n1. Prepare sauce. Meanwhile, rinse Brussels sprouts well. Trim brown bases of sprouts; do not remove so much of base that leaves come off.\\n\\n2. Put carrots in a large saucepan and add water to cover. Bring to a boil, cover, and cook over medium-low heat 8 to 10 minutes or until carrots are just tender. Remove carrots with a slotted spoon, reserving liquid. Pour 1⁄4 cup carrot cooking liquid into a bowl and set aside.\\n\\n3. Add more water to carrot cooking liquid in saucepan so there is enough to cover Brussels sprouts. Bring to a boil and add a pinch of salt and the sprouts. Cook uncovered over high heat 8 to 10 minutes or until they are just tender; check by removing one with slotted spoon and piercing its base with a small sharp knife. Drain gently in a colander or large strainer, rinse with cold running water until cool and drain well.\\n\\n4. Heat oil in saucepan. Add onion and sauté over medium-low heat, stirring often, 7 minutes or until tender but not brown. Add cream sauce and bring to a simmer, stirring.\\n\\n5. Add cooked vegetables to sauce. Heat uncovered 2 to 3 minutes, gently stirring them occasionally; add 1 to 2 tablespoons of carrot cooking liquid if sauce becomes too thick. Remove from heat. Stir in grated lemon rind and parsley. Adjust seasoning. Serve hot.\\n\\n# Turnips with Spinach and Garlic\\n\\nMakes 4 servings\\n\\nWe tend to overlook turnips, perhaps thinking they are too strong. They become mild and delicately sweet when cooked, however. This Egyptian dish is a tasty accompaniment for baked or roasted chicken, for Barbecue-Sauced Brisket with Onions or a Bulgur Wheat Pilaf. It's easy to prepare and reheats beautifully.\\n\\n2 pounds turnips, peeled\\n\\n31⁄2 tablespoons olive oil or vegetable oil\\n\\n6 large cloves garlic, chopped\\n\\n1 cup finely chopped spinach leaves\\n\\n1 large onion, chopped\\n\\n3⁄4 cup chicken, beef, or vegetable stock\\n\\nSalt and freshly ground pepper, to taste\\n\\n1. Cut turnips into 3⁄4-inch dice. Heat 2 tablespoons oil in a stew pan. Add turnips and sauté over medium heat 3 minutes. Remove them with slotted spoon. Add 1⁄2 tablespoon oil to pan and heat it briefly. Add garlic and sauté 15 seconds. Add spinach and sauté about 30 seconds or until dry. Remove from skillet.\\n\\n2. Add remaining tablespoon oil to pan. Add onion and sauté over medium heat about 5 minutes or until beginning to brown. Add broth and bring to boil. Add turnips, cover, and simmer over low heat 15 minutes. Add spinach mixture and cook 5 minutes or until turnips are tender, adding a few tablespoons stock or water if pan becomes dry. Adjust seasoning. Serve hot.\\n\\nSAUCES\\n\\n# Grilled Red Pepper Sauce\\n\\nMakes about 6 servings\\n\\nGrilling bell peppers was a traditional technique in the Sephardic kitchen long before it became trendy on restaurant menus. When they are in season, it's a good idea to grill plenty of peppers. You can freeze them and use them to make this easy sauce. If you don't have home-grilled peppers, you can use roasted sweet red peppers from a jar. This sauce has almost as many uses as tomato sauce. Use it to top broiled, baked, or fried eggplant to accompany vegetable kugels, or to liven up plain steamed vegetables.\\n\\n3 large grilled red bell peppers, peeled\\n\\n2 tablespoons extra-virgin olive oil (optional)\\n\\n3 large cloves garlic, chopped\\n\\nAbout 1 cup vegetable stock\\n\\n11⁄2 teaspoons fresh thyme or 1⁄2 teaspoon dried\\n\\nSalt and freshly ground pepper, to taste\\n\\n1 to 2 teaspoons strained fresh lemon juice, or to taste\\n\\n1. Prepare peppers. Then, cut peeled peppers in half and discard seeds and ribs. Cut peppers in pieces. Puree in a food processor with oil, if using, until smooth, or leave it a little chunky if you prefer.\\n\\n2. Combine garlic and 1⁄2 cup stock in a medium saucepan and bring to a boil. Boil 2 minutes. Add thyme. Stir in pepper puree. Add enough of remaining stock to thin sauce to the consistency you like. Season with salt and pepper. Add lemon juice. Serve hot or cold.\\n\\n# Mediterranean Green Sauce for Vegetables\\n\\nMakes 4 servings\\n\\nSephardic Jews in Italy and southern France serve this pareve cousin of pesto with cooked meats and chicken. It's also good with hard boiled eggs. But my favorite way to serve it is with cooked vegetables of all\"]\n","861 ['<|endoftext|> is fairly contaminated with mercury. Mercury mass balance (in- and outflows of mercury to the Bay of Puck ecosystem) calculated by Boszke ([@CR12]) showed that between 1.1 and 3.8\\xa0kg\\xa0year^−1^ of Hg enters annually from the atmosphere, whereas the load of Hg carried to the bay with the river water was about seven times lower (0.13--0.44\\xa0kg\\xa0year^−1^). The budget has proven that the main source of mercury in the system is the atmosphere. The mercury fluxes via groundwater discharge appear to be insignificant compared to both the abovementioned sources. The mercury flux obtained in this study is much lower in comparison with other groundwater-impacted areas, e.g., Etretat and Yport along the Pays de Caux Estuary, France (Laurier et al. [@CR23]); Waquoit Bay in Massachusetts, USA (Bone et al. [@CR11]); Elkhorn Slough in Central California, USA (Black et al. [@CR9]); Stinson Beach in Northern California, USA (Black et al. [@CR9]); Hwasun and Bangdu Bays on Jeju Islands, Korea (Lee et al. [@CR24]); and Malibu Lagoon, CA, USA (Ganguli et al. [@CR17]). In Malibu Lagoon, the average mercury flux via SGD was equal to 82.24\\xa0ng\\xa0day^−1^\\xa0m^−2^, which was higher than that in Hwasun Bay (74.22\\xa0ng\\xa0day^−1^\\xa0m^−2^) and lower than in Bangdu Bay (158.47\\xa0ng\\xa0day^−1^\\xa0m^−2^), Stinson Beach (501.48\\u2009±\\u2009320.95\\xa0ng\\xa0day^−1^\\xa0m^−2^), Elkhorn Slough (601.77\\u2009±\\u2009401.18\\xa0ng\\xa0day^−1^\\xa0m^−2^), Waquit Beach (94.28\\u2009±\\u2009381.12\\xa0ng\\xa0day^−1^\\xa0m^−2^), Etretat (461.36\\u2009±\\u2009762.24\\xa0ng\\xa0day^−1^\\xa0m^−2^), and Yport (126.37\\u2009±\\u2009421.24\\xa0ng\\xa0day^−1^\\xa0m^−2^). This may be caused by both a lower concentration of mercury and lower SGD correlated with lower discharges of suspended rates in the study area in comparison with the other studies or a combination of these factors.\\n\\nThus, there is a need to note and discuss reasons for low concentrations of dissolved mercury in groundwater, much lower than concentrations of dissolved mercury in the wet atmospheric deposition. The water that is recharging the aquifer should have been delivering large mercury loads to the groundwater that are not manifested as increased concentrations of dissolved mercury in groundwater. Most of the load must be retained in the unsaturated and saturated zone of the surface soil since the groundwater mercury concentrations are low.\\n\\nAssuming SGD rate to the Bay of Puck at 0.03\\xa0km^3^ (Korzeniewski [@CR18]), the dissolved mercury concentration in rainwater at 8.6\\xa0ng\\xa0dm^−3^ (Boszke [@CR12]), and the average dissolved mercury concentration in the seeping groundwater at 0.6\\xa0ng\\xa0dm^−3^ (this study, Table\\xa0[1](#Tab1){ref-type=\"table\"}), the load of mercury that is retained in the surface soil in rainwater percolating to the saturated zone is equal to 0.03\\xa0km^3^\\u2009×\\u200910^9^\\xa0m^3^/km^3^\\u2009×\\u2009(8.6−0.6)ng\\xa0dm^−3^\\u2009×\\u200910^3^\\xa0dm^3^/m^3^\\u2009×\\u200910^−6^\\xa0mg/ng\\u2009=\\u20090.24\\u2009×\\u200910^3^\\xa0g. The catchment area of the Bay of Puck is close to 100\\xa0km^2^ (Korzeniewski [@CR18]; Kozerski [@CR20]); surface soil is composed of peat and other organic-rich deposits and clays (Lidzbarski [@CR25]; Kozerski [@CR20]) that are characterized by high affinity and complexing capacity towards mercury (Boszke et al. [@CR13]). Thus, it can be safely assumed that yearly retention of mercury, equal to 2.4\\xa0g mercury\\xa0km^−2^, is well within a reasonably assumed retention capacity of the catchment. This conclusion agrees well with a very low concentration of mercury in the land-based wells used for extraction of drinking water (this study, Table\\xa0[1](#Tab1){ref-type=\"table\"}) (Kozerski [@CR20]).\\n\\nSummary and Conclusions {#Sec13}\\n=======================\\n\\nTotal dissolved mercury', '<|endoftext|> they are infected. Large-scale hepatitis screenings in the community might be beneficial to find infected patients who require further hepatitis surveillance. However, to detect serum HBsAg and anti-HCV nationwide is expensive and inefficient. To recognize those highly possibly-infected patients for further hepatitis screening could be more cost-saving. For example, checking the anti-HCV titer in those subjects with APRI ≥1.1 should be reasonable and effective in the community, because the prevalence of HCV infection in this group is possibly close to 50%.\\n\\nAPRI and FIB-4, two non-invasive indexes, have been frequently used to predict liver fibrosis with an acceptable diagnostic performance in different liver diseases including HBV infection and HCV infection \\\\[[@pone.0222196.ref013],[@pone.0222196.ref014]\\\\]. Additionally, the two indexes are based on inexpensive laboratory tests and appear well reproducible and easily performed. In this large community-based cohort, 38% of the general population had an APRI level more than 0.3. With the elevation of different cut-offs of APRI from 0.3 to 1.3, the prevalence of chronic virus hepatitis significantly increased from 30% to over 70%. Using FIB-4, 27% of the general population had a FIB-4 level more than 1.75. Likewise, with the elevation of different cut-offs of FIB-4 from 1.75 to 4.25, the prevalence of chronic virus hepatitis increased from 30% to over 50%. We found that the increase of hepatitis prevalence was mainly related to the increase of HCV patients. The prevalence of HBV infection was around 12% to 16% in using APRI and around 10% to 13% in using FIB-4, which was close to the national prevalence of HBV infection in Taiwan. HBsAg spontaneous clearance in chronic HBV infection has been observed in several studies, especially in aged cohorts \\\\[[@pone.0222196.ref023]--[@pone.0222196.ref025]\\\\]. The annual incidence of HBsAg clearance of these studies was around 1.1%. Our previous study reported that old age was one of the associated factors for HBsAg disappearance, which is a well-known and reasonable factor \\\\[[@pone.0222196.ref025]\\\\]. Unlike chronic HBV infection, chronic HCV infection in aged cohorts is usually reactive \\\\[[@pone.0222196.ref026]\\\\]. Our other small-sized community study showed that nearly two-thirds of aged anti-HCV-positive subjects were HCV RNA-positive, and more than half of them had elevated ALT levels \\\\[[@pone.0222196.ref022]\\\\]. The difference in performance of APRI and FIB-4 in identifying underlying HCV and HBV might be the risk of underlying advanced fibrosis with HCV (chronic hepatitis) relative to HBV (broad phenotype that includes many carriers with indolent disease).\\n\\nBased on a large-scale database of more than 180,000 subjects, the distribution of chronic virus hepatitis by different cut-offs of APRI and FIB-4 was a good reference to reflect HBV or HCV hepatitis status in other endemic areas. Additionally, in most community-based health screenings, the tests to calculate ARPI and FIB-4 are common and inexpensive. Moreover, those subjects with higher APRI of FIB-4 might have severer liver fibrosis but remain unaware of their liver disease. Hence, we could economically discover those highly possible hepatitis-infected patients requiring further HBsAg and anti-HCV examinations based on different cut-offs of APRI or FIB-4.\\n\\nIn 31 townships of Tainan county, we also found that APRI ≥ 0.7 or FIB-4 ≥ 3.5 was not related to the prevalence of HBV infection at township level. But APRI ≥ 0.7 or FIB-4 ≥ 3.5 was highly correlated with the prevalence of HCV infection (r = 0.95, p\\\\<0.001 in APRI; r = 0.809, p\\\\<0.001 in FIB-4). This finding was compared with a previous report that the accuracy of APRI and FIB-4 is lower in HBV-infected patients than in HCV-infected patients \\\\[[@pone.0222196.ref014]\\\\]. Elevated APRI and FIB-4 reflect more advanced liver fibrosis. Because no data of ultrasound or pathology related to real liver fibrosis could be offered in such a large community study, we tried to use the decade incidence of HCC to represent the severe complication of advanced liver fibrosis in Tainan. This study compared the prevalence of APRI ≥ 0.7 or FIB-4 ≥ 3.5 with the decade incidence of HCC in townships of Tainan from 1999 to 2008. The correlation was still significantly high (r = 0.894, p\\\\<0.001 in APRI; r = 0.804, p\\\\<0.001 in FIB-4). From the township level, this finding hinted that HCC', \"<|endoftext|> tests found high amounts of lead in blood samples taken from children in the majority African-American city.\\n\\nImage copyright AP Image caption Although the water has improved, many Flint residents still use bottled water for drinking\\n\\nThe contamination can be traced back to April 2014, when Mr Earley, the emergency manager at the time, decided to change the city's water source from Lake Huron to the Flint River to save money.\\n\\nThe acidic water of Flint River corroded the city's pipes, which leached lead into the water.\\n\\nFlint switched back to the previous water system in October 2015 and federal regulators say that filter tap water is now safe to drink, but still recommend bottled water for young children and pregnant women.\\n\\nSo far 13 people have been charged in connection to the investigation into Flint's water supply and an outbreak of Legionnaires' disease.\\n\\nThe state brought charges against two state regulators and a city employee for official misconduct in April.\\n\\nIn July, prosecutors charged six health and environmental workers for concealing data that showed elevated levels of lead in children's blood was tied to the water supply.\\n\\nMr Early and Mr Ambrose face up to 46 years in prison while Mr Croft and Mr Johnson could face up to 40 years behind bars.\\n\\nMr Schuette's announcement comes a day after a report found nearly 3,000 areas with recently recorded lead poisoning rates twice as much as those in Flint during the height of the city's water crisis.\\n\\nMore than 1,100 of those communities had a rate of elevated blood tests at least four times higher, according to the Reuters report.<|endoftext|>[timestamp]\\ndefault-storage-engine=innodb\\n\\n[trx_id]\\ndefault-storage-engine=innodb\\n<|endoftext|>Q:\\n\\nGroup multiple rows together\\n\\nI have a table which contains the following and I am looking to group them to get the below output. Is it possible?\\nInput\\nID    Value1    Value2    Value3\\n5     Y         NULL      NULL\\n5     NULL      1         NULL\\n5     NULL      NULL      USA\\n5     NULL      NULL      NULL\\n6     N         NULL      NULL\\n6     NULL      2         NULL\\n6     NULL     NULL       GBP\\n6     NULL     NULL       NULL\\n\\nOutput\\nID     Value1     Value2     Value3\\n5      Y          1          USA\\n6      N          2          GBP\\n\\nA:\\n\\nGroup by the id and use max() to get the non-null value per each group\\nselect id, \\n       max(value1) as value1, \\n       max(value2) as value2, \\n       max(value3) as value3\\nfrom your_table\\ngroup by id\\n\\nBTW you should think about changing you table design. It is not normalized.\\n\\n<|endoftext|>About Me\\n\\nI'm just me - a solitary wanderer who trekked across much of the world and recently retired to a small farm in the Ozarks.\\nMy checkered past includes time spent as an Army officer, high school teacher and principal, real estate broker, child protection worker and administrator, and social worker with the U.S. military.\\nOver the years I have resided in a variety of places including Missouri, Virginia, Okinawa, Kansas, Kentucky, and Arizona. I have also traveled to Germany, Mexico, Canada, Russia, Sweden, Great Britain, Belize, Guatemala, Taiwan, Guam, South Korea, Vietnam, and numerous islands in the Caribbean - including Cuba.\\nI have ridden in a Russian ambulance, hitch-hiked across Moscow late at night, fought an ostrich, celebrated New Year's at a street party in Hanoi, and bicycled across the Caribbean. My travels have taken me to Ground Zero in Hiroshima, the Bolshoi Ballet, China Beach, and the White House kitchen.\\nThe nine things in life that I am most proud of are my children: Nick, Molly, and Tim, and my grandchildren: Boone, Sebastian, Judah, Olive, Willow, and Sullivan.\\nLife has been very good to me indeed!\\n\\nSaturday, February 25, 2012\\n\\nThe Sand Hag Smells a Stunt\\n\\nby Pa RockCitizen Journalist\\n\\nJan Brewer, the governor of Arizona, has been invited to testify before the United States Senate Subcommittee on Immigration, Refugees, and Border Security. The invitation came from the subcommittee chairman, Senator Charles Schumer of New York, and specifically asked the governor to speak on the defining piece of legislation of her administration - the infamous SB 1070. Specifically Schumer wants to hear the governor's views on the necessity of maintaining the draconian SB 1070 in the face of substantial gains that the federal government has made in securing the nation's southwestern border.\\n\\nThe governor has been\", '<|endoftext|>: 0.38--2.70). However, a positive association was reported between drinking water arsenic exposure and stillbirth after adjusting for potential confounders. The risk of stillbirth was 6.07 times higher (95% CI: 1.54--24.00) among women exposed to arsenic concentration ≥200 ppb compared to women exposed to arsenic concentration \\\\<50 ppb. Arsenic exposure during pregnancy for each of the participants was determined through a comprehensive strategy utilizing interview and laboratory data \\\\[[@B28-ijerph-14-00556]\\\\].\\n\\nAnother small cross-sectional study in villages of West Bengal, India, found statistically higher (*p* \\\\< 0.05) rates of spontaneous abortion and stillbirth among women exposed to arsenic in drinking water between 10 and 600 ppb compared to women exposed to \\\\<10 ppb. This study included 240 female participants from four villages with high arsenic concentrations in drinking water and 60 female participants from a village with a low arsenic exposure \\\\[[@B29-ijerph-14-00556]\\\\].\\n\\nA hospital-based case-control study did not observe a statistically significant association between low--moderate level exposure to drinking water arsenic (0.00 to 175.10 μg/L, with median 0.40 μg/L and 90th percentile 9.40 μg/L) and spontaneous pregnancy loss of \\\\<20 weeks completed gestation \\\\[[@B30-ijerph-14-00556]\\\\]. On the other hand, a small study investigated pregnancy outcomes of four women suffering from chronic arsenic toxicity in Patna District of India, where arsenic concentration was more than 10 mg/L in 61% hand tube-wells and above 50 mg/L in 44%. Among a total of 19 pregnancies, the outcomes are as follows: four stillbirth, five spontaneous abortion, four neonatal death and two preterm birth \\\\[[@B31-ijerph-14-00556]\\\\].\\n\\nCollectively, the majority of studies support the positive association between arsenic exposure and spontaneous abortion. The studies range in sample size from 18 to hundreds of thousands. The most frequently employed study design was cross-sectional. Aside from three studies, all had adjusted associations for confounders. Of the three studies that reported no association, two measured the association between low--moderate arsenic exposure (0--2 ppb; 0.4 ppb) and spontaneous abortion. The remainder of the studies reported on associations based on higher arsenic exposure (\\\\>10 ppb). In addition, of the 12 studies assessing the association of arsenic exposure with stillbirth, nine supported a positive association.\\n\\n4.2. Neonatal and Post Neonatal Death {#sec4dot2-ijerph-14-00556}\\n-------------------------------------\\n\\nOnly a few studies have been conducted exploring the association between chronic arsenic exposure and neonatal death (mortality within the first 28 days following delivery) and post neonatal death (mortality between 28 days and 364 days following delivery). The literature includes one cross sectional study and one ecologic study. Although one study suggests a positive and statistically significant association between arsenic exposure and neonatal/post-neonatal death, this area requires further evidence to support this association. Milton et al., in their study on chronic arsenic exposure and adverse pregnancy outcomes in Bangladesh, observed a positive but statistically insignificant association (OR: 1.80, 95% CI: 0.90--3.60) between chronic arsenic exposure and neonatal death \\\\[[@B24-ijerph-14-00556]\\\\]. Whereas a study from Chile compared the trends in infant mortality between 1950 and 1996 among two geographical areas: Antofagasta, with a well-documented history of arsenic exposure from naturally contaminated water and Valparaiso, with low arsenic contamination. The study reported an increased and statistically significant association between arsenic exposure and late fetal mortality (RR: 1.70, 95% CI: 1.50--1.90), neonatal mortality (RR: 1.53, 95% CI: 1.40--1.70) and post neonatal mortality (RR: 1.26, 95% CI: 1.20--1.30) rates for Antofagasta compared to Valparaiso, particularly during the time period when Antofagasta had high arsenic concentration in drinking water \\\\[[@B19-ijerph-14-00556]\\\\].\\n\\n4.3. Low Birth Weight and Preterm Birth {#sec4dot3-ijerph-14-00556}\\n---------------------------------------\\n\\nThere have been several studies reporting on the association between arsenic exposure and low birth weight (birth weight of less than 2500 g) and preterm birth (live delivery prior to 37 weeks completed gestation). The literature includes 11 studies assessing the association of arsenic exposure with low birth weight, including: seven prospective cohort studies, one retrospective cohort study, one cross sectional study and one longitudinal study. Of these, six support an increasing risk with greater exposure while four did not observe a statistically significant association. In addition, the literature includes three studies assessing the association of arsenic exposure with preterm birth, including: one cross-sectional study and two retrospective cohort studies. Of', \"<|endoftext|> in the bivariate analysis, and a relative risk of 22.6 (95% CI \\\\[4.8, 106.4\\\\]) in the multivariate analysis. Bivariate and multivariate analyses suggested a monotonic increase in risk with exposure. For occupational exposures, the relative risk of lung cancer for subjects exposed to arsenic from smelting alone was 12.3 (95% CI \\\\[1.7, 91.9\\\\]), while the risk from mining alone was 8.8 (95% CI \\\\[2.4, 32.2\\\\]), and the risk of smelting and mining combined was 22.0 (95% CI \\\\[4.9, 98.2\\\\]). Taylor et al. (1989) \\\\[[@R50]\\\\] observed that, among arsenic-exposed individuals, those who developed lung cancer were exposed to arsenic for a longer duration, but at a lower average intensity. This finding indicates that the duration of exposure may be more important than intensity in the development of lung cancer. The more than 20-fold increase in lung cancer incidence after arsenic exposure has important implications.\\n\\nArgentina studies {#s1_12}\\n-----------------\\n\\nArsenic exposure from drinking water in Argentina is well-documented. The exposure is often above 100 ppb and up to 2000 ppb, making Argentina a suitable region for arsenic exposure research \\\\[[@R51], [@R52]\\\\]. An ecologic study conducted in Cordoba \\\\[[@R51]\\\\] examined the relationship between drinking arsenic-contaminated water and kidney, lung, skin, bladder, and liver cancers. The authors found increasing trends for kidney and lung cancer mortality with drinking water with higher arsenic. The dose-response relationships in standardized mortality ratios (SMR) for kidney cancer, from high to low arsenic exposure, were 1.57, 1.33, and 0.87 for men, and 1.81, 1.36, and 1.00 for women (*p* \\\\< 0.001 in trend test for both). For lung cancer, the SMR from high to low arsenic exposure were 1.77, 1.54 and 0.92 for men, and 2.16, 1.34, and 1.24 for women (*p* \\\\< 0.001 in trend test for both). These results are similar to those from another study \\\\[[@R52]\\\\] that examined bladder cancer (2.14, 1.28, and 0.80 for men, 1.81, 1.39, and 1.22 for women). However, there was only a small positive trend for liver cancer. Skin cancer mortality was only elevated for women in the high exposure group, while an unexpected increase in mortality was observed in men in the low exposure group. These results add to the evidence that arsenic ingestion increases the risk of lung and kidney cancers. However, the association between arsenic and mortality from liver and skin cancers was not clear \\\\[[@R51]\\\\].\\n\\nAnother study of 26 Cordoba Counties \\\\[[@R52]\\\\] investigated bladder cancer mortality in 1986--1991. The authors grouped counties into high, medium, and low exposure categories. Bladder cancer SMRs were higher in the counties with arsenic exposure. The results demonstrated a significant dose-response relationship between ingested inorganic arsenic and bladder cancer. The corresponding SMRs were 2.14 (95% CI \\\\[1.78, 2.53\\\\]), 1.42 (95% CI \\\\[1.14, 1.74\\\\]), and 0.80 (95% CI \\\\[0.66, 0.96\\\\]) for men, and 1.82 (95% CI \\\\[1.19, 2.64\\\\]), 1.58 (95% CI \\\\[1.01, 2.35\\\\]), and 1.21 (95% CI \\\\[0.85, 1.64\\\\]) for women.\\n\\nJapan studies {#s1_13}\\n-------------\\n\\nResidents of Japan\\\\'s Niigata Prefecture lived in an arsenic-polluted area and used well water containing inorganic arsenic. A Japanese historical cohort study \\\\[[@R53]\\\\] investigated the long-term effect of high exposure to ingested arsenic (≥ 1000 ppb). From 1949 until 1952, 454 residents who used well water containing inorganic arsenic were followed. The exposure period was estimated at about 5 years (1955--1959). The calculated SMR was 15.69 (95% CI \\\\[7.38, 31.02\\\\]) for lung cancer and 31.18 (95% CI \\\\[8.62, 91.75\\\\]) for urinary tract cancer. Although there is a lack of research regarding urinary tract cancer and arsenic exposure, this study supports the possibility of an increased risk of urinary tract cancer, with an estimation of a 30-fold increase in cancer incidence after high arsenic exposure. A recent study suggested a link between mortality from pancreatic cancer and childhood exposure to arsenic-contaminated milk powder \\\\[[@R54]\\\\].\\n\\nTaiwan and Bangladesh studies {#s1_14}\\n-----------------------------\\n\\nConvincing evidence has also been provided by five important Taiwanese studies \\\\[[@R55]--[@R59]\\\\]. Chen and Ahsan (2004\", \"<|endoftext|> been criticised on social media and elsewhere for failing to endorse gay marriage, a stance at odds with NSW Labor policy.<|endoftext|>Q:\\n\\nDjnago ORM выбор из двух таблиц\\n\\nЗдравствуйте! У меня есть две модели связанные между собой через ForeignKey\\nclass User(models.Model):\\n    object = models.ForeignKey(Object, on_delete=models.CASCADE)\\n\\nclass Object(models.Model):\\n    count = FloatField()\\n\\nПодскажите, как выбрать всех User для Object у которых count меньше определенного значения? �� пробовал так, но возвращается пустой queryset:\\ndef get_queryset(self):\\n    ...\\n    return queryset.filter(object_id=object__location__distance_lt=10)\\n\\nA:\\n\\nЕсли правильно понял, то так\\n.filter(object__count__lt=10)\\n\\n<|endoftext|>The overall goals of this proposal are to examine geographical variation in the association between cancer risk and potential environmental exposures, in particular arsenic exposure, and to then determine the homogeneity of the associations as the geographical scale changes. Uses of Geographic Information Systems (GIS) have made it more feasible to link multiple sources of descriptive attribute information for various geographic levels with health outcome data. The use of GIS allows the spatial relationships between the data elements to maintained and analyzed. Arsenic exposure may be a causal agent in the development of bladder, lung, kidney, and skin cancers. Furthermore, arsenic is known to vary across geographical locations. Several geographically delineated data sets exist in the State of Arizona that allow for epidemiological exploration of the relationship between arsenic exposure and cancer occurrence. Geocoded cancer incidence and mortality data are available from the Arizona Cancer Registry for bladder, kidney, and lung cancer. Skin cancer data are available from a completed population-based case control study. Arsenic concentrations are available from a multimedia, multipathway survey conducted in Arizona. The specific aims for this proposed research are 1) to evaluate spatial scales and determine relationships between the scale used by the Atlas of Cancer Mortality and scales potentially more useful within the state and 2) to evaluate the relationships between the various cancers and arsenic exposure for the various geographical scales. This proposal presents a cohesive research team that encompasses faculty and staff from various colleges within the University of Arizona and state health agencies and will utilize archival data collected by various state agencies and completed epidemiological studies of skin cancer and environmental exposures.<|endoftext|>1. Field of the Invention\\nThis invention generally relates to semiconductor manufacturing equipment and, more particularly, to an improved method for rapid thermal processing of a semiconductor wafer.\\n2. Related Art\\nIn the semiconductor manufacturing industry, depending upon the particular process, a semiconductor wafer may be treated at temperatures of from about 100° C. to about 1300° C., under controlled conditions, in rather sophisticated furnaces. Commonly, these furnaces are horizontal or vertical type furnaces, which use various energy sources to heat the wafer, including radiant heaters, arc lamps, and tungsten-halogen lamps. As shown in FIG. 1, a typical horizontal or vertical type furnace requires a time t1 for ramping up to a particular process temperature to process the wafers. The ramp up rate for a typical furnace is usually between 5° C./min to about 15° C./min, which makes time t1 typically on the order of about 1 hour. A time t2 is required for cooling of the wafers, which is generally on the order of about 2 hours. Long processing times are typically unacceptable in advanced semiconductor device manufacturing because of dopant redistribution, excessive costs, excessive exposure to temperature, and high power requirements.\\nIn order to continue to make advancements in the development of semiconductor devices, especially semiconductor devices of decreased dimensions, new processing and manufacturing techniques have been developed. One such processing technique is know as Rapid Thermal Processing (RTP), which reduces the amount of time that a semiconductor device is exposed to high temperatures during processing. The rapid thermal processing technique, typically includes raising the temperature of the wafer and holding it at that temperature for a time long enough to successfully perform a fabrication process, and avoid such problems as unwanted dopant diffusion that would otherwise occur at the high processing temperatures.<|endoftext|>Where to watch\\n\\nForever Young\\n\\nSynopsis\\n\\nTime waits for no man, but true love waits forever.\\n\\nA 1939 test pilot asks his best friend to use him as a guinea pig for a cryogenics experiment. Daniel McCormick wants to be frozen for a year so that he doesn't have to watch his love lying in a coma. The next thing Daniel knows is that he's been awoken in 1992\", '<|endoftext|> Potter star Rupert Grint and Russell Tovey from BBC Three\\'s Being Human as their joint 10/1 favourites to named the next Doctor\", the Beeb notes.\\n\\nIt adds: \"They are also offering odds on Sherlock star Martin Freeman, on Skyfall\\'s Ben Whishaw and on former assistant Billie Piper returning to the series as the Doctor\\'s new incarnation.\"<|endoftext|>docs\\n<|endoftext|>Arsenic exposure from drinking water, dietary intakes of B vitamins and folate, and risk of high blood pressure in Bangladesh: a population-based, cross-sectional study.\\nThe authors performed a cross-sectional analysis to evaluate the association between arsenic exposure from drinking water and blood pressure using baseline data of 10,910 participants in the Health Effects of Arsenic Longitudinal Study in Bangladesh (October 2000-May 2002). A time-weighted well arsenic concentration (TWA) based on current and past use of drinking wells was derived. Odds ratios for high pulse pressure (> or = 55 mmHg) by increasing TWA quintiles (< or = 8, 8.1-40.8, 40.9-91.0, 91.1-176.0, and 176.1-864.0 microg/liter) were 1.00 (referent), 1.39 (95% confidence interval (CI): 1.14, 1.71), 1.21 (95% CI: 0.99, 1.49), 1.19 (95% CI: 0.97, 1.45), and 1.19 (95% CI: 0.97, 1.46). Among participants with a lower than average dietary intake level of B vitamins and folate, the odds ratios for high pulse pressure by increasing TWA quintiles were 1.00 (referent), 1.84 (95% CI: 1.07, 3.16), 1.89 (95% CI: 1.11, 3.20), 1.83 (95% CI: 1.09, 3.07), and 1.89 (95% CI: 1.12, 3.20). The odds ratios for systolic hypertension suggest a similar but weaker association. No apparent associations were observed between TWA and general or diastolic hypertension. These findings indicate that the effect of low-level arsenic exposure on blood pressure is nonlinear and may be more pronounced in persons with lower intake of nutrients related to arsenic metabolism and cardiovascular health. Future research is needed to evaluate the effect of low-level arsenic exposure on specific cardiovascular outcomes.<|endoftext|>In the morning I was super hungry and I wanted to eat before I worked out. I grabbed a box of cereal off the shelf and the milk out of the fridge. I hesitated just a little over the milk jug. The date on the outside said ‘Expires April 20’.\\n\\nThat’s today, I thought, smelling it warily. Which means I should have all day on April 20th, right?\\n\\nI thought the milk smelled okay so I poured it over my cereal and grabbed a spoon. In my state of super-hungry I scarfed down the cereal. Only when I was down to the last little bit in the bowl did I notice that the milk tasted just a little bit off. Not enough to taste really bad, but just slightly wrong.\\n\\nI dumped the rest of the cereal out as though it would negate what I’d already eaten. I took the milk jug out of the fridge and put it in the sink as a reminder to rinse it out and throw it away later.\\n\\nI was feeling less than motivated to work out. I put on workout clothes hoping that would push me to do something active. The closest I came to working out was picking up the house and doing laundry. I took two naps on the couch and later in the afternoon I watched the original Friday the Thirteenth (yes, for the first time, even the movie is as old as I am). I spent the entire movie curled around a pillow with a terrible stomach ache nursing a glass of ginger ale.\\n\\nLater that night I was feeling a little better. My friend Veronica stopped by with some Scottish shortbread cookies she’d made. She used two pounds of butter making them, so of course they were uh-mazing.\\n\\nWhile Veronica stood in my kitchen Hannah spotted the milk jug in the sink. I’d forgotten all about it.\\n\\n“Can I have this?” Hannah asked.\\n\\n“Sure,” I said. “What are you gonna do with it?”\\n\\n“I want to make something.”\\n\\n“You can poke holes in the top of the plastic lid,” Veronica suggested. “Then it becomes a watering can for plants.”\\n\\nHannah was in. She grabbed the scissors and dumped the remainder of the milk out into the sink.\\n\\nThe milk came out in chunks.\\n\\nVeronica looked at it made a face. “Ew.', '<|endoftext|> 97,200 to 228,100) (29,700 deaths among women and 135,900 deaths among men) were caused by alcohol based on using the alcohol RR functions from the meta-analyses used for other countries. These differences in the estimated numbers of deaths stem primarily from differences in the number of deaths estimated to be caused by injuries, ischemic strokes and IHD attributable to alcohol; there was little observed difference in the mortality burdens for pneumonia, hemorrhagic and other non-ischemic strokes, and cirrhosis of the liver attributable to alcohol. See Table\\xa0[4](#Tab4){ref-type=\"table\"} for the number of deaths and DALYs lost by cause attributable to alcohol for men and women using Russia-specific alcohol RR functions and using general alcohol RR functions. See Additional file [4](#MOESM4){ref-type=\"media\"} for the number of YLL and YLD by cause attributable to alcohol consumption for men and women using Russia-specific alcohol RR functions and using general alcohol RR functions.Table 4Deaths and DALYs lost attributable to alcohol consumption in Russia in 2012 using Russia-specific alcohol RR functions and general population alcohol RR functions for people 0 to 64\\xa0years of ageWomenMenTotalCause\\\\*DeathsDALYsDeathsDALYsDeathsDALYsRussia-specific alcohol RRsCommunicable, maternal, neonatal and nutritional disordersLower respiratory infection1,96086,7004,550173,0006,510259,700Non-communicable diseasesIschemic heart disease25,5201,009,60038,8701,507,00064,3902,516,600Ischemic stroke2,43086,5003,260116,0005,690202,500Hemorrhagic and other non-ischemic strokes3,400129,6003,520137,0006,920266,600Cirrhosis of the liver11,750494,90011,750510,00023,5001,004,900Acute and chronic pancreatitis97043,6003,210153,0004,180196,600InjuriesTransport injuries2,120157,1008,230552,00010,350709,100Unintentional injuries (other than transport injuries)\\\\*\\\\*8,990555,70035,3801,891,00044,3702,446,700Self-harm and personal violence\\\\*\\\\*\\\\*4,400233,20020,0001,074,00024,4001,307,200Total70,8003,670,000161,1009,625,000231,90013,295,000Total (per 100,000 people)1186,09125115,02318710,694Non-Russia-specific alcohol RRsCommunicable, maternal, neonatal and nutritional disordersLower respiratory infection41018,5001,94074,2002,35092,700Non-communicable diseasesIschemic heart disease130−21,900−5,570−227,600−5,440−249,500Ischemic stroke−300−10,3001,50052,9001,20042,600Hemorrhagic and other non-ischemic strokes3,880146,3005,900230,6009,780376,900Cirrhosis of the liver10,070425,80018,680811,90028,7501,237,700Acute and chronic pancreatitis36016,2002,920139,6003,280155,800InjuriesTransport injuries1,44096,90015,110961,20016,5501,058,100Unintentional injuries (other than transport injuries)\\\\*\\\\*2,960161,50040,9302,085,70043,8902,247,200Self-harm and personal violence\\\\*\\\\*\\\\*1,42076,80022,1601,199,10023,5801,275,900Total29,7001,783,000135,9008,840,000165,60010,623,000Total (per 100,000 people)492,95921213,7981338,545\\\\*See Additional file [2](#MOESM2){ref-type=\"media\"} for ICD categories included in each cause\\\\*\\\\*Includes poisonings, falls, fires, drowning and other unintentional injuries\\\\*\\\\*\\\\*Includes self-inflicted injuries and homicide\\n\\nWhen using the alcohol RR functions from the meta-analyses, 10,623,000 DALYs (95\\xa0% UI: 7,265,000 to 13,754,000) were lost (1,783,000 DALYs lost among women and 8,840,000 DALYs lost among men) for people 0 to 64\\xa0years of age. This compares to an estimated 13,295,000 DALYs lost (95', '<|endoftext|> CPAP adherence or developing more tolerable treatments for OSA. Further investments in this area are clearly needed.\\n\\nThere also may exist subgroups that are more sensitive to the hypertensive effects of OSA and therefore to the anti-hypertensive effects of CPAP. These may relate to specific hypertensive pathways (e.g., hyperaldosteronism) or specific genetic backgrounds. For example, one study suggests African-Americans, a group at particularly high risk for hypertension and less responsive to standard antihypertensive medications, may have a greater blood pressure response to CPAP.11\\n\\nIn the end, however, despite all the interest in blood pressure, we must remember that blood pressure is merely a surrogate outcome. What our patients really care about and the question we need to strive to answer directly is whether CPAP therapy reduces cardiovascular events and mortality.<|endoftext|>Q:\\n\\nHTML/CSS How do i remove the button icon\\n\\nHow do I remove the bottom left icon from the button to search.\\n<form action=\"search.php\" method=\"POST\">\\n                                        <input type=\"text\" id=\"search\" name=\"search\" placeholder=\"Search something...\" required>\\n                                        <div id=\"close-icon\"></div>\\n                                        <button type=\"submit\" name=\"submit-search\"></button>\\n                                    </form>\\n\\nhere is the html \\n\\nA:\\n\\nAre you just trying to hide the tiny button on the bottom left? If so, this should sort you out!\\n<form action=\"search.php\" method=\"POST\">\\n    <input type=\"text\" id=\"search\" name=\"search\" placeholder=\"Search something...\" required>\\n    <div id=\"close-icon\"></div>\\n    <button type=\"submit\" name=\"submit-search\" style=\"display:none\"></button>\\n</form>\\n\\nYou can also do this in css using the following:\\n<style> \\n.display-none { display:none; }\\n</style>\\n\\n<form action=\"search.php\" method=\"POST\">\\n    <input type=\"text\" id=\"search\" name=\"search\" placeholder=\"Search something...\" required>\\n    <div id=\"close-icon\"></div>\\n    <button type=\"submit\" name=\"submit-search\" class=\"display-none\"></button>\\n</form>\\n\\n<|endoftext|>– This episode we talked to freelance photographer Erica Morano of Buffalo.com. We also talked about the Blizzard that never was, Outer Harbor Development, Cars on Main Street for the first time in 30 years, and Hertel Avenue’s new businesses! Enjoy and let us know what you think!<|endoftext|>Snyder: Office will release staff emails on Flint water\\n\\nMichigan Gov. Rick Snyder talks about the Flint water crisis and the emails which will soon be released during seesion with The Detroit News Editorial Board and reporters on Monday.(Photo: John T. Greilick / The Detroit News)Buy Photo\\n\\nGov. Rick Snyder said Monday his office will release thousands of pages of emails his staff sent or received related to Flint’s water supply switch and subsequent contamination dating back to 2011.\\n\\nSnyder said the release of his office’s Flint records would come “relatively soon” after state lawyers remove any documents that would normally be exempt under the Michigan Freedom of Information Act, which doesn’t apply to the governor’s office.\\n\\n“You’re talking thousands and thousands of emails, so I want to make sure they do it carefully and thoughtfully,” Snyder told The Detroit News Editorial Board.\\n\\nThe Republican governor stopped short of endorsing an expansion of Freedom of Information Act to make his office and the Legislature subject to the same public records law imposed on all other levels of government in the state. Michigan is one of two states that don’t release emails from these branches of government open to public inspection.\\n\\n“I’m starting with that in terms of this release,” Snyder said. “So I’m not going to get into the broader question at this point in time. … To be blunt, I’m working on making sure we get the information out on the executive office.”\\n\\nThe Snyder administration has posted online several thousand pages of records related to Flint’s 2014 switch to the Flint River water and the state Department of Environmental Quality’s failure to require anti-corrosive chemicals to be added to the water.\\n\\nFlint switched back to Detroit’s water supply in mid-October after state officials confirmed independent studies showing high levels of lead in Flint’s water and the bloodstreams of some residents. Corrosion of Flint’s aging lead water pipes is blamed for causing the toxic metal to leach into the city’s water supply.\\n\\nCLOSE\\n\\nGov. Rick Snyder said Monday his office will release thousands of pages of emails his staff sent or received related to Flint’s', '<|endoftext|> model.\\n\\nSubgroup analyses (e.g., by sex, age groups, or smoking status) were not performed due to limited sample size, especially for specific cancer types. We performed several sensitivity analyses. First, we further adjusted for cigarette pack-years as well as for arsenic in the subset of participants with information on pack-years and urine arsenic concentrations available (*n*\\xa0=\\xa03,737). Arsenic is an established carcinogen that has been related to cancer mortality \\\\[[@CR23]\\\\] and diabetes \\\\[[@CR24]\\\\] in the Strong Heart Study. Second, we further adjusted for time since the diagnosis of diabetes. Third, to account for competing risks by causes of death other than cancer, we estimated proportional hazards regression models according to the method of Fine and Gray \\\\[[@CR25]\\\\]. Findings from all sensitivity analyses were consistent with those reported (data not shown).\\n\\nResults {#Sec8}\\n=======\\n\\nTables\\xa0[1](#Tab1){ref-type=\"table\"} and [2](#Tab2){ref-type=\"table\"} show participant characteristics stratified by cancer mortality and diabetes status, respectively. In this cohort of American Indians, there were 13.7\\xa0% participants with IFG and 45.7\\xa0% with diabetes at baseline. The prevalence of diabetes in this cohort was previously reported as 43\\xa0% for men and 52\\xa0% for women; a random sample (*n*\\xa0=\\xa0311) of non-participants from this population showed a similar proportion of participants and non-participants with diabetes (40 and 38\\xa0%, respectively) \\\\[[@CR14]\\\\]. During follow-up, 187 men and 243 women died from cancer, mainly from lung and prostate cancer in men and lung and breast cancer in women.Table\\xa01Baseline characteristics of study participants overall and by cancer mortality statusOverall (*n*\\xa0=\\xa04,419)Cancer deaths (*n*\\xa0=\\xa0430)Non-cancer deaths or alive (*n*\\xa0=\\xa03,989)*p* value\\\\*Age (years)55.1 (8.1)60.4 (8.2)54.6 (8.0)\\\\<0.01Men (%)40.643.540.30.21Arizona (%)33.026.733.7\\\\<0.01Oklahoma (%)32.432.633.40.71North/South Dakota (%)33.640.732.9\\\\<0.01\\\\<High school (%)47.754.446.9\\\\<0.01Current smoking (%)33.844.432.7\\\\<0.01Former smoking (%)33.931.434.10.25Current drinking (%)41.435.142.1\\\\<0.01Obesity (BMI\\xa0≥\\xa030) (%)50.946.351.30.05Diabetes (%)\\\\*\\\\*45.744.945.80.73Impaired fasting glucose (%)\\\\*\\\\*\\\\*13.715.613.50.24HOMA-IR (%)^a^4.0 (3.6)3.8 (3.5)4.1 (3.6)0.28HbA1C (%)^b^6.7 (2.4)6.4 (2.1)6.7 (2.5)0.02Data in the table are percentages for categorical variables or means (standard deviations) for continuous variables\\\\*\\xa0Based on the Chi-square test for qualitative variables and analysis of the variance for quantitative variables\\\\*\\\\*\\xa0Defined as a fasting plasma glucose level ≥126\\xa0mg/dL\\\\*\\\\*\\\\*\\xa0Defined as a fasting plasma glucose level of 110--125\\xa0mg/dL^a^Based on 2,400 participants without diabetes and with HOMA-IR available^b^Based on 4,116 participants with this information availableTable\\xa02Population characteristics by diabetes statusNormal fasting glucose (*n*\\xa0=\\xa01,795)Impaired fasting glucose (*n*\\xa0=\\xa0606)\\\\*Diabetes (*n*\\xa0=\\xa02,018)\\\\*\\\\**p* value\\\\*\\\\*\\\\*Age (years)53.7 (8.0)55.3 (8.4)56.1 (7.9)0.14Men (%)43.942.137.3\\\\<0.01Arizona (%)19.226.947.2\\\\<0.01Oklahoma (%)38.936.127.6\\\\<0.01North/South Dakota (%)41.937.025.2\\\\<0.01\\\\<High school (%)41.245.554.1\\\\<0.01Current smoking (%)41.834.726.5\\\\<0.01Former smoking (%)29.933.337.6\\\\<0.01Current drinking (%)48.343.434.7\\\\<0.01Obesity (BMI\\xa0≥\\xa030) (%)38.858.359.4\\\\<0.01HOMA-IR (%)^a^3.4 (2.9)6.0 (4.5)--\\\\<0', '<|endoftext|> camera.\\n\\nHere are 15 things you should do after building your quad. Most of these things you’ve probably done, it’s just a summary / reminder.\\n\\n^ Back to Top\\n\\n15. Setting up Betaflight\\n\\nTo setup Betaflight for your first flight, follow the instructions in this guide “how to setup Betaflight for the first time“.\\n\\n^ Back to Top\\n\\n16. How to Tune Mini Quad\\n\\nTuning your quad is basically making it to fly and behave exactly the way you want. You don’t have to tune your quad, and it will fly just fine. But if you are serious about performance, then you have more stuff to learn! :D\\n\\nFor me, tuning a mini quad is basically going through these settings and get them dialed in:\\n\\nRC Rates and Expo\\n\\nPID\\n\\nFilters\\n\\nOther Betaflight settings (min throttle, antigravity, feedforward, throttle boost etc….)\\n\\nMy PID and Rate Profile\\n\\nYou might have your own preference about PID and Rate/Expo, but if you have no idea where to start, you can try my personal preference.\\n\\nMy rate:\\n\\nRC Rate: 1.3\\n\\nRC Expo: 0.24\\n\\nSuper Rate: 0.66\\n\\n[Updating… ] I will be testing Betaflight 4.0. Will come back and update my settings here soon.\\n\\n^ Back to Top\\n\\n17. Learning How to Fly a Racing Drone\\n\\nIf you have little to no experience in flying a mini quad, you should definitely check out these tutorials to get started:\\n\\nFlight Videos!\\n\\nFlight with this quad:\\n\\nHere are some other videos with the Martian frame.\\n\\nMore Quadcopter Builds?\\n\\nLooking for more examples and inspiration? Here are some of my latest builds and parts list.\\n\\nStrix Screech\\n\\nImpulseRC Reverb\\n\\nDiatone 2018 GT-M200\\n\\nGEPRC LSX5 Leopard\\n\\nPre-Built Racing Drone Options\\n\\nI don’t want to build, which pre-build drone to buy? There are a lot of options on the market, but many are garbage or simply overpriced. Here are some of the best ones that are worth looking into:\\n\\nLow Budget:\\n\\nMedium Budget:\\n\\nEdit History<|endoftext|>Summaries of health policy coverage from major news organizations\\n\\nLocal Health Care Workers Help Flint Residents Respond To Water Contamination Crisis\\n\\nDoctors, local hospitals and insurers are coordinating the local health effort in Flint, Mich. In related news, ProPublica explores the causes of the tainted drinking water emergency. And a former prosecutor is selected to lead up the investigation of the events that led to the crisis.\\n\\nCrain\\'s Detroit Business:\\nHealth Care Community Helps Flint Respond To Emergency\\nPhysicians in Flint, Mich., sounded the alarms early last fall about possible lead poisoning. Now, local healthcare providers and insurers are helping the city respond to the crisis. When the city switched to the Flint River in April 2014, residents immediately complained about the water\\'s smell, taste and color, said Kirk Smith, CEO of the Flint Area Health Coalition, which is coordinating the local health effort. (Greene, 1/25)\\n\\nProPublica:\\nHow Did The Flint Water Crisis Happen?\\nThe water crisis in Flint, Michigan – in which the city’s drinking water became contaminated with lead, bacteria and other pollutants – has come to national attention in recent weeks. President Obama declared a federal emergency in Flint, freeing up $5 million in federal aid, but Flint’s water problems have been unfolding for almost two years. (Gordy, 1/25)\\n\\nThe Associated Press:\\nEx-Prosecutor To Spearhead Investigation Into Flint Water\\nMichigan’s attorney general named a former prosecutor on Monday to spearhead an investigation into the process that left Flint’s drinking water tainted with lead, though Democrats questioned whether the special counsel would be impartial. Republican Bill Schuette said Todd Flood, a former assistant prosecutor for Wayne County, which includes Detroit, will lead the probe and be joined by Andy Arena, a retired head of Detroit’s FBI office. (Eggert and Householder, 1/24)\\n\\nThis is part of the KHN Morning Briefing, a summary of health policy coverage from major news organizations. Sign up for an email subscription.<|endoftext|>{\\n    \"callOutput3\" : {\\n        \"_info\" : {\\n            \"comment\" : \"\",\\n            \"filledwith\" : \"testeth 1.6.0-alpha.0-11+commit.978e68d2\",\\n            \"lllcversion\" : \"Version: 0.5.0-develop', '<|endoftext|> the petition were fully considered upon the original submission and decision of the case.  We, accordingly, deny the petition for a rehearing.\\n\\n<|endoftext|>By Matthew Daly, Associated Press\\n\\nWASHINGTON (AP) — The Environmental Protection Agency had sufficient authority and information to issue an emergency order to protect residents of Flint, Michigan, from lead-contaminated water as early as June 2015 — seven months before it declared an emergency, the EPA\\'s inspector general said Thursday.\\n\\nThe Flint crisis should have generated \"a greater sense of urgency\" at the agency to \"intervene when the safety of drinking water is compromised,\" Inspector General Arthur Elkins said in an interim report (pdf).\\n\\nFlint\\'s drinking water became tainted when the city began drawing from the Flint River in April 2014 to save money. The impoverished city of 100,000 north of Detroit was under state control at the time. Regulators failed to ensure water was treated properly and lead from aging pipes leached into the water supply.\\n\\nFederal, state and local officials have argued over who\\'s to blame as the crisis continues to force residents to drink bottled or filtered water. Doctors have detected elevated levels of lead in hundreds of children.\\n\\nA panel appointed by Michigan Gov. Rick Snyder concluded that the state is \"fundamentally accountable\" for the lead crisis because of decisions made by state environmental regulators and state-appointed emergency managers who controlled the city.\\n\\nEven so, Snyder and other Republicans have faulted the EPA for a slow response.\\n\\n\"As Gov. Snyder has stated all along, what happened in Flint was the result of failure of government at all levels,\" spokeswoman Anna Heaton said Thursday.\\n\\nState agencies have undergone \"culture changes\" and updated procedures to prevent a recurrence, so \"it\\'s encouraging to see other agencies undergoing evaluations that can result in improvements to help people here and across the nation,\" Heaton said.\\n\\nFlint Mayor Karen Weaver called the report \"deeply troubling.\"\\n\\nWeaver, a Democrat who took office after the Flint crisis emerged, said agencies such as the EPA and the Michigan Department of Environmental Quality are \"in place to help ensure the well-being and safety of men, women and children, yet they failed when it comes to the man-made water disaster in Flint. Those responsible must be held accountable.\"\\n\\nThe report by the inspector general says officials at the EPA\\'s Midwest region did not issue an emergency order because they concluded that actions taken by the state prevented the EPA from doing so. The report calls that interpretation incorrect and says that under federal law, when state actions are deemed insufficient, \"the EPA can and should proceed with an (emergency) order\" aimed at \"protecting the public in a timely manner.\"\\n\\nWithout EPA intervention, \"the conditions in Flint persisted, and the state continued to delay taking action to require corrosion control or provide alternative drinking water supplies,\" the report said.\\n\\nMichigan officials declared a public health emergency in October 2015; the EPA declared an emergency three months later.\\n\\nEPA Administrator Gina McCarthy has acknowledged that her agency should have been more aggressive in testing the water and requiring changes, but told Congress that officials \"couldn\\'t get a straight answer\" from the state about what was being done in Flint.\\n\\nSpokeswoman Monica Lee said Thursday that EPA issued an order in the Flint case \"as soon as it became apparent that the city and state were failing to address the serious problems with the Flint drinking water system.\"\\n\\nThe director of the EPA\\'s Midwest regional office stepped down Feb. 1 amid withering criticism that the agency failed to act sooner to address lead contamination in the predominantly African-American city.\\n\\nThe official, Susan Hedman, denied wrongdoing, but said she was leaving to avoid becoming a distraction.\\n\\nIn a memo from June 2015, Miguel Del Toral, a scientist in the EPA\\'s Midwest office, had warned of dangerously high levels of lead. He later criticized the agency for not taking swift action.\\n\\nThe inspector general\\'s office said a final report on Flint is still being developed. Separately, criminal investigators with the IG\\'s office are assisting in an ongoing probe of the Flint crisis being led by the U.S. attorney\\'s office.\\n\\nAssociated Press writer Ed White in Detroit contributed to this report.\\n\\nTo Learn More:\\n\\nManagement Alert: Drinking Water Contamination in Flint, Michigan, Demonstrates a Need to Clarify EPA Authority to Issue Emergency Orders to Protect the Public (EPA, Office of Inspector General) (pdf)\\n\\nTop EPA Official Resigns over Muted Response to Flint Water Contamination (by Timothy Gardner and Fiona Ortiz, Reuters)\\n\\nEPA Admits to Slow Response to Flint Water Contamination Crisis (by David Shepardson, Reuters)<|endoftext|>Car Design News\\n\\nCar Design News (CDN) () is an online news and information service for the international automotive design community.', '<|endoftext|> learn from this experience, because Flint is not the only city that has an aging infrastructure.”\\n\\nThe public health crisis began 18 months ago when the city switched from Lake Huron water to the Flint River water system to cut costs. The new water was not being treated with an anti-corrosive, causing the pipes to deteriorate and exposing residents to hazardous levels of lead.\\n\\nDespite studies from water quality experts and considerable outcry from residents, officials did little to acknowledge or resolve the problem. One study showed that the number of children with above average levels of lead in their bloodstream had nearly doubled since the city switched to the Flint water.\\n\\nMarc Edwards, an expert on municipal water quality at Virginia Tech, formed a volunteer research team to address the problems with Flint’s water. He was shocked with both the contamination that his team discovered and the fact that people at the city seemed to know about it, but refused to do anything.\\n\\nAt least 25 percent of homes in Flint had levels of lead that was well above the federal level, which is 15ppb. In some homes, it was 13,200ppb. And nearly every home had water that was distasteful or discolored.\\n\\n“It was the injustice of it all and that the very agencies that are paid to protect these residents from lead in water, knew or should’ve known after June at the very very latest of this year, that federal law was not being followed in Flint, and that these children and residents were not being protected,” says Edwards. “And the extent to which they went to cover this up exposes a new level of arrogance and uncaring that I have never encountered.”\\n\\nMelissa Mays, a Flint resident and parent, immediately noticed the difference when the switch in the water supply was made.\\n\\n“My children would ask me, ‘Why does the water smell funny? Why is the water yellow?’ They would come running out of the bathroom screaming because the bath would be yellow or blue, and they’d say, ‘Mom, something’s wrong with the water again.’”\\n\\nMays says the water quality directly impacted all three of her children’s health, potentially with long-term consequences. Tests confirmed that everyone in the family has high levels of lead, copper, aluminum, tin and chromium in their bloodstream.\\n\\n“My middle child is 12,” continues Mays. “He fell off his bike and he has two buckle fractures in his wrists, just from falling over. So his bones are weaker. My oldest has holes in the smooth sides of his teeth. The dentist believes it’s because of the lead. And my youngest is still struggling. We can’t get his white blood cell count above 4, when a year and a half ago, it was 10.4. So his immune system is compromised, and he’s getting sick basically whenever somebody sneezes. And they’re all now struggling in school: memory, brain fog. ... I’m terrified for my kids.”\\n\\nMays formed “Water You Fighting For,” a group that aimed to raise awareness of the problem, and to call on the government to act. But rather than anger at the dangerous levels of chemicals, she received ridicule. The authorities continued to encourage residents to drink the water, despite knowledge that it was potentially harmful. The former mayor would even go on TV and drink tap water, just to show it was safe.\\n\\n“We had all these experts bringing us all of this science and evidence. They would sit there and tell us that even if it’s discolored, just run your tap for a while and it’ll be fine. ‘It’s safe. Just let your water run. No big deal. It’ll be fine. This is just a bump in the road.’ It was just a plethora of excuses and lies.”\\n\\nEdwards, the water scientist from Virginia Tech, said that the situation essentially amounts to a cover-up.\\n\\n“Rather than address the legitimate science questions, they mounted a public relations campaign to discredit the residents, to discredit us. I have never seen this level of arrogance and incompetence. It was mostly confined to a few key individuals, but other people are guilty of being far too trusting of those individuals, and not listening to the people who were drinking this water.”\\n\\nEdwards notes that the nearly the entire problem arose from the fact that they did not include a corrosion control chemical to the water. And in a city with roughly 50 percent lead pipes, like Flint, that can be extremely dangerous.\\n\\nWhile it probably saved money upfront, adding a corrosion control chemical to the water saves pipes, notes Edwards, saving thousands in repair costs.\\n\\n“So not only is it unsafe and illegal, it’s financially irresponsible, too,” says Edwards.\\n\\nThe hardest hit in these types of situations are those who don’t breastfeed — the most', '<|endoftext|>, odds ratio). The cancer types and environmental exposures considered within HENVINET are reported in Table [1](#T1){ref-type=\"table\"}.\\n\\n###### \\n\\nList of cancers and environmental exposure considered within HENVINET\\n\\n  Cancer types             Environmental exposures\\n  ------------------------ --------------------------------------\\n  Breast Cancer            Alcohol\\n                           DDT and DDE\\n                           PCB\\n                           PAHs\\n                           \\n  Lung cancer and          Arsenic\\n  Malignant Mesothelioma   Asbestos\\n                           PM2.5\\n                           Radon\\n                           \\n  Brain Tumors             Radiofrequency\\n                           Pesticides\\n                           \\n  Colorectal Cancer        Meat consumption\\n                           Fruits and vegetables consumption\\n                           Intake of calcium and Vitamin D\\n                           Intake of folic acid\\n                           \\n  Leukemia                 Low frequency electromagnetic fields\\n                           Pesticides\\n                           Low level ionizing radiation\\n                           \\n  Melanoma                 UV light, artificial light\\n                           Ionizing radiation\\n                           Cosmetics (including sun screen)\\n                           Photosensitizing drugs\\n                           Exogenous hormones\\n\\nGlossary and references\\n-----------------------\\n\\nA glossary and selected references are made available to users to ensure fluent browsing and transparency. The glossary is an important tool aimed at assuring a consistent terminology across the exposure-cancer diagrams (e.g., meaning of reported biological effects, biological activity). Diagrams were specifically developed to allow users to actively explore the depicted exposure-effect interactions within the continuum between cancer initiation and detection. Their appearance is shown in Figure [6](#F6){ref-type=\"fig\"} as an example for exposure to radiofrequency and its association with brain tumours, one the hottest and most controversial topic in environmental health. The reader, after selecting a specific environmental exposure within a given cancer type, access a diagram showing the known risk factors, the evidence of susceptibility available, the reported mechanisms of action for a given environmental exposure/agent, and the quantitative measure of the exposure-effect association estimated by recent systematic review. The glossary and the reference list can be both accessed through a link placed on the left side of the interactive diagrams accessible on the HENVINET portal (Figure [6](#F6){ref-type=\"fig\"}).\\n\\nEvaluation of knowledge: the online questionnaires\\n--------------------------------------------------\\n\\nFor each interactive diagram a questionnaire including a limited set of items (questionnaire) was prepared to allow expert reviewers and users to express their level of confidence on the current scientific evidence and the understanding of the various aspects of the exposure-cancer diagram examined. 13 expert reviewers included researchers from the following fields: environmental and occupational epidemiology, cancer epidemiology, risk assessment, exposure assessment, molecular/biomarkers epidemiology, medical statistics, and atmospheric pollution and health effects. Nine of them accepted to review the interactive diagrams and filled in the questionnaire. The structure of the questionnaires has been standardized to provide similar questions across the paths of the exposure-adverse effects considered within the project (i.e., asthma and allergies, cancer, neurodevelopmental disorders, and endocrine disruptors). For each question included in the questionnaires the level of confidence was scored by expert reviewers as very high, high, medium, low and very low. An example of the questions included in the questionnaire for the association between exposure to radiofrequency and brain tumours is shown in Figure [7](#F7){ref-type=\"fig\"}. The causal diagrams were made accessible to experts selected according to their experience in environmental health and/or oncology. This process is identified in the HENVINET portal as the evaluation of knowledge. Review of diagrams performed by experts was also an exercise for testing of the questionnaire which is meant to be used by readers with different background.\\n\\n![Questionnaire items used for the evaluation of knowledge (questions for radiofrequency and brain cancer)](1476-069X-11-S1-S9-7){#F7}\\n\\nCausal diagram evaluation\\n-------------------------\\n\\nHENVINET cancer causal diagrams were actually a new experience for experts as they offer a simultaneous overview of all xenobiotics described in the etiology of selected site specific cancers.\\n\\nBased on the assumption that expert reviewers should be able to come to exact agreement about how to apply the possible five levels of scoring to each questions, consensus indexes of interpreter reliability were computed as estimates of how experts shared a common interpretation of the construct. The consensus index ranges between 1 (full agreement) and 0 (no agreement). An unexpectedly low consensus index was detected for the questions related to the role of exposure to environmental level of arsenic ( 0.43), radon (0.54), and PM2.5 (0.27) on lung cancer risk and for polycyclic aromatic hydrocarbons (PAH) on breast cancer (0.51) (Figure [8a-c](#F8){ref-type=\"', '<|endoftext|> mate around 8 years old. Females are pregnant for about 13 months and only get pregnant approximately every three to five years. Calves are born able to swim. A mother and her calf form a very close attachment. The calf spends most of its time swimming close to its mother and is carried in the mother\\'s \"slip stream,\" the wake which develops as the mother swims.\\n\\nBecause of an absence of teeth (which can be used to estimate age in other mammals), it is difficult to tell how old right whales are when they die. It is believed that right whales live at least 50 years.\\n\\nRight whales die of natural causes and are sometimes preyed upon by killer whales. Humans commercially hunted right whales for oil, meat, and apparel materials (for corset stays, umbrella ribs, buggy whips etc.) from the 17th to early 20th centuries. Right whales may also be harmed by pollution, ship strikes, or entanglement in fishing gear.<|endoftext|>By Serena Maria Daniels\\n\\nLANSING, Mich (Reuters) - Michigan Governor Rick Snyder, facing protests, lawsuits and calls for his resignation over drinking water contamination in Flint, on Tuesday apologized to the city\\'s residents and called for the state to spend $28 million on fixes.\\n\\n\"To you, the people of Flint, I say tonight as I have before, I am sorry and I will fix it,\" Snyder said in his annual speech to lawmakers, adding that federal, state and local leaders had failed residents.\\n\\nSnyder, a Republican, asked lawmakers to authorize $28 million in spending on diagnostic tests, health treatment for children and adolescents, replacement of old fixtures in Flint schools and day care centers and a study of the city\\'s water pipes. He also said additional funding would be needed.\\n\\nSome people have reported rashes, hair loss and other problems since Flint, under a state-appointed emergency manager, switched to Flint River water in April 2014 from a Detroit-run water system to save money, attorneys for the residents said.\\n\\nComplaints about the water began within a month of the switch, but Flint did not return to Detroit water until October 2015 after tests showed elevated levels of lead in Flint tap water and in some children.\\n\\nThe corrosive river water caused more lead to leach from Flint pipes than Detroit water did, increasing contaminants in the tap water.\\n\\nPresident Barack Obama met on Tuesday with recently elected Flint Mayor Karen Weaver over the crisis, which has become part of the U.S. presidential debate with candidates on both sides questioning the slow response.\\n\\nThe U.S. Environmental Protection Agency said it acted too slowly to address the situation in Flint.\\n\\nSnyder promised to release his Flint-related emails from 2014 and 2015 on Wednesday. He has rejected calls for his resignation by some protesters.\\n\\n\"Lansing failed in one of its most basic functions, ensuring the well-being and health of our citizens,\" state House Democratic Leader Tim Greimel said after the speech.\\n\\nStory continues\\n\\nAt least 1,000 people protested at the Capitol on Tuesday, some holding baby bottles filled with brown water.\\n\\n\"The governor has a business agenda and his business agenda was to take over the water to profit in it,\" said Lila Cabbil, a demonstrator from Detroit.\\n\\nSeveral lawsuits have been filed. The latest on Tuesday asks a judge to stop Flint from issuing shutoff notices to residents, who are still receiving bills for water declared undrinkable.\\n\\nAttorney Cary McGehee said lawyers have heard from more than 500 people reporting health problems and financial hardships.\\n\\n\\n\\n\\n\\n(Reporting by Serena Maria Daniels in Michigan, Suzannah Gonzales in Chicago and David Bailey in Minneapolis; Editing by Cynthia Osterman and Lisa Shumaker)<|endoftext|>lørdag den 13. oktober 2012\\n\\nRestoration shaman in Mist of Pandaria.\\n\\nRestoration shaman in Mist of Pandaria.\\n\\nI think we are far enough into the expansion to take\\na look at how the restoration shaman performs and competes against other\\nclasses.\\n\\nFrom Beta to Live there has been a tremendous\\nimprovement, and I do think our whine on the forums have helped since it\\nappears that quite a few of the points that we made have been noticed, which is\\nvery good.\\n\\nIn this expansion we got a throughput CD which we\\nhave been waiting for, and it is amazing Ascendance is a very, very powerful CD\\nwhen used properly. Our talents is more or less okay, and there is room for some\\npersonal preferences e.g. Astral Shift vs. Stone Bulwark Totem. Furthermore, we\\nalso got the option to take another CD Healing Tide Totem, or well I say option\\nbut in reality it is mandatory since it is so good.\\n\\nSo that is two new CDs, and if you', '<|endoftext|> description and analysis of arsenic metabolism. Modelling methods performed across the studies were adjusted for different factors, so the possibility of residual confounding cannot be excluded. Second, despite these results, the possibility of publication bias cannot be ignored, as null associations may be less likely to be published. Publication bias may overestimate the consistency of the relationship between arsenic metabolism and UC. In particular, cohort studies with no cases of UC and studies with non-significant association among UC and arsenic metabolites were not found in our research. In addition, as all the analysed studies were case--controlled ones, the possibility of reverse causation cannot be excluded. In fact, in case--control studies UC is a prevalent case and the collection of blood and urine samples was performed after the diagnosis of cancer. So, these measurements may be considered reliable only if we assume that the exposure to As and its metabolism remain stable in time. Also, some studies were performed in the same hospital, so the possibility of patients overlap among studies cannot be excluded due to anonymous data reported in all studies. Finally, the great part of included studies (six of nine) was performed in the same country (Taiwan), and it can make these results less generalizable. From included studies is not possible to find a threshold for the carcinogenic risk of As metabolites. So public health decision-makers need focused prospective studies both to evaluate the minimum level of risky As metabolism concentrations, both to evaluate the risk of long time exposure to As. However, the consistency of these findings sets the stage for additional research to determine the causality of these associations.\\n\\n5. Conclusions {#sec5-ijerph-17-03105}\\n==============\\n\\nArsenic metabolites levels in urine resulted significantly associated with urothelial cancer. The presence of As in soil and drinking water is a public health concern due to its possible role in urinary tract carcinogenesis. Public health policies and intervention should be aimed to improve surveillance and preventive strategies and to protect population exposed to arsenic. Future studies using large sample size, appropriate baseline, and prospective arsenic metabolism estimation will help to verify the independent association between arsenic metabolites and UC. In addition, a prospective evaluation of chronic exposure and As metabolism over time, could help in assessing the dose-response effect on urinary tract and its impact on UC development.\\n\\nAuthors are very grateful to Marzia Iasenza (PhD in English Linguistics) for reviewing the English manuscript.\\n\\nThe following are available online at <https://www.mdpi.com/1660-4601/17/9/3105/s1>, Research strategies; Table S1. Quality assessment according to Newcastle-Ottawa Quality Control Scale; Table S2. Assessment of publication bias considering metabolites as continuous variables; Table S3. Assessment of publication bias considering metabolites as dichotomous variables; Figure S1. Funnel plots performed to evaluate publication bias for metabolites reported as continuous variables; Figure S2. Funnel plots performed to evaluate publication bias for metabolites reported as categorical variables.\\n\\n###### \\n\\nClick here for additional data file.\\n\\nConceptualization, G.D.M., P.D.G., T.S.; methodology, F.C., M.F.,P.S., G.D.M.; formal analysis, G.L.; data curation, G.D.M., P.D.G.; writing---original draft preparation, G.D.M., P.S.; writing---review and editing, F.C, F.M., P.D.G., F.R.; supervision, T.S., F.R. All authors have read and agreed to the published version of the manuscript.\\n\\nThis research received no external funding.\\n\\nThe authors declare no conflict of interests.\\n\\n![Flowchart of the study selection.](ijerph-17-03105-g001){#ijerph-17-03105-f001}\\n\\n![Forest-plot of weighted mean differences in arsenic metabolites between cases and control.](ijerph-17-03105-g002){#ijerph-17-03105-f002}\\n\\n![Forest-plot of association between arsenic metabolites distribution and urothelial cancer.](ijerph-17-03105-g003){#ijerph-17-03105-f003}\\n\\nijerph-17-03105-t001_Table 1\\n\\n###### \\n\\nCharacteristics of included studies.\\n\\n  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n  Study                   Year   Country                 Study Design   Participants               IA% Cases (Mean)   MMA% Cases (Mean)   DMA% Cases (Mean)   Risk Estimate Contrast\\\\   Risk Estimate\\\\   Risk Estimate Contrast\\\\   Risk Estimate\\\\   Risk Estimate Contrast\\\\    Risk Estimate\\\\   Adjustment                                                                     Conclusion\\n                                                                                                                                                              IA%                       IA%              MMA%                      MMA%             DMA%                       DMA%                                                                                            \\n  ----------------------- ------ ----------------------- -------------- --------------------------', '<|endoftext|> we’re still blaming the low achievement of lead-damaged children on schools, teachers, and parents through our reliance on test scores and our underfunding of those schools serving children who need the most help.\\n\\nAre we doing enough to eliminate lead from the environment? Not according to this article. We spend billions on testing, but apparently can’t afford to keep our children safe from poisoning. The problem is that most of those who are affected by environmental toxins like lead are poor children of color. Chances are if we had lead poisoning in areas where wealthy white people lived, it would be taken care of immediately.\\n\\nFlint, Michigan is facing that situation. There aren’t enough special education teachers to handle the increased case load in Flint’s schools. The author of the article (and the plaintiffs in the lawsuit) don’t blame the lead in the water for the increased need for speical ed services in Flint. It seems likely, however, that the near doubling of the number of children identified for special education over the last 8 years has something to do with the damage done to Flint’s children by the lead in the water.\\n\\nWho should pay for the permanent damage done to an entire community of lead poisoned children? Who should be held accountable? Will teachers’ evaluations reflect the lower test scores of their students damaged by policy makers’ neglect?\\n\\nIn a suit brought by the American Civil Liberties Union of Michigan, the Education Law Center, and the New York-based firm of White & Case, lawyers representing Flint families have sued the school system, the Michigan education department, and the Genesee County Intermediate school district, alleging systematic failure to meet the needs of special education students. The Genesee district helps oversee special education services in Flint and other county districts.\\n\\nWhile the lawsuit does not pin the increased need for special education services solely on the prolonged lead exposure, research has linked lead toxicity to learning disabilities, poor classroom performance, and increased aggression.\\n\\nWe shouldn’t use student achievement tests to evaluate teachers. Student achievement tests are developed to assess student achievement, not teacher effectiveness…not school effectiveness…and not school system effectiveness. This misuse of standardized tests invalidates the results.\\n\\nMcCormick also said it is “past time” for the state to take students’ standardized test scores out of teachers’ evaluations. The argument is that scores should be used to inform educators on what concepts students have mastered and where they need help, rather than a way of evaluating how well teachers are doing their jobs.\\n\\n“ILEARN was a snapshot in time, it was a one-day assessment,” McCormick said. “It gave us information on where students are performing, but there are a lot of pieces to student performance beyond one assessment.”\\n\\nAs for why the first year of scores were low, McCormick said the new test was “much more rigorous” and weighed skills differently, prioritizing “college and career readiness” skills.\\n\\n• Hold schools harmless for test results for accountability purposes. In other words, schools would receive the higher of the grade they earned in 2018 or 2019.\\n• Pause the intervention timeline that allows the state to close or take over schools that are rated F for multiple consecutive years.\\n• Give emergency rule-making authority to the State Board of Education to enable it to reconfigure the accountability system to align with the new assessment.\\n\\nMcCormick also said it’s past time to decouple test scores from teacher evaluations, which can determine whether teachers get raises. Current law says teacher evaluations must be “significantly informed” by objective measures, like students’ test scores.\\n\\nOnce more teachers tell policy makers (this time “business and education leaders”) how the state of Indiana (and the nation) has damaged public education and the teaching profession. Apparently, the only people who don’t know why there’s a teacher shortage are those who have caused it…\\n\\nOne by one, teachers and community members took to the mic to give their input of what they believe needs to be done to increase teacher pay as well as revenues available to school corporations.\\n\\nRecommendations included — but were not limited to — looking into low-enrollment schools, increasing state taxes, dropping standardized testing and examining charter schools’ “harmful impact” on public education.\\n\\nTeachers need a broad understanding about reading instruction and how to assess the reading needs of each student, especially when students are young and learning to read.\\n\\nThis includes decoding for children who have reading disabilities. But a variety of teaching tools and methods help children learn to read. The conditions in their schools and classrooms should be conducive for this to happen.\\n\\nIt would be helpful to read more about lowering class sizes, a way to better teach children in earlier grades.\\n\\nThe Reading First scandal was noxious, and I have not done justice describing it in this post. Today, most understand that NCLB was not', '<|endoftext|> and shutter another distribution plant.\\n\\nThe moves are expected to result in at least 600 job losses. The No. 1 U.S. chicken producer by volume said the tray-pack business in El Dorado, Ark., will be handled by six other case-ready facilities. Approximately 600 of the 1,215 positions at the El Dorado plant will be eliminated by Sept. 19.\\n\\nNow even the Chicken Business is losing money. Add it to our list of ABCs.....autos, airlines, banks, construction, and chicken. Can anyone tell me who is going to pay taxes this year with soooooo many companies losing money and workers getting released?<|endoftext|>Introduction\\n============\\n\\nArsenic is a natural component of the Earth\\'s crust. It can be found in soil and water that have interacted with arsenic-rich rocks. Arsenic can also be introduced into the groundwater anthropogenically through the application of the arsenic-rich herbicides and pesticides that are frequently used on agricultural lands.\\n\\nThe maximum acceptable levels of dissolved arsenic in drinking water is 0.01 mg/l and 0.05 mg/l according to the World Health Organization and the United States Environmental Protection Agency, respectively \\\\[[@b1-ijerph-02-00204], [@b2-ijerph-02-00204]\\\\]. Acceptable levels of dissolved arsenic in drinking water in Bangladesh are 0.05 mg/l. Drinking water that has elevated levels of arsenic for a prolonged time period is unsafe, and specific health risks are well documented \\\\[[@b3-ijerph-02-00204], [@b4-ijerph-02-00204]\\\\].\\n\\nArsenic-contaminated groundwater was first documented in groundwater in 1984 \\\\[[@b4-ijerph-02-00204]\\\\]. Since then, several systematic studies have been carried out to determine the extent and severity of this contamination \\\\[[@b5-ijerph-02-00204], [@b6-ijerph-02-00204]\\\\]. The magnitude of the problem is not yet known, however, the number of affected tube wells and arsenic-related health complaints is on the rise. About 30% of 10 million private wells are highly contaminated. Most people in Bangladesh use groundwater water as a source of drinking water because the surface water has unacceptable level of bacterial contamination. A total of 269 out of Bangladesh\\'s 464 administrative units, called *upazilla*, more than half the country, contain high levels of arsenic-contaminated drinking water ([Fig. 1](#f1-ijerph-02-00204){ref-type=\"fig\"}).\\n\\nIn addition to Bangladesh, several countries in the world have identified excess amount arsenic in drinking water including Argentina, Bangladesh, Chile, China, Hungary, India, Japan, Mexico, Mongolia, Poland, Taiwan, and the United States. However, it is noteworthy that the number of people affected by arsenic pollution in Bangladesh exceeds the total number of people affected by arsenic pollution in all other countries combined.\\n\\nGeology of Bangladesh in Relation to Arsenic in Groundwater\\n-----------------------------------------------------------\\n\\nMost of Bangladesh and West Bengal, India, fall within the Bengal Basin, one of the world\\'s largest geosynclinal troughs (a large elongate or basin-like structure on Earth\\'s surface). The Ganges-Brahmaputra-Meghna river system occupies this extensive basin. As it nears the Bay of Bengal coast, this system spreads out forming many distibutary channels. Along the coast, the mean tidal range is high, and wave energy is low. As a result, the Ganges-Brahmaputra deltaic complex serves as a textbook model of a tide-dominated delta.\\n\\nThe Bengal Basin comprises a wide variety of fluvial (e.g., channels, floodplains, natural levees, back swamps) and marginal marine (e.g., distributary channels, mangrove forests, tidal flats, beaches) sedimentary environments. Distinctive sediment, biological activity, and chemical and physical processes characterize each of these environments. They inter finger laterally as well as vertically and continuously change their position in response to tectonic disturbances as well as global variations in climate and sea-level fluctuations.\\n\\nAlthough sea level has varied considerably throughout geologic time, the changes over the last 1.6 million years (Pleistocene and Holocene epochs) have been dramatic. During this time, the sedimentary environments of the Bengal Basin shifted both seaward and landward relative to the present coastline in response to global sea-level changes. It is likely that the southern boundaries of the Pleistocene highlands, terraces such as the Barind Tract, Madhupur Tract, and Tippera Terrace, marked the position of the paleoshoreline (shoreline position at a given time in the past) during the last interglacial period (125,000 years ago).\\n\\nAs sea level fell to its lowest stand during the last', \"<|endoftext|> mines in Cornwall\\nCategory:Disasters in Cornwall\\nCategory:1893 in England\\nCategory:1893 mining disasters\\nCategory:Arsenic mines\\nCategory:Camborne\\nCategory:Industrial archaeological sites in Cornwall<|endoftext|>Doug Kinna, union spokesperson, was in Campbell River for the one-day strike to focus the public’s attention on the union’s issues.\\n\\n“We want a fair and reasonable agreement,” Kinna said. “This is our first strike since 1988 – we’re not strike happy. We’ve been able to negotiate fair agreements in the past.\\n\\n“Maybe we should bring (former premier Gordon) Campbell back. At least he knew what he was doing when it came to collective bargaining.”\\n\\nThe BCGEU has followed the province’s wage freeze mandate, not having a pay increase since 2009. The union’s contract expired on April 1, 2012 but the union and the province first sat down at the bargaining table in January. The BCGEU is asking for a 3.5 per cent wage increase this year and a raise equivalent to the cost of living increase for 2013.\\n\\nThe union has already rejected the province’s offer of a two per cent pay increase for 2012 and another 1.5 per cent next yet.\\n\\nOn Wednesday it was announced that the province had withdrawn that offer, which the BCGEU turned down just prior to its first strike at liquor distribution warehouses in Kamloops, Vancouver and Victoria on July 3.\\n\\nKinna did not indicate when and if there will be future strikes, but the union did announce weeks ago it intended to stage a series of rotating strikes without hurting the public.\\n\\n“That would be a $280 to $300 million increase in revenue without raising taxes. They’ve had lots of time to review these and they’ve rejected them.”\\n\\nFinance Minister Kevin Falcon disagrees with the BCGEU’s numbers and said having liquor stores open on Sundays would maybe save $11 million – not enough to fund the increase the union wants – because employees would have to be paid overtime.\\n\\nFalcon also said it would take away sales from private liquor stores that operate on Sundays.\\n\\nWe encourage an open exchange of ideas on this story's topic, but we ask you to follow our guidelines for respecting community standards. Personal attacks, inappropriate language, and off-topic comments may be removed, and comment privileges revoked, per our Terms of Use. Please see our FAQ if you have questions or concerns about using Facebook to comment.<|endoftext|>Acute epiglottitis in adults.\\nAcute epiglottitis in adults is a fulminant disease characterized by local cellulitis of supraglottic structures. Symptoms include sore throat, dysphagia, respiratory difficulty and muffled voice. Signs are pharyngitis, swollen and inflamed epiglottis, epiglottic abscess and/or cervical swelling. Diagnosis is facilitated by an upright, lateral neck x-ray and indirect laryngoscopy. The mainstays of treatment are airway maintenance, antibiotics, steroids, hydration, cool mist, oxygen and supportive care.<|endoftext|>Conventional fuel systems for vehicles with internal combustion engines can include a canister that accumulates fuel vapor from a headspace of a fuel tank. If there is a leak in the fuel tank, the canister, or any other component of the fuel system, fuel vapor could escape through the leak and be released into the atmosphere instead of being accumulated in the canister. Various government regulatory agencies, e.g., the U.S. Environmental Protection Agency and the Air Resources Board of the California Environmental Protection Agency, have promulgated standards related to limiting fuel vapor releases into the atmosphere. Thus, it is believed that there is a need to avoid releasing fuel vapors into the atmosphere, and to provide an apparatus and a method for performing a leak diagnostic, so as to comply with these standards.\\nIn such conventional fuel systems, excess fuel vapor can accumulate immediately after engine shutdown, thereby creating a positive pressure in the fuel vapor pressure management system. Excess negative pressure in closed fuel systems can occur under some operating and atmospheric conditions, thereby causing stress on components of these fuel systems. Thus, it is believed that there is a need to vent, or “blow-off,” the positive pressure, and to vent, or “relieve,” the excess negative pressure. Similarly, it is also believed to be desirable to relieve excess positive pressure that can occur during tank refueling. Thus, it is believed that there is a need to allow air, but not fuel vapor, to exit the tank at high flow rates during tank refueling. This is commonly referred to as onboard refueling vapor recovery (ORVR).<|endoftext|>Join the Catty Shack Volunteer family! Come to our mandatory volunteer meeting and learn about what to expect as a Catty Shack volunteers and get all your questions answered. Click here to learn more about volunteering and\", '<|endoftext|> in consumption of hormone-rich dairy produce, the use of the contraceptive pill and other steroid drugs, and oestrogenic environmental pollutants such as DDT, PCBs, plastic wrapping and exhaust fumes are all conspiring to wipe out our reproductive ability. Certainly it has given environmentalists plenty to shout about, with some calling for an immediate ban on all things oestrogenic and predicting the destruction of the human race by Clingfilm. Most of the population quietly get on with their lives without paying too much heed to unproved possibilities, but others are more anxious. As one would-be father asked me: “We’re trying for a baby this month. Should we be drinking tap water?”.\\n\\nWell, it’s a damn site better for you than drinking untreated sewage. Research from Brunel University found very few oestrogenic chemicals (except at effluent outlets) in British tap water, and concluded that any oestrogenic contaminants that might possibly harm us are likely to come from food. As there are 5,000 food chemicals to test and science requires that only one be tested at a time, it’ll be a little while yet before we know the true state of play. As to why the dip has occurred, it all depends on which planet you inhabit. Is it God’s way of punishing human greed or Mother Earth’s answer to environmental destruction? Is it a Darwinian response to over-population (sperm were up after WW2 because we needed to replace our young men, but that need has now passed).\\n\\nIs “stress” the trigger? Or perhaps the pervading feeling of male helplessness as women take over the planet has stunted our development to such an extent that we just can’t be bothered to play ball. There are lots of other possible causes of low sperm count. like steroid abuse or undescended testicles, and equally lots that can be done to help. For more information. In the meantime, if you do want to give whatever sperm you have every chance of success, follow the top tips below:\\n\\nHow to keep your sperm alive\\n\\nTry not to overdose on your partner’s contraceptive pills\\n\\nAir your genitals at every socially acceptable opportunity\\n\\nPiping hot baths are out\\n\\nDon’t go swimming in untreated sewage\\n\\nAvoid radiation, industrial cleaners and children with mumps if you haven’t had it\\n\\nNo tight G strings – Let ‘em hang\\n\\nCut down on the things you associate with pubs (smoking, excessive alcohol, unprotected sex with strangers)<|endoftext|>I didn\\'t think that you ever officially reported to me.  Let me know.  I \\ndidn\\'t think I needed to do your review.<|endoftext|>Hack \\'n\\' Slash\\n\\nHack \\'n\\' Slash is a video game developed by Double Fine Productions. Prototyped during Double Fine\\'s open Amnesia Fortnight 2012, Hack \\'n\\' Slash is a top-down action-adventure game similar to The Legend of Zelda, though with in-game weapons and objects that allow the player to hack the game\\'s world to achieve victory. The game was released to Steam\\'s Early Access on May 6, 2014 for Microsoft Windows, OS X, and Linux computers. It left early access status and became a full release on September 9, 2014.\\n\\nGameplay\\nThe player controls the game\\'s primary character, Alice (a reference to the common Alice and Bob placeholder names), armed with a \"USB Sword\" from a top-down view. While the player can use the sword and other weapons and tools to explore dungeons and fight enemies in a traditional manner, the sword itself can also interact in special ways with any game object, including enemies and obstacles, that has a USB port. At this point, the player can alter the basic parameters of the object to alter their behavior. Examples include adjusting the movement speed of an enemy, or setting a container\\'s hit points to zero causing it to collapse and release its contents. The player can also hack Alice\\'s variables, such as her name or health points. For game objects that lack these USB ports, the player can use limited bombs that pause the execution of code from objects caught in the explosion, allowing them to temporarily hack the object\\'s code, such as setting a flag that gives these objects a USB port to be hacked further.\\n\\nAnother tool Alice has is the Third Eye Hat that opens a debugging interface, the same that Double Fine has used to create and test the game. Through this, the player can see elements of the code behind the objects, such as the contents of a container or invisible blocks. Although the player cannot hack the code while in debug mode, they can use this knowledge to achieve goals. In one case, with a series of invisible blocks floating very slowly over a chasm, the player is able to hack the game\\'s internal clock that would, to the player, speed up the movement of the']\n","layer 1\n","82 ['<|endoftext|>m in Sources */ = {isa = PBXBuildFile; fileRef = F4E675C71B21D1440054530B /* Wrappers.pbobjc.m */; };\\n/* End PBXBuildFile section */\\n\\n/* Begin PBXFileReference section */\\n\\t\\t1D30AB110D05D00D00671497 /* Foundation.framework */ = {isa = PBXFileReference; lastKnownFileType = wrapper.framework; name = Foundation.framework; path = System/Library/Frameworks/Foundation.framework; sourceTree = SDKROOT; };\\n\\t\\t5102DABB1891A052002037B6 /* GPBConcurrencyTests.m */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.objc; path = GPBConcurrencyTests.m; sourceTree = \"<group>\"; };\\n\\t\\t51457B5F18D0B7AF00CCC606 /* GPBCodedInputStream_PackagePrivate.h */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.h; path = GPBCodedInputStream_PackagePrivate.h; sourceTree = \"<group>\"; };\\n\\t\\t515B840C18B7DEE30031753B /* GPBDescriptor_PackagePrivate.h */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.h; path = GPBDescriptor_PackagePrivate.h; sourceTree = \"<group>\"; };\\n\\t\\t5196A06918CE16B000B759E2 /* GPBMessage_PackagePrivate.h */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.h; path = GPBMessage_PackagePrivate.h; sourceTree = \"<group>\"; };\\n\\t\\t7401C1A90F950347006D8281 /* UnitTests-Info.plist */ = {isa = PBXFileReference; lastKnownFileType = text.plist.xml; path = \"UnitTests-Info.plist\"; sourceTree = \"<group>\"; };\\n\\t\\t7461B48D0F94F99000A0C422 /* GPBBootstrap.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = GPBBootstrap.h; sourceTree = \"<group>\"; };\\n\\t\\t7461B48E0F94F99000A0C422 /* GPBCodedInputStream.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = GPBCodedInputStream.h; sourceTree = \"<group>\"; };\\n\\t\\t7461B48F0F94F99000A0C422 /* GPBCodedInputStream.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; lineEnding = 0; path = GPBCodedInputStream.m; sourceTree = \"<group>\"; };\\n\\t\\t7461B4900F94F99000A0C422 /* GPBCodedOutputStream.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = GPBCodedOutputStream.h; sourceTree = \"<group>\"; };\\n\\t\\t7461B4910F94F99000A0C422 /* GPBCodedOutputStream.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; path = GPBCodedOutputStream.m; sourceTree = \"<group>\"; };\\n\\t\\t7461B4A80F94F99000A0C422 /* GPBExtensionRegistry.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = GPBExtensionRegistry.h; sourceTree = \"<group>\"; };\\n\\t\\t7461B4A90F94F99000A0C422 /* GPBExtensionRegistry.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; path = GPBExtensionRegistry.m; sourceTree = \"<group>\"; };\\n\\t\\t7461B4AE0F94F99000A0C422 /* GPBUnknownField.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = GPBUnknownField.h; sourceTree = \"<group>\"; };\\n\\t\\t7461B4AF0F94F99000A0C422 /* GPBUnknownField.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; path = GPBUnknownField.m; sourceTree = \"<group', '<|endoftext|>Tree = \"<group>\"; };\\n\\t\\tCC07437F1BB9E9570075E407 /* XCToolUtil.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; name = XCToolUtil.m; path = ../Common/XCToolUtil.m; sourceTree = \"<group>\"; };\\n\\t\\tCC0743891BB9E9FC0075E407 /* EventSink.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; name = EventSink.h; path = ../Common/EventSink.h; sourceTree = \"<group>\"; };\\n\\t\\tCC07438A1BB9EB490075E407 /* XcodeBuildSettings.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; name = XcodeBuildSettings.h; path = ../Common/XcodeBuildSettings.h; sourceTree = \"<group>\"; };\\n\\t\\tCC07438B1BB9EB490075E407 /* XcodeBuildSettings.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; name = XcodeBuildSettings.m; path = ../Common/XcodeBuildSettings.m; sourceTree = \"<group>\"; };\\n\\t\\tCC43C4711B79725500AEDFB5 /* reporters-tests.xcconfig */ = {isa = PBXFileReference; lastKnownFileType = text.xcconfig; path = \"reporters-tests.xcconfig\"; sourceTree = \"<group>\"; };\\n\\t\\tCC46A4F81BD768D5007B8C42 /* libiconv.dylib */ = {isa = PBXFileReference; lastKnownFileType = \"compiled.mach-o.dylib\"; name = libiconv.dylib; path = usr/lib/libiconv.dylib; sourceTree = SDKROOT; };\\n\\t\\tCC58B4791BB9E3D300E92B42 /* NSConcreteTask.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; name = NSConcreteTask.h; path = ../Common/NSConcreteTask.h; sourceTree = \"<group>\"; };\\n\\t\\tCC75C2A91BB9D95F004315B2 /* TaskUtil.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; name = TaskUtil.h; path = ../Common/TaskUtil.h; sourceTree = \"<group>\"; };\\n\\t\\tCC75C2AA1BB9D95F004315B2 /* TaskUtil.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; name = TaskUtil.m; path = ../Common/TaskUtil.m; sourceTree = \"<group>\"; };\\n\\t\\tCC8AA20518F368EE00D9F322 /* user-notifications-Info.plist */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = text.plist.xml; name = \"user-notifications-Info.plist\"; path = \"user-notifications/user-notifications-Info.plist\"; sourceTree = \"<group>\"; };\\n\\t\\tCCC0AAED18EC8A1F004FD861 /* main.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; name = main.m; path = \"user-notifications/main.m\"; sourceTree = \"<group>\"; };\\n\\t\\tCCC0AAF218EC8A92004FD861 /* UserNotificationsReporter.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; name = UserNotificationsReporter.h; path = \"user-notifications/UserNotificationsReporter.h\"; sourceTree = \"<group>\"; };\\n\\t\\tCCC0AAF318EC8A92004FD861 /* UserNotificationsReporter.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; name = UserNotificationsReporter.m; path = \"user-notifications/UserNotificationsReporter.m\"; sourceTree = \"<group>\"; };\\n\\t\\tCCC0AB0018EC8AC4004FD861 /* user-notifications */ = {isa = PBXFileReference; explicitFileType = \"compiled.mach-o.', '<|endoftext|>; };\\n\\t\\t28FD15080DC6FC5B0079059D /* QuartzCore.framework in Frameworks */ = {isa = PBXBuildFile; fileRef = 28FD15070DC6FC5B0079059D /* QuartzCore.framework */; };\\n\\t\\t944A656F195747D90094A81E /* libSDL2.a in Frameworks */ = {isa = PBXBuildFile; fileRef = 944A656E1957463F0094A81E /* libSDL2.a */; };\\n\\t\\t945C4F53195AF17F00DBBF61 /* Default-568h@2x.png in Resources */ = {isa = PBXBuildFile; fileRef = 945C4F52195AF17F00DBBF61 /* Default-568h@2x.png */; };\\n\\t\\tFA8B4B97196703B400F8EB7C /* CoreMotion.framework in Frameworks */ = {isa = PBXBuildFile; fileRef = FA8B4B96196703B400F8EB7C /* CoreMotion.framework */; };\\n\\t\\tFAE0E9651BAF967F0098DFA4 /* GameController.framework in Frameworks */ = {isa = PBXBuildFile; fileRef = FAE0E9641BAF967F0098DFA4 /* GameController.framework */; };\\n\\t\\tFD779EDE0E26BA1200F39101 /* CoreAudio.framework in Frameworks */ = {isa = PBXBuildFile; fileRef = FD779EDD0E26BA1200F39101 /* CoreAudio.framework */; };\\n\\t\\tFD77A07D0E26BD8C00F39101 /* Icon.png in Resources */ = {isa = PBXBuildFile; fileRef = FD77A07C0E26BD8C00F39101 /* Icon.png */; };\\n\\t\\tFD77A07F0E26BDA900F39101 /* Default.png in Resources */ = {isa = PBXBuildFile; fileRef = FD77A07E0E26BDA900F39101 /* Default.png */; };\\n\\t\\tFD77A0850E26BDB800F39101 /* AudioToolbox.framework in Frameworks */ = {isa = PBXBuildFile; fileRef = FD77A0840E26BDB800F39101 /* AudioToolbox.framework */; };\\n\\t\\tFD77A09D0E26BDE500F39101 /* main.c in Sources */ = {isa = PBXBuildFile; fileRef = FD77A09C0E26BDE500F39101 /* main.c */; };\\n\\t\\tFDB8BFC60E5A0F6A00980157 /* CoreGraphics.framework in Frameworks */ = {isa = PBXBuildFile; fileRef = FDB8BFC50E5A0F6A00980157 /* CoreGraphics.framework */; };\\n/* End PBXBuildFile section */\\n\\n/* Begin PBXContainerItemProxy section */\\n\\t\\t944A656D1957463F0094A81E /* PBXContainerItemProxy */ = {\\n\\t\\t\\tisa = PBXContainerItemProxy;\\n\\t\\t\\tcontainerPortal = 944A65681957463F0094A81E /* SDL.xcodeproj */;\\n\\t\\t\\tproxyType = 2;\\n\\t\\t\\tremoteGlobalIDString = FD6526630DE8FCCB002AD96B;\\n\\t\\t\\tremoteInfo = libSDL;\\n\\t\\t};\\n/* End PBXContainerItemProxy section */\\n\\n/* Begin PBXFileReference section */\\n\\t\\t1D30AB110D05D00D00671497 /* Foundation.framework */ = {isa = PBXFileReference; lastKnownFileType = wrapper.framework; name = Foundation.framework; path = System/Library/Frameworks/Foundation.framework; sourceTree = SDKROOT; };\\n\\t\\t1D6058910D05DD3D006BFB54 /* ___PROJECTNAME___.app */ = {isa = PBXFileReference; explicitFileType = wrapper.application; includeInIndex = 0; path = \"___PROJECTNAME___.app\"; sourceTree = BUILT_PRODUCTS_DIR; };\\n\\t\\t1DF5F4DF0D08C38300B7A737 /* UIKit.framework */ = {isa = PBXFileReference; lastKnownFileType = wrapper.framework; name = UIKit.framework; path = System/Library/Frameworks/UIKit.framework; sourceTree = SDKROOT; };\\n\\t\\t28FD14FF0DC6FC520079059D /* OpenGLES.framework */ = {isa = PBXFileReference; lastKnownFileType = wrapper.framework', '<|endoftext|>D0F72F000981E51 /* CoreGraphics.framework */ = {isa = PBXFileReference; lastKnownFileType = wrapper.framework; name = CoreGraphics.framework; path = System/Library/Frameworks/CoreGraphics.framework; sourceTree = SDKROOT; };\\n\\t\\t1D6058910D05DD3D006BFB54 /* HelloWorld.app */ = {isa = PBXFileReference; explicitFileType = wrapper.application; includeInIndex = 0; path = HelloWorld.app; sourceTree = BUILT_PRODUCTS_DIR; };\\n\\t\\t1DF5F4DF0D08C38300B7A737 /* UIKit.framework */ = {isa = PBXFileReference; lastKnownFileType = wrapper.framework; name = UIKit.framework; path = System/Library/Frameworks/UIKit.framework; sourceTree = SDKROOT; };\\n\\t\\t29B97316FDCFA39411CA2CEA /* main.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; path = main.m; sourceTree = \"<group>\"; };\\n\\t\\t32CA4F630368D1EE00C91783 /* HelloWorld_Prefix.pch */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = HelloWorld_Prefix.pch; sourceTree = \"<group>\"; };\\n\\t\\t8D1107310486CEB800E47090 /* Info.plist */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = text.plist.xml; path = Info.plist; sourceTree = \"<group>\"; };\\n\\t\\t8E3A1F080FAA199F009B0518 /* cover320x416.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = cover320x416.png; sourceTree = \"<group>\"; };\\n\\t\\t8E4156E70FA4EE0E0006D27C /* Default.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = Default.png; sourceTree = \"<group>\"; };\\n\\t\\t8E4156E80FA4EE0E0006D27C /* icon.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = icon.png; sourceTree = \"<group>\"; };\\n\\t\\t8E785FCA0FCDB853006EA81F /* TestBedViewController.xib */ = {isa = PBXFileReference; lastKnownFileType = file.xib; path = TestBedViewController.xib; sourceTree = \"<group>\"; };\\n\\t\\t8ED1FAD1102A32E700501086 /* AccelerometerHelper.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = AccelerometerHelper.h; sourceTree = \"<group>\"; };\\n\\t\\t8ED1FAD2102A32E700501086 /* AccelerometerHelper.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; path = AccelerometerHelper.m; sourceTree = \"<group>\"; };\\n\\t\\t8ED1FB1A102A369E00501086 /* AudioToolbox.framework */ = {isa = PBXFileReference; lastKnownFileType = wrapper.framework; name = AudioToolbox.framework; path = \"../00DeployedSampleCode/C14-Device/AccelForce/iphoneos2.0/System/Library/Frameworks/AudioToolbox.framework\"; sourceTree = SOURCE_ROOT; };\\n\\t\\t8ED1FB31102A36F100501086 /* whoosh.aif */ = {isa = PBXFileReference; lastKnownFileType = file; path = whoosh.aif; sourceTree = \"<group>\"; };\\n/* End PBXFileReference section */\\n\\n/* Begin PBXFrameworksBuildPhase section */\\n\\t\\t1D60588F0D05DD3D006BFB54 /* Frameworks */ = {\\n\\t\\t\\tisa = PBXFrameworksBuildPhase;\\n\\t\\t\\tbuildActionMask = 2147483647;\\n\\t\\t\\tfiles = (\\n\\t\\t\\t\\t1D60589F0D05DD5A006BFB54 /* Foundation.framework in Frameworks */,\\n\\t\\t\\t\\t1DF5F4E00D08C38300B7A737 /* UIKit.framework in Frameworks */,\\n\\t\\t\\t\\t1D3623EC0D0F72F000981E51 /* CoreGraphics.framework in Frameworks */,\\n\\t\\t\\t\\t8ED1FB1B102A369E00501086 /*', '<|endoftext|> sourceTree = \"<group>\"; };\\n\\t\\t840116DC152CBBF600B07E4D /* triangle.cpp */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = triangle.cpp; sourceTree = \"<group>\"; };\\n\\t\\t840116DD152CBBF600B07E4D /* ui.cpp */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = ui.cpp; sourceTree = \"<group>\"; };\\n\\t\\t840116DE152CBBF600B07E4D /* util.cpp */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = util.cpp; sourceTree = \"<group>\"; };\\n\\t\\t840116DF152CBBF600B07E4D /* vector.cpp */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = vector.cpp; sourceTree = \"<group>\"; };\\n\\t\\t840116E0152CBBF600B07E4D /* vol.cpp */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = vol.cpp; sourceTree = \"<group>\"; };\\n\\t\\t84011729152D6E3E00B07E4D /* trace.tbb.cpp */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = trace.tbb.cpp; sourceTree = \"<group>\"; };\\n\\t\\t84011761152D6F6C00B07E4D /* tachyon.serial.app */ = {isa = PBXFileReference; explicitFileType = wrapper.application; includeInIndex = 0; path = tachyon.serial.app; sourceTree = BUILT_PRODUCTS_DIR; };\\n\\t\\t8401179A152D6F8400B07E4D /* tachyon.tbb1d.app */ = {isa = PBXFileReference; explicitFileType = wrapper.application; includeInIndex = 0; path = tachyon.tbb1d.app; sourceTree = BUILT_PRODUCTS_DIR; };\\n\\t\\t8401179D152D6FC600B07E4D /* trace.tbb1d.cpp */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = trace.tbb1d.cpp; sourceTree = \"<group>\"; };\\n\\t\\t8401179F152D6FD100B07E4D /* trace.serial.cpp */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = trace.serial.cpp; sourceTree = \"<group>\"; };\\n\\t\\t84B8DA6F152CA90100D59B95 /* main.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; name = main.m; path = ../../../common/gui/xcode/tbbExample/main.m; sourceTree = \"<group>\"; };\\n\\t\\t84B8DA70152CA90100D59B95 /* OpenGLView.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; name = OpenGLView.h; path = ../../../common/gui/xcode/tbbExample/OpenGLView.h; sourceTree = \"<group>\"; };\\n\\t\\t84B8DA71152CA90100D59B95 /* OpenGLView.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; name = OpenGLView.m; path = ../../../common/gui/xcode/tbbExample/OpenGLView.m; sourceTree = \"<group>\"; };\\n\\t\\t84B8DA72152CA90100D59B95 /* tbbAppDelegate.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; name = tbbAppDelegate.h; path = ../../../common/gui/xcode/tbbExample/tbbAppDelegate.h; sourceTree = \"<group>\"; };\\n\\t\\t84B8DA73152CA90100D59B95 /* tbbAppDelegate.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; name = tbb', '<|endoftext|>TableviewSectionViewModel.h; sourceTree = \"<group>\"; };\\n\\t\\tCB67C3CF1EA9DF4D00B6125B /* SJStaticTableviewSectionViewModel.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; path = SJStaticTableviewSectionViewModel.m; sourceTree = \"<group>\"; };\\n\\t\\tCB67C3DD1EAB820300B6125B /* SJEmoticonViewController.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = SJEmoticonViewController.h; sourceTree = \"<group>\"; };\\n\\t\\tCB67C3DE1EAB820300B6125B /* SJEmoticonViewController.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; path = SJEmoticonViewController.m; sourceTree = \"<group>\"; };\\n\\t\\tCB67C3E11EAB82D500B6125B /* MBProgressHUD.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = MBProgressHUD.h; sourceTree = \"<group>\"; };\\n\\t\\tCB67C3E21EAB82D500B6125B /* MBProgressHUD.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; path = MBProgressHUD.m; sourceTree = \"<group>\"; };\\n\\t\\tCB67C3E41EAB896F00B6125B /* Emoji.xcassets */ = {isa = PBXFileReference; lastKnownFileType = folder.assetcatalog; path = Emoji.xcassets; sourceTree = \"<group>\"; };\\n\\t\\tCBC2D26F1E7ED0BD002A5357 /* SJStaticTableViewDemo.app */ = {isa = PBXFileReference; explicitFileType = wrapper.application; includeInIndex = 0; path = SJStaticTableViewDemo.app; sourceTree = BUILT_PRODUCTS_DIR; };\\n\\t\\tCBC2D2731E7ED0BD002A5357 /* main.m */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.objc; path = main.m; sourceTree = \"<group>\"; };\\n\\t\\tCBC2D2751E7ED0BD002A5357 /* AppDelegate.h */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.h; path = AppDelegate.h; sourceTree = \"<group>\"; };\\n\\t\\tCBC2D2761E7ED0BD002A5357 /* AppDelegate.m */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.objc; path = AppDelegate.m; sourceTree = \"<group>\"; };\\n\\t\\tCBC2D2781E7ED0BD002A5357 /* ViewController.h */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.h; path = ViewController.h; sourceTree = \"<group>\"; };\\n\\t\\tCBC2D2791E7ED0BD002A5357 /* ViewController.m */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.objc; path = ViewController.m; sourceTree = \"<group>\"; };\\n\\t\\tCBC2D27C1E7ED0BD002A5357 /* Base */ = {isa = PBXFileReference; lastKnownFileType = file.storyboard; name = Base; path = Base.lproj/Main.storyboard; sourceTree = \"<group>\"; };\\n\\t\\tCBC2D2811E7ED0BD002A5357 /* Base */ = {isa = PBXFileReference; lastKnownFileType = file.storyboard; name = Base; path = Base.lproj/LaunchScreen.storyboard; sourceTree = \"<group>\"; };\\n\\t\\tCBC2D2831E7ED0BD002A5357 /* Info.plist */ = {isa = PBXFileReference; lastKnownFileType = text.plist.xml; path = Info.plist; sourceTree = \"<group>\"; };\\n\\t\\tCBC2D2881E7ED0BD002A5357 /* SJStaticTableViewDemoTests.xctest */ = {isa = PBXFileReference; explicitFileType = wrapper.cfbundle; includeInIndex = 0; path = SJStaticTableViewDemoTests.xctest; sourceTree = BUILT_PRODUCTS_DIR; };\\n\\t\\tCBC2D28C1', '<|endoftext|>\\t8FA6F8A5135F9FD7003CF4D6 /* ReadMe.txt in Resources */ = {isa = PBXBuildFile; fileRef = 8FA6F8A4135F9FD7003CF4D6 /* ReadMe.txt */; };\\n\\t\\t8FA6FAC313664E89003CF4D6 /* Icon-72.png in Resources */ = {isa = PBXBuildFile; fileRef = 8FA6FABC13664E89003CF4D6 /* Icon-72.png */; };\\n\\t\\t8FA6FAC413664E89003CF4D6 /* Icon-Small-50.png in Resources */ = {isa = PBXBuildFile; fileRef = 8FA6FABD13664E89003CF4D6 /* Icon-Small-50.png */; };\\n\\t\\t8FA6FAC513664E89003CF4D6 /* Icon-Small.png in Resources */ = {isa = PBXBuildFile; fileRef = 8FA6FABE13664E89003CF4D6 /* Icon-Small.png */; };\\n\\t\\t8FA6FAC613664E89003CF4D6 /* Icon-Small@2x.png in Resources */ = {isa = PBXBuildFile; fileRef = 8FA6FABF13664E89003CF4D6 /* Icon-Small@2x.png */; };\\n\\t\\t8FA6FAC713664E89003CF4D6 /* Icon.png in Resources */ = {isa = PBXBuildFile; fileRef = 8FA6FAC013664E89003CF4D6 /* Icon.png */; };\\n\\t\\t8FA6FAC813664E89003CF4D6 /* Icon@2x.png in Resources */ = {isa = PBXBuildFile; fileRef = 8FA6FAC113664E89003CF4D6 /* Icon@2x.png */; };\\n\\t\\t8FA6FADE13665025003CF4D6 /* iTunesArtwork in Resources */ = {isa = PBXBuildFile; fileRef = 8FA6FADD13665025003CF4D6 /* iTunesArtwork */; };\\n\\t\\t8FA96C2512F3917D00F25744 /* PlayerModel.m in Sources */ = {isa = PBXBuildFile; fileRef = 8FA96C2412F3917D00F25744 /* PlayerModel.m */; };\\n/* End PBXBuildFile section */\\n\\n/* Begin PBXFileReference section */\\n\\t\\t1D30AB110D05D00D00671497 /* Foundation.framework */ = {isa = PBXFileReference; lastKnownFileType = wrapper.framework; name = Foundation.framework; path = System/Library/Frameworks/Foundation.framework; sourceTree = SDKROOT; };\\n\\t\\t1D3623240D0F684500981E51 /* GKAchievementsAppDelegate.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = GKAchievementsAppDelegate.h; sourceTree = \"<group>\"; };\\n\\t\\t1D3623250D0F684500981E51 /* GKAchievementsAppDelegate.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; path = GKAchievementsAppDelegate.m; sourceTree = \"<group>\"; };\\n\\t\\t1D6058910D05DD3D006BFB54 /* GKAchievements.app */ = {isa = PBXFileReference; explicitFileType = wrapper.application; includeInIndex = 0; path = GKAchievements.app; sourceTree = BUILT_PRODUCTS_DIR; };\\n\\t\\t1DF5F4DF0D08C38300B7A737 /* UIKit.framework */ = {isa = PBXFileReference; lastKnownFileType = wrapper.framework; name = UIKit.framework; path = System/Library/Frameworks/UIKit.framework; sourceTree = SDKROOT; };\\n\\t\\t288765A40DF7441C002DB57D /* CoreGraphics.framework */ = {isa = PBXFileReference; lastKnownFileType = wrapper.framework; name = CoreGraphics.framework; path = System/Library/Frameworks/CoreGraphics.framework; sourceTree = SDKROOT; };\\n\\t\\t29B97316FDCFA39411CA2CEA /* main.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; path = main.m;', '<|endoftext|>h; path = PSTCollectionViewItemKey.h; sourceTree = \"<group>\"; };\\n\\t\\t4C3A072216316EB30064777C /* PSTCollectionViewItemKey.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; path = PSTCollectionViewItemKey.m; sourceTree = \"<group>\"; };\\n\\t\\t4C3A072316316EB30064777C /* PSTCollectionViewLayout.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = PSTCollectionViewLayout.h; sourceTree = \"<group>\"; };\\n\\t\\t4C3A072416316EB30064777C /* PSTCollectionViewLayout.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; path = PSTCollectionViewLayout.m; sourceTree = \"<group>\"; };\\n\\t\\t4C3A072516316EB30064777C /* PSTGridLayoutInfo.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = PSTGridLayoutInfo.h; sourceTree = \"<group>\"; };\\n\\t\\t4C3A072616316EB30064777C /* PSTGridLayoutInfo.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; path = PSTGridLayoutInfo.m; sourceTree = \"<group>\"; };\\n\\t\\t4C3A072716316EB30064777C /* PSTGridLayoutItem.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = PSTGridLayoutItem.h; sourceTree = \"<group>\"; };\\n\\t\\t4C3A072816316EB30064777C /* PSTGridLayoutItem.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; path = PSTGridLayoutItem.m; sourceTree = \"<group>\"; };\\n\\t\\t4C3A072916316EB30064777C /* PSTGridLayoutRow.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = PSTGridLayoutRow.h; sourceTree = \"<group>\"; };\\n\\t\\t4C3A072A16316EB30064777C /* PSTGridLayoutRow.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; path = PSTGridLayoutRow.m; sourceTree = \"<group>\"; };\\n\\t\\t4C3A072B16316EB30064777C /* PSTGridLayoutSection.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = PSTGridLayoutSection.h; sourceTree = \"<group>\"; };\\n\\t\\t4C3A072C16316EB30064777C /* PSTGridLayoutSection.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; path = PSTGridLayoutSection.m; sourceTree = \"<group>\"; };\\n\\t\\t4C3A073D16316F4C0064777C /* QuartzCore.framework */ = {isa = PBXFileReference; lastKnownFileType = wrapper.framework; name = QuartzCore.framework; path = System/Library/Frameworks/QuartzCore.framework; sourceTree = SDKROOT; };\\n\\t\\t78E7A7631654EF00000C70BE /* PSTCollectionViewUpdateItem.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = PSTCollectionViewUpdateItem.h; sourceTree = \"<group>\"; };\\n\\t\\t78E7A7641654EF00000C70BE /* PSTCollectionViewUpdateItem.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; path = PSTCollectionViewUpdateItem.m; sourceTree = \"<group>\"; };\\n\\t\\t981FA1E316C79B6E00F6149A /* NSIndexPath+PSTCollectionViewAdditions.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = \"NSIndexPath+PSTCollectionViewAdditions.h\"; sourceTree = \"<group>\"; };\\n\\t\\t981FA1E416C79B6E00F6149A /* NSIndexPath+', '<|endoftext|> = Library/Frameworks/XCTest.framework; sourceTree = DEVELOPER_DIR; };\\n\\t\\t526F369E18862DE0002CC3DA /* Foundation.framework */ = {isa = PBXFileReference; lastKnownFileType = wrapper.framework; name = Foundation.framework; path = Library/Frameworks/Foundation.framework; sourceTree = DEVELOPER_DIR; };\\n\\t\\t526F36A018862DE0002CC3DA /* UIKit.framework */ = {isa = PBXFileReference; lastKnownFileType = wrapper.framework; name = UIKit.framework; path = Library/Frameworks/UIKit.framework; sourceTree = DEVELOPER_DIR; };\\n\\t\\t526F36A418862DE0002CC3DA /* BNRDynamicTypeManager Tests-Info.plist */ = {isa = PBXFileReference; lastKnownFileType = text.plist.xml; path = \"BNRDynamicTypeManager Tests-Info.plist\"; sourceTree = \"<group>\"; };\\n\\t\\t526F36A618862DE0002CC3DA /* en */ = {isa = PBXFileReference; lastKnownFileType = text.plist.strings; name = en; path = en.lproj/InfoPlist.strings; sourceTree = \"<group>\"; };\\n\\t\\t526F36A818862DE0002CC3DA /* BNRDynamicTypeManagerTests.m */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.objc; path = BNRDynamicTypeManagerTests.m; sourceTree = \"<group>\"; };\\n\\t\\t526F36AA18862DE0002CC3DA /* BNRDynamicTypeManager Tests-Prefix.pch */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.h; path = \"BNRDynamicTypeManager Tests-Prefix.pch\"; sourceTree = \"<group>\"; };\\n\\t\\t526F36B3188636EB002CC3DA /* BNRDynamicTypeManagedLabelTests.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; path = BNRDynamicTypeManagedLabelTests.m; sourceTree = \"<group>\"; };\\n\\t\\t526F36B518863978002CC3DA /* BNRDynamicTypeControlTest.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; path = BNRDynamicTypeControlTest.m; sourceTree = \"<group>\"; };\\n\\t\\t526F36B718863989002CC3DA /* BNRDynamicTypeControlTest.h */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.h; path = BNRDynamicTypeControlTest.h; sourceTree = \"<group>\"; };\\n\\t\\t526F36B818863D02002CC3DA /* BNRDynamicTypeManagedLabel.xib */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = file.xib; path = BNRDynamicTypeManagedLabel.xib; sourceTree = \"<group>\"; };\\n\\t\\t526F36BA18863E61002CC3DA /* BNRDynamicTypeManagedTextFieldTests.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; path = BNRDynamicTypeManagedTextFieldTests.m; sourceTree = \"<group>\"; };\\n\\t\\t526F36BC18863EF0002CC3DA /* BNRDynamicTypeManagedTextField.xib */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = file.xib; path = BNRDynamicTypeManagedTextField.xib; sourceTree = \"<group>\"; };\\n\\t\\t526F36BE18863F4E002CC3DA /* BNRDynamicTypeManagedTextViewTests.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; path = BNRDynamicTypeManagedTextViewTests.m; sourceTree = \"<group>\"; };\\n\\t\\t526F36C018863F96002CC3DA /* BNRDynamicTypeManagedTextView.xib */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = file.xib; path = BNRDynamicTypeManagedTextView.xib; sourceTree = \"<group>\"; };\\n\\t\\t526F36C2188640D6002CC3DA /* BNRDynamicTypeManagedButtonTests.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; path = BNRDynamicTypeManagedButtonTests.m; sourceTree = \"<group>\"; };\\n\\t\\t526F36C418864135002CC3DA /* BNRDynamicTypeManagedButton', '<|endoftext|>Reference section */\\n\\t\\t32272D511B7961E30010A4BA /* LaunchScreen.storyboard */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = file.storyboard; path = LaunchScreen.storyboard; sourceTree = \"<group>\"; };\\n\\t\\t326C8031197AB211003C0B1C /* ch19p632containerControllerConstraints-Bridging-Header.h */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.h; path = \"ch19p632containerControllerConstraints-Bridging-Header.h\"; sourceTree = \"<group>\"; };\\n\\t\\t326C8032197AB211003C0B1C /* ViewController.swift */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.swift; path = ViewController.swift; sourceTree = \"<group>\"; };\\n\\t\\tC910675C17D0515F00AC4CDA /* ch19p632containerControllerConstraints.app */ = {isa = PBXFileReference; explicitFileType = wrapper.application; includeInIndex = 0; path = ch19p632containerControllerConstraints.app; sourceTree = BUILT_PRODUCTS_DIR; };\\n\\t\\tC910676717D0515F00AC4CDA /* ch19p632containerControllerConstraints-Info.plist */ = {isa = PBXFileReference; lastKnownFileType = text.plist.xml; path = \"ch19p632containerControllerConstraints-Info.plist\"; sourceTree = \"<group>\"; };\\n\\t\\tC910676B17D0515F00AC4CDA /* main.m */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.objc; path = main.m; sourceTree = \"<group>\"; };\\n\\t\\tC910676E17D0515F00AC4CDA /* AppDelegate.h */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.h; path = AppDelegate.h; sourceTree = \"<group>\"; };\\n\\t\\tC910676F17D0515F00AC4CDA /* AppDelegate.m */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.objc; path = AppDelegate.m; sourceTree = \"<group>\"; };\\n\\t\\tC910677217D0515F00AC4CDA /* Base */ = {isa = PBXFileReference; lastKnownFileType = file.storyboard; name = Base; path = Base.lproj/Main.storyboard; sourceTree = \"<group>\"; };\\n\\t\\tC910677717D0515F00AC4CDA /* Assets.xcassets */ = {isa = PBXFileReference; lastKnownFileType = folder.assetcatalog; path = Assets.xcassets; sourceTree = \"<group>\"; };\\n\\t\\tC910679417D0526B00AC4CDA /* FirstView.xib */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = file.xib; path = FirstView.xib; sourceTree = \"<group>\"; };\\n\\t\\tC910679517D0526B00AC4CDA /* FirstViewController.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = FirstViewController.h; sourceTree = \"<group>\"; };\\n\\t\\tC910679617D0526B00AC4CDA /* FirstViewController.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; path = FirstViewController.m; sourceTree = \"<group>\"; };\\n\\t\\tC910679717D0526B00AC4CDA /* SecondView.xib */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = file.xib; path = SecondView.xib; sourceTree = \"<group>\"; };\\n\\t\\tC910679817D0526B00AC4CDA /* SecondViewController.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = SecondViewController.h; sourceTree = \"<group>\"; };\\n\\t\\tC910679917D0526B00AC4CDA /* SecondViewController.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; path = SecondViewController.m; sourceTree = \"<group>\"; };\\n/* End PBXFileReference section */\\n\\n/* Begin PBXFrameworksBuildPhase section */\\n\\t\\tC910675917D0515F00AC4CDA /* Frameworks */ =', '<|endoftext|>18009701BF /* ModelGroup.xcdatamodeld in Sources */ = {isa = PBXBuildFile; fileRef = 148C33461BD7CB18009701BF /* ModelGroup.xcdatamodeld */; };\\n\\t\\t148C33511BD7CB67009701BF /* main.m in Sources */ = {isa = PBXBuildFile; fileRef = 148C33501BD7CB67009701BF /* main.m */; };\\n\\t\\t148C33541BD7CB67009701BF /* AppDelegate.m in Sources */ = {isa = PBXBuildFile; fileRef = 148C33531BD7CB67009701BF /* AppDelegate.m */; };\\n\\t\\t148C33571BD7CB67009701BF /* DemoObjectiveC.xcdatamodeld in Sources */ = {isa = PBXBuildFile; fileRef = 148C33551BD7CB67009701BF /* DemoObjectiveC.xcdatamodeld */; };\\n\\t\\t148C33591BD7CB67009701BF /* Assets.xcassets in Resources */ = {isa = PBXBuildFile; fileRef = 148C33581BD7CB67009701BF /* Assets.xcassets */; };\\n\\t\\t148C335C1BD7CB67009701BF /* LaunchScreen.storyboard in Resources */ = {isa = PBXBuildFile; fileRef = 148C335A1BD7CB67009701BF /* LaunchScreen.storyboard */; };\\n\\t\\t148C33681BD7CB74009701BF /* AppDelegate.swift in Sources */ = {isa = PBXBuildFile; fileRef = 148C33671BD7CB74009701BF /* AppDelegate.swift */; };\\n\\t\\t148C336B1BD7CB74009701BF /* DemoSwift.xcdatamodeld in Sources */ = {isa = PBXBuildFile; fileRef = 148C33691BD7CB74009701BF /* DemoSwift.xcdatamodeld */; };\\n\\t\\t148C336D1BD7CB74009701BF /* Assets.xcassets in Resources */ = {isa = PBXBuildFile; fileRef = 148C336C1BD7CB74009701BF /* Assets.xcassets */; };\\n\\t\\t148C33701BD7CB74009701BF /* LaunchScreen.storyboard in Resources */ = {isa = PBXBuildFile; fileRef = 148C336E1BD7CB74009701BF /* LaunchScreen.storyboard */; };\\n\\t\\t148C33771BD7CB98009701BF /* ViewController.m in Sources */ = {isa = PBXBuildFile; fileRef = 148C33761BD7CB98009701BF /* ViewController.m */; };\\n\\t\\t148C33791BD7CBAC009701BF /* ViewController.swift in Sources */ = {isa = PBXBuildFile; fileRef = 148C33781BD7CBAC009701BF /* ViewController.swift */; };\\n\\t\\t148DF0DB1DAA782000638F9F /* LightweightMigrationModel.xcdatamodel in Sources */ = {isa = PBXBuildFile; fileRef = 148DF0DA1DAA782000638F9F /* LightweightMigrationModel.xcdatamodel */; };\\n\\t\\t14A139B41AEFC72B00AD732F /* Tests.swift in Sources */ = {isa = PBXBuildFile; fileRef = 14A139B31AEFC72B00AD732F /* Tests.swift */; };\\n\\t\\t14B46FA31CBF90D2004779E2 /* DATAStack.h in Headers */ = {isa = PBXBuildFile; fileRef = 14B3898D1CBF8166001123DC /* DATAStack.h */; settings = {ATTRIBUTES = (Public, ); }; };\\n\\t\\t14BC053A1CBEF21C006278EA /* DATAStack.swift in Sources */ = {isa = PBXBuildFile; fileRef = 14BC05381CBEF21C006278EA /* DATAStack.swift */; };\\n\\t\\t14BC053B1CBEF21C006278EA /* DATAStack.swift in Sources */ = {isa = PBXBuildFile; fileRef = 14BC05381CBEF21C006278EA /* DATAStack.swift */; };\\n\\t\\t14BC053C1CBEF21C006278EA /* DATAStack.swift in Sources */ = {isa = PBXBuildFile; fileRef = 14BC05381CBEF21C006278EA /* DATAStack.', '<|endoftext|>;\\n\\t\\t\\tremoteInfo = EventCenterMac;\\n\\t\\t};\\n/* End PBXContainerItemProxy section */\\n\\n/* Begin PBXFileReference section */\\n\\t\\t35FF85751E1CDC9B00A664D3 /* TestApp-iOS.app */ = {isa = PBXFileReference; explicitFileType = wrapper.application; includeInIndex = 0; path = \"TestApp-iOS.app\"; sourceTree = BUILT_PRODUCTS_DIR; };\\n\\t\\t35FF85781E1CDC9B00A664D3 /* main.m */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.objc; path = main.m; sourceTree = \"<group>\"; };\\n\\t\\t35FF857A1E1CDC9B00A664D3 /* AppDelegate.h */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.h; path = AppDelegate.h; sourceTree = \"<group>\"; };\\n\\t\\t35FF857B1E1CDC9B00A664D3 /* AppDelegate.m */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.objc; path = AppDelegate.m; sourceTree = \"<group>\"; };\\n\\t\\t35FF857D1E1CDC9B00A664D3 /* ViewController.h */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.h; path = ViewController.h; sourceTree = \"<group>\"; };\\n\\t\\t35FF857E1E1CDC9B00A664D3 /* ViewController.m */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.objc; path = ViewController.m; sourceTree = \"<group>\"; };\\n\\t\\t35FF85811E1CDC9B00A664D3 /* Base */ = {isa = PBXFileReference; lastKnownFileType = file.storyboard; name = Base; path = Base.lproj/Main.storyboard; sourceTree = \"<group>\"; };\\n\\t\\t35FF85831E1CDC9B00A664D3 /* Assets.xcassets */ = {isa = PBXFileReference; lastKnownFileType = folder.assetcatalog; path = Assets.xcassets; sourceTree = \"<group>\"; };\\n\\t\\t35FF85861E1CDC9B00A664D3 /* Base */ = {isa = PBXFileReference; lastKnownFileType = file.storyboard; name = Base; path = Base.lproj/LaunchScreen.storyboard; sourceTree = \"<group>\"; };\\n\\t\\t35FF85881E1CDC9B00A664D3 /* Info.plist */ = {isa = PBXFileReference; lastKnownFileType = text.plist.xml; path = Info.plist; sourceTree = \"<group>\"; };\\n\\t\\t35FF85A81E1CE05500A664D3 /* MobileCoreServices.framework */ = {isa = PBXFileReference; lastKnownFileType = wrapper.framework; name = MobileCoreServices.framework; path = Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS10.1.sdk/System/Library/Frameworks/MobileCoreServices.framework; sourceTree = DEVELOPER_DIR; };\\n\\t\\t35FF871A1E1E423800A664D3 /* IOKit */ = {isa = PBXFileReference; lastKnownFileType = \"compiled.mach-o.dylib\"; name = IOKit; path = ../../OTC/Frameworks/iOS7/IOKit.framework/Versions/A/IOKit; sourceTree = \"<group>\"; };\\n\\t\\t35FF871C1E1E425E00A664D3 /* IPC.xcodeproj */ = {isa = PBXFileReference; lastKnownFileType = \"wrapper.pb-project\"; name = IPC.xcodeproj; path = \"../../IPC/Source-IPC/IPC.xcodeproj\"; sourceTree = \"<group>\"; };\\n\\t\\tC224F5731CC4CB43007C7AF8 /* UnstructuredManager.xcodeproj */ = {isa = PBXFileReference; lastKnownFileType = \"wrapper.pb-project\"; name = UnstructuredManager.xcodeproj; path = ../../PhoenixEngine/Phoenix/UnstructuredManager/UnstructuredManager.xcodeproj; sourceTree = \"<group>\"; };\\n\\t\\tC224F57F1CC4CB62007C7AF8 /* HTTP.xcodeproj */ = {isa = PBXFileReference; lastKnownFileType = \"wrapper.pb-project\"; name = HTTP.xc', '<|endoftext|> */ = {isa = PBXBuildFile; fileRef = 4C3A072816316EB30064777C /* PSTGridLayoutItem.m */; };\\n\\t\\t4C3A073616316EB30064777C /* PSTGridLayoutRow.m in Sources */ = {isa = PBXBuildFile; fileRef = 4C3A072A16316EB30064777C /* PSTGridLayoutRow.m */; };\\n\\t\\t4C3A073716316EB30064777C /* PSTGridLayoutSection.m in Sources */ = {isa = PBXBuildFile; fileRef = 4C3A072C16316EB30064777C /* PSTGridLayoutSection.m */; };\\n\\t\\t4C3A073E16316F4C0064777C /* QuartzCore.framework in Frameworks */ = {isa = PBXBuildFile; fileRef = 4C3A073D16316F4C0064777C /* QuartzCore.framework */; };\\n\\t\\t78E7A7651654EF00000C70BE /* PSTCollectionViewUpdateItem.m in Sources */ = {isa = PBXBuildFile; fileRef = 78E7A7641654EF00000C70BE /* PSTCollectionViewUpdateItem.m */; };\\n\\t\\t981FA1E516C79B6E00F6149A /* NSIndexPath+PSTCollectionViewAdditions.m in Sources */ = {isa = PBXBuildFile; fileRef = 981FA1E416C79B6E00F6149A /* NSIndexPath+PSTCollectionViewAdditions.m */; };\\n/* End PBXBuildFile section */\\n\\n/* Begin PBXFileReference section */\\n\\t\\t4C3A06E6163167080064777C /* CollectionExample.app */ = {isa = PBXFileReference; explicitFileType = wrapper.application; includeInIndex = 0; path = CollectionExample.app; sourceTree = BUILT_PRODUCTS_DIR; };\\n\\t\\t4C3A06EA163167080064777C /* UIKit.framework */ = {isa = PBXFileReference; lastKnownFileType = wrapper.framework; name = UIKit.framework; path = System/Library/Frameworks/UIKit.framework; sourceTree = SDKROOT; };\\n\\t\\t4C3A06EC163167080064777C /* Foundation.framework */ = {isa = PBXFileReference; lastKnownFileType = wrapper.framework; name = Foundation.framework; path = System/Library/Frameworks/Foundation.framework; sourceTree = SDKROOT; };\\n\\t\\t4C3A06EE163167080064777C /* CoreGraphics.framework */ = {isa = PBXFileReference; lastKnownFileType = wrapper.framework; name = CoreGraphics.framework; path = System/Library/Frameworks/CoreGraphics.framework; sourceTree = SDKROOT; };\\n\\t\\t4C3A06F2163167080064777C /* CollectionExample-Info.plist */ = {isa = PBXFileReference; lastKnownFileType = text.plist.xml; path = \"CollectionExample-Info.plist\"; sourceTree = \"<group>\"; };\\n\\t\\t4C3A06F4163167080064777C /* en */ = {isa = PBXFileReference; lastKnownFileType = text.plist.strings; name = en; path = en.lproj/InfoPlist.strings; sourceTree = \"<group>\"; };\\n\\t\\t4C3A06F6163167080064777C /* main.m */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.objc; path = main.m; sourceTree = \"<group>\"; };\\n\\t\\t4C3A06F8163167080064777C /* CollectionExample-Prefix.pch */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.h; path = \"CollectionExample-Prefix.pch\"; sourceTree = \"<group>\"; };\\n\\t\\t4C3A06F9163167080064777C /* AppDelegate.h */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.h; path = AppDelegate.h; sourceTree = \"<group>\"; };\\n\\t\\t4C3A06FA163167080064777C /* AppDelegate.m */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.objc; path = AppDelegate.m; sourceTree = \"<group>\"; };\\n\\t\\t4C3A06FC163167080064777C /* Default.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = Default.png; sourceTree = \"<group>\"; };\\n\\t\\t4C', '<|endoftext|>262 /* UIBezierPath+Trim.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = \"UIBezierPath+Trim.h\"; sourceTree = \"<group>\"; };\\n\\t\\t66D1B7961AFEAC6F00210262 /* UIBezierPath+Trim.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; path = \"UIBezierPath+Trim.m\"; sourceTree = \"<group>\"; };\\n\\t\\t66D4021C1A7EDA9000043802 /* PerformanceBezierClockwiseTests.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; path = PerformanceBezierClockwiseTests.m; sourceTree = \"<group>\"; };\\n\\t\\t66D4021E1A7EDACA00043802 /* PerformanceBezierAbstractTest.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = PerformanceBezierAbstractTest.h; sourceTree = \"<group>\"; };\\n\\t\\t66D4021F1A7EDACA00043802 /* PerformanceBezierAbstractTest.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; path = PerformanceBezierAbstractTest.m; sourceTree = \"<group>\"; };\\n\\t\\t66F2EBE31A8DC05100D536E9 /* PerformanceBezier.framework */ = {isa = PBXFileReference; explicitFileType = wrapper.framework.static; includeInIndex = 0; path = PerformanceBezier.framework; sourceTree = BUILT_PRODUCTS_DIR; };\\n\\t\\t66F2EBE71A8DC05100D536E9 /* Info.plist */ = {isa = PBXFileReference; lastKnownFileType = text.plist.xml; path = Info.plist; sourceTree = \"<group>\"; };\\n\\t\\t66F2EBEA1A8DC05100D536E9 /* PerformanceBezier-Info.plist */ = {isa = PBXFileReference; lastKnownFileType = text.plist.xml; path = \"PerformanceBezier-Info.plist\"; sourceTree = \"<group>\"; };\\n\\t\\tC51D49D324771241002BECC8 /* PerformanceBezierElementTest.m */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.objc; path = PerformanceBezierElementTest.m; sourceTree = \"<group>\"; };\\n\\t\\tC57B2FB2247871A200C4D44B /* PerformanceBezierEqualsTest.m */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.objc; path = PerformanceBezierEqualsTest.m; sourceTree = \"<group>\"; };\\n\\t\\tC5976A47246DE9D10018C3C5 /* PerformanceBezierTrimTest.m */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.objc; path = PerformanceBezierTrimTest.m; sourceTree = \"<group>\"; };\\n/* End PBXFileReference section */\\n\\n/* Begin PBXFrameworksBuildPhase section */\\n\\t\\t66B9D2891A8D5FDE00CAC341 /* Frameworks */ = {\\n\\t\\t\\tisa = PBXFrameworksBuildPhase;\\n\\t\\t\\tbuildActionMask = 2147483647;\\n\\t\\t\\tfiles = (\\n\\t\\t\\t\\t6617530D1A8DC45A0051D5CB /* PerformanceBezier.framework in Frameworks */,\\n\\t\\t\\t);\\n\\t\\t\\trunOnlyForDeploymentPostprocessing = 0;\\n\\t\\t};\\n\\t\\t66F2EBDE1A8DC05100D536E9 /* Frameworks */ = {\\n\\t\\t\\tisa = PBXFrameworksBuildPhase;\\n\\t\\t\\tbuildActionMask = 2147483647;\\n\\t\\t\\tfiles = (\\n\\t\\t\\t\\t66F2EBE41A8DC05100D536E9 /* Foundation.framework in Frameworks */,\\n\\t\\t\\t);\\n\\t\\t\\trunOnlyForDeploymentPostprocessing = 0;\\n\\t\\t};\\n/* End PBXFrameworksBuildPhase section */\\n\\n/* Begin PBXGroup section */\\n\\t\\t661B30C81A7EB43A008549C7 = {\\n\\t\\t\\tisa = PBXGroup;\\n\\t\\t\\tchildren = (\\n\\t\\t\\t\\t660E0FDB1A80226100F19D8A /* README.md */,\\n\\t\\t\\t\\t66767CC71AFEE4BB00443B03 /* SubdivideLicense */,\\n\\t\\t\\t\\t660E0FDC1A80284C00F19D8A /* LICENSE */,\\n\\t\\t\\t\\t66B9D2831', '<|endoftext|>ItemProxy */ = {\\n\\t\\t\\tisa = PBXContainerItemProxy;\\n\\t\\t\\tcontainerPortal = 0867D690FE84028FC02AAC07 /* Project object */;\\n\\t\\t\\tproxyType = 1;\\n\\t\\t\\tremoteGlobalIDString = 3B07BDE90E3F3F9E00647869;\\n\\t\\t\\tremoteInfo = WidgetFrameworkTest;\\n\\t\\t};\\n\\t\\t4024D1EC113D840900C7059E /* PBXContainerItemProxy */ = {\\n\\t\\t\\tisa = PBXContainerItemProxy;\\n\\t\\t\\tcontainerPortal = 0867D690FE84028FC02AAC07 /* Project object */;\\n\\t\\t\\tproxyType = 1;\\n\\t\\t\\tremoteGlobalIDString = 8D07F2BC0486CC7A007CD1D0;\\n\\t\\t\\tremoteInfo = WidgetFramework;\\n\\t\\t};\\n\\t\\t4024D1EE113D840D00C7059E /* PBXContainerItemProxy */ = {\\n\\t\\t\\tisa = PBXContainerItemProxy;\\n\\t\\t\\tcontainerPortal = 0867D690FE84028FC02AAC07 /* Project object */;\\n\\t\\t\\tproxyType = 1;\\n\\t\\t\\tremoteGlobalIDString = 4024D162113D7D2400C7059E;\\n\\t\\t\\tremoteInfo = Test;\\n\\t\\t};\\n/* End PBXContainerItemProxy section */\\n\\n/* Begin PBXFileReference section */\\n\\t\\t3B07BDEA0E3F3F9E00647869 /* WidgetFrameworkTest */ = {isa = PBXFileReference; explicitFileType = \"compiled.mach-o.executable\"; includeInIndex = 0; path = WidgetFrameworkTest; sourceTree = BUILT_PRODUCTS_DIR; };\\n\\t\\t3B7EB1230E5AEE3500C7F239 /* widget.cc */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = widget.cc; sourceTree = \"<group>\"; };\\n\\t\\t3B7EB1240E5AEE3500C7F239 /* widget.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = widget.h; sourceTree = \"<group>\"; };\\n\\t\\t3B7EB1270E5AEE4600C7F239 /* widget_test.cc */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = widget_test.cc; sourceTree = \"<group>\"; };\\n\\t\\t4024D183113D7D5500C7059E /* libgtest_main.a */ = {isa = PBXFileReference; lastKnownFileType = archive.ar; name = libgtest_main.a; path = /usr/local/lib/libgtest_main.a; sourceTree = \"<absolute>\"; };\\n\\t\\t4024D185113D7D5500C7059E /* libgtest.a */ = {isa = PBXFileReference; lastKnownFileType = archive.ar; name = libgtest.a; path = /usr/local/lib/libgtest.a; sourceTree = \"<absolute>\"; };\\n\\t\\t4024D1E2113D838200C7059E /* runtests.sh */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = text.script.sh; path = runtests.sh; sourceTree = \"<group>\"; };\\n\\t\\t8D07F2C70486CC7A007CD1D0 /* Info.plist */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = text.plist; path = Info.plist; sourceTree = \"<group>\"; };\\n\\t\\t8D07F2C80486CC7A007CD1D0 /* Widget.framework */ = {isa = PBXFileReference; explicitFileType = wrapper.framework; includeInIndex = 0; path = Widget.framework; sourceTree = BUILT_PRODUCTS_DIR; };\\n/* End PBXFileReference section */\\n\\n/* Begin PBXFrameworksBuildPhase section */\\n\\t\\t3B07BDE80E3F3F9E00647869 /* Frameworks */ = {\\n\\t\\t\\tisa = PBXFrameworksBuildPhase;\\n\\t\\t\\tbuildActionMask = 2147483647;\\n\\t\\t\\tfiles = (\\n\\t\\t\\t\\t4024D189113D7D7A00C7059E /* libgtest_main.a in Frameworks */,\\n\\t\\t\\t\\t4024D188113D7D7800C7059E /* libgtest.a in Frameworks */,\\n\\t\\t\\t\\t3B7EB1480E5AF3B400C7F239 /*', '<|endoftext|>18E593D300849289 /* PBXContainerItemProxy */ = {\\n\\t\\t\\tisa = PBXContainerItemProxy;\\n\\t\\t\\tcontainerPortal = C2655E2417D70C9F00F0DF40 /* FxStd.xcodeproj */;\\n\\t\\t\\tproxyType = 2;\\n\\t\\t\\tremoteGlobalIDString = 0885379A17F98FC900AB08F2;\\n\\t\\t\\tremoteInfo = FxStdMac;\\n\\t\\t};\\n\\t\\t35051C7718E593D300849289 /* PBXContainerItemProxy */ = {\\n\\t\\t\\tisa = PBXContainerItemProxy;\\n\\t\\t\\tcontainerPortal = C2655E1E17D70C9100F0DF40 /* IPC.xcodeproj */;\\n\\t\\t\\tproxyType = 2;\\n\\t\\t\\tremoteGlobalIDString = 086B114117FA732900D21FD5;\\n\\t\\t\\tremoteInfo = IPCMac;\\n\\t\\t};\\n\\t\\tC2655E1317D70C6300F0DF40 /* PBXContainerItemProxy */ = {\\n\\t\\t\\tisa = PBXContainerItemProxy;\\n\\t\\t\\tcontainerPortal = C2655E0F17D70C6300F0DF40 /* FxEvents.xcodeproj */;\\n\\t\\t\\tproxyType = 2;\\n\\t\\t\\tremoteGlobalIDString = D2AAC07E0554694100DB518D;\\n\\t\\t\\tremoteInfo = FxEvents;\\n\\t\\t};\\n\\t\\tC2655E2217D70C9100F0DF40 /* PBXContainerItemProxy */ = {\\n\\t\\t\\tisa = PBXContainerItemProxy;\\n\\t\\t\\tcontainerPortal = C2655E1E17D70C9100F0DF40 /* IPC.xcodeproj */;\\n\\t\\t\\tproxyType = 2;\\n\\t\\t\\tremoteGlobalIDString = D2AAC07E0554694100DB518D;\\n\\t\\t\\tremoteInfo = IPC;\\n\\t\\t};\\n\\t\\tC2655E2817D70C9F00F0DF40 /* PBXContainerItemProxy */ = {\\n\\t\\t\\tisa = PBXContainerItemProxy;\\n\\t\\t\\tcontainerPortal = C2655E2417D70C9F00F0DF40 /* FxStd.xcodeproj */;\\n\\t\\t\\tproxyType = 2;\\n\\t\\t\\tremoteGlobalIDString = D2AAC07E0554694100DB518D;\\n\\t\\t\\tremoteInfo = FxStd;\\n\\t\\t};\\n\\t\\tC2655E2E17D70CA600F0DF40 /* PBXContainerItemProxy */ = {\\n\\t\\t\\tisa = PBXContainerItemProxy;\\n\\t\\t\\tcontainerPortal = C2655E0F17D70C6300F0DF40 /* FxEvents.xcodeproj */;\\n\\t\\t\\tproxyType = 1;\\n\\t\\t\\tremoteGlobalIDString = D2AAC07D0554694100DB518D;\\n\\t\\t\\tremoteInfo = FxEvents;\\n\\t\\t};\\n\\t\\tC2655E3C17D70CA600F0DF40 /* PBXContainerItemProxy */ = {\\n\\t\\t\\tisa = PBXContainerItemProxy;\\n\\t\\t\\tcontainerPortal = C2655E1E17D70C9100F0DF40 /* IPC.xcodeproj */;\\n\\t\\t\\tproxyType = 1;\\n\\t\\t\\tremoteGlobalIDString = D2AAC07D0554694100DB518D;\\n\\t\\t\\tremoteInfo = IPC;\\n\\t\\t};\\n\\t\\tC2655F5517D71E4E00F0DF40 /* PBXContainerItemProxy */ = {\\n\\t\\t\\tisa = PBXContainerItemProxy;\\n\\t\\t\\tcontainerPortal = C2655E2417D70C9F00F0DF40 /* FxStd.xcodeproj */;\\n\\t\\t\\tproxyType = 1;\\n\\t\\t\\tremoteGlobalIDString = D2AAC07D0554694100DB518D;\\n\\t\\t\\tremoteInfo = FxStd;\\n\\t\\t};\\n/* End PBXContainerItemProxy section */\\n\\n/* Begin PBXFileReference section */\\n\\t\\t32CA4F630368D1EE00C91783 /* MSFKL_Prefix.pch */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = MSFKL_Prefix.pch; sourceTree = \"<group>\"; };\\n\\t\\t35051C8B18E5955500849289 /* libsubstrate_arm64.dylib */ = {isa = PBXFileReference; lastKnownFileType = \"compiled.mach-o.dylib\"; name = libsubstrate_arm64.dylib; path = ../../OTC/MobileSubstrate/libsubstrate_arm64.dylib; sourceTree =', '<|endoftext|>ylib\"; name = libxml2.2.dylib; path = usr/lib/libxml2.2.dylib; sourceTree = SDKROOT; };\\n\\t\\t04A618F412CA84FC004ADB76 /* AppDelegate.lua */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = text; path = AppDelegate.lua; sourceTree = \"<group>\"; };\\n\\t\\t04A618F612CA84FC004ADB76 /* init.lua */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = text; path = init.lua; sourceTree = \"<group>\"; };\\n\\t\\t04A618F712CA84FC004ADB76 /* someTest.lua */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = text; path = someTest.lua; sourceTree = \"<group>\"; };\\n\\t\\t1D30AB110D05D00D00671497 /* Foundation.framework */ = {isa = PBXFileReference; lastKnownFileType = wrapper.framework; name = Foundation.framework; path = System/Library/Frameworks/Foundation.framework; sourceTree = SDKROOT; };\\n\\t\\t1D6058910D05DD3D006BFB54 /* ___PROJECTNAME___.app */ = {isa = PBXFileReference; explicitFileType = wrapper.application; includeInIndex = 0; path = \"___PROJECTNAME___.app\"; sourceTree = BUILT_PRODUCTS_DIR; };\\n\\t\\t1DF5F4DF0D08C38300B7A737 /* UIKit.framework */ = {isa = PBXFileReference; lastKnownFileType = wrapper.framework; name = UIKit.framework; path = System/Library/Frameworks/UIKit.framework; sourceTree = SDKROOT; };\\n\\t\\t288765FC0DF74451002DB57D /* CoreGraphics.framework */ = {isa = PBXFileReference; lastKnownFileType = wrapper.framework; name = CoreGraphics.framework; path = System/Library/Frameworks/CoreGraphics.framework; sourceTree = SDKROOT; };\\n\\t\\t29B97316FDCFA39411CA2CEA /* main.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; path = main.m; sourceTree = \"<group>\"; };\\n\\t\\t32CA4F630368D1EE00C91783 /* ___PROJECTNAMEASIDENTIFIER____Prefix.pch */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = \"___PROJECTNAMEASIDENTIFIER____Prefix.pch\"; sourceTree = \"<group>\"; };\\n\\t\\t8D1107310486CEB800E47090 /* ___PROJECTNAMEASIDENTIFIER___-Info.plist */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = text.plist.xml; path = \"___PROJECTNAMEASIDENTIFIER___-Info.plist\"; plistStructureDefinitionIdentifier = \"com.apple.xcode.plist.structure-definition.iphone.info-plist\"; sourceTree = \"<group>\"; };\\n/* End PBXFileReference section */\\n\\n/* Begin PBXFrameworksBuildPhase section */\\n\\t\\t1D60588F0D05DD3D006BFB54 /* Frameworks */ = {\\n\\t\\t\\tisa = PBXFrameworksBuildPhase;\\n\\t\\t\\tbuildActionMask = 2147483647;\\n\\t\\t\\tfiles = (\\n\\t\\t\\t\\t1D60589F0D05DD5A006BFB54 /* Foundation.framework in Frameworks */,\\n\\t\\t\\t\\t1DF5F4E00D08C38300B7A737 /* UIKit.framework in Frameworks */,\\n\\t\\t\\t\\t288765FD0DF74451002DB57D /* CoreGraphics.framework in Frameworks */,\\n\\t\\t\\t\\t04A618D812CA83F0004ADB76 /* libxml2.2.dylib in Frameworks */,\\n\\t\\t\\t);\\n\\t\\t\\trunOnlyForDeploymentPostprocessing = 0;\\n\\t\\t};\\n/* End PBXFrameworksBuildPhase section */\\n\\n/* Begin PBXGroup section */\\n\\t\\t04A617D012CA7AB6004ADB76 /* wax */ = {\\n\\t\\t\\tisa = PBXGroup;\\n\\t\\t\\tchildren = (\\n\\t\\t\\t\\t04A617D512CA7AB6004ADB76 /* extensions */,\\n\\t\\t\\t\\t04A6180612CA7AB6004ADB76 /* lua */,\\n\\t\\t\\t\\t04A6183D12CA7AB6004ADB76 /* stdlib */,\\n\\t\\t\\t\\t04A6185712CA7AB6004ADB76 /* wax.h */,\\n\\t\\t\\t\\t04A', '<|endoftext|>91B20684200463DC8 /* SystemConfiguration.framework */; };\\n\\t\\t35EBCBC81B20683600463DC8 /* AppKit.framework in Frameworks */ = {isa = PBXBuildFile; fileRef = 35EBCBC71B20683600463DC8 /* AppKit.framework */; };\\n\\t\\t35EBCBCA1B20684200463DC8 /* SystemConfiguration.framework in Frameworks */ = {isa = PBXBuildFile; fileRef = 35EBCBC91B20684200463DC8 /* SystemConfiguration.framework */; };\\n\\t\\t35EBCBEB1B2068E900463DC8 /* libFxStdMac.a in Frameworks */ = {isa = PBXBuildFile; fileRef = 35EBCBEA1B2068A100463DC8 /* libFxStdMac.a */; };\\n\\t\\t35EBCBEC1B2068EF00463DC8 /* libFxEventsMac.a in Frameworks */ = {isa = PBXBuildFile; fileRef = 35EBCBE41B2068A100463DC8 /* libFxEventsMac.a */; };\\n\\t\\t35EBCBFA1B20693A00463DC8 /* libSystemUtilsMac.a in Frameworks */ = {isa = PBXBuildFile; fileRef = 35EBCBF91B20693600463DC8 /* libSystemUtilsMac.a */; };\\n/* End PBXBuildFile section */\\n\\n/* Begin PBXContainerItemProxy section */\\n\\t\\t35270C781D1A4603004BFF76 /* PBXContainerItemProxy */ = {\\n\\t\\t\\tisa = PBXContainerItemProxy;\\n\\t\\t\\tcontainerPortal = 35EBCB9A1B20675500463DC8 /* FxStd.xcodeproj */;\\n\\t\\t\\tproxyType = 2;\\n\\t\\t\\tremoteGlobalIDString = FCBD2F8C1BABEF5A0061109F;\\n\\t\\t\\tremoteInfo = \"FxStd-E\";\\n\\t\\t};\\n\\t\\t35CFD4DF1B20701B00913353 /* PBXContainerItemProxy */ = {\\n\\t\\t\\tisa = PBXContainerItemProxy;\\n\\t\\t\\tcontainerPortal = 35EBCB9A1B20675500463DC8 /* FxStd.xcodeproj */;\\n\\t\\t\\tproxyType = 1;\\n\\t\\t\\tremoteGlobalIDString = 0885379917F98FC900AB08F2;\\n\\t\\t\\tremoteInfo = FxStdMac;\\n\\t\\t};\\n\\t\\t35CFD4E11B20701E00913353 /* PBXContainerItemProxy */ = {\\n\\t\\t\\tisa = PBXContainerItemProxy;\\n\\t\\t\\tcontainerPortal = 35EBCBA41B20678600463DC8 /* FxEvents.xcodeproj */;\\n\\t\\t\\tproxyType = 1;\\n\\t\\t\\tremoteGlobalIDString = 08629AF317F957080085D580;\\n\\t\\t\\tremoteInfo = FxEventsMac;\\n\\t\\t};\\n\\t\\t35CFD4E31B20702600913353 /* PBXContainerItemProxy */ = {\\n\\t\\t\\tisa = PBXContainerItemProxy;\\n\\t\\t\\tcontainerPortal = 35EBCBF11B20693600463DC8 /* SystemUtils.xcodeproj */;\\n\\t\\t\\tproxyType = 1;\\n\\t\\t\\tremoteGlobalIDString = 0840247F17F419E7005D14EF;\\n\\t\\t\\tremoteInfo = SystemUtilsMac;\\n\\t\\t};\\n\\t\\t35CFD51F1B2072FE00913353 /* PBXContainerItemProxy */ = {\\n\\t\\t\\tisa = PBXContainerItemProxy;\\n\\t\\t\\tcontainerPortal = 350D3E2F1A919C35001ED61E /* Project object */;\\n\\t\\t\\tproxyType = 1;\\n\\t\\t\\tremoteGlobalIDString = 35CFD4B41B206EFD00913353;\\n\\t\\t\\tremoteInfo = UserActivityMonitorAgentUI;\\n\\t\\t};\\n\\t\\t35EBCBE11B2068A100463DC8 /* PBXContainerItemProxy */ = {\\n\\t\\t\\tisa = PBXContainerItemProxy;\\n\\t\\t\\tcontainerPortal = 35EBCBA41B20678600463DC8 /* FxEvents.xcodeproj */;\\n\\t\\t\\tproxyType = 2;\\n\\t\\t\\tremoteGlobalIDString = D2AAC07E0554694100DB518D;\\n\\t\\t\\tremoteInfo = FxEvents;\\n\\t\\t};\\n\\t\\t35EBCBE31B2068A100463DC8 /* PBXContainerItemProxy */ = {\\n\\t\\t\\tisa = PBXContainerItemProxy;\\n\\t\\t\\tcontainerPortal = 35EBCBA41B20678600463DC8 /* FxEvents.xcodeproj */;\\n\\t\\t\\tproxy', '<|endoftext|>CF9000C820D7 /* statusbar-warning@2x.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = \"statusbar-warning@2x.png\"; sourceTree = \"<group>\"; };\\n\\t\\tF8340B8A1C96CF9000C820D7 /* statusbar.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = statusbar.png; sourceTree = \"<group>\"; };\\n\\t\\tF8340B8B1C96CF9000C820D7 /* statusbar@2x.png */ = {isa = PBXFileReference; lastKnownFileType = image.png; path = \"statusbar@2x.png\"; sourceTree = \"<group>\"; };\\n\\t\\tF89B59391DA7DC350028D75F /* Reachability.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = Reachability.h; sourceTree = \"<group>\"; };\\n\\t\\tF89B593A1DA7DC350028D75F /* Reachability.m */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.objc; path = Reachability.m; sourceTree = \"<group>\"; };\\n\\t\\tF8B315891FA6BB1400839784 /* fr */ = {isa = PBXFileReference; lastKnownFileType = text.plist.strings; name = fr; path = fr.lproj/MainMenu.strings; sourceTree = \"<group>\"; };\\n\\t\\tF8D61B8520C8731A00DE2453 /* CachetHQ.xcodeproj */ = {isa = PBXFileReference; lastKnownFileType = \"wrapper.pb-project\"; name = CachetHQ.xcodeproj; path = CachetHQ/CachetHQ.xcodeproj; sourceTree = \"<group>\"; };\\n\\t\\tF8ECE1732323970E00C17247 /* Hello IT.entitlements */ = {isa = PBXFileReference; lastKnownFileType = text.plist.entitlements; path = \"Hello IT.entitlements\"; sourceTree = \"<group>\"; };\\n/* End PBXFileReference section */\\n\\n/* Begin PBXFrameworksBuildPhase section */\\n\\t\\tE1D067F71B51D08E00567172 /* Frameworks */ = {\\n\\t\\t\\tisa = PBXFrameworksBuildPhase;\\n\\t\\t\\tbuildActionMask = 2147483647;\\n\\t\\t\\tfiles = (\\n\\t\\t\\t);\\n\\t\\t\\trunOnlyForDeploymentPostprocessing = 0;\\n\\t\\t};\\n\\t\\tE1D0680A1B51D08F00567172 /* Frameworks */ = {\\n\\t\\t\\tisa = PBXFrameworksBuildPhase;\\n\\t\\t\\tbuildActionMask = 2147483647;\\n\\t\\t\\tfiles = (\\n\\t\\t\\t);\\n\\t\\t\\trunOnlyForDeploymentPostprocessing = 0;\\n\\t\\t};\\n/* End PBXFrameworksBuildPhase section */\\n\\n/* Begin PBXGroup section */\\n\\t\\tE12F1E4B1B52355B005A4418 /* Products */ = {\\n\\t\\t\\tisa = PBXGroup;\\n\\t\\t\\tchildren = (\\n\\t\\t\\t\\tE12F1E511B52355C005A4418 /* TestHTTP.hitp */,\\n\\t\\t\\t);\\n\\t\\t\\tname = Products;\\n\\t\\t\\tsourceTree = \"<group>\";\\n\\t\\t};\\n\\t\\tE14B67A81B57856000941A27 /* Products */ = {\\n\\t\\t\\tisa = PBXGroup;\\n\\t\\t\\tchildren = (\\n\\t\\t\\t\\tE14B67AC1B57856000941A27 /* OpenApplication.hitp */,\\n\\t\\t\\t);\\n\\t\\t\\tname = Products;\\n\\t\\t\\tsourceTree = \"<group>\";\\n\\t\\t};\\n\\t\\tE14B67D01B59059000941A27 /* Products */ = {\\n\\t\\t\\tisa = PBXGroup;\\n\\t\\t\\tchildren = (\\n\\t\\t\\t\\tE14B67D41B59059000941A27 /* ScriptedItem.hitp */,\\n\\t\\t\\t);\\n\\t\\t\\tname = Products;\\n\\t\\t\\tsourceTree = \"<group>\";\\n\\t\\t};\\n\\t\\tE17743301B51E6E600A5B406 /* Plugins */ = {\\n\\t\\t\\tisa = PBXGroup;\\n\\t\\t\\tchildren = (\\n\\t\\t\\t\\tF8D61B8520C8731A00DE2453 /* CachetHQ.xcodeproj */,\\n\\t\\t\\t\\tF83294AE1F773076009DA574 /* ADPass.xcodeproj */,\\n\\t\\t\\t\\tE17743591B51EA8500A5B406 /* OpenResource.xcodeproj */,\\n\\t\\t\\t\\tE17743751B51F19B00A5B406', '<|endoftext|> Assets.xcassets in Resources */ = {isa = PBXBuildFile; fileRef = E2C023C51D6338BB0033AD25 /* Assets.xcassets */; };\\n\\t\\tE2C023C91D6338BB0033AD25 /* Main.storyboard in Resources */ = {isa = PBXBuildFile; fileRef = E2C023C71D6338BB0033AD25 /* Main.storyboard */; };\\n\\t\\tE2C023CE1D6339580033AD25 /* Device.framework in Frameworks */ = {isa = PBXBuildFile; fileRef = E2C023AA1D6331010033AD25 /* Device.framework */; };\\n\\t\\tE2C023CF1D6339580033AD25 /* Device.framework in Embed Frameworks */ = {isa = PBXBuildFile; fileRef = E2C023AA1D6331010033AD25 /* Device.framework */; settings = {ATTRIBUTES = (CodeSignOnCopy, RemoveHeadersOnCopy, ); }; };\\n\\t\\tE2DAC74A1D643D9F00E7A07B /* DeviceMacOS.swift in Sources */ = {isa = PBXBuildFile; fileRef = E2DAC7491D643D9F00E7A07B /* DeviceMacOS.swift */; };\\n/* End PBXBuildFile section */\\n\\n/* Begin PBXContainerItemProxy section */\\n\\t\\t001C447E1C3C08C000F6599D /* PBXContainerItemProxy */ = {\\n\\t\\t\\tisa = PBXContainerItemProxy;\\n\\t\\t\\tcontainerPortal = BE11EEDF1BE3FC0300816835 /* Project object */;\\n\\t\\t\\tproxyType = 1;\\n\\t\\t\\tremoteGlobalIDString = 001C44681C3C08C000F6599D;\\n\\t\\t\\tremoteInfo = Device;\\n\\t\\t};\\n\\t\\tE2C023D01D6339580033AD25 /* PBXContainerItemProxy */ = {\\n\\t\\t\\tisa = PBXContainerItemProxy;\\n\\t\\t\\tcontainerPortal = BE11EEDF1BE3FC0300816835 /* Project object */;\\n\\t\\t\\tproxyType = 1;\\n\\t\\t\\tremoteGlobalIDString = E2C023A91D6331010033AD25;\\n\\t\\t\\tremoteInfo = \"Device macOS\";\\n\\t\\t};\\n/* End PBXContainerItemProxy section */\\n\\n/* Begin PBXCopyFilesBuildPhase section */\\n\\t\\t001C44851C3C08C000F6599D /* Embed Frameworks */ = {\\n\\t\\t\\tisa = PBXCopyFilesBuildPhase;\\n\\t\\t\\tbuildActionMask = 2147483647;\\n\\t\\t\\tdstPath = \"\";\\n\\t\\t\\tdstSubfolderSpec = 10;\\n\\t\\t\\tfiles = (\\n\\t\\t\\t\\t001C44811C3C08C000F6599D /* Device.framework in Embed Frameworks */,\\n\\t\\t\\t);\\n\\t\\t\\tname = \"Embed Frameworks\";\\n\\t\\t\\trunOnlyForDeploymentPostprocessing = 0;\\n\\t\\t};\\n\\t\\tE2C023D21D6339580033AD25 /* Embed Frameworks */ = {\\n\\t\\t\\tisa = PBXCopyFilesBuildPhase;\\n\\t\\t\\tbuildActionMask = 2147483647;\\n\\t\\t\\tdstPath = \"\";\\n\\t\\t\\tdstSubfolderSpec = 10;\\n\\t\\t\\tfiles = (\\n\\t\\t\\t\\tE2C023CF1D6339580033AD25 /* Device.framework in Embed Frameworks */,\\n\\t\\t\\t);\\n\\t\\t\\tname = \"Embed Frameworks\";\\n\\t\\t\\trunOnlyForDeploymentPostprocessing = 0;\\n\\t\\t};\\n/* End PBXCopyFilesBuildPhase section */\\n\\n/* Begin PBXFileReference section */\\n\\t\\t001C44691C3C08C000F6599D /* Device.framework */ = {isa = PBXFileReference; explicitFileType = wrapper.framework; includeInIndex = 0; path = Device.framework; sourceTree = BUILT_PRODUCTS_DIR; };\\n\\t\\t001C446C1C3C08C000F6599D /* Info.plist */ = {isa = PBXFileReference; lastKnownFileType = text.plist.xml; path = Info.plist; sourceTree = \"<group>\"; };\\n\\t\\t001C446D1C3C08C000F6599D /* Device.h */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.h; path = Device.h; sourceTree = \"<group>\"; };\\n\\t\\tBE11EEE71BE3FC0300816835 /* Example.app */ = {isa = PBXFileReference; explicitFileType = wrapper.application; includeInIndex = 0; path = Example.app; sourceTree = BUILT_PRODUCTS_DIR; };\\n\\t\\tBE11EEFC1BE3FD9200816835 /* AppDelegate.swift */']\n","530 ['<|endoftext|>, og således at en mere moderne økonomi er en mere global økonomi. Det betyder endvidere, at vi skal fremme handelen inden for finansielle tjenesteydelser, som vil give udviklingslandene mulighed for at modernisere deres økonomier og dermed gøre den internationale handelsstruktur mere effektiv. Det betyder naturligvis også, at vi skal drøfte indførelsen af standarder for handelsregulering, virksomhedsledelse og regulering af finansielle tjenesteydelser. \\nAlbert Deß (PPE-DE ),\\n\\xa0\\xa0 Hr. formand, fru kommissær, først vil jeg gerne takke min kollega, hr. Papastamkos, hjerteligt for hans betænkning og for de klare og entydige holdninger til, hvordan vi forestiller os en WTO-aftale.\\nOgså Udvalget om Landbrug og Udvikling af Landdistrikter ønsker en vellykket afslutning på Doha-runden, men ikke for enhver pris. Det kan ikke være rigtigt, at der kun er nogle få, fru kommissær, som har en fordel heraf, og mange andre må bukke under. Det, som vi har brug for, er fair handelsbetingelser. Jeg hilser kravet i betænkningen om, at det er nødvendigt med en gennemgribende reform af WTO, velkommen. Det er ikke tilstrækkeligt, hvis man i forbindelse med WTO-forhandlinger fastsætter handelsudvidelsen som det primære mål. Miljø-, forbruger- og dyrebeskyttelsesstandarder samt sociale minimumsstandarder skal ligeledes fastsættes som WTO-mål. Det kan ikke være rigtigt, at det ved afslutningen på WTO-forhandlingerne forholder sig således, at fordelene tilfalder dem, der øver rovdrift på naturen og udbytter mennesker socialt.\\nDet er unfair, hvis de europæiske landmænd skal opfylde det ene påbud efter det andet i forbindelse med levnedsmiddelproduktionen, mens disse påbud ikke gælder for importvarer. Helmut Kohl, den tidligere tyske kansler, sagde en gang, at han ville ønske, at der galt de samme regler for levnedsmiddelimport som for bilindustrien. Det er ganske vist tilladt at importere biler fra Japan, USA og Korea til Tyskland, men de får kun tilladelse til at køre på de tyske veje, hvis de opfylder de høje tekniske standarder, som der er fastsat her. Hvis importerede levnedsmidler skal opfylde de samme høje standarder, som er gældende for europæiske landmænd, er vi ikke bange for den globale konkurrence.\\nVi er gerne parat til at tage konkurrencen op, men vi har imidlertid brug for en aftale, hvor mange medvirker til velstandsøgningen og ikke kun nogle få. \\nPaul Rübig,\\n\\xa0\\xa0 Hr. formand, fru kommissær, mine damer og herrer, jeg vil gerne takke hr. Papastamkos hjerteligt, fordi han allerede havde nogle klare mål i Hongkong. Vi kan prise os lykkelige over, at der blev opnået en politisk ramme i Hongkong, som nu de facto udgør målsætningen for forhandlingerne i Genève. Politikken har alligevel opnået en del her. Nu er det imidlertid op til eksperterne i Genève at få afklaret substansen. Vi kan dermed kun håbe på, at dette sker så hurtigt som muligt. Vi ved, at det ikke er nemt, men der hersker et vist tidspres, og som oftest er det kun under tidspres, at der kommer løsninger i stand på dette område.\\n', \"<|endoftext|>kter. Det gælder således ønsket om mindre forurenende transportformer, om hensyntagen til skove og beskyttede områder og om at sikre fødevareforsyningen.\\nVi glæder os ligeledes over, at der knyttes en forbindelse mellem fattigdom og miljø, selv om vi beklager, at det vigtigste punkt i så henseende er blevet forkastet i plenarforsamlingen, herunder konstateringen af, at liberaliseringspolitikken ikke hjælper mod fattigdom og social udstødelse, og den kritik, der er blevet fremført af de foreslåede foranstaltninger, fordi de ikke i tilstrækkelig grad bidrager til at bekæmpe fattigdom, social udstødelse og stigende ulighed. \\nHélène Goudin, Nils Lundgren og Lars Wohlin (IND/DEM ),\\n\\xa0\\xa0 Denne betænkning behandler en række betydningsfulde spørgsmål inden for området bæredygtig udvikling. Junilisten mener, at der er gode grunde til EU-samarbejde i grænseoverskridende miljøanliggender. I betænkningen tages dog en række centrale politiske områder op, som bør ligge uden for EU's kompetence. Som eksempel kan nævnes følgende:\\n- Hvilke investeringer der skal foretages inden for kollektiv trafik eller, som det passer i foreliggende tilfælde, udvidelse af vejnettet i medlemsstaterne.\\n- Gældsafskrivninger til udviklingslande.\\n- Miljøskatter på EU-niveau.\\n- Om miljø skal være et emne, som indgår i grunduddannelsen i medlemsstaternes skoler.\\n- Skatten på arbejde i medlemslandene.\\n- Beskæftigelse og social integration.\\nVi er stærkt kritiske over for det faktum, at EU's institutioner har en glubsk appetit på øget indflydelse. Vi har dermed valgt at stemme nej til helheden, men er positive over for enkelte afsnit, især dem, som behandler virkelige grænseoverskridende miljøproblemer. \\nLuís Queiró (PPE-DE ),\\n\\xa0\\xa0 Det er hævet over enhver tvivl, at bæredygtig udvikling i dag er et fundamentalt mål for EU og en global udfordring. Strategierne for bæredygtig udvikling kræver derfor en langsigtet politisk vision på højeste niveau.\\nOver for de sociale, miljømæssige og demokratiske udfordringer må vi agere med ansvar, ikke blot som politikere, men også som borgere. Vi må dog også bestræbe os på, at de foranstaltninger, som vi træffer, svarer til vores målsætninger om vækst og social og økonomisk udvikling, der er af afgørende betydning for vores samfunds fremtid.\\nI denne betænkning evalueres de fremskridt, der er gjort siden 2001, og der foreslås nye foranstaltninger. Som et led i denne proces skal vi bekræfte bæredygtig udvikling som en prioritet for Europas fremtid og fastholde vores mål om at føre Lissabon-strategien ud i livet.\\nJeg har derfor stemt for Ferreira-betænkningen. \\nAlyn Smith (Verts/ALE ),\\n\\xa0\\xa0 Bæredygtig udvikling må have en mere fremtrædende rolle på hele vores politiske område, og jeg er glad for, at denne betænkning giver et udgangspunkt for, hvordan vi kan nå dette, og det vil jeg gerne støtte. I mit eget land, Skotland, har vi et enestående bidrag\", '<|endoftext|>bud af betonreparationer på søjler, bjælker og dæk.\\n\\nSe oversigt over arbejdet nederst i artiklen.\\n\\nDet er første fase i den store renoveringsplan. Fase to til godt 250 mio. kroner omfatter en gennemgribende renovering af primært betonen i perioden 2021-2025, mens den sidste fase indeholder genopretning af en skæv broklap til 14 mio. kroner; et arbejde, der skal udføres senest i 2029.\\n\\nUdvalget har endnu ikke godkendt planen. Teknik- og Miljøborgmester Ninna Hedeager (Ø) har sagt til Berlingske, at renoveringen er det mest sandsynlige scenarie frem for en ny bro.\\n\\nOverblik over de akutte renoveringer i pakken til 36 mio. kroner:\\n\\nKonstruktionsdel Tilstand Reparation/tiltag Pris (mio. kr.) (2020 p/l) Slidlag på vej og cykelsti Asfaltbelægningen på broen er slidt og meget sporkørt. Flere steder er det underlæggende drænlag knust. Dette kan påvirke den underliggende konstruktion af broen, hvor broens membran og betondæk kan blive ødelagt. Fræsning af det eksisterende slidlag (øverste lag af belægningen) og udskiftning med nyt slidlag. 15,1 Afvanding Det eksisterende afvandingssystem for broklapperne fungerer ikke optimalt, så der trænger vand ind i brokonstruktionerne. Afvanding udskiftes og nyt afvandingssystem monteres. 5,9 Kunststofbelægning på fortov Kunststofbelægningen på broens fortovsarealer er nedslidt og hullet, hvilket medvirker til, at der siver vand ned i den underliggende betonkonstruktion, som dermed bliver nedbrudt. Kunststofbelægning udskiftes. 5,7 Dæk over maskinrum På begge sider af broen står de store maskiner, der åbner og lukker broen, i nogle store rum. Tagene på disse rum er meget utætte, hvilket betyder, at der trænger vand ind, som løber ind i og ødelægger maskinerne. Betondæk over maskinrum på begge sider af broen skal renoveres. 4,6 Belysningsmaster Alle 16 stålbelysningsmaster er stærkt gennemtærede af rust. Der er fare for, at de kan knække. Masterne skal udskiftes. 3,5 Betonkonstruktion i P-kælder Betonen i brodæk, søjler og bjælker (især omkring de tværgående brofuger) er nedbrudt med armeringskorrosion (rust, der har gennemtæret stålet) og afskalning af beton. Det betyder, at der er konstateret bæreevnesvigt i konstruktionerne, som på nuværende tidspunkt bliver støttet med stålsøjler. Projektering og udbud af betonreparationer på søjler, bjælker og dæk i forskellige dele af brokonstruktionen og p-kælderen. 1,5 I alt 36,3\\n\\nTabel: Teknik- og Miljøforvaltningen, Københavns Kommune<|endoftext|>Hotel Patrie\\n\\nThe Hotel Patrie in Roberts, Idaho was built in 1892 and expanded in 1915 and in the 1920s.  It has also been known as the Adams Hotel, as the Roberts Hotel, and as the American Hotel.  It was listed on the National Register of Historic Places in 1978.\\n\\nIt is a two-story U-shaped brick building that, after expansions, is eight bays wide.\\n\\nIt was deemed significant as one of the oldest and largest buildings surviving in Roberts after the 1976 Teton dam flood.', '<|endoftext|> foreslog, var blevet udarbejdet også under medvirken fra vores gruppe. Der er således fremkommet en tekst, der særligt lægger vægt på, at der vedtages programmer for vævs- og celletransplantation, som er baseret på frivillige og vederlagsfrie donationer med anonymitet for både donor og recipient. På den anden side forbyder den forskning i menneskelig kloning til reproduktive formål og at skabe humane embryoner udelukkende til forskning eller udtagning af stamceller. På nogle punkter, f.eks. med hensyn til brug af føtale celler og væv, ville jeg foretrække fagudvalgets tekst - men eftersom plenarmødet forkastede det, er jeg tilfreds med, at den ændring, som jeg tilsluttede mig som andet alternativ, er blevet vedtaget. Meget vigtigt er det, at afstemningen om det fuldstændige forbud mod destruktiv forskning i embryoner (ændringsforslag 86/3 af Flemming) har ...\\n(Indlægget forkortet i henhold til forretningsordenens artikel 137, stk. 1)\\nFigueiredo (GUE/NGL)\\nUdviklingen af produktionsmidlerne på grundlag af de nye teknologier har nået et højere udviklingsstadium, som ikke er foreneligt med de private interesser, der besidder produktionsmidlerne. Kapitalismen har også gjort livet og naturarven til en vare og til et spørgsmål om ejendomsret. Vi fordømmer lodret patentering af livet, af mennesket og af hele naturarven, ligesom at de gøres til en vare.\\nSpørgsmålet om ejendomsretten har skabt forvirring om, hvad der er en opdagelse, og hvad der er en opfindelse. De videnskabelige opdagelser må fremmes gennem forskning og betragtes som et offentligt tilgængeligt gode. Livet findes, og dets love kan ikke opfindes. De opdages. Problemet er, at den meste forskning i dag ikke er offentlig. Den udføres af store, multinationale virksomheder, der ønsker at sætte sig i besiddelse af alt og få profit ud af denne tilegnelse, hvilket bringer opdagelser og udviklinger, der tilhører menneskeheden og det enkelte individ, i fare.\\nI denne sammenhæng bør salg - også frivilligt - af menneskelige celler og væv (som f.eks. blod) totalt forbydes. Den biologiske og bioteknologiske forskning bør først og fremmest være offentlig og bør komme alle til gavn, ikke kun dem, der kan betale.\\nGoebbels (PSE)\\nBetænkningen om kvalitet og sikkerhed ved humane væv og celler behandler et forholdsvis teknisk, men meget fornuftigt direktivforslag. Miljøudvalget og Retsudvalget har imidlertid forvandlet dette direktiv til et manifest, som blander såkaldt etiske betragtninger med et regulært angreb på forskningen inden for biovidenskab, samtidig med at det tramper på subsidiaritetsprincippet. Hvis der ikke er nogen i Europa-Parlamentet, der forsvarer menneskelig kloning, kan vi ikke regulere et sådant spørgsmål ad bagdøren, det vil sige ad omveje i form af en betragtning eller en artikel, som henviser til et andet emne. Vi kan især ikke rejse nogle fællesskabsbarrierer imod forskning i embryonale stamceller. Hvis nogle stater ønsker at forbyde den slags forskning på nationalt niveau, står det dem frit for, og de har ikke', \"<|endoftext|> som hr. Goepel sagde, at det ikke behøver at vare elleve måneder, men at det også med dette retsgrundlag er muligt at vedtage de pågældende forordninger hurtigere. Så meget i denne forbindelse.\\n\\nVandemeulebroucke\\nFru formand, på et tidspunkt under forhandlingen spurgte jeg kommissær Fischler, om han kunne gå ind for en nøjere undersøgelse af indførelsen af et elektronisk chip-system, gående ud på at dyret i så fald ville kunne følges hele livet. Mit spørgsmål er, om han er rede til at undersøge, om det kan lade sig gennemføre og hvad det koster.\\n\\nOlsson\\nFru formand, først vil jeg gerne sige, at det er meget væsentligt, at kommissæren gik med til at ændre retsgrundlaget til artikel 100 A. Det er i overensstemmelse med, hvad hr. Santer sagde i går, og det glæder mig. I øvrigt giver min betænkning reelt ikke anledning til problemer - i hvert fald ikke til mange. Kommissæren accepterer hovedparten af ændringsforslagene, dog med undtagelse af dem, som vedrører komitologien, og som ville have udvidet Kommissionens beføjelser og bragt større åbenhed i det forberedende arbejde. Det havde uden tvivl været værdifuldt, om disse også havde kunnet godkendes.\\nJeg må sige som en kommentar til Papayannakis' betænkning, at en strengere holdning som den, som Parlamentet gør sig til talsmand for, og hvorefter kødmærkningsordningen skal være obligatorisk, havde været at foretrække. Jeg er praktisk nok anlagt til at forstå, at det er vanskeligt. Men jeg mener samtidig, at de signaler, som vi udsender, må være stærke, for ellers sker der ikke noget. Der vil kunne gå meget lang tid, før der sker noget, hvis Kommissionen nu fastsætter en lang overgangsperiode. Derfor gælder det efter min mening om, at Parlamentet på mødet i dag udsender et klart signal.\\n\\nPapayannakis\\nFru formand, hr. kommissær, tolkningen gik meget hurtigt, og derfor fik jeg ikke fat i det hele, så jeg vil bede Dem svare mig på tre helt simple spørgsmål; men først vil jeg takke Dem, fordi De accepterer det ændrede retsgrundlag.\\nDet første spørgsmål drejer sig om listen over, hvilke oplysninger mærkningen skal indeholde. De sagde, at vi ikke skulle drøfte dette, eftersom mærkningen ikke er obligatorisk på nuværende tidspunkt, den vil være fakultativ i en periode. Jeg mener - og her vil jeg gerne bede om Deres synspunkt - at selv om mærkningen er fakultativ i en periode, skal den indeholde konkrete informationer. At mærkningen er fakultativ, betyder ikke, at man kan skrive, hvad man vil; det ville ikke være acceptabelt og ville undergrave ordningen.\\nDet andet spørgsmål vedrører produkterne. Der tales om mærkning af kødet. Miljøudvalget og dets ordfører, undertegnede, insisterer på, at mærkningen også skal omfatte produkter fremstillet af oksekød og forarbejdede produkter med indhold af oksekød. Jeg forstod ikke helt, hvad Deres holdning var til dette. Kan De acceptere det eller ikke?\\nMit tredje spørgsmål drejer sig om det fælles system, harmoniseringen af identifikations- og registreringssystemet.\", \"<|endoftext|> når der er problemer. Det skal være vores mål, for så er vi der, hvor vi skal være. Indtil da skal vi præcist kunne opspore, hvad der er sket, skal vi give forbrugerne god information, og indtil da må vi være tilfredse med de lappeløsninger, vi har. Hertil hører helt bestemt også brugen af et mærke med medlemsstatens navn. Det er en god ting, for det er begyndelsen til genoprettelsen af producentens tillid, især i en tid, hvor fødevaresikkerheden er på et højt niveau. Det er ganske enkelt nødvendigt.\\nDet er godt, når det angives, at der kan være et tidspunkt, hvor tilliden kan genoprettes. I den henseende må jeg sige, at der i min delegation og i dele af min gruppe er støtte til hr. Maatens og hr. de Roos ændringsforslag 61, hvori det angives, hvornår der på bestemte tidspunkter er tillid til kontrollen af BSE og andre ting, og at der kan komme et tidspunkt, hvor EU-mærket finder anvendelse. Det ser jeg som et mellemtrin, og til sidst ser jeg ét stort mål, nemlig genoprettelsen af tilliden, at vi får et stærkt EU-mærke og i sidste ende et stærkt sikkerhedskontor for fødevarer, for de diskussioner hænger sammen.\\n\\nMyller\\nHr. formand, hr. kommissær, fødevaresikkerhed er måske det mest populære samtaleemne hos borgerne, og det er derfor godt, at vi også her i Europa-Parlamentet tager det op. Men det vigtigste er, at det ikke kun bliver et samtaleemne, men at vi også gør noget ved det. Papayannakis' arbejde har allerede fået megen tak her, hvilket jeg tilslutter mig, det udgør et godt grundlag for en større forbrugersikkerhed i hele Europa. Vi har jo talrige eksempler på, at det ikke er forbrugerne, der er blevet prioriteret i fødevareproduktionen.\\nDet indre marked og varernes frie bevægelighed giver borgerne en større valgfrihed og bedre markeder for producenterne. Når der er tale om fødevarer, er det endnu vigtigere end ellers at sikre, at friheden også begrænses med ansvar, for at forbrugerne bliver beskyttet. Forbrugerne har ret til at vide, hvad deres næring består af. I dette tilfælde er det yderst vigtigt, at kød og forarbejdede kødprodukterne hører til de produkter, som forbrugerne ved, hvorfra de stammer. Rigtigt mange her har allerede konstateret, at der er behov for mere præcise informationer end bare EF-mærkning. Det er jeg enig i. Det er absolut nødvendigt at kende produkternes oprindelsesland. Derudover skal det ikke kun gælde for kødprodukterne, men også for forarbejdede kødprodukters råvarer, at oprindelsen skal fremgå på den bedst mulige måde. Mærkningsordningen skal også hurtigst muligt gøres obligatorisk. Den tidsplan, som Udvalget om Miljø- og Sundhedsanliggender og Forbrugerpolitik har foreslået, er ikke for meget forlangt. Medlemsstaterne bør allerede have forberedt sig på dette.\\n\\nBusk\\nHr. formand, denne ordning kan ikke udskydes længere, og jeg støtter fuldt ud de opstramninger i tidsplanen, Europa-Parlamentet lægger op til i ændringsforslagene til Kommissionens forslag. Forbrugerne har krav på\", \"<|endoftext|>eblikket er under behandling, sådan som kommissæren påpegede, blev det besluttet at vende tilbage til bestemmelserne i forordningen om oprettelse af Overvågningscentret og afvente resultatet af disse forhandlinger.\\nDet har fra første færd været vores mål at skabe enighed mellem de tre institutioner, altså også med Rådet og Kommissionen, under førstebehandlingen af denne sag. Det glæder mig derfor meget, at det efter mange drøftelser er lykkedes. Det foreliggende kompromis indeholder næsten alle Europa-Parlamentets forslag, og vi er derfor også overbevist om, at intet er til hinder for, at der i morgen kan opnås en aftale eller godkendelse af dette.\\nJeg vil gerne takke det østrigske formandskab, men også Kommissionen og afgjort også skyggeordførerne fra alle grupper for et i alle henseender konstruktivt samarbejde. \\nJiří Maštálka (GUE/NGL ),\\n\\xa0\\xa0 Hr. formand, mine damer og herrer! Allerførst vil jeg gerne komplimentere og takke ordføreren for den foreliggende betænkning. Vi er vel alle enige om, at narkotika og narkotikamisbrug, ikke kun i EU's medlemsstater, men også i resten af verden, er et følsomt område med en enorm social og økonomisk indvirkning på samfundet. Netop derfor er det væsentligt og yderst ønskværdigt med et meget tæt samarbejde mellem alle de berørte samfundssektorer. Selv om dette er et erklæret fælles mål, er det meget ofte svært at blive enige om, hvordan man skal nå det.\\nJeg hilser de positive ændringer i denne betænkning velkommen. Først og fremmest glæder jeg mig over de ændringsforslag, som Udvalget om Miljø, Folkesundhed og Fødevaresikkerhed har godkendt, især dem, der vedrører et tættere samarbejde mellem Unionens medlemsstater. Et eksempel på dette tættere samarbejde er centrets opgave med at levere information om bedste praksis og retningslinjer og fremme udveksling heraf mellem medlemsstaterne.\\nDet er almindeligt anerkendt, at narkotika ikke kender nogen grænser, og det gælder især i forbindelse med EU's grænser, både internt og eksternt. Jeg beklager, at forslaget om et intensivt samarbejde med lande, der ikke er medlemmer af EU, med henblik på at bekæmpe udbredelse og handel med narkotika ikke er medtaget i den endelige betænkning, selv om det netop er fra disse mange ikke-EU-lande, at den største mængde narkotika kommer ind i Europa.\\nTil gengæld glæder jeg mig over, at forslaget om udveksling af oplysninger mellem centret, FN og Verdenssundhedsorganisationen er blevet medtaget. Denne udveksling vil hindre dobbeltarbejde i forbindelse med indsamling af oplysninger og lette behandlingen af dem. Jeg glæder mig også over forslaget om et aktivt samarbejde med Europol, som vil kunne bidrage betydeligt til bekæmpelse af narkotikarelateret kriminalitet.\\nForslaget om, at centret skal have pligt til at orientere medlemsstaterne om ny udvikling og tendensforandringer inden for brug af narkotika, er af central betydning og vil øge medlemsstaternes muligheder for at forberede sig og reagere effe\", '<|endoftext|>. Det betyder således, at Østrig, Finland og Sverige fortsat kan pålægge langt striksere normer, og det er der ikke noget problem i.\\nJeg vil imidlertid sige til Hautala, at jeg synes, hun går en smule for langt, og at man skal tage de økonomiske problemer, som betænkningen nævner, i betragtning. Jeg kan således ikke gå ind for, at forslaget udvides til at omfatte hverken tung brændselsolie, dieselolie eller kerosen til fly, som kun udgør 0, 2 % af den samlede svovlemission, og som kun berører de øvre atmosfæriske lag. På samme måde tror jeg, hvad angår skibsbrændstof, at det er at foretrække at afvente Den Internationale Søfartsorganisations forhandlinger om Marpol-konventionen, som snart er færdig, og som skal fastsætte svovlindholdet i skibsbrændstof og definere særlige beskyttelseszoner. Jeg mener, det er rimeligt at vente, til disse forhandlinger er afsluttet, og ikke forstyrre en god afvikling af disse forhandlinger.\\nEndelig vil jeg gerne, at man, stadigvæk af økonomiske grunde, ikke lægger sig fast på alt for korte frister for at mindske svovlindholdet, dels i tunge brændselsolier, dels i dieselolie. Når man beslutter at fastsætte disse reduktioner til 1999, selvom vi allerede er midt i 1998, mener jeg, at fristerne er usædvanligt korte, og at dette kan skade økonomien.\\n\\nVirgin\\nHr. formand, disse tre betænkninger, som vi debatterer, hænger jo i høj grad sammen. Pollackbetænkningen er indrettet på luftforurening, som er en trussel mod borgernes sundhed. Jeg er overbevist om, at det er fuldt ud muligt at stille strengere krav, end Kommissionen har gjort, i hvert fald på visse områder. Visse lande er allerede nået længere.\\nJeg vil dog her koncentrere mig om Hulthén-betænkningen om en fælles strategi mod forsuring. Det er en god betænkning om et meget alvorligt miljøproblem. Miljøudvalget mener, at et mere ambitiøst mål for år 2015 er på sin plads. På visse områder vil den kritiske belastningsgrænse blive overskredet, men de områder bør være meget lette at tælle.\\nI Sverige er bevillingerne til kalkning af søer for at forhøje pH-værdien faldet. Man regner med, at alene denne handling kan være årsag til, at ca. 3.000 fiskebestande og 1 million bestande af hvirvelløse dyr forsvinder.\\nMange steder i Europa finder vi betydelige skovskader på grund af de sure udslip. I 1993 stod brugen af kul for ca. 60 % af svovldioxidudslippene. Forslaget om ophævelse af nationale kulsubventioner er derfor vigtigt. Kul burde i stedet belastes med afgifter på svovludslippene.\\nOrdføreren har også taget andre effekter af forsurende udslip op, bl.a. helbredseffekterne. Hvis man bruger data fra Kommissionens egen eksterne rapport om forskellige energityper, kan man konstatere, at hvis vi i en tiårig periode erstattede atomkraften med kulkraft, ville Unionen have haft ca. 20.000 flere tilfælde af kræft, end det er tilfældet i dag. Vi bør også erkende, at den sikre vestlig', '<|endoftext|>melsesproceduren og afgjort ved kvalificeret flertal i Rådet. Vi mener, at dette vil gavne såvel demokratiet som gennemskueligheden, og at det vil sikre, at det bliver lettere at skaffe sig ordentlige informationer. Vi ønsker at højne kvalitetsniveauet for de informationer, der bliver lagt frem, og vi ønsker, at medlemsstaterne skal indgive indberetninger om den faktiske gennemførelse og håndhævelse, og ikke blot omsætte det til lovgivningen i disse medlemsstater.\\nVi mener, at det er nødvendigt at kodificere den eksisterende lovgivning, således at denne bliver forståelig og sammenhængende. Man oplever kun alt for ofte, at sammenhængen kun fremgår, hvis man råder over et helt bibliotek af EF-Tidende. Vi mener naturligvis, at der skal sikres tilstrækkelige ressourcer til gennemførelsen. Der er ingen mening i at tvinge Kommissionen til at gøre en større indsats, hvis ressourcerne ikke strækker til, og hvis budgettet ikke indeholder en bevilling til gennemførelsen af miljølovgivningen. Vi mener, at inspektionsvirksomheden skal udbygges, og at sanktionerne skal skærpes, og samtlige medlemsstater må have et tilsyn - hvilket ikke er tilfældet nu - som Kommissionen kan overvåge på unionsplan i samarbejde med Det Europæiske Miljøagentur på den ene side og IMPEL-nettet på den anden.\\nPå det lokale plan bør de medlemsstater, hvor sådanne kontorer bliver placeret, ikke påligne disse kontorer økonomiske byrder, der begrænser deres muligheder for at arbejde effektivt. I mit eget land blev det skotske Miljøbeskyttelseskontor oprettet for lidt over et år siden, og det blev for en måneds tid siden opdaget, at dette kontor faktisk skal betale omkring 10 % af sit budget i skat, fordi embedsmændene har sjusket med formuleringen af lovgivningen i første omgang. Det er en vanvittig situation, som man ikke bør opmuntre medlemsstaterne til at kopiere i fremtiden.\\nBetænkningen her fik støtte på kryds og tværs af partierne i udvalget. Den har stor betydning, og det, at der ikke er kommet så mange ændringsforslag, betyder ikke, at den er ligegyldig. Der er kun to ændringsforslag, og jeg vil støtte det forslag, som fru Roth-Behrendt har stillet. Skønt jeg mener, at forslaget fra hr. Florenz er positivt, kan jeg ikke støtte det, fordi jeg finder, at det indebærer en unødvendig begrænsning af det enkelte menneskes og agenturernes manøvrefrihed.\\n\\nGebhardt\\nFru formand, hr. Collins, når der er indgivet så få ændringsforslag, skyldes det vel også, at De har udarbejdet en særdeles god betænkning, og der derfor næppe er noget at tilføje, og det, som vi har foreslået i Retsudvalget, har De jo også overtaget i Deres betænkning, således at vi ikke havde nogen problemer med det.\\nDe sagde, at der er meget store problemer med gennemførelsen og anvendelsen af miljølovgivningen i Den Europæiske Union. I modsætning til andre lovgivningsområder findes der ingen reel, økonomisk interesseret lobby, som sørger for, at denne miljølov', '<|endoftext|>sen er særdeles tilfældig, og at borgerne ikke ydes den beskyttelse mod pesticider, som de med rette kan forvente på baggrund af de foreliggende videnskabelige beviser.\\nDet er især vigtigt at bemærke, at lovgivningen vedrører reststoffer ud fra princippet om, at der er en acceptabel dosis.\\nVi ved imidlertid, at dette princip for visse stoffers vedkommende ikke længere er aktuelt, ligesom der ikke findes nogen sikkerhedstærskel. Der tages heller ikke hensyn til visse væsentlige aspekter som hormonforstyrrende stoffer og tilstedeværelsen af udsatte grupper.\\nAt der desuden er dukket genetisk modificerede frø op, som er resistente over for pesticider, burde have afstedkommet en prioriteret evaluering af de pågældende midler. Det er tydeligvis ikke sket. Der er andre spørgsmål som forsinkelsen med hensyn til behandlingen af farlige stoffer, f.eks. lindan, hvilket er beklageligt, men jeg mener, at ordføreren har behandlet alle disse spørgsmål meget grundigt, og det var mig en glæde at støtte betænkningen.\\n\\nFatuzzo (PPE-DE).\\nFru formand, hr. Lannoye skriver i sin betænkning, at Kommissionen er noget tilbageholdende og ikke videre besluttet på at forbyde brugen af pesticider i landbruget i løbet af kort tid. Jeg mener ikke, at Kommissionen og kommissionsformand Prodi, som er ansvarlig for Kommissionen, er tilbageholdende i dette initiativ, men for at vi kan være sikre på dette, vil jeg alligevel gerne foreslå, at vi serverer salat, tomater, ribs, jordbær og hindbær for dem - man bliver helt sulten ved tanken! - som er behandlet med fenpropathrin, ammoniumglufosinat, imidacloprid, amitrol og thiabendazol. Det er kun endnu mere appetitvækkende! Så kan de tage stilling til, om brugen af disse stoffer skal fortsætte eller ophøre.\\n\\nLulling (PPE-DE)\\nJeg vil gerne i forbindelse med hr. Lannoyes betænkning understrege den katastrofesituation, som vores europæiske biavlere befinder sig i for tiden.\\nDen 13. december 2001 vedtog Europa-Parlamentet sin beslutning om Kommissionens beretning om forbedring af produktionen og afsætningen af honning. Denne beslutning indeholder et egentligt advarselssignal om biavlerne og deres bistaders beklagelige situation. Europa-Parlamentets appel blev hørt af Rådet, bl.a. på Rådet (landbrug) den 18. februar 2002.\\nDesværre fik vores beslutning ikke samme modtagelse i Kommissionen, som stadig ikke har reageret. Samtidig bliver situationen blot værre og værre.\\nJeg besluttede derfor i sidste uge at sende et skriftligt spørgsmål til Kommissionen for at beklage dennes stokkonservative holdninger. I den franske Grand-Ouest-region er mere end 4.000 bistader ramt, og 70% af honningproduktionen er allerede gået tabt på grund af de fungicider, der sprøjtes med i kornmarkerne. Slutresultatet bliver, at alle bier vil være udryddet om nogle år, hvis Kommissionens stokkonservatisme fortsætter.\\nLannoye-betænkningen om plantebeskyttelsesmidlerne berører også det problem, at Landbrugsudvalget har stillet to ændringsforslag i sin udtalelse til Miljøudvalget.\\n(Stemmeforklaring', '<|endoftext|> af 2005 skal indføre nationale opgørelsessystemer til beregning af de antropogene emissioner af drivhusgasser fordelt på kilder. Overholdelse af Kyoto-aftalen - både opstillingen af endelige mål og overvågningen af, hvorvidt de nås - afhænger helt klart meget af, hvordan opgørelsessystemet indføres. Det er selvfølgelig beklageligt, at der ikke er nogen garanti for, at dette system er i brug, når medlemsstaterne foretager den første fordeling, for så vidt angår emissionshandel. Det er vigtigt, at samtlige 48 ændringsforslag i kompromispakken vedtages under morgendagens afstemning, så medlemsstaterne snarest kan begynde at forberede sig på den nationale gennemførelse.\\nI denne forbindelse vil jeg udtrykke et lille håb. Under Kyoto-protokollen vil emissionerne i den første periode i henhold til Kyoto-protokollen blive undersøgt på baggrund af et femårigt gennemsnit. Jeg håber, at Fællesskabet - f.eks. Det Europæiske Miljøagentur - også vil begynde at offentliggøre emissionstendenser på basis af et femårigt gennemsnit. På denne måde vil vi f.eks. kunne eliminere forskelle som følge af årlige udsving i temperaturer og regn, når vi skal vurdere, hvor langt Fællesskabet og medlemsstaterne er fra målet. Den nuværende praksis giver anledning til uberettiget optimisme og uberettiget pessimisme, hvilket kan være svært at forstå for den brede offentlighed.\\nDe Rossa (PSE ).\\n\\xa0\\xa0 - Hr. formand, vi er afgjort forpligtet til at tage skridt til at foreslå over for Parlamentet, at der iværksættes en klar og effektiv mekanisme til overvågning af emissioner af drivhusgasser. Jeg støtter derfor fuldt ud det kompromisforslag, der stilles i morgen, fordi det er vigtigt, at vi handler hurtigt i denne sag.\\nDet er desværre en realitet, at emissionen af gasser i Europa siden underskrivelsen af Kyoto-protokollen er steget og ikke faldet. Det er på høje tid, at vi påtager os vores ansvar. Dette ansvar er hovedsageligt medlemsstaternes, og det er, som jeg sagde, på tide, at vi påtager os vores ansvar for ikke blot befolkningens sundhed i dag, men også for beskyttelsen af miljøet for de fremtidige generationer.\\nSidste uges betænkning indikerede, at tre lande - Irland, Spanien og Italien - tegnede sig for næsten halvdelen af de 500 overtrædelser af miljølovgivningen i EU i de sidste fem år. Det er et eksempel på, hvordan medlemsstaterne efter godkendelsen og gennemførelsen af direktiver ikke sikrer, at de gennemføres. \\nCaudron (GUE/NGL ).\\n\\xa0\\xa0 - Hr. formand, jeg vil på egne og GUE/NGL-Gruppens vegne lykønske ordføreren og mine kolleger i Miljøudvalget, som gennem et effektivt samarbejde har været i stand til at forelægge os en række kompromisændringsforslag, der skal sikre, at denne betænkning kan vedtages under førstebehandlingen.\\nHasteproceduren var uden tvivl påkrævet over for en så forfærdelig plage som drivhusgasserne og deres langsigtede følger i form af klimatiske ændringer og indvirkning på økosystemet og biodiversiteten', '<|endoftext|>, der blev vedtaget efter valget den 28. september, hjalp os med at komme videre, håber vi, at vi fortsat kan få Parlamentets støtte i vores embedsperiode.\\nBenita Ferrero-Waldner\\nmedlem af Kommissionen. - (EN) Hr. formand! Jeg har set, at et meget bredt flertal har den samme holdning, som vi har. Det betyder, at vi har tilbudt Belarus muligheden for at komme tættere på EU gennem den europæiske naboskabspolitik. Vi har i princippet tilbudt en skyggehandlingsplan og også en mulighed for at komme med i østpartnerskabet på det rette tidspunkt, selvfølgelig når betingelserne er rigtige.\\nNår det er sagt, vil jeg gerne besvare nogle få specifikke spørgsmål, der er rejst. Vedrørende finanskrisen: Belarus har klaret følgerne af finanskrisen og de stigende gaspriser i 2007 og 2008 rimeligt godt indtil nu som følge af sin meget begrænsede integration i den globale økonomi og også takket være de betydelige lån fra Rusland, Kina og Venezuela. Men nu har landet, som hr. Belder - tror jeg - ganske rigtigt sagde, været nødt til at bede IMF om et betinget lån på 2,5 mia. EUR og herefter devaluere sin valuta med henblik på at modvirke de negative følger af den globale krise. Eftersom der fortsat i det store og hele ikke er foretaget nogen reform og strukturering af landets økonomi og industri, forventer vi, at den negative tendens vil fortsætte med deraf følgende negative sociale konsekvenser. Så det er rigtigt - det er en vigtig faktor.\\nLad mig vedrørende kernekraftværket og spørgsmålene om sikkerhed og sikkerhedskontrol fortælle, at vi i vores tekniske energidialog med Belarus er særligt opmærksomme på også at sikre, at dette land overholder internationale sikkerhedsstandarder. Vi kan sige, at Belarus samarbejder meget aktivt med IAEA i Wien og har været bemærkelsesværdigt åben med hensyn til at give Kommissionen informationer om denne proces.\\nMen jeg vil også gerne tilbage til spørgsmålet om visumgebyrer. Som jeg sagde i min første bemærkning, er vi parate til at bidrage til forhandlingen, så snart Rådet også har udtrykt ønske om at prøve at styre det og give alle medlemsstater mulighed for at få en fuld visumaftale og en tilbagetagelsesaftale. Efter min vicegeneraldirektør Mingarellis besøg i Minsk kan jeg fortælle, at der i øjeblikket ikke er noget nyt om det specielle spørgsmål. Jeg kan blot sige, at visumgebyrer og visa til børn er specifikke for hvert enkelt land. Vi er endnu ikke nået dertil, at vi har én generel aftale. Også det ville skulle forhandles af Kommissionen.\\nFormanden\\n\", jf. forretningsordenens artikel 103, stk. 2.\\nForhandlingen er afsluttet.\\nAfstemningen finder sted torsdag den 15. januar 2009.\\nSkriftlige erklæringer (artikel 142)\\nAdam Bielan  \\nskriftligt. - (PL) Hr. formand! Vi har på det seneste talt om et politisk tøbrud i Belarus. Alexander Milinkievich\\' oppositionsbevægelse \"For Freedom\" er endelig blevet registreret. Belarus har givet udtryk for vilje til at deltage i østpartnerskabet. Selv Washington har sagt, at relationerne mellem de to lande er forbed', '<|endoftext|>. Blandt mange andre aktioner på dette område søger Kommissionen at koncentrere en del af den næste strukturfondpakke om bykvarterer med særlige behov beliggende i mål nr. 2-regioner, således som foreslået i Agenda 2000. Men også under mål nr. 1 bør der ske en lignende koncentration af ressourcer om specifikke kvarterer. Boligsektoren er en afgørende faktor i kampen mod ulighed, udstødelse og kriminalitet i byområder, ligesom det er en sektor med potentiale for beskæftigelse og udvikling af små og mellemstore virksomheder.\\nAf disse årsager vil Kommissionen overveje mulighederne for at også at lade strukturfondsmidlerne omfatte specifikke programmer for boligsektoren, såfremt de er afgørende for udviklingen af lokalsamfundene og udgør en del af en samlet plan for byfornyelse. Jeg er klar over, Kommissionen er klar over, at Parlamentet går ind for at opretholde fællesskabsinitiativet Urban. På grund af Urban-initiativets succes, som et initiativ på lokalt grundlag, har Kommissionen besluttet at integrere det i de aktioner, der omfattes af fællesskabsstøtterammerne fra år 2000. Et af elementerne i denne integration består i en udvidelse af partnerskabsdefinitionen i udkastet til forordning for strukturfondene, således at lokale myndigheder og sociale og økonomiske organisationer inddrages, et aspekt, som visse medlemsstater finder noget kontroversielt. Fra Kommissionens synspunkt er det afgørende, at de lokale myndigheder inddrages i partnerskabsmekanismerne med henblik på at finde en løsning på byområdernes problemer og en vellykket politisk integrering af Urban-initiativet.\\nEt andet problem, som indgår i Kommissionens aktionsplan nu og fremover, er bymiljø- og livskvalitet, der jo også har været meget omtalt i betænkningerne og i parlamentsmedlemmernes indlæg. Der må findes mere bæredygtige forvaltningsformer med henblik på at forbedre livskvaliteten i byerne, sikre konkurrencedygtigheden for deres erhverv og beskytte det samlede miljø. Miljølovgivningen er helt sikkert det vigtigste instrument, som Fællesskabet råder over til at forbedre kvaliteten af byernes miljø, særlig de forholdsregler, der er blevet taget med hensyn til luft-, vand- og affaldskvalitet og kontrol med industriforureningen, alle med tydelig virkning for byerne.\\nDen gældende lovgivning om vurdering af miljøvirkninger udgør også et værdifuldt redskab til at sikre, at nye udbygninger af byområderne bliver miljømæssigt bæredygtige. Rådets direktiv om strategisk miljøvurdering lægger op til, at der ses på udviklingens miljøvirkninger lige fra planlægningsprocessens begyndelse, og forstærker hermed den samling miljøredskaber, som vi har til rådighed. På dette område medvirker et betragteligt antal lokale projekter i en proces, som Kommissionen opmuntrer til. Men der er stadig behov for, at vi fornyer vores anstrengelser til fordel for miljømæssigt bæredygtige byer gennem mere strukturelle forholdsregler, i forhold til hvilke Kommissionen vil iværksætte en r', \"<|endoftext|>fløse den med en debat om procedurer. For, kære kolleger, lad os ikke tage fejl, det er en politisk beslutning, som vi skal træffe, når vi skal stemme om Cabrol-betænkningen.\\nHvis det kommer for retten, og hvis Domstolen skærer igennem angående retsgrundlaget, har den ret til det. Men Parlamentet, EU-borgernes stemme, kan ikke forbigå denne lejlighed til at forsvare EU's sundhed, som står vores medborgere nær, og på samme tid et viljekraftigt og pragmatisk billede på et EU, som for én gangs skyld lader en politisk beslutning veje tungere end den administrative forfrossenhed\\n\\nKestelijn-Sierens\\nHr. formand, hr. kommissær, kære kolleger, hele balladen om bestridelsen af retsgrundlaget er en manøvre, som vi ikke må lade os fange af. Juridiske tjenester fra både Parlamentet, Kommissionen og Rådet siger, at artikel 100 A er det rette grundlag. Det drejer sig her klart om en sag for det indre marked, ligesom der i Canada og Australien blev indført et føderalt forbud på grundlag af mediernes og reklametjenesternes frie bevægelighed på det harmoniserede marked.\\nNu kommer jeg til indholdet. Nogle hævder, at reklame må kunne bruges, så længe et produkt sælges på lovlig vis. Et reklameforbud for et lovligt produkt er ikke noget nyt. I 1992 blev der indført et forbud mod reklame for lægemidler, vel at mærke på grundlag af artikel 100 A. Andre siger, at brug af tobak ikke reduceres gennem et reklameforbud. Af tal fra det britiske sundhedsministerium læser vi, at rygning er reduceret i Norge, Finland, Canada og New Zealand som følge af forbuddet mod tobaksreklame. Som liberal siger jeg, at beskyttelse af sundheden tillader begrænsninger for ytringsfriheden og den frie markedsøkonomis principper. Samfundet har til opgave at beskytte borgerne mod et produkt, som direkte er ansvarligt for mere end en halv million europæiske borgeres død om året. Det er for øvrigt også samme samfund, som får lov at betale udgifterne til sundhedsvæsenet.\\nKære kolleger, det gælder endvidere også om at beskytte vores unge. De påvirkes let af den seje cowboy, som for øvrigt selv døde af lungekræft. Og til dem, som bruger beskæftigelsesargumentet: De økonomiske og sociale følger af dette direktiv begrænses af de lange frister for ikrafttrædelse, som står i det i Rådet opnåede kompromis.\\nKære kolleger, kampen mod tobak føres ikke blot her, men også andre steder i verden. Vi kender tobakssektorens perverse holdning. Jeg vil opfordre mine kolleger til at stemme for den fælles holdning og imod alle ændringsforslag, selvom de siges at være stillet med den hensigt at beskytte folkesundheden endnu bedre.\\n\\nGonzález Álvarez\\nHr. formand, vores gruppe støtter Miljøudvalgets og hr. Cabrols holdning - som er den samme - i den forstand, at vi forkaster alle de ændringsforslag, der kan svække Rådets aftale, for selvom ændringsforslagene fremsættes med den bedste vilje, kan man kun opnå, at Rådets holdning ikke forbliver den samme som oprindeligt. Beviset for, at der er medlemmer\", '<|endoftext|> andenbehandlingen holdt fast ved mindst disse 7 millioner euro. Jeg beklager meget, at kravet om en højere - og faktisk mere hensigtsmæssig - tærskelværdi end 7 millioner euro desværre ikke ser ud til at være mulig under den afsluttende behandling af udbudsdirektivet.\\nLige så vigtig som spillet om millionerne vedrørende tærskelværdien i det europæiske udbudsdirektiv er for mig også beskyttelsen af små og mellemstore virksomheder mod illoyal konkurrence. De selvstændige, som overholder loven, må ikke blive bragt i vanskeligheder af konkurrenter, som hverken overholder overenskomsterne, gældende arbejdsret, bestemmelserne om sundhedsbeskyttelse og sikkerhedsforanstaltninger til forebyggelse af ulykker på arbejdspladsen, eller som er ligeglade med miljøbeskyttelse.\\nDermed prioriterer vi det kommunale selvstyre højt, og det er også rigtigt, for det ligger fast, at de lokale myndigheder er det politiske plan, som er tættest på borgerne.\\nHr. Bolkestein, De har ret, når De siger, at skatteydernes penge skal gives ud på den bedst mulige måde. Det er jeg enig med Dem i. Men det er ikke nødvendigvis ensbetydende med det billigste tilbud. \"Bedst mulig\" er forbundet med kvalitet og bæredygtighed, det vil sige, at der skal tages hensyn til sociale, miljømæssige og andre forhold.\\nSchörling (Verts/ALE).\\nHr. formand, hr. kommissær, som ordfører for Miljøudvalgets udtalelse til denne betænkning fra Udvalget om Retlige Anliggender ved førstebehandlingen har jeg tænkt mig at koncentrere mig om miljøspørgsmålene og om spørgsmålet om bæredygtig udvikling.\\nKommissionsmedlem Bolkestein mente, at vi kan se frem til en happy end på den lange rejse mod en god lovgivning inden for offentlig kontraktindgåelse. Ja, at det bliver en \"end\", kan vi godt blive enige om, men hvor \"happy\" den bliver, tror jeg vil blive afgjort ved afstemningen. Rådet har naturligvis også stor indflydelse herpå.\\nJeg er bekymret over de ændringsforslag, som Udvalget om Retlige Anliggender har stillet, eftersom de går stik imod det, vi sagde ved førstebehandlingen. Vi er alle enige om, at offentlig kontraktindgåelse er en stor økonomisk faktor i EU, som står for 14-16 % af BNI. Når man tager hensyn til økonomien, bør man dog ikke kun se på det mest økonomisk fordelagtige tilbud. Det gælder om at have en bredere definition af økonomi, som også omfatter bevarelsen af naturressourcer, rent vand, ren luft og den biologiske mangfoldighed. Dette er præcis, hvad man har sagt fra Kommissionens og fra EU\\'s side generelt, og det er bl.a. blevet sagt i Johannesburg, nemlig at offentlig kontraktindgåelse skal bidrage til en bæredygtig udvikling. Det er underligt, at det har forbigået visse personers opmærksomhed i Europa-Parlamentet. Jeg hørte Lehne sige, at miljøspørgsmålene skal behandles for sig og de økonomiske spørgsmål for sig, men da har man misset hele pointen. Den offentlige kontraktindgåelse, hvor man anvender vores fælles ressourcer', '<|endoftext|>ens holdning til både de ændringsforslag, der er blevet godkendt i Udvalget om Retlige Anliggender og det Indre Marked, og til de ændringsforslag, som forhåbentlig bliver godkendt, når plenarforsamlingen kommer med en udtalelse vedrørende den gruppe af ændringsforslag, vi nu har præsenteret.\\nDavies (ELDR).\\nHr. formand, som andre medlemmer her i dag har jeg været udsat for omfattende lobbyaktivitet i forbindelse med dette direktiv, og jeg er imponeret over opbakningen - eller i det mindste den principielle opbakning - til det. Miljøforkæmperne opfatter det som en hellig gral, en metode til gennemførelse af princippet om, at forureneren betaler, i praksis. Repræsentanter for erhvervslivet har fortalt mig, at de også er enige i principperne, og forsikringsbranchen har sagt, at den kan få det til at fungere, når blot det indføres gradvis, og man får tid til at beregne omkostningerne korrekt.\\nSå hvorfor står Parlamentet, og også min gruppe, da så splittet i et spørgsmål, som alle synes at være enige om? Det lader til, at princippet er udmærket, så længe det ikke omsættes til praksis. I den sammenhæng opfatter jeg mig selv som pragmatiker. Jeg vil sikre, at lovgivningen kan anvendes i praksis og ikke medfører byrder, som tvinger erhvervslivet eller landbrugerne i knæ. Det er en af grundene til, at jeg modsætter mig indførelsen af solidarisk ansvar. Hvis der er fare for miljøet, er nogen nødt til at betale, og når forurenerne kan identificeres entydigt, skal de være de første til at betale.\\nAlle organisationer skal frem for alt være yderst opmærksomme på behovet for at indføre foranstaltninger, der kan forhindre skader i første omgang. Jeg mener ikke, at Udvalget om Retlige Anliggender og det Indre Marked har ydet Parlamentet retfærdighed. Det har indtaget holdninger, der ikke kun er minimalistiske, men rent faktisk er tilbageskridt, og som svækker Kommissionens forslag. Parlamentet er nødt til at foretage ændringer. Jeg er ikke enig i, at retsgrundlaget skal ændres. Vi bør udvide definitionen af miljøskader for at sikre særlige levesteder og arter. Vi bør benytte muligheden for at lægge pres på de medlemsstater, der ikke har ratificeret de internationale havkonventioner. Vi bør give borgerne ret til at gå direkte til domstolene for at forhindre miljøskader eller for at få erstatning.\\nIntet af dette er særligt radikalt. Vi har alle udtrykt bekymring over de skader, som menneskets aktiviteter påfører vores miljø. Denne foranstaltning er en mulighed, hvor vi kan begynde at gøre noget praktisk for at beskytte miljøet og sætte handling bag alle de smukke ord.\\n(Bifald fra venstre)\\nMacCormick (Verts/ALE).\\nHr. formand, som hele min gruppe glæder jeg mig i alt væsentligt over dette forslag og muligheden for at tale på gruppens vegne. Som min ven hr. Lannoye sagde, er det om ikke \"for lidt, for sent\" så i hvert tilfælde \"ikke særlig meget og temmelig sent\". Men det er et skridt i den rigtige retning, og det er meget vigtigt at få indført princippet om, at', '<|endoftext|> dette anbefalede ikke nogen grænseværdi på timebasis, men jeg mener, at det er mere realistisk at forsøge at reducere overskridelserne end at vælge den meget lavere grænseværdi, som nogle kolleger ønsker. SO2 -grænseværdierne bør vi se på igen i forbindelse med tilbageblikket i 2003, og vi må være klar over, at nogle medlemsstater har en lavere grænseværdi end den, der er angivet i teksten.\\nDer er et mindre problem med Kommissionens forslag om at beskytte økosystemer mod SO2 . WHO-retningslinjerne så på en række værdier for forskellige typer vegetation - afgrøder, skove, følsom vegation og lav. Miljøudvalget har besluttet at vælge den grænseværdi, der var fastsat for at beskytte lav, som er den mest følsomme vækst, og dette er betydeligt strengere end Kommissionens tekst. Jeg mener, at Kommissionen og Rådet bør se på dette igen og afgøre, om de ikke kan finde en bedre måde at fastsætte hensigtsmæssige grænseværdier. Det er ret så vanskeligt at vælge et tilfældigt antal, når man forsøger at beskæftige sig med fire forskellige ting.\\n��ndringsforslag 32 er en kompromistekst vedrørende placeringen af målestationer i små områder med følsomme økosystemer, hvilket jeg finder er en væsentlig forbedring i forhold til Kommissionens tekst. Vi har også, om end ret så modstræbende, åbnet døren for en række lokaliserede overskridelsestolerancer for bly, hvor nogle smelteværker for ikkejernholdigt metal simpelthen ikke vil være i stand til at overholde tidsfristen selv med den bedst tilgængelige teknologi. Det vil helt klart skulle overvåges meget omhyggeligt.\\nKolleger fra De Grønne ønsker betydeligt strengere grænseværdier for nitrogenoxider og svævestøv. Disse ændringsforslag er velmenende, men totalt urealistiske, og blev alle afvist i Udvalget. Men vi bør se omhyggeligt på, hvor langt vi er nået i år 2003. Stofferne er farlige, og jeg deler deres ønske om at skride hurtigere frem. Men niveauerne i teksten betyder allerede en stor reduktion af nitrogenoxider og svævestøv, og for at nå det, de foreslår, må vi på det nærmeste forbyde biler og lukke industrien. Som Londonbo kender jeg kun alt for godt til problemerne med luftforurening forårsaget af trafik, og der findes ingen nemme løsninger. Men en række andre direktiver, der befinder sig på tegnebrættet, vil bidrage til dette.\\nEndelig vil jeg gerne takke Kommissionen, den britiske repræsentation, udvalgssekretariatet og mine egne assistenter for alt det hårde arbejde, de har gjort. Jeg håber, at de regionale og lokale myndigheder vil være i stand til at gennemføre de meget strenge grænseværdier, der er fastsat. Jeg anbefaler direktivet og ændringsforslagene for Europa-Parlamentet.\\n\\nHulthén\\nHr. formand, forsuring er et kompliceret problem, da det rammer forskelligt. En del har aldrig set den sure regns effekter, andre kan stort set dagligt mærke forsuringens resultater. Det drejer sig således om mærkeligt voksende træer, døde grantræer, søer lige så', '<|endoftext|>\\nDe Grønne bakker fuldstændig op omkring Collins betænkning, som er glimrende. Afstemningen under førstebehandlingen var allerede fremragende, og den fælles holdning forbedrer i betydelig grad direktivet fra 1980.\\nNår dette er sagt, er der en hel del af de ændringsforslag, som blev genfremsat under andenbehandlingen, som efter vores mening er uomgængelige. Vi er specielt interesserede i ændringsforslag 25 og 26. Det første vedrører stoffer, som forstyrrer hormonsystemet. Man ved, i hvor høj grad disse stoffer, ifølge utallige forskere, selv i små doser kan have en ekstremt ødelæggende virkning på hormonsystemet.\\nI øvrigt er det andet ændringsforslag, som omhandler radioaktivitet, også et bevis på, at en hel del ting har ændret sig siden 1980. Vi ved nu, at der ikke er nogen nedre grænse, hvad angår radioaktivitets virkninger. Man kan således ikke tillade at acceptere, at drikkevand indeholder selv små doser radioaktivitet. Man skal formindske indholdet af radioaktivitet så meget som muligt, men vide, at det ikke er muligt at fjerne det fuldstændigt.\\nJeg vil gerne henlede opmærksomheden på stoffet tritium, som er et supertungt hydrogen. Tritium har den dobbelte egenskab både at kunne danne tritieret vand og at kunne indgå forbindelser med organiske partikler. I den forbindelse, og når man tager den lange levetid i betragtning, kan det potentielt spille en meget alvorlig rolle som kræftfremkaldende stof. Forskerne er ikke enige på dette punkt, men jeg tror, at hvis man holder sig til forsigtighedsprincippet, ville det være ønskeligt, hvis man kunne vedtage de værdier, som Udvalget om Miljø har fastlagt.\\nAf den grund beder jeg Kommissionen om at støtte dette ændringsforslag, således at man kan stemme om et direktiv, som er væsentligt forbedret i forhold til det tidligere.\\n\\nKronberger\\nHr. formand, når vi taler om vand eller om vandets kvalitet, skal vi være klar over, at der kun findes et vand i hele verden. En adskillelse af vand i vand, vi kan forurene, må forgifte, og som vi benytter til at få vores affald transporteret væk, og i vand, som vi skal bruge til vores livsfornødenheder, vil ikke være mulig i det lange løb. Vi bliver derfor nødt til at beskytte det samlede vandsystem overalt i verden optimalt, da jordens samlede vandsystem står i indbyrdes forbindelse.\\nBetænkningen - og her gentager jeg mig selv - er naturligvis det rigtige skridt i den rigtige retning. Navnlig historiske forkerte beslutninger som anvendelsen af blyrør, der udgør en fare for folks sundhed, skal korrigeres så hurtigt som muligt. Lige så betydningsfuld er indførelsen af grænseværdier for radioaktivitet. Da desinfektion af vand er en særlig god forretning for den kemiske industri, skal det også fremover påses, at tilsætningen af kemikalier reduceres til et absolut minimum.\\n\\nApolinário\\nHr. formand, ærede medlemmer, jeg vil gerne give udtryk for min fulde støtte til Collinsbetænkningen, navnlig med hensyn til det, der har med drikkevandets kvalitet at gøre. Tilfælde som dem, som man for nogle', '<|endoftext|>ssige aspekter.\\nMan skulle dog på baggrund af det vigtige i at få taget fat på produktionen af disse stoffer og de interesser, der er forbundet med den, forvente en langt klarere og mere direkte tilgang - for ikke at tale om, at der blev plæderet for at aktivere de eksisterende retningsgivende politiske mekanismer, der desværre indtil videre kun er blevet implementeret i begrænset omfang.\\n\\nReding\\nSyntetiske stoffer er farlige, selvom de ofte banaliseres. Da de er atypiske og derfor ikke må slås i hartkorn med de traditionelle stoffer (heroin, kokain osv.), anses de ofte fejlagtigt for at være harmløse.\\nAt det ikke er tilfældet, ved specialisterne. Men også de unge er udmærket klar over, at designer drugs og ecstasy på ingen måde er harmløse. Ifølge et rundspørge anså 95 % af de adspurgte unge de syntetiske stoffer for at være narkotika; 90 % angiver, at ecstasy er skadelig for sundheden; 77 % ved, at indtagelse af designer drugs medfører afhængighed.\\nAlligevel bliver talrige unge afhængige af disse stoffer. Da designer drugs for længst er blevet en del af en bestemt ungdomskultur, indtages de ved offentlige eller private dansearrangementer af de unge (hovedsagelig i aldersgruppen 17 til 25 år, men af og til også af helt unge på 13 år!). Det formodes, at 5 millioner unge i Unionen af og til eller regelmæssigt indtager syntetiske stoffer. I Luxembourg er fænomenet så akut, at \"Centre de prévention des toxicomanies« har ladet udarbejde en rapport om syntetiske stoffer i Luxembourg.\\nSyntetiske stoffer fremstilles af kemiske stoffer i køkkenlignende laboratorier. Det er derfor også uomgængeligt nødvendigt at få kontrol med disse stoffer (som ofte stammer fra Central- og Østeuropa). Et forbud mod fremstilling af og handel med designer drugs og amfetaminer er stærkt påkrævet, og det gælder i lige høj grad i samtlige EU-stater. De nationale lovgivninger skal tilpasses den nye situation.\\nMed henblik på en begrænsning af skaderne er der hårdt brug for forebyggelse og information. Her er der i nogle medlemsstater indhøstet interessante erfaringer (bl.a. med diskoteksaftener og Internet), og de bør udbredes i så høj grad som muligt.\\nDet er endvidere vigtigt, at der forskes mere i virkning og bivirkninger af disse relativt nye stoffer, for at særlig farlige stoffer kan erkendes i tide.\\nAlt i alt gælder det om at erkende, at de nye stoffer er farlige, at bekæmpe fremstilling af og handel med dem og informere de unge, for at skaden kan begrænses.\\n(Mødet udsat kl. 13.45 og genoptaget kl. 15.00)\\n\\nKvaliteten af drikkevand\\nFormanden\\nNæste punkt på dagsordenen er indstilling ved andenbehandling (A4-0146/98) for Udvalget om Miljø- og Sundhedsanliggender og Forbrugerbeskyttelse om Rådets fælles holdning fastlagt med henblik på vedtagelse af Rådets direktiv om kvaliteten af drikkevand (C4-0083/98-95/0010(SYN))) (Ordfører: K. Collins).\\n\\nGrossetête\\n Hr. formand, for os drejer det sig om at diskutere andenbehandlingen, efter førstebehandling', '<|endoftext|>ktiver. Jeg går derfor ud fra, at vi har et godt retsgrundlag, bl.a. efter at jeg har hørt udtalelser fra Parlamentets, Kommissionens og Rådets juridiske tjenester.\\nTil sidst lige to mere generelle bemærkninger, den første om unge og rygning. Det ville glæde mig, hvis medlemsstaterne ville øge deres bestræbelser på at fraråde de unge at begynde med at ryge, f.eks. gennem en prispolitik, eller f.eks. ved at gøre salgssteder utiltrækkende for de unge og vanskeligt tilgængelige eller ved at forbyde gratis uddeling af cigaretter på fortovscaféer eller i nærheden af skoler. Det er ikke overalt tilfældet.\\nEn anden bemærkning vedrører subsidierne til tobak. Vi har på den ene side dette direktiv, som vil fraråde rygning, og som gør opmærksom på sundhedsrisikoen, men samtidig giver Europa stadig vældig store subsidier til tobaksdyrkning. Jeg er tilhænger af, at denne efterhånden afvikles.\\nTil sidst vil jeg give ordføreren en kompliment for resultatet og takke ham for samarbejdet.\\n\\nSacconi\\nFru formand, vi er nu nået til sidste etape af dette vigtige direktiv. Den enighed, man nåede til i Forligsudvalget, bekræfter ordførerens glimrende arbejde og det samarbejde, der har været i Parlamentet om dette emne, som er så vigtigt for de europæiske borgere. Den tekst, vi nu skal vedtage, er en betydelig forbedring i forhold til Kommissionens tekst, og den er i endnu højere grad en forbedring i forhold til den tidligere situation.\\nFor en gangs skyld har man i det indre markeds harmoniseringsbestemmelser lagt større vægt på de europæiske borgeres sundhed end på de store fabrikanters interesser. Denne tekst er faktisk et vigtigt eksempel på, hvordan EU har til hensigt at efterkomme borgernes stadig mere indtrængende ønske om, at man beskytter deres sundhed. Vi håber virkelig, at dette eksempel snart bliver efterfulgt på andre områder, f.eks. når det gælder fødevaresikkerhed.\\nJeg vil ikke komme yderligere ind på forligets indhold, men blot understrege to vigtige punkter. Det første vigtige punkt er, at pligten til at overholde de maksimale grænseværdier for tjære, nikotin og kulilte også kommer til at gælde for cigaretter, der eksporteres til tredjelandes markeder. Denne bestemmelse var genstand for debat, og det var den først i Miljøudvalget og herefter på plenarmødet. Der var nogle, der forsvarede eksportvirksomhedernes interesser ved at hævde, at EU bestemt ikke ville bidrage til at forbedre verdenssundheden på denne måde, mens andre foretrak at fastslå princippet om, at det, der er skadeligt for EU-borgerne, også er skadeligt for tredjelandsborgerne, idet de dog også gav udtryk for, at det er nødvendigt med en tilstrækkeligt lang overgangsperiode for at give denne sektors virksomheder mulighed for at omstille sig. Vi gik ind for sidstnævnte mulighed, og den tekst, der blev vedtaget i Forligsudvalget, viste, at vi havde ret.\\nDet andet vigtige punkt er en definitiv regulering af tilsætningsstoffer til tobaksprodukter. Ud']\n","layer 2\n","995 ['<|endoftext|>}\\n\\n        private Filter csrfHeaderFilter() {\\n            return new OncePerRequestFilter() {\\n                @Override\\n                protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException {\\n\\n                    CsrfToken csrf = (CsrfToken) request.getAttribute(CsrfToken.class.getName());\\n                    if (csrf != null) {\\n                        Cookie cookie = WebUtils.getCookie(request, \"XSRF-TOKEN\");\\n                        String token = csrf.getToken();\\n                        if (cookie == null || token != null && !token.equals(cookie.getValue())) {\\n                            cookie = new Cookie(\"XSRF-TOKEN\", token);\\n                            cookie.setPath(\"/\");\\n                            response.addCookie(cookie);\\n                        }\\n                    }\\n                    filterChain.doFilter(request, response);\\n                }\\n            };\\n        }\\n\\n        private CsrfTokenRepository csrfTokenRepository() {\\n            HttpSessionCsrfTokenRepository repository = new HttpSessionCsrfTokenRepository();\\n            repository.setHeaderName(\"X-XSRF-TOKEN\");\\n            return repository;\\n        }\\n\\n    }\\n\\n}\\n\\nThe relevant segment of the server logs showing the CSRF error is:  \\n2016-01-20 02:02:06.811 DEBUG 3995 --- [nio-9000-exec-5] o.s.s.w.header.writers.HstsHeaderWriter  : Not injecting HSTS header since it did not match the requestMatcher org.springframework.security.web.header.writers.HstsHeaderWriter$SecureRequestMatcher@70b8c8bb\\n2016-01-20 02:02:06.813 DEBUG 3995 --- [nio-9000-exec-5] o.s.security.web.FilterChainProxy        : /send-pin at position 4 of 13 in additional filter chain; firing Filter: \\'CsrfFilter\\'\\n2016-01-20 02:02:06.813 DEBUG 3995 --- [nio-9000-exec-5] o.s.security.web.csrf.CsrfFilter         : Invalid CSRF token found for http://localhost:9000/send-pin\\n\\nWhat specific changes do I need to make to the code above to resolve this CSRF error?  \\nHow do I force an immediate update of the XSRF cookie upon whenever the backend /user service changes a user\\'s status (login, logout, etc.)?  \\nNote:  I am guessing (based on my research) that the solution to this problem will involve changing the configuration of some combination of the following Spring Security classes, all of which are defined in the UiApplication.java shown below:  \\n\\nthe WebSecurityConfigurerAdapter,  \\nthe OncePerRequestFilter,  \\nthe CsrfTokenRepository,  \\nthe GlobalAuthenticationConfigurerAdapter and/or  \\nthe Principal returned by the /user service.  \\n\\nBut what specific changes need to be made to solve the problem?\\n\\nA:\\n\\nUpdated Answer\\nThe reason you are getting a 401 is because a basic authentication header is found in the request when the user is registering. This means Spring Security tries to validate the credentials but the user is not yet present so it responds with a 401.\\nYou should\\n\\nMake the /register endpoint public and provide a controller that registers the user\\nDo not include the username/password for registration form in the Authorization header as this will cause Spring Security to try to validate the credentials. Instead include the parameters as JSON or form encoded parameters that your /register controller process\\n\\nOriginal Answer\\nAfter authenticating, Spring Security uses CsrfAuthenticationStrategy to invalidate any CsrfToken\\'s (to ensure that a session fixation attack is not possible). This is what triggers a new CsrfToken to be used.\\nHowever, the problem is that csrfTokenRepository is invoked before authentication is performed. This means that when csrfTokenRepository checks to see if the token has changed the result if false (it has not changed yet).\\nTo resolve the issue, you can inject a custom AuthenticationSuccessHandler. For example:\\npublic class MyAuthenticationSuccessHandler extends SavedRequestAwareAuthenticationSuccessHandler {\\n\\n    public void onAuthenticationSuccess(HttpServletRequest request,\\n                HttpServletResponse response, Authentication authentication)\\n                throws ServletException, IOException {\\n        CsrfToken csrf = (CsrfToken) request.getAttribute(CsrfToken.class.getName());\\n        if (csrf != null) {\\n            Cookie cookie = WebUtils.getCookie(request, \"XSRF-TOKEN\");\\n            ', '<|endoftext|> always had such a large back? and the boy risks everything he has to escape a dead end.\" \"Fullmetal Alchemist:\" \"The Fool\\'s Progress.\" \"You shall be the one to open fire.\"<|endoftext|>Q:\\n\\nSpring MVC handling session expired\\n\\nI\\'m working with Jboss EAP 6.2, Java EE 6 and Spring MVC 4.0.2.\\nWhen the session expired I want to execute a page redirect.\\nI have developed a Spring Interceptor\\n@Component\\npublic class SessionExpiredInterceptor extends HandlerInterceptorAdapter {\\n\\n    static final Logger logger = Logger.getLogger(SessionExpiredInterceptor.class);\\n    @Override\\n    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {\\n     final HttpSession session = request.getSession(false);\\n         if ( session == null || session.isNew() ) {\\n             ConfigurationProperties confProp = ConfigurationProperties.getInstance();\\n             logger.info(\"Sessione scaduta, redirect home page\");\\n             request.getSession(true);\\n             response.sendRedirect(request.getContextPath() + \"/\" + \\n                     confProp.getInstance().getProperty(\"session.expired.redirect\"));\\n         } \\n        return true;\\n\\n    }\\n}\\n\\nbut I have the following exeception:\\norg.springframework.beans.factory.BeanCreationException: Error creating bean with name \\'scopedTarget.navigator\\': Scope \\'session\\' is not active for the current thread; consider defining a scoped proxy for this bean if you intend to refer to it from a singleton; nested exception is java.lang.IllegalStateException: JBWEB000043: Cannot create a session after the response has been committed\\n    org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:353)\\n    org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)\\n    org.springframework.aop.target.SimpleBeanTargetSource.getTarget(SimpleBeanTargetSource.java:35)\\n    org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.getTarget(CglibAopProxy.java:676)\\n    org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:627)\\n    it.lispa.sire.finanziamentionline.web.mvc.model.Navigator$$EnhancerBySpringCGLIB$$b6b810e.addNavigationMessages(<generated>)\\n    it.lispa.sire.finanziamentionline.web.mvc.UserSessionInterceptor.preHandle(UserSessionInterceptor.java:91)\\n    org.springframework.web.servlet.HandlerExecutionChain.applyPreHandle(HandlerExecutionChain.java:130)\\n    org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:939)\\n    org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:876)\\n    org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961)\\n    org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:852)\\n    javax.servlet.http.HttpServlet.service(HttpServlet.java:734)\\n    org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837)\\n    javax.servlet.http.HttpServlet.service(HttpServlet.java:847)\\nJBWEB000071: root cause\\n\\njava.lang.IllegalStateException: JBWEB000043: Cannot create a session after the response has been committed\\n    org.apache.catalina.connector.Request.doGetSession(Request.java:2627)\\n    org.apache.catalina.connector.Request.getSession(Request.java:2361)\\n    org.apache.catalina.connector.RequestFacade.getSession(RequestFacade.java:790)\\n    org.springframework.web.context.request.ServletRequestAttributes.getSession(ServletRequestAttributes.java:79)\\n    org.springframework.web.context.request.ServletRequestAttributes.getSessionMutex(ServletRequestAttributes.java:212)\\n    org.springframework.web.context.request.SessionScope.get(SessionScope.java:91)\\n    org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:', '<|endoftext|>ArrayInputStream;\\nimport java.io.ByteArrayOutputStream;\\nimport java.io.IOException;\\nimport java.io.InputStreamReader;\\nimport java.io.ObjectInputStream;\\nimport java.io.ObjectOutput;\\nimport java.io.ObjectOutputStream;\\nimport java.io.PrintWriter;\\nimport java.io.StringWriter;\\nimport java.net.DatagramPacket;\\nimport java.net.DatagramSocket;\\nimport java.net.InetAddress;\\n\\nimport javax.servlet.ServletException;\\nimport javax.servlet.annotation.WebServlet;\\nimport javax.servlet.http.HttpServlet;\\nimport javax.servlet.http.HttpServletRequest;\\nimport javax.servlet.http.HttpServletResponse;\\n\\nimport javax.servlet.*;\\nimport javax.servlet.http.*;\\n\\n/**\\n * Servlet implementation class DefaultServlet\\n */\\n\\npublic class DefaultServlet extends HttpServlet \\n{\\n    private static final long serialVersionUID = 1L;\\n    private MatchHandler matchHandler;\\n    private RequestDispatcher jsp;\\n    private ParisHandler parisHandler;\\n\\n    /**\\n     * @see HttpServlet#HttpServlet()\\n     */\\n    public DefaultServlet() \\n    {\\n        super();\\n        matchHandler = new MatchHandler();\\n        parisHandler = new ParisHandler();\\n    }\\n\\n    /**\\n     * @see HttpServlet#doGet(HttpServletRequest request, HttpServletResponse response)\\n     */\\n    protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException \\n    {\\n        System.out.println(\"doGet\");\\n        processRequest(request, response);\\n    }\\n\\n    /**\\n     * @see HttpServlet#doPost(HttpServletRequest request, HttpServletResponse response)\\n     */\\n    protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException \\n    {\\n        System.out.println(\"doPost\");\\n        processRequest(request, response);\\n    }\\n\\n    protected void processRequest(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {\\n        // 1. get received JSON data from request\\n        BufferedReader br = new BufferedReader(new InputStreamReader(request.getInputStream()));\\n        String json = null;\\n        try \\n        {\\n            /*json = matchHandler.GetListeMatchJSON();\\n            System.out.println(json);\\n\\n            String reponse =  parisHandler.PostParis(\"Miaw\", \"Montreal\", 5, \"1\");\\n            System.out.println(reponse);*/\\n        } \\n        catch (ClassNotFoundException e) \\n        {\\n            e.printStackTrace();\\n        }\\n        //response.getWriter().write(arg0);\\n        //response.sendRedirect(\"http://localhost:8080/HockeyNightWeb/index.jsp\");\\n    }\\n\\n}\\n\\nDoes anyone have an idea why?\\nThank you\\n\\nA:\\n\\nNote: You are referring to diffrent URLs with the same servlet-name !\\nUse only this as your web.xml entry\\n<display-name>HockeyNightWeb</display-name>\\n   <welcome-file-list>\\n    <welcome-file>login.jsp</welcome-file>\\n   </welcome-file-list>\\n\\n    <servlet>\\n        <servlet-name>DefaultServlet</servlet-name>\\n        <servlet-class>DefaultServlet</servlet-class>\\n    </servlet>\\n</web-app>\\n\\n<|endoftext|>Q:\\n\\nReplace plus, double quotes and spaces except spaces surrounded by double quotes\\n\\nI have such text text + \" \" + getIncrementedNumber(). I want to replace to empty string the following characters via JavaScript: +, \" and all spaces except that spaces, which are surounded by double quotes. Examples of input and output, which I want to achieve:\\n\\ninput: text + \" \" + getIncrementedNumber(); \\noutput: text getIncrementedNumber()\\ninput: text + \"WhateveR\" + getIncrementedNumber(); \\noutput: textWhateveRgetIncrementedNumber()\\ninput: text +\"Lorem ipsuM\"+ getIncrementedNumber(); \\noutput: textLorem ipsuMgetIncrementedNumber()\\n\\nI am trying with these RegExps:\\n\\nsourceText.replace( /\\\\+|\\\\s|\\\\b\"(.*?)\\\\b\"/g, \\'\\' ), which results in \\'text\"\"getIncrementedNumber()\\'\\nsourceText.replace( /\\\\+|\\\\s|\\\\\"(.*?)\\\\\"/g, \\'\\' ), which results in \\'textgetIncrementedNumber', '<|endoftext|> and the relevant portions of the record reflected therein. We concur with\\ncounsel’s assessment that the appeal presents no nonfrivolous issue for\\n\\n\\n       * Pursuant to 5TH CIR. R. 47.5, the court has determined that this opinion should not\\nbe published and is not precedent except under the limited circumstances set forth in 5TH\\nCIR. R. 47.5.4.\\n\\x0c    Case: 19-40770    Document: 00515348908    Page: 2   Date Filed: 03/18/2020\\n\\n\\n                                No. 19-40770\\n\\nappellate review.    Accordingly, counsel’s motion for leave to withdraw is\\nGRANTED, counsel is excused from further responsibilities herein, and the\\nAPPEAL IS DISMISSED. See 5TH CIR. R. 42.2.\\n\\n\\n\\n\\n                                      2\\n\\x0c<|endoftext|>/*\\n * Copyright (c) MuleSoft, Inc.  All rights reserved.  http://www.mulesoft.com\\n * The software in this package is published under the terms of the CPAL v1.0\\n * license, a copy of which has been included with this distribution in the\\n * LICENSE.txt file.\\n */\\npackage org.mule.runtime.module.deployment.impl.internal.domain;\\n\\nimport org.mule.runtime.deployment.model.api.domain.Domain;\\nimport org.mule.runtime.deployment.model.api.domain.DomainDescriptor;\\nimport org.mule.runtime.module.deployment.impl.internal.artifact.DeployableArtifactWrapper;\\n\\nimport java.io.IOException;\\n\\n/**\\n * Domain wrapper used to notify domain factory that a domain has been disposed or started.\\n */\\npublic class DomainWrapper extends DeployableArtifactWrapper<Domain, DomainDescriptor> implements Domain {\\n\\n  private final DefaultDomainFactory domainFactory;\\n\\n  protected DomainWrapper(final Domain delegate, final DefaultDomainFactory domainFactory) throws IOException {\\n    super(delegate);\\n    this.domainFactory = domainFactory;\\n  }\\n\\n  @Override\\n  public boolean containsSharedResources() {\\n    return getDelegate().containsSharedResources();\\n  }\\n\\n  @Override\\n  public void dispose() {\\n    try {\\n      getDelegate().dispose();\\n    } finally {\\n      domainFactory.dispose(this);\\n    }\\n  }\\n}\\n<|endoftext|>Q:\\n\\nGoogle Script testing add-on, unable to load file\\n\\nI\\'ve been making simple scripts in Google Docs and Sheets for a couple of years, but now I\\'m trying to convert some of it to an add-on. I think I should test the add-on before I publish it and send it to review. \\nIn the scripting window i click: Run > Test as add-on.\\nI choose another document for testing, but when I hit the blue test-button I get an error message: \"Unable to load file. Try load it again or send an error report.\"\\nScreen shot of error\\nI may open the document manually. I\\'ve tried with several different files and scripts. Same error. \\nI hope you may give me a clue to the cause of this. I\\'m using Firefox 57.0.4 (64-bits) and a private Google account. \\n\\nA:\\n\\nUsing Chrome works! I also rebooted the computer, but didn\\'t have to delete settings etc. \\n\\n<|endoftext|>---\\nabstract: \\'We present a spatio-kinematical study of the planetary nebula (PN) IC4634 which has experienced several episodes of point-symmetric ejections oriented at different directions. The nebula displays two S-shaped low-ionization arcs that are probably related to two relatively recent point-symmetric ejections, the outer S-shaped arc representing a beautiful example of a bow-shock resolved in a PN. We report here the discovery of an arc-like string of knots at larger distances from IC4634 central star that represents a much earlier point-symmetric ejection.\\'\\nauthor:\\n- \\'Martín A.\\xa0Guerrero, Luis F.\\xa0Miranda, You-Hua Chu\\'\\ntitle: \\'Multiple Point-Symmetric Ejections in IC4634\\'\\n---\\n\\nIntroduction\\n============\\n\\nIC4634 is one of the most spectacular point-symmetric planetary nebulae (PNe). Its remarkable double-S-shaped morphology is reflected in its kinematics, with two oppositely directed pairs of red- and blue-shifted features straddling the nebula (Schwarz 1993). The morphology and kinematics suggest a precession or rotation of the source that produced these highly symmetric outflows.\\n\\nWe have used narrow-band archival [*HST*]{} images in the \\\\[O\\xa0[iii]{}\\\\], H$\\\\alpha$, and \\\\[N\\xa0[ii]{}', '<|endoftext|> named by Constantine Samuel Rafinesque\\nCategory:Marine fish genera<|endoftext|>Q:\\n\\nDeleting a remote branch with Egit\\n\\nI am using EGit 3.2 with Eclipse.  I cannot figure out how to delete a branch from my remote repository.  I\\'m working on a Drupal project and the mods there want me to delete the master branch. I have the version specific branch (7.x-1.x) set up and on the server.  When I go to the Git perspective and delete the master branch from the remote tracking section, the branch disappears but not from the server.  I\\'ve tried deleting and then pushing the project back up to no avail.  \\nI\\'ve also tried it from the PHP perspective by going to Team --> Advanced --> Delete Branch and selecting the master branch.  \\nWhat do I need to do?\\n\\nA:\\n\\nGo in your menu to Team > Remote > Push. \\nSelect your repository, and click Next. \\nUnder Remote ref to delete - select your branch and click Add spec. Then Finish.\\nThis will delete the remote branch.\\n\\n<|endoftext|>/*\\n * Copyright 2015 Stormpath, Inc.\\n *\\n * Licensed under the Apache License, Version 2.0 (the \"License\");\\n * you may not use this file except in compliance with the License.\\n * You may obtain a copy of the License at\\n *\\n *     http://www.apache.org/licenses/LICENSE-2.0\\n *\\n * Unless required by applicable law or agreed to in writing, software\\n * distributed under the License is distributed on an \"AS IS\" BASIS,\\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n * See the License for the specific language governing permissions and\\n * limitations under the License.\\n */\\npackage com.stormpath.sdk.servlet.filter.config;\\n\\nimport com.stormpath.sdk.servlet.config.Config;\\nimport com.stormpath.sdk.servlet.config.ConfigResolver;\\nimport com.stormpath.sdk.servlet.config.ConfigSingletonFactory;\\nimport com.stormpath.sdk.servlet.filter.DefaultUnauthorizedHandler;\\nimport com.stormpath.sdk.servlet.filter.UnauthorizedHandler;\\n\\nimport javax.servlet.ServletContext;\\n\\n/**\\n * @since 1.0.RC3\\n */\\npublic class UnauthorizedHandlerFactory extends ConfigSingletonFactory<UnauthorizedHandler> {\\n\\n    @Override\\n    protected UnauthorizedHandler createInstance(ServletContext servletContext) throws Exception {\\n        Config config = ConfigResolver.INSTANCE.getConfig(servletContext);\\n        String unauthorizedUrl = config.getUnauthorizedUrl();\\n        return new DefaultUnauthorizedHandler(unauthorizedUrl);\\n    }\\n}\\n<|endoftext|>Hipólito Ruiz López\\n\\nHipólito Ruiz López (August 8, 1754 in Belorado, Burgos, Spain – 1816 in Madrid), or Hipólito Ruiz, was a Spanish botanist known for researching the floras of Peru and Chile during an expedition under Carlos III from 1777 to 1788. During the reign of Carlos III, three major botanical expeditions were sent to the New World; Ruiz and José Antonio Pavón Jiménez were the botanists for the first of these expeditions, to Peru and Chile.\\n\\nBackground\\nAfter studying Latin with an uncle who was a priest, at the age of 14 Ruiz López went to Madrid to study logic, physics, chemistry and pharmacology. He also studied botany at the Migas Calientes Botanical Gardens (now the Real Jardín Botánico de Madrid), under the supervision of Casimiro Gómez Ortega (1741–1818) and Antonio Palau Verdera (1734–1793).\\n\\nRuiz had not yet completed his pharmacology studies when he was named the head botanist of the expedition. The French physician Joseph Dombey was named as his assistant, and the pharmacologist José Antonio Pavón y Jimenez was also appointed. Completing the expedition were the botanical illustrators Joseph Bonete and Isidro Gálvez.\\n\\nThe expedition\\n\\nThe expedition sailed from Cádiz in 1777, arriving at Lima in April 1778. They explored throughout Peru and Chile for ten years (1778–1788), collecting specimens. The expedition collected 3,000 specimens of plants and made 2,500 life-sized botanical illustrations. When they returned to Spain they brought back a great many living plants.\\n\\nOne of the medical remedies brought back by this expedition was the boiled spouts of the quisoar plant, Buddleja incana, which was used to cure colds or, mixed with urine, to alleviate toothache.\\n\\n', '<|endoftext|>LOG, \"Connection info: \" + log);\\n        }\\n\\n        private Voice parseSynthesisVoiceType(String t, Locale locale) throws Exception {\\n            String voiceName = parseProtocolParameter(t, \"VOICE\", \"VOICE_NAME_OR_GENDER\");\\n            if ((voiceName.equals(\"male\") || voiceName.equals(\"female\")) && locale != null) {\\n                // Locale-specific interpretation of gender\\n                return Voice.getVoice(locale, new Voice.Gender(voiceName));\\n            } else {\\n                // Plain old voice name\\n                return Voice.getVoice(voiceName);\\n            }\\n        }\\n\\n        private MaryDataType parseSynthesisRequiredInputType(StringTokenizer t) throws Exception {\\n            if (!t.hasMoreTokens()) {\\n                Log.d(Mary.LOG, new Exception(\"Expected IN=<INPUTTYPE>\").toString());\\n                throw new Exception(\"Expected IN=<INPUTTYPE>\");\\n            }\\n            String input = parseProtocolParameter(t.nextToken(), \"IN\", \"INPUTTYPE\");\\n            MaryDataType inputType = MaryDataType.get(input);\\n            if (inputType == null) {\\n                Log.d(Mary.LOG, new Exception(\"Invalid input type: \" + input).toString());\\n                throw new Exception(\"Invalid input type: \" + input);\\n            }\\n            return inputType;\\n        }\\n\\n        private MaryDataType parseSynthesisRequiredOutputType(StringTokenizer t) throws Exception {\\n            if (!t.hasMoreTokens()) {\\n                Log.d(Mary.LOG, new Exception(\"Expected OUT=<OUTPUTTYPE>\").toString());\\n                throw new Exception(\"Expected OUT=<OUTPUTTYPE>\");\\n            }\\n            String output = parseProtocolParameter(t.nextToken(), \"OUT\", \"OUTPUTTYPE\");\\n            MaryDataType outputType = MaryDataType.get(output);\\n            if (outputType == null) {\\n                Log.d(Mary.LOG, new Exception(\"Invalid output type: \" + output).toString());\\n                throw new Exception(\"Invalid output type: \" + output);\\n            }\\n            return outputType;\\n        }\\n\\n        private Locale parseSynthesisRequiredLocale(StringTokenizer t) throws Exception {\\n            if (!t.hasMoreTokens()) {\\n                Log.d(Mary.LOG, new Exception(\"Expected LOCALE=<locale>\").toString());\\n                throw new Exception(\"Expected LOCALE=<locale>\");\\n            }\\n            String localeString = parseProtocolParameter(t.nextToken(), \"LOCALE\", \"locale\");\\n            return MaryUtils.string2locale(localeString);\\n        }\\n\\n        private boolean handleNumberRequest(String inputLine, Reader reader)\\n                throws Exception {\\n            // * if number\\n            int id = 0;\\n            try {\\n                id = Integer.parseInt(inputLine);\\n            } catch (NumberFormatException e) {\\n                return false;\\n            }\\n            //   -- find corresponding infoSocket and request in clientMap\\n            Socket infoSocket = null;\\n            Request request = null;\\n            // Wait up to TIMEOUT milliseconds for the first ClientHandler\\n            // to write its clientMap entry:\\n            long TIMEOUT = 1000;\\n            long startTime = System.currentTimeMillis();\\n            Object[] value = null;\\n            do {\\n                Thread.yield();\\n                value = clientMap.get(id);\\n            } while (value == null && System.currentTimeMillis() - startTime < TIMEOUT);\\n            if (value != null) {\\n                infoSocket = (Socket) value[0];\\n                request = (Request) value[1];\\n            }\\n            // Verify that the request is non-null and that the\\n            // corresponding socket comes from the same IP address:\\n            if (request == null || infoSocket == null || !infoSocket.getInetAddress().equals(client.getInetAddress())) {\\n                Log.d(Mary.LOG, new Exception(\"Invalid identification number.\").toString());\\n                throw new Exception(\"Invalid identification number.\");\\n                // Don\\'t be more specific, because in general it is none of\\n                // their business whether in principle someone else has\\n                // this id.\\n            }\\n\\n            //   -- delete clientMap entry\\n            try {\\n                clientMap.remove(id);\\n            } catch (UnsupportedOperationException e) {\\n                Log.i(Mary.LOG, \"Cannot remove clientMap entry\", e);\\n            }\\n            //   -- send off to new request\\n            RequestHandler rh = new RequestHandler(request, info', '<|endoftext|>      \\n    }\\n\\n    /**\\n     * @see HttpServlet#doGet(HttpServletRequest request, HttpServletResponse response)\\n     */\\n    protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {\\n        response.setContentType(\"text/html\");\\n        PrintWriter out = response.getWriter();\\n        out.println(\"<html>\");\\n        out.println(\"<head><title>Check tempetaure</title></head>\");\\n        out.println(\"<body>\");\\n        out.println(\"<input type=\\\\\"submit\\\\\" value=\\\\\"Check temperature\\\\\" name=\\\\\"button\\\\\"/>\");\\n        out.println(\"<input type=\\\\\"submit\\\\\" value=\\\\\"Get AC state\\\\\" name=\\\\\"button\\\\\"/>\");\\n        out.println(\"<input type=\\\\\"submit\\\\\" value=\\\\\"Turn ON AC\\\\\" name=\\\\\"button\\\\\"/>\");\\n        out.println(\"<input type=\\\\\"submit\\\\\" value=\\\\\"Turn OFF AC\\\\\" name=\\\\\"button\\\\\"/>\");\\n        out.println(\"</body>\");\\n        out.println(\"</html>\");     \\n    }\\n    /**\\n     * @see HttpServlet#doPost(HttpServletRequest request, HttpServletResponse response)\\n     */\\n    protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {\\n        PrintWriter out = response.getWriter();\\n        String button = request.getParameter(\"button\");\\n        if(button.equalsIgnoreCase(\"Check temperature\")){\\n            request.getRequestDispatcher(\"/WEB-INF/jsps/checkTemperature.jsp\").include(request, response);\\n        } else if(button.equalsIgnoreCase(\"Get AC state\")){\\n            request.getRequestDispatcher(\"/WEB-INF/jsps/acState.jsp\").include(request, response);\\n        } else if(button.equalsIgnoreCase(\"Turn ON AC\")){\\n            request.getRequestDispatcher(\"/WEB-INF/jsps/turnOn.jsp\").include(request, response);\\n        } else if(button.equalsIgnoreCase(\"Turn OFF AC\")){\\n            request.getRequestDispatcher(\"/WEB-INF/jsps/turnOff.jsp\").include(request, response);\\n        }           \\n    }    \\n}\\n\\nweb.xml\\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<web-app xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://java.sun.com/xml/ns/javaee\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd\" id=\"WebApp_ID\" version=\"3.0\">\\n  <display-name>ArduinoController</display-name>\\n  <welcome-file-list>\\n    <welcome-file>index.html</welcome-file>\\n    <welcome-file>index.htm</welcome-file>\\n    <welcome-file>index.jsp</welcome-file>\\n    <welcome-file>default.html</welcome-file>\\n    <welcome-file>default.htm</welcome-file>\\n    <welcome-file>default.jsp</welcome-file>\\n  </welcome-file-list>\\n  <servlet>\\n    <description></description>\\n    <display-name>ACController</display-name>\\n    <servlet-name>MainServlet</servlet-name>\\n    <servlet-class>ro.dnad.controller.MainServlet</servlet-class>\\n  </servlet>\\n  <servlet-mapping>\\n    <servlet-name>MainServlet</servlet-name>\\n    <url-pattern>/main</url-pattern>\\n  </servlet-mapping>\\n</web-app>\\n\\ncheckTemperature.jsp\\n<%@ page language=\"java\" contentType=\"text/html; charset=ISO-8859-1\"\\npageEncoding=\"ISO-8859-1\"%>\\n<%@ page import=\"ro.dnad.controller.EthernetACDriver\" %>\\n\\n<%EthernetACDriver driver = new EthernetACDriver(\"localhost\",8080); %>\\n<%double temp = driver.getTemperature() * 5; %>\\n<%=temp%>\\n\\nacState.jsp\\n<%@ page language=\"java\" contentType=\"text/html; charset=ISO-8859-1\"\\npageEncoding=\"ISO-8859-1\"%>\\n<%@ page import=\"ro.dnad.controller.EthernetACDriver\"', '<|endoftext|>(URI baseURI) {\\n        return baseURI.resolve(SERVLET_NAME);\\n    }\\n\\n    @Override\\n    protected void doPut(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {\\n        request.getServletContext().log(request.getRequestURI() + \":PUT\");\\n        HttpSession session = request.getSession();\\n        SessionActivationListener listener = new ImmutableSessionActivationListener(true);\\n        session.setAttribute(IMMUTABLE_ATTRIBUTE_NAME, listener);\\n        listener.assertActive();\\n        listener = new MutableSessionActivationListener(true);\\n        session.setAttribute(MUTABLE_ATTRIBUTE_NAME, listener);\\n        listener.assertActive();\\n    }\\n\\n    @Override\\n    protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {\\n        request.getServletContext().log(request.getRequestURI() + \":GET\");\\n        HttpSession session = request.getSession();\\n        ((SessionActivationListener) session.getAttribute(IMMUTABLE_ATTRIBUTE_NAME)).assertActive();\\n        ((SessionActivationListener) session.getAttribute(MUTABLE_ATTRIBUTE_NAME)).assertActive();\\n    }\\n\\n    @Override\\n    protected void doDelete(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {\\n        request.getServletContext().log(request.getRequestURI() + \":DELETE\");\\n        HttpSession session = request.getSession();\\n        request.getServletContext().log(request.getRequestURI() + \":removeAttribute(\" + IMMUTABLE_ATTRIBUTE_NAME + \")\");\\n        session.removeAttribute(IMMUTABLE_ATTRIBUTE_NAME);\\n        request.getServletContext().log(request.getRequestURI() + \":removeAttribute(\" + MUTABLE_ATTRIBUTE_NAME + \")\");\\n        session.removeAttribute(MUTABLE_ATTRIBUTE_NAME);\\n    }\\n\\n    private static class MutableSessionActivationListener extends SessionActivationListener {\\n        private static final long serialVersionUID = 7944013938798510317L;\\n\\n        MutableSessionActivationListener(boolean active) {\\n            super(active);\\n        }\\n    }\\n\\n    @Immutable\\n    private static class ImmutableSessionActivationListener extends SessionActivationListener {\\n        private static final long serialVersionUID = -6294242158180373273L;\\n\\n        ImmutableSessionActivationListener(boolean active) {\\n            super(active);\\n        }\\n    }\\n\\n    private abstract static class SessionActivationListener implements HttpSessionActivationListener, HttpSessionBindingListener, Serializable {\\n        private static final long serialVersionUID = 8262547876438811845L;\\n\\n        private transient boolean active = false;\\n\\n        SessionActivationListener(boolean active) {\\n            this.active = active;\\n        }\\n\\n        public void assertActive() {\\n            if (!this.active) {\\n                throw new IllegalStateException(String.format(\"%s.sessionDidActivate(...) not invoked\", this.getClass().getSimpleName()));\\n            }\\n        }\\n\\n        @Override\\n        public void sessionWillPassivate(HttpSessionEvent event) {\\n            if (!this.active) {\\n                throw new IllegalStateException(String.format(\"%s.sessionWillPassivate(...) already invoked\", this.getClass().getSimpleName()));\\n            }\\n            this.active = false;\\n        }\\n\\n        @Override\\n        public void sessionDidActivate(HttpSessionEvent event) {\\n            if (this.active) {\\n                throw new IllegalStateException(String.format(\"%s.sessionDidActivate(...) already invoked\", this.getClass().getSimpleName()));\\n            }\\n            this.active = true;\\n        }\\n\\n        @Override\\n        public void valueBound(HttpSessionBindingEvent event) {\\n            this.assertActive();\\n        }\\n\\n        @Override\\n        public void valueUnbound(HttpSessionBindingEvent event) {\\n            this.assertActive();\\n        }\\n\\n        private void writeObject(java.io.ObjectOutputStream out) throws IOException {\\n            if (this.active) {\\n                throw new NotSerializableException(String.format(\"%s.sessionWillPassivate(...) not invoked\", this.getClass().getSimpleName()));\\n            }\\n            out.defaultWriteObject();\\n        }\\n    }\\n}\\n<|endoftext|>Only 7.2 people out of every 1,000 got married in China last year, the lowest marriage rate', '<|endoftext|>dependent Ultrastructure of Seed Surface.\\nBoth scanning electron microscopy (SEM) and contact mode imaging via atomic force microscopy (AFM) have been utilized to elucidate the ultrastructure of mung bean seed surfaces. The results indicate: 1) that AFM is useful in the examination of seed surface ultrastructure ex-vaccuo without the need for additional complex preparative procedures; and 2) that both the cotyledon and seed coat of different strains of mung beans bear specific ultrastructural details unique to each strain. To our knowledge, these are the first AFM images of seed surfaces.<|endoftext|>Q:\\n\\nHow to redirect to another page by clicking on image\\n\\npackage com.system.servlets;\\n\\nimport java.io.BufferedInputStream;\\n\\nimport java.io.BufferedOutputStream;\\nimport java.io.FileInputStream;\\nimport java.io.IOException;\\nimport java.io.PrintWriter;\\n\\nimport javax.servlet.ServletConfig;\\nimport javax.servlet.ServletException;\\nimport javax.servlet.ServletOutputStream;\\nimport javax.servlet.annotation.WebServlet;\\nimport javax.servlet.http.HttpServlet;\\nimport javax.servlet.http.HttpServletRequest;\\nimport javax.servlet.http.HttpServletResponse;\\n\\n/**\\n * Servlet implementation class Redirect\\n */\\n@WebServlet(\"/Redirect\")\\npublic class Redirect extends HttpServlet {\\n    private static final long serialVersionUID = 1L;\\n\\n    /**\\n     * @see Servlet#init(ServletConfig)\\n     */\\n    public void init(ServletConfig config) throws ServletException {\\n    System.out.println(\"servlet is intialized\");\\n    }\\n\\n    /**\\n     * @see HttpServlet#doGet(HttpServletRequest request, HttpServletResponse response)\\n     */\\n    protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {\\n        response.setContentType(\"image/jpeg\");  \\n        ServletOutputStream out;  \\n        out = response.getOutputStream();  \\n        FileInputStream fin = new FileInputStream(\"/home/mpatil/Desktop/Ram/downloads/gmail image.jpg\");  \\n\\n        BufferedInputStream bin = new BufferedInputStream(fin);  \\n        BufferedOutputStream bout = new BufferedOutputStream(out);  \\n        int ch =0; ;  \\n        while((ch=bin.read())!=-1)  \\n        {  \\n        bout.write(ch);  \\n        }  \\n\\n        bin.close();  \\n        fin.close();  \\n        bout.close();  \\n        out.close();    \\n\\n    }\\n\\n}\\n\\nThis is my servlets program,it would  showing gmail image.Now my question is if i click on gmail image then it redirect to gmail login page.Is there any possible in Servlets ?What are the changes in my program.?give me suggestion for my case.Good answers will always appreciate.\\n\\nA:\\n\\nYou cannot do what you want to do in the way you have tried. Here you are sending the image in the stream. What you have to do is send a HTML page which has a link to image and have that image inside href tag which directs to google login. (as following)\\n<html>\\n<body>\\n<a href=\"link to page where you want it to go on click\"><img src=\"path to your image\"></a>\\n</body>\\n</html>\\n\\nopen a notepad or any text editor copy above html as required and save it as a jsp with required file name.\\n\\n<|endoftext|>Q:\\n\\nreact-intl render react component as placeholder in formatMessage\\n\\nI have a component, that uses the injectIntl-HOC, and returns a message\\n...\\nreturn (\\n  <Message>\\n    {intl.formatMessage({\\n      id: \\'page.checkout.hint\\'\\n    }, {\\n      link: <b>{intl.formatMessage({ id: \\'page.checkout.hint.hyperlink\\' })}</b>\\n    })}\\n  </Message>\\n)\\n...\\n\\nand my language file looks like this:\\n...\\n\"page.checkout.hint\": \"You\\'re going to be redirected automatically. If nothing happens, please click {link}\",\\n\"page.checkout.hint.hyperlink\": \"here\",\\n...\\n\\nThis results in: You\\'re going to be redirected automatically. If nothing happens, please click [object Object].\\nif i use <FormattedMessage id=\"page.checkout.hint\" values={{ link: <b>{intl.formatMessage({ id: \\'page.checkout.hint.hyper', '<|endoftext|> permissions and limitations\\n * under the License.\\n *\\n * Contributors:\\n *     Florent Guillaume\\n */\\npackage org.nuxeo.ecm.core.opencmis.bindings;\\n\\nimport static javax.servlet.http.HttpServletResponse.SC_OK;\\nimport static org.apache.chemistry.opencmis.commons.impl.JSONConstants.ERROR_EXCEPTION;\\nimport static org.apache.chemistry.opencmis.commons.impl.JSONConstants.ERROR_MESSAGE;\\nimport static org.apache.chemistry.opencmis.commons.impl.JSONConstants.ERROR_STACKTRACE;\\n\\nimport java.io.IOException;\\n\\nimport javax.servlet.ServletException;\\nimport javax.servlet.http.HttpServletRequest;\\nimport javax.servlet.http.HttpServletResponse;\\n\\nimport org.apache.chemistry.opencmis.commons.exceptions.CmisBaseException;\\nimport org.apache.chemistry.opencmis.commons.impl.json.JSONObject;\\nimport org.apache.chemistry.opencmis.commons.server.CallContext;\\nimport org.apache.chemistry.opencmis.commons.server.CmisService;\\nimport org.apache.chemistry.opencmis.server.impl.browser.AbstractBrowserServiceCall;\\nimport org.apache.chemistry.opencmis.server.impl.browser.BrowserCallContextImpl;\\nimport org.apache.chemistry.opencmis.server.impl.browser.CmisBrowserBindingServlet;\\nimport org.apache.chemistry.opencmis.server.shared.Dispatcher;\\nimport org.apache.chemistry.opencmis.server.shared.ExceptionHelper;\\nimport org.apache.commons.lang3.StringUtils;\\nimport org.nuxeo.ecm.core.opencmis.bindings.NuxeoCmisErrorHelper.ErrorInfo;\\nimport org.nuxeo.ecm.platform.web.common.vh.VirtualHostHelper;\\nimport org.slf4j.Logger;\\nimport org.slf4j.LoggerFactory;\\n\\n/**\\n * Subclass NuxeoCmisBrowserBindingServlet to inject a virtual-hosted base URL if needed.\\n */\\npublic class NuxeoCmisBrowserBindingServlet extends CmisBrowserBindingServlet {\\n\\n    private static final long serialVersionUID = 1L;\\n\\n    private static final Logger LOG = LoggerFactory.getLogger(NuxeoCmisBrowserBindingServlet.class);\\n\\n    public static final NuxeoBrowserServiceCall CALL = new NuxeoBrowserServiceCall();\\n\\n    @Override\\n    protected void service(HttpServletRequest request, HttpServletResponse response) throws ServletException,\\n            IOException {\\n        String baseUrl = VirtualHostHelper.getBaseURL(request);\\n        if (baseUrl != null) {\\n            baseUrl = StringUtils.stripEnd(baseUrl, \"/\") + request.getServletPath() + \"/\"\\n                    + AbstractBrowserServiceCall.REPOSITORY_PLACEHOLDER + \"/\";\\n            request.setAttribute(Dispatcher.BASE_URL_ATTRIBUTE, baseUrl);\\n        }\\n        super.service(request, response);\\n    }\\n\\n    /**\\n     * Extracts the error from the exception.\\n     *\\n     * @param ex the exception\\n     * @return the error info\\n     * @since 7.1\\n     */\\n    protected ErrorInfo extractError(Exception ex) {\\n        return NuxeoCmisErrorHelper.extractError(ex);\\n    }\\n\\n    @Override\\n    public void printError(CallContext context, Exception ex, HttpServletRequest request, HttpServletResponse response) {\\n        ErrorInfo errorInfo = extractError(ex);\\n        if (response.isCommitted()) {\\n            LOG.warn(\"Failed to send error message to client. \" + \"Response is already committed.\", ex);\\n            return;\\n        }\\n\\n        String token = (context instanceof BrowserCallContextImpl ? ((BrowserCallContextImpl) context).getToken()\\n                : null);\\n\\n        if (token == null) {\\n            response.resetBuffer();\\n            CALL.setStatus(request, response, errorInfo.statusCode);\\n\\n            String message = ex.getMessage();\\n            if (!(ex instanceof CmisBaseException)) {\\n                message = \"An error occurred!\";\\n            }\\n\\n            JSONObject jsonResponse = new JSONObject();\\n            jsonResponse.put(ERROR_EXCEPTION, errorInfo.exceptionName);\\n            jsonResponse.put(ERROR_MESSAGE, errorInfo.message);\\n\\n            String st', '<|endoftext|>PrintWriter;\\n\\nimport javax.servlet.ServletException;\\nimport javax.servlet.annotation.WebServlet;\\nimport javax.servlet.http.HttpServlet;\\nimport javax.servlet.http.HttpServletRequest;\\nimport javax.servlet.http.HttpServletResponse;\\nimport java.sql.*;\\nimport java.util.*;\\n\\n/**\\n * Servlet implementation class TenUsers\\n */\\n@WebServlet(\"/TenUsers\")\\npublic class TenUsers extends HttpServlet {\\n    /**\\n     * @see HttpServlet#doGet(HttpServletRequest request, HttpServletResponse response)\\n     */\\n    protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {\\n\\n        PrintWriter out = response.getWriter();\\n        String mySqlUrl = \"jdbc:mysql://localhost:3306/mysql\";\\n\\n        Properties userInfo = new Properties();\\n        userInfo.put(\"user\", \"root\");\\n        userInfo.put(\"password\", \"SabababArba\");\\n        try{\\n            Connection connection = DriverManager.getConnection(mySqlUrl, userInfo);\\n        }catch(Exception e) {\\n            out.println(e);\\n        }      \\n    }\\n}\\n\\nIf I add Class.forName(\"com.mysql.jdbc.Driver\"); before Connection connection = DriverManager.getConnection(mySqlUrl, userInfo); I get java.lang.ClassNotFoundException: com.mysql.jdbc.Driver\\n\\nA:\\n\\nTry to insert this:\\nDriverManager.registerDriver(new com.mysql.jdbc.Driver());\\n\\nbefore getting the JDBC Connection.\\n\\nA:\\n\\n1: I have downloaded the mysql-connector-java-5.1.24-bin.jar\\n\\nOkay.\\n\\n2: I have created a lib folder in my project and put the jar in there.\\n\\nWrong. You need to drop JAR in /WEB-INF/lib folder. You don\\'t need to create any additional folders.\\n\\n3: properties of project->build path->add JAR and selected the JAR above.\\n\\nUnnecessary. Undo it all to avoid possible conflicts.\\n\\n4: I still get java.sql.SQLException: No suitable driver found for jdbc:mysql//localhost:3306/mysql\\n\\nThis exception can have 2 causes:\\n\\nJDBC driver is not in runtime classpath. This is to be solved by doing 2) the right way.\\nJDBC URL is not recognized by any of the loaded JDBC drivers. Indeed, the JDBC URL is wrong, there should as per the MySQL JDBC driver documentation be another colon between the scheme and the host.\\njdbc:mysql://localhost:3306/mysql\\n\\nA:\\n\\nYou can paste the .jar file of the driver in the Java setup instead of adding it to each project that you create. Paste it in C:\\\\Program Files\\\\Java\\\\jre7\\\\lib\\\\ext or wherever you have installed java. \\nAfter this you will find that the .jar driver is enlisted in the library folder of your created project(JRE system library) in the IDE. No need to add it repetitively.\\n\\n<|endoftext|>                IN THE COURT OF APPEALS OF THE STATE OF IDAHO\\n\\n                                        Docket No. 43224\\n\\nSTATE OF IDAHO,                                  )   2015 Unpublished Opinion No. 698\\n                                                 )\\n        Plaintiff-Respondent,                    )   Filed: November 9, 2015\\n                                                 )\\nv.                                               )   Stephen W. Kenyon, Clerk\\n                                                 )\\nDEREK LOGAN PRANO,                               )   THIS IS AN UNPUBLISHED\\n                                                 )   OPINION AND SHALL NOT\\n        Defendant-Appellant.                     )   BE CITED AS AUTHORITY\\n                                                 )\\n\\n        Appeal from the District Court of the Fourth Judicial District, State of Idaho, Ada\\n        County. Hon. Timothy Hansen, District Judge.\\n\\n        Judgment of conviction and sentence; and order relinquishing jurisdiction,\\n        affirmed.\\n\\n        Sara B. Thomas, State Appellate Public Defender; Jenevieve C. Swinford, Deputy\\n        Appellate Public Defender, Boise, for appellant.\\n\\n        Hon. Lawrence G. Wasden, Attorney General; Lori A. Fleming, Deputy Attorney\\n        General, Boise, for respondent.\\n                  ________________________________________________\\n\\n                     Before MELANSON, Chief Judge; GUTIERREZ, Judge;\\n                                   and HUSKEY, Judge\\n                    ________________________________________________\\n\\nPER CURIAM\\n        Derek Logan Prano pleaded guilty to sexual battery of a minor child under sixteen or\\nseventeen years of age, Idaho Code § 18-1508A. In exchange for his guilty', '<|endoftext|> and conference databases is performed to identify clinical trials with specific anti-angiogenic agents in gastric cancer treatment The risk of disease progression (37-52%) and death (19-22%) with ramucirumab as second-line treatment decreases in phase III trials in advanced gastric cancer. No significant improvement in overall survival (OS) with the addition of bevacizumab to chemotherapy is shown. Bevacizumab or ramucirumab combined with traditional chemotherapy is associated with higher adverse event rate compared to chemotherapy alone. Except for apatinib, phase II trials of other tyrosine kinase inhibitors (TKIs) may improve overall response rate, but there are no significant improvements in OS and progression-free survival (PFS) when combined with chemotherapy. Phase III trials in advanced gastric cancer have demonstrated improved outcome with ramucirumab as second-line treatment. Most of the other studies on anti-angiogenic agents in gastric cancer have reported improvement in response rate but not in OS compared to chemotherapy alone. Future research is expected in optimizing the anti-angiogenic therapy combined with traditional treatment.<|endoftext|>\\n\\n\\n\\n\\n\\n\\n\\nHere\\'s a little peek at a page from Robert Crumb\\'s forthcoming Book of Genesis, a literal adaptation from the first book in the Old Testament. It\\'s been years-in-the-making (Here\\'s a 2004 Guardian article about it). The only other book I\\'m looking forward to with as much excitment as this one is Harvey Kurtzman\\'s Humbug anthology.\\n\\nThe long-awaited publication of Robert Crumb\\'s Book of Genesis, an adaptation of the Bible story, which Norton will be publishing in Fall 2009. I had the privilege of seeing some of the pages in France two years ago, and the scope of the work has haunted me ever since. I\\'m sure the religious right will be all up in arms with cliché horror that a quote unquote \"cartoonist\" has defamed their sacred cow, but Crumb is taking this work very seriously, and Genesis is some of his best work.\\n\\nR. Crumb Illustrates The Book of Genesis literally<|endoftext|>fileFormatVersion: 2\\nguid: 4cdce803110994d49874b4c1ebc1c108\\nfolderAsset: yes\\nDefaultImporter:\\n  externalObjects: {}\\n  userData: \\n  assetBundleName: \\n  assetBundleVariant: \\n<|endoftext|>/*\\n * Copyright 2019 WeBank\\n *\\n * Licensed under the Apache License, Version 2.0 (the \"License\");\\n *  you may not use this file except in compliance with the License.\\n * You may obtain a copy of the License at\\n *\\n * http://www.apache.org/licenses/LICENSE-2.0\\n *\\n * Unless required by applicable law or agreed to in writing, software\\n * distributed under the License is distributed on an \"AS IS\" BASIS,\\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\n * See the License for the specific language governing permissions and\\n * limitations under the License.\\n */\\n\\npackage com.webank.wedatasphere.qualitis.filter;\\n\\nimport javax.servlet.ReadListener;\\nimport javax.servlet.ServletInputStream;\\nimport javax.servlet.http.HttpServletRequest;\\nimport javax.servlet.http.HttpServletRequestWrapper;\\nimport java.io.BufferedReader;\\nimport java.io.ByteArrayInputStream;\\nimport java.io.IOException;\\nimport java.io.InputStreamReader;\\nimport java.util.stream.Collectors;\\n\\n/**\\n * @author howeye\\n */\\npublic class BodyReaderHttpServletRequestWrapper extends HttpServletRequestWrapper {\\n\\n    private final byte[] body;\\n\\n    public BodyReaderHttpServletRequestWrapper(HttpServletRequest request) throws IOException {\\n        super(request);\\n        body = request.getReader().lines().collect(Collectors.joining(System.lineSeparator())).getBytes();\\n    }\\n\\n    @Override\\n    public BufferedReader getReader() throws IOException {\\n        return new BufferedReader(new InputStreamReader(getInputStream()));\\n    }\\n\\n    @Override\\n    public ServletInputStream getInputStream() throws IOException {\\n        final ByteArrayInputStream bais = new ByteArrayInputStream(body);\\n        return new ServletInputStream() {\\n            @Override\\n            public boolean isFinished() {\\n                return true;\\n            }\\n\\n            @Override\\n            public boolean isReady() {\\n                return true;\\n            }\\n\\n            @Override\\n            public void setReadListener(ReadListener readListener) {\\n\\n            }\\n\\n            @Override\\n            public int read() throws IOException {\\n                return bais.read();\\n            }\\n        };\\n    }\\n}\\n<|endoftext|>Eupithecia decorata\\n\\nEupithecia decorata is a moth in the  family Geomet', '<|endoftext|>Version(version_string)\\n        with self.assertRaises(ec2rlcore.programversion.ProgramVersionInvalidComparisonError):\\n            bool(test_dict != version_object)\\n\\n    def test_programversion_comparison_different_object_type_lt(self):\\n        \"\"\"\\n        Test that InvalidComparisonError is raised when a ProgramVersion is compared for equality with another \\n        object of a different type using the \\'>\\' operator.\\n        \"\"\"\\n        test_dict = {\"version\": \"1.0.0\"}\\n        version_string = \"1.0.0\"\\n        version_object = ec2rlcore.programversion.ProgramVersion(version_string)\\n        with self.assertRaises(ec2rlcore.programversion.ProgramVersionInvalidComparisonError):\\n            bool(test_dict > version_object)\\n\\n    def test_programversion_print_release(self):\\n        \"\"\"\\n        Test that ProgramVersion.__str__ returns the expected string representation of the ProgramVersion whose\\n        release type is \\'release\\'.\\n        \"\"\"\\n        version_string = \"1.0.0\"\\n        version_object = ec2rlcore.programversion.ProgramVersion(version_string)\\n        self.assertEqual(str(version_object), version_string)\\n\\n    def test_programversion_print_beta(self):\\n        \"\"\"\\n        Test that ProgramVersion.__str__ returns the expected string representation of the ProgramVersion whose\\n        release type is \\'beta\\'.\\n        \"\"\"\\n        version_string = \"1.0.0b1\"\\n        version_object = ec2rlcore.programversion.ProgramVersion(version_string)\\n        self.assertEqual(str(version_object), version_string)\\n\\n    def test_programversion_print_alpha(self):\\n        \"\"\"\\n        Test that ProgramVersion.__str__ returns the expected string representation of the ProgramVersion whose\\n        release type is \\'alpha\\'.\\n        \"\"\"\\n        version_string = \"1.0.0a1\"\\n        version_object = ec2rlcore.programversion.ProgramVersion(version_string)\\n        self.assertEqual(str(version_object), version_string)\\n\\n    def test_programversion_print_rc(self):\\n        \"\"\"\\n        Test that ProgramVersion.__str__ returns the expected string representation of the ProgramVersion whose\\n        release type is \\'candidate\\'.\\n        \"\"\"\\n        version_string = \"1.0.0rc1\"\\n        version_object = ec2rlcore.programversion.ProgramVersion(version_string)\\n        self.assertEqual(str(version_object), version_string)\\n\\n    def test_programversion_repr(self):\\n        \"\"\"\\n        Test that ProgramVersion.__repr__ returns the expected string representations of the ProgramVersion instances.\\n        \"\"\"\\n        version_object = ec2rlcore.programversion.ProgramVersion(\"1.0.0rc1\")\\n        self.assertEqual(repr(version_object), \\'ProgramVersion(\"1.0.0rc1\")\\')\\n        version_object = ec2rlcore.programversion.ProgramVersion(\"1.0.0\")\\n        self.assertEqual(repr(version_object), \\'ProgramVersion(\"1.0.0\")\\')\\n\\n    def test_programversion_len(self):\\n        \"\"\"\\n        Test that ProgramVersion works with the Python built-in len(). The length of the string representation is\\n        expected to be returned..\\n        \"\"\"\\n        version_string = \"1.0.0rc1\"\\n        version_object = ec2rlcore.programversion.ProgramVersion(version_string)\\n        self.assertEqual(len(version_object), 8)\\n<|endoftext|>import * as mutationTypes from \\'./mutation-types\\';\\nimport * as actionTypes from \\'./action-types\\';\\n\\n/**\\n * Actions with injected search API mapper.\\n *\\n * @param {{ [resourceName: string]: Search }} searchMap mapper of each resources searchApi\\n */\\nexport default function actionsWithSearch(searchMap) {\\n  return {\\n    [actionTypes.RECEIVE_RESULT]({ commit }, { resourceName, result, text }) {\\n      commit(mutationTypes.SET_SEARCH_RESULT, {\\n        resourceName,\\n        result,\\n        text,\\n      });\\n    },\\n\\n    [actionTypes.searchApi.INDEX_RESOURCE](_, params) {\\n      const { resourceName } = params;\\n      searchMap[resourceName].indexResource(params);\\n    },\\n\\n    [actionTypes.searchApi.PERFORM_SEARCH](_, { resourceName, searchString }) {\\n', '<|endoftext|> expect me to clean up after them–sometimes they’ll cover up a coughed-up hairball with whatever’s on the floor nearby such as a slipper. But I don’t mind taking on the “mommy” role there. I knowingly took on that responsibility as part of the deal.<|endoftext|>RTP provider Vortek obtains new funding\\n\\nVANCOUVER - Chip-equipment startup Vortek Industries Ltd. has received a round of funding and disclosed new data about its rapid thermal processing (RTP) tool for 200- and 300-mm production.\\n\\nThe Vancouver-based company has received $4.1 million in funding from its current shareholders.\\n\\nIt has also revealed the latest results about its RTP tool, dubbed the FlashFire. FlashFire makes use of a water-wall arc lamp in both the continuous and flash modes to enable processing of ultra-shallow junctions in IC designs.\\n\\nIn the company\\'s RPT tool, the wafer is first brought up to a temperature of about 700 degrees Celsius at several hundred degrees a second. Then, the entire front surface receives a pulse of energy that brings it up to 1300 degrees Celsius in a millisecond.\\n\\n\"This means that Vortek RTP tools cover the full temperature envelope required for ultra-shallow junction anneals. We already have data meeting the requirements of the 32-nm node, and are progressing further from there,\" stated Reg Allen, Vortek\\'s CEO.<|endoftext|>package com.yourpackagename.framework.dispatcher;\\n\\nimport javax.servlet.ServletException;\\nimport javax.servlet.http.HttpServletRequest;\\nimport javax.servlet.http.HttpServletResponse;\\nimport java.io.IOException;\\n\\n/**\\n * BaseDispatcherServlet acts as a wrapper for Spring\\'s DispatcherServlet class\\n * so that we can have our own custom implementations written here to have those facilities\\n * or features being provided to everybody extending this class\\n *\\n * @author Y Kamesh Rao\\n */\\npublic class BaseDispatcherServlet extends org.springframework.web.servlet.DispatcherServlet {\\n\\n    private static final long serialVersionUID = 112233448L;\\n\\n\\n    @Override\\n    protected void doService(final HttpServletRequest request, final HttpServletResponse response) throws Exception {\\n        super.doService(request, response);\\n    }\\n\\n\\n    @Override\\n    protected void doDispatch(final HttpServletRequest request, final HttpServletResponse response) throws Exception {\\n        super.doDispatch(request, response);\\n    }\\n\\n\\n    @Override\\n    protected void service(final HttpServletRequest request, final HttpServletResponse response) throws ServletException,\\n            IOException {\\n        super.service(request, response);\\n    }\\n\\n}<|endoftext|>Truth (with a capital \"T\") is the elephant, and humanity the blind touching, sniffing, tasting, listening to this big \"T\" and of course we all rhapsodize a different tale (or tail?), yet in the end the big \"T\" is still the big \"T\" and all our various tales describe a tiny bit of that reality, the elephant.\\n\\nTranslate\\n\\nTuesday, February 06, 2007\\n\\nJesus in Japan\\n\\nLast night Bro. Simon was talking about his early travels in Japan, with rucksack and sandals he spent five years criss-crossing the country, and as he puts it, \"seeking to get to the bottom of this Zen thing.\" Well, he never got to the \"bottom\" of Zen, but he described meeting an elderly Buddhist, he too traveling by foot, and with his limited Japanese was able to understand that this old fellow was going to see the \"grave of Jesus Christ!\" Bro. Simon was rather puzzled at the time, listening to this Buddhist speaking of the grave of Jesus, and actually pointing toward a far off hill, and uttering in English, \"Grave ... grave ...\" So the journey began, the two walking side by side, the young American and the elderly Japanese, both hiking to the grave of Jesus. Bro. Simon\\'s bemusement was only intensified when they came upon a wooden directional sign, and in the midst of Japanese characters were the printed English words: \"Jesus Grave\" with an arrow pointing straight ahead. Late afternoon they arrived, and this is what Bro. Simon copied down, transcribed from the wooden sign that was posted before a mound that had a large cross.\\n\\nWhen He was 21 years old, Jesus Christ (イエスキリスト) came to Japan and studied theology for 12 years. He came back to Judea at the age of 33 in order to preach, but people there rejected His teachings and arrested Him to crucify Him. However, it was His little brother Jsus Chri (イスキリ) who took His place and ended his life on the cross. Jesus', '<|endoftext|> boolean isOwner() {\\n        return getConnector().isOwner(this);\\n    }\\n\\n    /**\\n     * @return GC username of the (actual) owner, might differ from the owner. Never empty.\\n     */\\n    @NonNull\\n    public String getOwnerUserId() {\\n        return ownerUserId;\\n    }\\n\\n    /**\\n     * Attention, calling this method may trigger a database access for the cache!\\n     *\\n     * @return the decrypted hint\\n     */\\n    public String getHint() {\\n        initializeCacheTexts();\\n        assertTextNotNull(hint, \"Hint\");\\n        return hint;\\n    }\\n\\n    /**\\n     * After lazy loading the lazily loaded field must be non {@code null}.\\n     *\\n     */\\n    private static void assertTextNotNull(final String field, final String name) throws InternalError {\\n        if (field == null) {\\n            throw new InternalError(name + \" field is not allowed to be null here\");\\n        }\\n    }\\n\\n    /**\\n     * Attention, calling this method may trigger a database access for the cache!\\n     */\\n    public String getDescription() {\\n        initializeCacheTexts();\\n        assertTextNotNull(description, \"Description\");\\n        return description;\\n    }\\n\\n    /**\\n     * loads long text parts of a cache on demand (but all fields together)\\n     */\\n    private void initializeCacheTexts() {\\n        if (description == null || shortdesc == null || hint == null || location == null) {\\n            if (inDatabase()) {\\n                final Geocache partial = DataStore.loadCacheTexts(this.getGeocode());\\n                if (description == null) {\\n                    setDescription(partial.getDescription());\\n                }\\n                if (shortdesc == null) {\\n                    setShortDescription(partial.getShortDescription());\\n                }\\n                if (hint == null) {\\n                    setHint(partial.getHint());\\n                }\\n                if (location == null) {\\n                    setLocation(partial.getLocation());\\n                }\\n            } else {\\n                setDescription(StringUtils.defaultString(description));\\n                setShortDescription(StringUtils.defaultString(shortdesc));\\n                setHint(StringUtils.defaultString(hint));\\n                setLocation(StringUtils.defaultString(location));\\n            }\\n        }\\n    }\\n\\n    /**\\n     * Attention, calling this method may trigger a database access for the cache!\\n     */\\n    public String getShortDescription() {\\n        initializeCacheTexts();\\n        assertTextNotNull(shortdesc, \"Short description\");\\n        return shortdesc;\\n    }\\n\\n    @Override\\n    public String getName() {\\n        return name;\\n    }\\n\\n    public String getCacheId() {\\n        // For some connectors ID can be calculated out of geocode\\n        if (StringUtils.isBlank(cacheId)) {\\n            if (getConnector() instanceof GCConnector) {\\n                return String.valueOf(GCConstants.gccodeToGCId(geocode));\\n            }\\n            if (getConnector() instanceof SuConnector) {\\n                return SuConnector.geocodeToId(geocode);\\n            }\\n        }\\n\\n        return cacheId;\\n    }\\n\\n    public String getGuid() {\\n        return guid;\\n    }\\n\\n    /**\\n     * Attention, calling this method may trigger a database access for the cache!\\n     */\\n    public String getLocation() {\\n        initializeCacheTexts();\\n        assertTextNotNull(location, \"Location\");\\n        return location;\\n    }\\n\\n    public String getPersonalNote() {\\n        return this.personalNote.getNote();\\n    }\\n\\n    public boolean supportsCachesAround() {\\n        return getConnector() instanceof ISearchByCenter;\\n    }\\n\\n    public boolean supportsNamechange() {\\n        return getConnector().supportsNamechange();\\n    }\\n\\n    public void shareCache(@NonNull final Activity fromActivity, final Resources res) {\\n        final Intent intent = getShareIntent();\\n\\n        fromActivity.startActivity(Intent.createChooser(intent, res.getText(R.string.cache_menu_share)));\\n    }\\n\\n    @NonNull\\n    public Intent getShareIntent() {\\n        final StringBuilder subject = new StringBuilder(\"Geocache \");\\n        subject.append(geocode);\\n        if (StringUtils.isNotBlank(name)) {\\n            subject.append(\" - \").append(name);\\n        }\\n\\n        final Intent intent = new Intent(Intent.', '<|endoftext|>’s medium purple creme Amethyst for some stamping on top.\\n\\nShare this: Twitter\\n\\nFacebook\\n\\nLike this: Like Loading... Related<|endoftext|>Identification of recipient Rh phenotype in a chronically transfused child by two-colour immunofluorescence.\\nA child with hyporegenerative anaemia was chronically transfused with group 0 Rh-negative blood. As typing with anti-D showed a mixed-field pattern, the patient\\'s red blood cells (RBC) were identified as D positive. Due to the transfused ccddee RBC, it was impossible to determine by simple agglutination whether c was present on the patient\\'s RBC. To resolve this question, two-colour indirect immunofluorescence was performed using D as a marker of the patient\\'s RBC. Likewise, Duffy and Kidd antigens could be determined on the patient\\'s RBC despite multiple transfusions.<|endoftext|>Surely I’m not the only Deadhead who has read the Song of Ice and Fire series and had the opening run of Dire Wolf run through their head the first time it was made known the House Stark’s sigil is the Dire Wolf?\\n\\nBut before there was Game of Thrones there was Workingman’s Dead. So I give the Grateful Dead the upper hand in this situation. (Ok, I admit I may be a bit biased!)\\n\\nIt seems that Billy is playing a bit behind the beat and the typically upbeat Dire Wolf plods along in a patient lope. Perhaps too patient? This give Jerry and Bob more time to concentrate on the vocals and they general sound pretty good, if not perfectly in sync. Jerry solo maintains an appropriate degree of twang, even if it is a bit brief. Keith adds a cascading run at one point, but other than that this is a pretty standard, albeit slow, reading of this number.\\n\\nComplete Setlist 11/30/73\\n\\nPrevious Dire Wolf DFAY Selections\\n\\n[AMAZONPRODUCTS asin=”0345535529″ features=”0″ locale=”com” listprice=”0″]<|endoftext|>Q:\\n\\nCannot iterate list inside JSP\\n\\nI am trying to answer a question using expression language in JSP. I tried some code, but it is not working properly. Can someone please help me ?\\nQuestion - \\nSource = How to call servlet on jsp page load\\nI want to call a servlet \\'latest_products\\' on load of index.jsp page.This servlet has records in List. I want to pass this List to index.jsp. but i don\\'t want to display the name of servlet in url. is there any way by which i can do this.\\nExpected output - Heading plus list of three product names.\\nActual output - Heading only.\\nWhat I tried -\\nServlet:\\npublic class ProductList extends HttpServlet {\\n    private static final long serialVersionUID = 1L;\\n\\n    public ProductList() {\\n        super();\\n        // TODO Auto-generated constructor stub\\n    }\\n\\n    protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {\\n        // TODO Auto-generated method stub\\n    }\\n\\n    protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {\\n        List<String> products = new ArrayList<String>();\\n        products.add(\"Car\");\\n        products.add(\"Gun\");\\n        products.add(\"Shades\");\\n\\n        request.setAttribute(\"productsList\", products);\\n\\n    }\\n\\n}\\n\\nJSP:\\n<%@ page language=\"java\" contentType=\"blah...\"%>\\n\\n<%@taglib uri=\"http://java.sun.com/jsp/jstl/core\" prefix=\"c\"%>\\n\\n<!DOCTYPE html PUBLIC \"blah...\">\\n\\n<html>\\n<head>\\n<meta http-equiv=\"blah...\">\\n</head>\\n<body>\\n\\n<c:import url=\"/ProductList\" />\\n\\n<c:set var=\"myProducts\" scope=\"request\" value=\"${param.productsList}\"/>\\n\\n<h1>List of products from servlet</h1>\\n<c:forEach var=\"product\" items= \"${myProducts}\" varStatus=\"i\">\\n${product}<br>\\n</c:forEach>\\n\\n</body>\\n</html>\\n\\nOne small question besides this, why do I get an error Encountered illegal body of tag \"c:set\" tag, given its attributes when I enclose the c:set tag with a </c:set> after the </c:foreach> tag ? I thought the c:set was like a block of code with a scope. But, it does not seem to be.\\nThanks.\\n\\nA', '<|endoftext|> e2;\\n                }\\n            }\\n            throw e;\\n        }\\n    }\\n\\n    private Class<?> doCompile(String name, String sourceCode, List<String> options) throws Exception {\\n        try {\\n            return classLoader.loadClass(name);\\n        } catch (ClassNotFoundException e) {\\n            int i = name.lastIndexOf(\\'.\\');\\n            String packageName = i < 0 ? \"\" : name.substring(0, i);\\n            String className = i < 0 ? name : name.substring(i + 1);\\n            JavaFileObjectImpl javaFileObject = new JavaFileObjectImpl(className, sourceCode);\\n            javaFileManager.putFileForInput(StandardLocation.SOURCE_PATH, packageName,\\n                    className + ClassUtils.JAVA_EXTENSION, javaFileObject);\\n            Boolean result = compiler.getTask(null, javaFileManager, diagnosticCollector, options,\\n                    null, Arrays.asList(javaFileObject)).call();\\n            if (result == null || !result) {\\n                throw new IllegalStateException(\"Compilation failed. class: \" + name + \", diagnostics: \" + diagnosticCollector.getDiagnostics());\\n            }\\n            if (compileDirectory != null) {\\n                saveBytecode(name, javaFileObject.getByteCode());\\n            }\\n            return classLoader.loadClass(name);\\n        }\\n    }\\n\\n    private static final class JavaFileObjectImpl extends SimpleJavaFileObject {\\n\\n        private final CharSequence source;\\n        private UnsafeByteArrayOutputStream bytecode;\\n\\n        public JavaFileObjectImpl(final String baseName, final CharSequence source) {\\n            super(ClassUtils.toURI(baseName + ClassUtils.JAVA_EXTENSION), Kind.SOURCE);\\n            this.source = source;\\n        }\\n\\n        JavaFileObjectImpl(final String name, final Kind kind) {\\n            super(ClassUtils.toURI(name), kind);\\n            source = null;\\n        }\\n\\n        public JavaFileObjectImpl(URI uri, Kind kind) {\\n            super(uri, kind);\\n            source = null;\\n        }\\n\\n        @Override\\n        public CharSequence getCharContent(final boolean ignoreEncodingErrors) throws UnsupportedOperationException {\\n            if (source == null) {\\n                throw new UnsupportedOperationException(\"source == null\");\\n            }\\n            return source;\\n        }\\n\\n        @Override\\n        public InputStream openInputStream() {\\n            return new UnsafeByteArrayInputStream(getByteCode());\\n        }\\n\\n        @Override\\n        public OutputStream openOutputStream() {\\n            return bytecode = new UnsafeByteArrayOutputStream();\\n        }\\n\\n        public byte[] getByteCode() {\\n            return bytecode.toByteArray();\\n        }\\n    }\\n\\n    private static final class JavaFileManagerImpl extends ForwardingJavaFileManager<JavaFileManager> {\\n\\n        private final ClassLoaderImpl classLoader;\\n\\n        private final Map<URI, JavaFileObject> fileObjects = new HashMap<URI, JavaFileObject>();\\n\\n        public JavaFileManagerImpl(JavaFileManager fileManager, ClassLoaderImpl classLoader) {\\n            super(fileManager);\\n            this.classLoader = classLoader;\\n        }\\n\\n        @Override\\n        public FileObject getFileForInput(Location location, String packageName, String relativeName) throws IOException {\\n            FileObject o = fileObjects.get(uri(location, packageName, relativeName));\\n            if (o != null)\\n                return o;\\n            return super.getFileForInput(location, packageName, relativeName);\\n        }\\n\\n        public void putFileForInput(StandardLocation location, String packageName, String relativeName, JavaFileObject file) {\\n            fileObjects.put(uri(location, packageName, relativeName), file);\\n        }\\n\\n        private URI uri(Location location, String packageName, String relativeName) {\\n            return ClassUtils.toURI(location.getName() + \\'/\\' + packageName + \\'/\\' + relativeName);\\n        }\\n\\n        @Override\\n        public JavaFileObject getJavaFileForOutput(Location location, String qualifiedName, Kind kind, FileObject outputFile)\\n                throws IOException {\\n            JavaFileObject file = new JavaFileObjectImpl(qualifiedName, kind);\\n            classLoader.add(qualifiedName, file);\\n            return file;\\n        }\\n\\n        @Override\\n        public ClassLoader getClassLoader(JavaFileManager.Location location) {\\n            return classLoader;\\n        }\\n\\n        @Override\\n        public String inferBinaryName(Location loc, JavaFileObject file) {\\n            if', '<|endoftext|>],[@B74-cancers-12-01121],[@B75-cancers-12-01121],[@B76-cancers-12-01121],[@B77-cancers-12-01121]\\\\]\\n  **Chemotherapy**      Can cause immunogenic cell death depending on the compoundCan suppress specific types of immune suppressive cell populationsEasy to combine with immune checkpoint inhibitorsWill release uncharacterized/ personal tumor antigens                                                    Overall toxicityNot all chemotherapeutic compounds have the favored immunogenic effectDestruction of healthy cells                                         \\\\[[@B78-cancers-12-01121],[@B79-cancers-12-01121],[@B80-cancers-12-01121],[@B81-cancers-12-01121],[@B82-cancers-12-01121],[@B83-cancers-12-01121],[@B84-cancers-12-01121]\\\\]\\n  **Oncolytic virus**   (Engineered to) Specifically target tumor cellCan Cause immunogenic cell deathWill release uncharacterized/ personal tumor antigensEasy to combine with immune checkpoint inhibitorsCan be engineered to express a tumor antigen or cytokines to modify the tumor micro environment   Anti-viral response can neutralizing the therapy, shortening the window of opportunity,Specialized facilities to monitor patients due to safety concerns   \\\\[[@B32-cancers-12-01121],[@B85-cancers-12-01121],[@B86-cancers-12-01121],[@B87-cancers-12-01121],[@B88-cancers-12-01121],[@B89-cancers-12-01121],[@B90-cancers-12-01121],[@B91-cancers-12-01121],[@B92-cancers-12-01121]\\\\]\\n<|endoftext|>package net.nitroshare.android.bundle;\\n\\nimport java.io.IOException;\\nimport java.util.Map;\\n\\n/**\\n * Individual item for transfer\\n *\\n * Every individual file, URL, etc. for transfer must be an instance of a\\n * class that implements Item. Items can have any number of properties, but\\n * they must implement TYPE, NAME, and SIZE at a minimum.\\n *\\n * If items contain content (SIZE is nonzero), the I/O functions are used to\\n * read and write the contents.\\n */\\nabstract public class Item {\\n\\n    /**\\n     * Unique identifier for the type of item\\n     */\\n    public static final String TYPE = \"type\";\\n\\n    /**\\n     * Name of the item\\n     *\\n     * This value is displayed in some clients during transfer. Files, for\\n     * example, also use this property for the relative filename.\\n     */\\n    public static final String NAME = \"name\";\\n\\n    /**\\n     * Size of the item content during transmission\\n     *\\n     * This number is sent over-the-wire as a string to avoid problems with\\n     * large integers in JSON. This number can be zero if there is no payload.\\n     */\\n    public static final String SIZE = \"size\";\\n\\n    /**\\n     * Mode for opening items\\n     */\\n    public enum Mode {\\n        Read,\\n        Write,\\n    }\\n\\n    /**\\n     * Retrieve a map of properties\\n     * @return property map\\n     */\\n    abstract public Map<String, Object> getProperties();\\n\\n    /**\\n     * Retrieve the value of the specified property\\n     * @param key property to retrieve\\n     * @param defaultValue default value or null if required\\n     * @param class_ type for conversion\\n     * @param <T> type of value\\n     * @return value of the key\\n     */\\n    private <T> T getProperty(String key, T defaultValue, Class<T> class_) throws IOException {\\n        try {\\n            T value = class_.cast(getProperties().get(key));\\n            if (value == null) {\\n                if (defaultValue == null) {\\n                    throw new IOException(String.format(\"missing \\\\\"%s\\\\\" property\", key));\\n                } else {\\n                    value = defaultValue;\\n                }\\n            }\\n            return value;\\n        } catch (ClassCastException e) {\\n            throw new IOException(String.format(\"cannot read \\\\\"%s\\\\\" property\", key));\\n        }\\n    }\\n\\n    /**\\n     * Retrieve the value of a string property\\n     * @param key property to retrieve\\n     * @param required true to require a value\\n     * @return value of the key\\n     */\\n    String getStringProperty(String key, boolean required) throws IOException {\\n        return getProperty(key, required ? \"\" : null, String.class);\\n    }\\n\\n    /**\\n     * Retrieve the value of a long property\\n     * @param key property to retrieve\\n     * @param required true to', \"<|endoftext|>. One common shortcoming of the above-described techniques is that they can only reduce the circuit leakage power in standby mode.\\nLeakage is important in both standby and active operation modes. The leakage in active mode is significantly larger due to the higher die temperature in active mode. Accordingly, efficient leakage power reduction must target both standby and active leakage power. A dual Vth technique has been proposed which uses high-threshold voltage devices on noncritical paths to reduce leakage while using low-threshold devices on critical paths to maintain circuit speed as described in Z. Chen, C. Diaz, J. Plummer, M. Cao, and W. Greene, “0.18 μm Dual Vt MOSFET Process and Energy-Delay Measurement,” in Proc. of the 1996 Int'l. Electron Devices Meeting, pp. 851-854, December 1996 and L. Wei, Z. Chen, M. Johnson, K. Roy, and V. De, “Design and Optimization of Low Voltage High Performance Dual Threshold CMOS Circuits,” in Proc. of the Design Auto. Conf., pp. 489-494, June 1998. It reduces both active and standby leakage. However, this technique does not reduce the leakage on critical paths. Thus, it is it not advantageous for practical circuits, whose paths are usually well balanced. Supply voltage scaling, developed for switching power reduction, also reduces both active and standby leakage power, as described in M. Takahashi et al., “A 60-mw MPEG4 Video CODEC Using Clustered Voltage Scaling with Variable Supply-voltage Scheme,” IEEE J. of Solid-State Circuits, vol. 33, pp. 1772-1780, November 1998 and T. D. Burd, T. A. Pering, A. J. Stratakos, and R. W. Brodersen, “A Dynamic Voltage Scaled Microprocessor System,” IEEE J. of Solid-State Circuits, vol. 35, pp. 1571-1580, November 2000. This technique has the shortcoming that level conversion is needed at the interface whenever an output from a low VDD unit drives a high VDD unit input. Another conventional approach proposed dynamic leakage reduction using supply gating, as described in S. Bhunia, N. Banerjee, Q. Chen, H. Mahmoodi, and K. Roy, “A Novel Synthesis Approach for Active Leakage Power Reduction Using Dynamic Supply Gating,” in Proc. of the Design Auto. Conf., pp. 479-484, June 2005. This technique uses the Shannon expansion to identify the idle circuit parts and dynamically gate the supply to those parts to save active leakage power.\\nIt is desirable to provide an improved active leakage power reduction method which targets the idle part of the circuit when it is in active mode.<|endoftext|>Q:\\n\\nCan we declare a field outside the method in servlet\\n\\ncan we declare a object of a class as an instance variable in a servlet\\npublic class BookServ extends HttpServlet {\\n    private static final long serialVersionUID = 1L;\\n\\n    // declared object\\n    User user=new User();\\n\\n    protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {\\n         ...\\n    }\\n}\\n\\nA:\\n\\nSure you can.\\nA User field makes not much sense, since your container would normally instantiate exactly ONE servlet instance with exactly ONE contained User instance. \\nBut this Servlet instance is allowed to run multiply in parallel on several threads, so several threads may access the single User instance concurrently. \\nYou might want to store state within the servlet, which are initialized in the init() method of the servlet:\\n    public class BookServ extends HttpServlet {\\n        private static final long serialVersionUID = 1L;\\n\\n        private String servletUID = null;\\n\\n        public void init() throws ServletException {\\n            servletUID = ... generate a random String as UID ...\\n        }\\n\\n        protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {    \\n              ...\\n        }\\n    }\\n\\nNevertheless you should be aware that there are several contexts, which should be used to store servlet data (request.getServletContext()), session data (request.getSession() or request data (request.setAttribute()/request.getAttribute()) to.\\nSo normally there is little need for fields within servlets.\\nAlso check \\nHow do servlets work? Instantiation, sessions, shared variables and multithreading\\n\\n<|endoftext|>TFA served the claim on Mr De Biase at his last known address, but petitioned the court to be allowed to do so via Facebook as well because there was doubt over whether he still lived there.<|endoftext|>UPDATE: Homicide at Stone\", '<|endoftext|> of 130 kgs.<|endoftext|>Amelia Island North Range Light\\n\\nThe Amelia Island North Range Light was built to mark a channel over the sandbar at the mouth of the St. Mary\\'s River, which led to the harbor at Fernandina Beach, Florida, on Amelia Island. It consisted of a lighthouse and a front range tower with a light, arranged so that when ships could see one light above the other, they were lined up with the channel. During the Civil War Confederate forces removed the lenses from the lights. Union forces seized Fernandina Beach, Fort Clinch and the lighthouse in 1862.\\n\\nIt is known that the front range tower was destroyed during the war. There is no record of when the lighthouse was destroyed, but a new lighthouse was built in 1872. As the channel over the sand bar shifted with time, the front range light was periodically moved to maintain an alignment with the channel. In 1887 the rear range light was moved from the lighthouse to a tramway to permit proper adjustments to be made to the alignment. The light was decommissioned in 1899 after the channel was sufficiently marked with buoys. The lighthouse was listed in a survey in 1924, but has since disappeared.\\n\\nSee also\\n\\n List of lighthouses in Florida\\n List of lighthouses in the United States\\n\\nReferences\\n\\nExternal links\\nFlorida Lighthouse Page - Amelia Island North Range Lighthouse History - accessed January 16, 2006, recovered using Wayback Machine on January 22, 2007\\n\\nCategory:Lighthouses completed in 1858\\nCategory:Houses completed in 1858\\nCategory:Lighthouses completed in 1872\\nCategory:Houses completed in 1872\\nCategory:Lighthouses in Florida\\nCategory:Transportation buildings and structures in Nassau County, Florida\\nCategory:1858 establishments in Florida\\nCategory:1899 disestablishments in Florida\\nCategory:Amelia Island<|endoftext|>Q:\\n\\nCan\\'t display text after displaying image in servlet?\\n\\nI wrote a servlet which takes the name of a image from the client and displays it to client by converting it to byte array.after displaying the image now when i am trying to print some text i m not able to do so.it simply doesn\\'t print the text even after using PrintWriter.\\nI am using jboss application server to deploy it.\\nhere is the servlet-Image.java:\\npackage javaserv.image;\\n\\nimport java.io.File;\\nimport java.io.FileInputStream;\\nimport java.io.IOException;\\nimport java.io.PrintWriter;\\n\\nimport javax.imageio.ImageIO;\\nimport javax.servlet.ServletException;\\nimport javax.servlet.ServletOutputStream;\\nimport javax.servlet.http.HttpServlet;\\nimport javax.servlet.http.HttpServletRequest;\\nimport javax.servlet.http.HttpServletResponse;\\nimport javax.swing.ImageIcon;\\n\\n    public class Image extends HttpServlet {\\n        private static final long serialVersionUID = 1L;\\n        public Image() \\n    {\\n        super();\\n    }\\n\\n    protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException \\n    {\\n        String imagename = request.getParameter(\"imagename\");\\n\\n        File fileimage = new File(\"C:/langs/projects/javaserv/\"+imagename+\".jpg\");\\n        byte [] imagearray;\\n        imagearray = new byte[(int)fileimage.length ()];\\n        FileInputStream fis = new FileInputStream (fileimage);\\n        fis.read (imagearray);\\n        response.setContentType(\"image/jpeg\");\\n        response.setContentLength((int)fileimage.length ());\\n        ServletOutputStream out = response.getOutputStream();\\n        int i=0;\\n        while(i<imagearray.length)\\n        {\\n            out.write(imagearray[i]);\\n            ++i;\\n        }\\n\\n        out.flush();\\n        out.close();\\n        out = response.getOutputStream();\\n        response.setContentType(\"text/html\");\\n        out.println(\"<html><body>\");\\n        out.println(\"here is your image\");\\n        out.println(\"<p>\");\\n\\n        out.println(\"</html></body>\");\\n\\n        out.close();\\n    }\\n\\n}\\n\\n\"imagename\" is the name of the image entered by client\\n\\nA:\\n\\nYou can either write your JPEG to the out, or the HTML, not both.\\nYour code writes the JPEG to the output, closes the output stream, then tries to open it again to write some HTML. \\nIf you want to display a synamic image on a HTML page, you should be using a servlet for the image, and']\n","829 ['<|endoftext|> fume resistance and long term flexibility. Fres~Coat is self-priming over many new and previously painted surfaces. Specific primers are recommended for many new wood surfaces. It is the perfect coating for any exterior surface requiring a long lasting beautiful semi gloss finish.<|endoftext|>\"Shouted, \"O thou of heaven, why dost thou rob me?\" \"\"Thou bearest away the eternal part of him,\" \"\"For one poor little tear, that takes him from me...\"\" \"Well, this is really the end!\" \"Now I can see you.\" \"In daylight for the first time.\" \"Are your women on strike?\" \"You\\'re still alive?\" \"They say work will kill you.\" \"It\\'s an honourable death!\" \"Hey, martyr!\" \"Listen to me, quit working.\" \"Come and join us at Metro-Goldwyn-Mayer.\" \"What makes you do it?\" \"Sleep at night instead of playing cards.\" \"It\\'s like a morgue here.\" \"Here\\'s a man who knows Scucchia.\" \"Come here.\" \"You tell them what happened to poor Barberone.\" \"Weren\\'t you here when he decided to make that bet with The German and Peppe the Nut?\" \"He said that he\\'d eat a kilo of potatoes, a bag of persimmons, and then swim without any problem.\" \"Yeah, so?\" \"And that Peppe the Nut wanted him to cross the river to the other side and back, not just dip in and out.\" \" Yes.\" \" He didn\\'t die of indigestion.\" \"He was exhausted.\" \"He\\'d never crossed the river.\" \"You dope!\" \"You can\\'t eat a meal and then go swimming.\" \"You\\'d die.\" \"The reaction from heat to cold stops your digestion, the blood circulation, and that\\'s it!\" \"I lost my money, but I still have my ring to bet.\" \"Bet, if you have the nerve.\" \"You\\'re all talk.\" \"You\\'re stubborn.\" \"Yeah!\" \"I want to kill you, too.\" \"What are you alive for anyway?\" \"The cemetery has room for everybody.\" \"Your brother\\'s courage would have won the war.\" \"Besides the ring, if I make it,\" \" I\\'ll spit in your face!\" \" Save your breath, you\\'ll need it.\" \"Come on.\" \"Maybe your brother\\'ll make you his substitute.\" \" I\\'m going to work.\" \" He said a bad word!\" \"And my 1,000 lire?\" \"Before killing yourself, pay me back!\" \"Buy a wreath if I die.\" \"What\\'s 1,000 lire?\" \"So give me another 1,000, take up a collection right now.\" \"Accattone, who are you leaving your Maddalena to?\" \"The vice squad!\" \"Joking aside, Accattone, you know, I\\'m an educated person.\" \"You can trust me.\" \"Can I help you with your funeral?\" \"With my friends laughing, and if anybody cries, he pays for the dinner.\" \"And what do we write on your stone?\" \"\"Try it yourself.\"\" \"You\\'re diving with all your gold on?\" \"Not taking off your chain and bracelet?\" \"I want to die with all my gold on me, like the Pharaohs.\" \"Give it to us!\" \"Come and dive for it.\" \"I\\'ve got a stiff neck.\" \"Go on and dive!\" \"Okay, let\\'s satisfy the masses.\" \"Hey, lunatic, you could\\'ve warned me!\" \"The digestive tract, the circulatory reaction...\" \"But Accattone...\" \"Not even the river can carry away Accattone.\" \"The wise guys, the Hun and Peppe the Nut.\" \"He did it!\" \"I\\'m alive.\" \"You wanted to sing the funeral march.\" \"I\\'ve still got to make lots of people cry.\" \"Saint Barberone protected you.\" \"Barberone was like this, with his eyes wide open, his belly swollen like a drum.\" \"God, he was ugly!\" \"Who carried off Barberone, Christ or the Devil?\" \"They\\'re fighting over him.\" \"Let\\'s have a swim.\" \"Let\\'s go, German.\" \"Accattone, I was supposed to tell you,\" \"Maddalena was hit by a motorcycle.\" \"She\\'s hurt.\" \"She\\'s home now, bandaged like a mummy.\" \"I knew it.\" \"Good thing I remembered.\" \"Come on.\" \" When?\" \" Two hours ago.\" \" And I came to look for you.\" \" Come on.\" \"Well?\" \"What happened?\" \"See for yourself.\" \"The bastards!\" \"I\\'d like to know where your head is when you\\'re walking!\" \"Stay home, then.\" \"What\\'s the use of you going out?\" \"If they hit you, then I\\'d be rid of you.\" \"I was going to pay for the shirt I', \"<|endoftext|>\\nfrom the very condition of their servitude.  They may act just as they\\nplease; provided they are true to the great ruling principle of their\\ninstitution.  It is, therefore, not at all wonderful, that people should\\nbe so desirous of adding themselves to that body, in which they may\\npossess and reconcile satisfactions the most alluring, and seemingly the\\nmost contradictory; enjoying at once all the spirited pleasure of\\nindependence, and all the gross lucre and fat emoluments of servitude.\\n\\nHere is a sketch, though a slight one, of the constitution, laws, and\\npolicy, of this new Court corporation.  The name by which they choose to\\ndistinguish themselves, is that of _King's men_, or the _King's friends_,\\nby an invidious exclusion of the rest of his Majesty's most loyal and\\naffectionate subjects.  The whole system, comprehending the exterior and\\ninterior Administrations, is commonly called, in the technical language\\nof the Court, _Double Cabinet_; in French or English, as you choose to\\npronounce it.\\n\\nWhether all this be a vision of a distracted brain, or the invention of a\\nmalicious heart, or a real faction in the country, must be judged by the\\nappearances which things have worn for eight years past.  Thus far I am\\ncertain, that there is not a single public man, in or out of office, who\\nhas not, at some time or other, borne testimony to the truth of what I\\nhave now related.  In particular, no persons have been more strong in\\ntheir assertions, and louder and more indecent in their complaints, than\\nthose who compose all the exterior part of the present Administration; in\\nwhose time that faction has arrived at such a height of power, and of\\nboldness in the use of it, as may, in the end, perhaps bring about its\\ntotal destruction.\\n\\nIt is true, that about four years ago, during the administration of the\\nMarquis of Rockingham, an attempt was made to carry on Government without\\ntheir concurrence.  However, this was only a transient cloud; they were\\nhid but for a moment; and their constellation blazed out with greater\\nbrightness, and a far more vigorous influence, some time after it was\\nblown over.  An attempt was at that time made (but without any idea of\\nproscription) to break their corps, to discountenance their doctrines, to\\nrevive connections of a different kind, to restore the principles and\\npolicy of the Whigs, to reanimate the cause of Liberty by Ministerial\\ncountenance; and then for the first time were men seen attached in office\\nto every principle they had maintained in opposition.  No one will doubt,\\nthat such men were abhorred and violently opposed by the Court faction,\\nand that such a system could have but a short duration.\\n\\nIt may appear somewhat affected, that in so much discourse upon this\\nextraordinary party, I should say so little of the Earl of Bute, who is\\nthe supposed head of it.  But this was neither owing to affectation nor\\ninadvertence.  I have carefully avoided the introduction of personal\\nreflections of any kind.  Much the greater part of the topics which have\\nbeen used to blacken this nobleman are either unjust or frivolous.  At\\nbest, they have a tendency to give the resentment of this bitter calamity\\na wrong direction, and to turn a public grievance into a mean personal,\\nor a dangerous national, quarrel.  Where there is a regular scheme of\\noperations carried on, it is the system, and not any individual person\\nwho acts in it, that is truly dangerous.  This system has not risen\\nsolely from the ambition of Lord Bute, but from the circumstances which\\nfavoured it, and from an indifference to the constitution which had been\\nfor some time growing among our gentry.  We should have been tried with\\nit, if the Earl of Bute had never existed; and it will want neither a\\ncontriving head nor active members, when the Earl of Bute exists no\\nlonger.  It is not, therefore, to rail at Lord Bute, but firmly to embody\\nagainst this Court party and its practices, which can afford us any\\nprospect of relief in our present condition.\\n\\nAnother motive induces me to put the personal consideration of Lord Bute\\nwholly out of the question.  He communicates very little in a direct\\nmanner with the greater part of our men of business.  This has never been\\nhis custom.  It is enough for him that he surrounds them with his\\ncreatures.  Several imagine, therefore, that they have a very good excuse\\nfor doing all the work\", '<|endoftext|> at the bottom of the slope,\\nMiss Grace must pass down it when she comes\\nback, and she will most likely rush into his\\narms; for as soon as the clock strikes, they\\'ll\\nbundle back home—along like hares.\\nI\\'ve seen such larries before.\"\\n\"Do you think I\\'d better?\" said Marty, reluctantly.\\n\"Oh yes, he\\'ll bless ye for it.\"\\n\"I don\\'t want that kind of blessing.\"\\nBut after a moment\\'s thought she went and\\ndelivered the information; and Grammer had\\nthe satisfaction of seeing Giles walk slowly\\nto the bend in the leafy defile along which\\nGrace would have to return.\\nMeanwhile Mrs. Melbury, deserted by Grace,\\nhad perceived Fitzpiers and Winterborne, and\\nalso the move of the latter.\\nAn improvement on Grammer\\'s idea entered the\\nmind of Mrs. Melbury, for she had lately discerned\\nwhat her husband had not—that Grace was\\nrapidly fascinating the surgeon.\\nShe therefore drew near to Fitzpiers.\\n\"You should be where Mr. Winterborne is standing,\"\\nshe said to him, significantly.\\n\"She will run down through that opening much\\nfaster than she went up it, if she is like\\nthe rest of the girls.\"\\nFitzpiers did not require to be told twice.\\nHe went across to Winterborne and stood beside\\nhim.\\nEach knew the probable purpose of the other\\nin standing there, and neither spoke, Fitzpiers\\nscorning to look upon Winterborne as a rival,\\nand Winterborne adhering to the off-hand manner\\nof indifference which had grown upon him since\\nhis dismissal.\\nNeither Grammer nor Marty South had seen the\\nsurgeon\\'s manoeuvre, and, still to help Winterborne,\\nas she supposed, the old woman suggested to\\nthe wood-girl that she should walk forward\\nat the heels of Grace, and \"tole\" her down\\nthe required way if she showed a tendency\\nto run in another direction.\\nPoor Marty, always doomed to sacrifice desire\\nto obligation, walked forward accordingly,\\nand waited as a beacon, still and silent,\\nfor the retreat of Grace and her giddy companions,\\nnow quite out of hearing.\\nThe first sound to break the silence was the\\ndistant note of Great Hintock clock striking\\nthe significant hour.\\nAbout a minute later that quarter of the wood\\nto which the girls had wandered resounded\\nwith the flapping of disturbed birds; then\\ntwo or three hares and rabbits bounded down\\nthe glade from the same direction, and after\\nthese the rustling and crackling of leaves\\nand dead twigs denoted the hurried approach\\nof the adventurers, whose fluttering gowns\\nsoon became visible.\\nMiss Melbury, having gone forward quite in\\nthe rear of the rest, was one of the first\\nto return, and the excitement being contagious,\\nshe ran laughing towards Marty, who still\\nstood as a hand-post to guide her; then, passing\\non, she flew round the fatal bush where the\\nundergrowth narrowed to a gorge.\\nMarty arrived at her heels just in time to\\nsee the result.\\nFitzpiers had quickly stepped forward in front\\nof Winterborne, who, disdaining to shift his\\nposition, had turned on his heel, and then\\nthe surgeon did what he would not have thought\\nof doing but for Mrs. Melbury\\'s encouragement\\nand the sentiment of an eve which effaced\\nconventionality.\\nStretching out his arms as the white figure\\nburst upon him, he captured her in a moment,\\nas if she had been a bird.\\n\"Oh!\"\\ncried Grace, in her fright.\\n\"You are in my arms, dearest,\" said Fitzpiers,\\n\"and I am going to claim you, and keep you\\nthere all our two lives!\"\\nShe rested on him like one utterly mastered,\\nand it was several seconds before she recovered\\nfrom this helplessness.\\nSubdued screams and struggles, audible from\\nneighboring brakes, revealed that there had\\nbeen other lurkers thereabout for a similar\\npurpose.\\nGrace, unlike most of these companions of\\nhers, instead of gasping and writhing, said\\nin a trembling voice, \"Mr. Fitzpiers, will\\nyou let me go?\"\\n\"Certainly,\" he said, laughing; \"as soon as\\nyou have recovered.\"\\nShe waited another few moments, then quietly\\nand firmly pushed him aside, and glided on\\nher path, the moon whitening her hot blush\\naway.\\nBut it had been enough—new relations between\\nthem had begun.\\nThe case of the other girls was different,\\nas has', '<|endoftext|>velled much to see their bearing, for the men of Úrin and those amongst whom Nienóri was nurtured were much upon horses, and both knave and maid among them rode even in tender years.\\n\\nAfter many days\\' going came now that cavalcade within view of a place that once had been a fair region, and through it a swift river ran over a rocky bed, and of one side was the brink of it high and tree-grown and of the other the land was more level and fertile and broad-swelling, but beyond the high bank of the river the hills drew close. Thither as they looked they saw that the land had become all barren and was blasted for a great distance about the ancient caverns of the Rodothlim, and the trees were crushed to the earth or snapped. Toward the hills a black heath stretched and the lands were scored with the great slots that that loathly worm made in his creeping.\\n\\nMany are the dragons that Melko has loosed upon the world and some are more mighty than others. Now the least mighty—yet were they very great beside the Men of those days—are cold as is the nature of snakes and serpents, and of them a many having wings go with the uttermost noise and speed; but the mightier are hot and very heavy and slow-going, and some belch flame, and fire flickereth beneath their scales, and the lust and greed and cunning evil of these is the greatest of all creatures: and such was the Foalókë whose burning there set all the places of his habitation in waste and desolation. Already greater far had this worm waxen than in the days of the onslaught upon the Rodothlim, and greater too was his hoarded treasure, for Men and Elves and even Orcs he slew, or enthralled that they served him, bringing him food to slake his lust [?on] precious things, and spoils of their harryings to swell his hoard.\\n\\nNow was that band aghast as they looked upon that region from afar, yet they prepared them for battle, and drawing lots sent one of their number with Nienóri and Mavwin to that high place21 upon the confines of the withered land that had been named, and it was covered with trees, and might be reached by hidden paths. Even as those three rode thither and the warriors crept stealthily toward the caves, leaving their horses that were already in a sweat of fear, behold the Foalókë came from his lair, and sliding down the bank lay across the stream, as often was his wont. Straightway great fog and steams leapt up and a stench was mingled therein, so that that band was whelmed in vapours and well-nigh stifled, and they crying to one another in the mist displayed their presence to the worm; and he laughed aloud. At that most awful of all sounds of beasts they fled wildly in the mists, and yet they could not discover their horses, for these in an extremity of terror broke loose and fled.\\n\\nThen Nienóri hearing far cries and seeing the great mist roll toward them from the river turned back with her mother to the place of sundering, and there alighting waited in great doubt. Suddenly came that blind mist upon them as they stood, and with it came flying madly the dim horses of the huntsmen. Then their own catching their terror trampled to death that Elf who was their escort as he caught at the flying bridles, and wild with fear they sped to the dark woods and never more bore Man or Elf upon their saddles; but Mavwin and Nienóri were left alone and succourless upon the borders of the places of fear. Very perilous indeed was their estate, and long they groped in the mist and knew not where they were nor saw they ever any of the band again, and only pale voices seemed to pass them by afar crying out as in dread, and then all was silent. Now did they cling together and being weary stumbled on heedless whither their steps might go, till on a sudden the sun gleamed thin above them, and hope returned to them; and behold the mists lifted and the airs became clearer and they stood not far from the river. Even now it smoked as it were hot, and behold the Foalókë lay there and his eyes were upon them.\\n\\nNo word did he speak nor did he move, but his baleful eye held their gaze until the strength seemed to leave their knees and their minds grew dim. Then did Nienóri drag herself by a might of will from that influence for a while, and \"Behold,\" she cried, \"O serpent of Melko, what wilt thou with us—be swift to say or', '<|endoftext|> (said he,) in my judgement, his\\nwordis, albeit thei war spoken, can never be treassone unto you; for\\nthe performance of the fact dependis upoun your will, whairto ye say\\nye have disassented; and so shall that purpose evanise and dye by the\\nself, onless that ye waiken it; for it is not to be supposed that he\\nwill accuse you of that which he him self [hes] devised, and whairto\\nye wold not consent.\" \"O, (said he,) ye understand not what craft is\\nused against me: It is treassone to conceall treassone.\" \"My Lord,\\n(said he,) treasson maun importe consent and determinatioun,\\nquhilk[775] I hear upoun neather of your partis. And thairfoir, my\\nLord, in my judgement it shalbe more suyre and moir honorable to you\\nto depend upoun your [awin] innocencye, and to abyde the injust\\naccusatioun of ane other, (yf any follow thairof, as I think thair\\nshall not,) then ye to accuise, (especiallie after so lait\\nreconciliatioun,) and have none other witnesses but your awin\\naffirmatioun.\" \"I know, (said he,) that he will offer the combatt unto\\nme; but that wold not be suffered in France; but I will do that which\\nI have purposed.\" And so he departed, and took with him to his\\nloodgeing the saidis Alexander Guthery and Mr. Richart Strang; from\\nwhense was dyted and written a letter to the Quenis Majestie,\\naccording to the formar purpose, which letter was direct with all\\ndiligence to the Quenis Majestie, who then was in Falkland.\\n\\n  [775] In MS. G, \"of the quhilks.\"\\n\\nThe Erle him self raid after to Kynneill, to his father, the Duckis\\nGrace.[776] How he was entreated, we have but the commoun bruyte; but\\nfrom thense he wrait ane other letter with his awin hand, in sypher,\\nto the Erle of Murray, compleanyng upoun his rigorous handelling and\\nentreatment by his awin father, and by his freindis; and affirmed\\nfarther, that he feared his lyef, in case that he gat not suddane\\nreskew. But thairupoun he remaned not, but brack the chalmer whairin\\nhe was put, and with great pain past to Striveling, and from thense he\\nwas convoyed to the Hallyardis,[777] whair he was keapt till that the\\nErie of Murray cam unto him, and convoyed him to the Quene, then beand\\nin Falkland, who then was sufficientlie instructed of the hoill mater;\\nand upoun suspitioun conceaved, had caused apprehend Maister Gawan\\nHammyltoun and the Erle Bothwell foirsaid; who knowing nothing of the\\nformar advertismentis, cam to Falkland,[778] which augmented the\\nformar suspitioun.\\n\\n  [776] \"Upon the 25th day of March 1562, my Lordis of Arrane, quha was\\n  eldest sone to James Duke of Chattellarault, and Bothwill, wer aggreit\\n  be Johne Knox minister, and thairefter raid and spak with the Duke.\"\\n  (Diurnal of Occurrents, p. 71.) \"And upoun the 29th day of March, my\\n  Lord of Arrane come furth of the Palice of Kynneill, in ane franysy,\\n  in the nycht, at ane heich wyndo, and past to the Quenis Grace at\\n  Falkland, and sayd to her that my Lord Duke his fader, and my Lord\\n  Bothwill, and Gawin Commendatare of Kilwynning, had conspirit aganis\\n  the Quenis Grace and Lord James.\" (Ib. p. 71.)\\n\\n  [777] Hallyards, in the parish of Auchertule in Fifeshire. Sir Robert\\n  Sibbald, in 1710, speaks of \"Hallyairds, the residence of a gentleman\\n  of the name of Skeen: a great building, surrounded with gardens, large\\n  enclosures and', '<|endoftext|> evil beasts of their company, and when, as happened at whiles, there was an Orc-feast in those halls, he would ofttimes be set to the roasting of birds and other meats upon spits before the mighty fires in Melko\\'s dungeons, until he swooned for the overwhelming heat; yet he knew himself fortunate beyond all hope in being yet alive among those cruel foes of Gods and Elves. Seldom got he food or sleep himself, and he became haggard and half-blind, so that he wished often that never straying out of the wild free places of Hisilómë he had not even caught sight afar off of the vision of Tinúviel.\\n\\n(17) But Melian laughed not, nor said aught thereto; for in many things was she wise and forewise—yet nonetheless it was a thing unthought in a mad dream that any Elf, still less a maiden, the daughter of that king who had longest defied Melko, should fare alone even to the borders of that sorrowful country amid which lies Angband and the Hells of Iron. Little love was there between the woodland Elves and the folk of Angband even in those days before the Battle of Unnumbered Tears when Melko\\'s power was not grown to its full, and he veiled his designs, and spread his net of lies. \"No help wilt thou get therein of me, little one,\" said she; \"for even if magic and destiny should bring thee safe out of that foolhardiness, yet should many and great things come thereof, and on some many sorrows, and my rede is that thou tell never thy father of thy desire.\"\\n\\nBut this last word of Melian\\'s did Thingol coming unaware overhear, and they must perforce tell him all, and he was so wroth when he heard it that Tinúviel wished that never had her thoughts been revealed even to her mother.\\n\\n(18) Indeed I have no love for him, for he has destroyed our play together, our music and our dancing.\" But Tinúviel said: \"I ask it not for him, but for myself, and for that very play of ours together aforetime.\" And Dairon said: \"And for thy sake I say thee nay\" and they spake no more thereof together, but Dairon told the king of what Tinúviel had desired of him, fearing lest that dauntless maiden fare away to her death in the madness of her heart.\\n\\n(18)...he might not shut his daughter for ever in the caves, where the light was only that of torches dim and flickering.\\n\\n(19)The names of all the tallest and longest things upon Earth were set in that song: the beards of the Indrafangs, the tail of Carcaras, the body of Glorund the drake, the bole of Hirilorn, and the sword of Nan she named, nor did she forget the chain Angainu that Aulë and Tulkas made, or the neck of Gilim the giant that is taller than many elm trees;...\\n\\nCarcaras is spelt thus subsequently in the typescript.\\n\\n(20)...as fast as her dancing feet would flit.\\n\\nNow when the guards awoke it was late in the morning, and they fled away nor dared to bear the tidings to their lord; and Dairon it was bore word of the escape of Tinúviel to Thingol, for he had met the folk that ran in amazement from the ladders which each morning were lifted to her door. Great was the mingled grief and wrath of the king, and all the deep places of his court were in uproar, and all the woods were ringing with the search; but Tinúviel was already far away dancing madly through the dark woods towards the gloomy foothills and the Mountains of Night. \\'Tis said that Dairon sped swiftest and furthest in pursuit, but was wrapped in the deceit of those far places, and became utterly lost, and came never back to Elfinesse, but turned towards Palisor; and there he plays subtle magic musics still, wistful and lonely in the woods and forests of the south.\\n\\nNow fared Tinúviel forward, and a sudden dread overtook her at the thought of what she had dared to do, and of what lay before her. Then did she turn back for a while, and wept, wishing that Dairon were with her. It is said that he was not indeed at that time far off, and wandered lost in Taurfuin, the Forest of Night, where after Túrin slew Beleg by mishap. Nigh was Tinúviel to those evil places; but she entered not', \"<|endoftext|> few paces from our cave, and beside it, equally mangled, and disemboweled, was the carcass of a huge cave-bear. To have had one's life saved by a saber-tooth tiger, and in the twentieth century into the bargain, was an experience that was to say the least unique; but it had happened—I had the proof of it before my eyes.\\n\\nSo enormous are the great carnivora of Caspak that they must feed perpetually to support their giant thews, and the result is that they will eat the meat of any other creature and will attack anything that comes within their ken, no matter how formidable the quarry. From later observation—I mention this as worthy the attention of paleontologists and naturalists—I came to the conclusion that such creatures as the cave-bear, the cave-lion and the saber-tooth tiger, as well as the larger carnivorous reptiles make, ordinarily, two kills a day—one in the morning and one after nightfall. They immediately devour the entire carcass, after which they lie up and sleep for a few hours. Fortunately their numbers are comparatively few; otherwise there would be no other life within Caspak. It is their very voracity that keeps their numbers down to a point which permits other forms of life to persist, for even in the season of love the great males often turn upon their own mates and devour them, while both males and females occasionally devour their young. How the human and semihuman races have managed to survive during all the countless ages that these conditions must have existed here is quite beyond me.\\n\\nAfter breakfast Ajor and I set out once more upon our northward journey. We had gone but a little distance when we were attacked by a number of apelike creatures armed with clubs. They seemed a little higher in the scale than the Alus. Ajor told me they were Bo-lu, or club-men. A revolver-shot killed one and scattered the others; but several times later during the day we were menaced by them, until we had left their country and entered that of the Sto-lu, or hatchet-men. These people were less hairy and more man-like; nor did they appear so anxious to destroy us. Rather they were curious, and followed us for some distance examining us most closely. They called out to us, and Ajor answered them; but her replies did not seem to satisfy them, for they gradually became threatening, and I think they were preparing to attack us when a small deer that had been hiding in some low brush suddenly broke cover and dashed across our front. We needed meat, for it was near one o'clock and I was getting hungry; so I drew my pistol and with a single shot dropped the creature in its tracks. The effect upon the Bo-lu was electrical. Immediately they abandoned all thoughts of war, and turning, scampered for the forest which fringed our path.\\n\\nThat night we spent beside a little stream in the Sto-lu country. We found a tiny cave in the rock bank, so hidden away that only chance could direct a beast of prey to it, and after we had eaten of the deer-meat and some fruit which Ajor gathered, we crawled into the little hole, and with sticks and stones which I had gathered for the purpose I erected a strong barricade inside the entrance. Nothing could reach us without swimming and wading through the stream, and I felt quite secure from attack. Our quarters were rather cramped. The ceiling was so low that we could not stand up, and the floor so narrow that it was with difficulty that we both wedged into it together; but we were very tired, and so we made the most of it; and so great was the feeling of security that I am sure I fell asleep as soon as I had stretched myself beside Ajor.\\n\\nDuring the three days which followed, our progress was exasperatingly slow. I doubt if we made ten miles in the entire three days. The country was hideously savage, so that we were forced to spend hours at a time in hiding from one or another of the great beasts which menaced us continually. There were fewer reptiles; but the quantity of carnivora seemed to have increased, and the reptiles that we did see were perfectly gigantic. I shall never forget one enormous specimen which we came upon browsing upon water-reeds at the edge of the great sea. It stood well over twelve feet high at the rump, its highest point, and with its enormously long tail and neck it was somewhere between seventy-five and a hundred feet in length. Its head was ridiculously small; its body was unarmored, but its great bulk gave it a most formidable appearance. My experience of Caspakian life led me to believe that the gigantic creature would but have to see us to attack us, and so I\", '<|endoftext|> officer from arresting another man on battery charges, according to the police report.\\n\\nThe police officer, who was part of a St. Patrick\\'s Day Clark Street detail, pushed Acosta back and ordered him to stay back, according to the police report, but Acosta continued to charge at him and try to pull away the other man. He also punched the officer in the arm and body several times, according to the police report.\\n\\nThe first police officer was unable to put Acosta into custody on his own, the report said, and several officers attempted to restrain him before the group fell into the John Barleycorn doorway and into the bar.\\n\\nOnce inside the bar an officer used his Taser on Acosta, yelling \"Taser, Taser, Taser,\" to warn others, the report said. Acosta was taken to Thorek Hospital to remove Taser probes and treat a bloody nose, the report said.\\n\\nAcosta was brought to the Cook County Criminal Courthouse on Monday afternoon and released on a $30,000 I-bond with electronic home monitoring required.<|endoftext|>（������） �������の金正��（キムジ��ンウン）・���������������長とロシアのプー��ン大����が今月����日に初めて実��した����会��で、金����長が非��化交��や����制��解除などでの��国の������の��りや不��をプー��ン氏に��つけていたことが����日までにわかった。\\n\\n��息��が明らかにした。��国のトランプ大����と金����長は今年��月��、��トナム・����イで��度目の����会��を開いたが非��化の対象�����や����制��の解除問��で対立し、物��れに��わっていた。\\n\\n一部の通信社は、ロ������会��で金����長は��国の����について��意がないと指��したと報道。����������情��は手��まり状��に��り、����会��を��めた����交��が始まる前の����な状��になったと��えたという。\\n\\nプー��ン氏と金����長の����会��はロシア����部ウラジオストクで行われていた。��息��によると、金氏は��上、プー��ン大����に����間を����し、��国��に���������の立場を��えるように求めたという。プー��ン氏は��じたとした。<|endoftext|>Commentary Critical and Explanatory on John 6: 35-50\\n\\nFrom the Commentary on the Whole Bible (Jamieson, Fausset and Brown, 1871).\\n\\n35. I am the bread of life—Henceforth the discourse is all in the first person,\\n\"I,\" \"Me,\" which occur in one form or other, as Stier reckons, thirty-five\\ntimes.\\n\\nhe that cometh to me—to obtain what the soul craves, and as the only\\nall-sufficient and ordained source of supply.\\n\\nhunger … thirst—shall have conscious and abiding satisfaction.\\n\\n36. But … ye have seen me, and believe not—seen Him not in His mere bodily\\npresence, but in all the majesty of His life, His teaching, His works.\\n\\n37-40. All that, &c.—This comprehensive and very grand passage is expressed with\\na peculiar artistic precision. The opening general statement (Joh 6:37) consists\\nof two members:\\n\\n(1) \"All that the Father Giveth me shall come to me\"—that is, \"Though ye, as I\\ntold you, have no faith in Me, My errand into the world shall in no wise be\\ndefeated; for all that the Father giveth', '<|endoftext|> language is a huge benefit. While Javascript classes are definitely not on the same scale as Java or C++, they are a step in the right direction as Javascript matures.\\n\\nClasses at least for now are purely cosmetic, but there are plans to introduce object-oriented syntax like; static, public, private in ES7, but we’ll wait and see if they make the cut.\\n\\nHowever, when coupled with a strong IDE and tooling, ES6 classes can be powerful in that they can be analysed by the IDE and we are given more options for tracing methods (especially when extending parent classes). My favourite ES6 capable IDE of choice is Webstorm which supports classes quite well.\\n\\nYou don’t realise how messy Javascript is until you work on a large-scale project comprised of more than two developers, ES6 classes come with all of the benefits of pre-existing prototypical inheritance, but require less typing and they make your code easier to understand and resemble closely an object-oriented programming language like Java and its approach to classes.\\n\\nThere really isn’t one reason I can think of to not use ES6 classes even if they are just syntactic sugar. They especially go hand-in-hand with ES6 modules functionality, but that will be for another post.\\n\\nES6 classes documentation & references\\n\\nThere are only a few resources out there on ES6 classes with only more to follow, here are a few helpful links to help you master them in your new God ES6 workflow.\\n\\nAn introduction to ES6 classes\\n\\nKangax ES6 Compatibility Table\\n\\nECMAScript 6 support in Mozilla\\n\\nUse ECMAScript 6 Today<|endoftext|>The Gospel According to St John\\n\\nChapter 5\\n\\nJesus heals an invalid on the Sabbath—He explains why men must honor the Son—Jesus promises to take the gospel to the dead—Man is resurrected, judged, and assigned his glory by the Son—Jesus obeys the divine law of witnesses.\\n\\n1 After this there was aa feast of the Jews; and Jesus went up to Jerusalem.\\n\\n2 Now there is at Jerusalem by the sheep market a pool, which is called in the Hebrew tongue Bethesda, having five porches.\\n\\n3 In these lay a great multitude of impotent folk, of blind, halt, withered, waiting for the moving of the water.\\n\\n4 For an angel went down at a certain season into the pool, and troubled the water: whosoever then first after the troubling of the water stepped in was made whole of whatsoever disease he had.\\n\\n5 And a certain man was there, which had an infirmity thirty and eight years.\\n\\n6 When Jesus saw him lie, and knew that he had been now a long time in that case, he saith unto him, Wilt thou be made whole?\\n\\n7 The impotent man answered him, Sir, I have no man, when the water is troubled, to put me into the pool: but while I am coming, another steppeth down before me.\\n\\n18 Therefore the Jews sought the more to kill him, because he not only had broken the sabbath, but said also that God was his aFather, making himself bequal with God.\\n\\n19 Then answered Jesus and said unto them, Verily, verily, I say unto you, The Son can do nothing of himself, but what he aseeth the bFather do: for what things soever he doeth, these also doeth the Son likewise.\\n\\n20 For the Father loveth the Son, and sheweth him all things that himself doeth: and he will shew him greater works than these, that ye may marvel.<|endoftext|>Khali Sweeney\\n\\nKhali Sweeney, known as Coach Khali, is the founder and CEO of the Downtown Boxing Gym Youth Program, a nonprofit organization he started in 2007 to provide academic support and boxing lessons to empower Detroit students. Sweeney established the organization to provide an education-focused safe haven with tutoring, mentorship, and boxing lessons for boys and girls, ages 8–18. Over 150 Detroit students currently attend for free, with a large waiting list to get in.\\n\\nAwards \\n\\n 2017 CNN Heroes Top 10 Finalist\\n 2017 Crain\\'s Michigan Change Maker\\n 2018 Governor\\'s Service Award, Mentor of the Year\\n 2018 Spirit of Detroit Award\\n 2019 Arthur L. Johnson Community Leadership Award, Wayne State University\\n\\nReferences\\n\\nCategory:Living people\\nCategory:Chief executive officers\\nCategory:Year of birth missing (living people)<|endoftext|>{\\n  \"assigned_to_str\": \"Jeffrey S. White\", \\n  \"case_name\": \"Anderson v. SeaWorld Parks and Entertainment\", \\n  \"cause\": \"28:1332 Diversity-Petition for Removal\", \\n  \"court_id\":', '<|endoftext|> after that\\nPharaoh would let them go.\\n\\nMoreover, he promised, as an inducement to their avarice, that they\\nshould not go empty away, for that the Lord God would give the Hebrews\\nfavor in the sight of the Egyptians, \"so that every woman should borrow\\nof her neighbor, and of her that sojourneth in her house, jewels of\\nsilver, jewels of gold, and raiment,\" and that they should spoil the\\nEgyptians. But all this time God did not disclose his name; so Moses\\ntried another way about. If he would not tell his name he might at least\\nenable Moses to work some wonder which should bring conviction to those\\nwho saw it, even if the god remained nameless. For Moses appreciated the\\ndifficulty of the mission suggested to him. How was he, a stranger in\\nEgypt, to gain the confidence of that mixed and helpless multitude,\\nwhom he was trying to persuade to trust to his guidance in so apparently\\ndesperate an enterprise as crossing a broad and waterless waste, in the\\nface of a well-armed and vigorous foe. Moses apprehended that there was\\nbut one way in which he could by possibility succeed. He might prevail\\nby convincing the Israelites that he was commissioned by the one deity\\nwhom they knew, who was likely to have both the will and the power to\\naid them, and that was the god who had visited Abraham on the plain\\nof Mamre, who had destroyed Sodom for its iniquity, and who had helped\\nJoseph to become the ruler of Egypt. Joseph above all was the man who\\nhad made to his descendants that solemn promise on whose faith Moses\\nwas, at that very moment, basing his hopes of deliverance; for Joseph\\nhad assured the Israelites in the most solemn manner that the god who\\nhad aided him would surely visit them, and that they should carry his\\nbones away with them to the land he promised. That land was the land\\nto which Moses wished to guide them. Now Moses was fully determined to\\nattempt no such project as this unless the being who spoke from the bush\\nwould first prove to him, Moses, that he was the god he purported to be,\\nand should beside give Moses credentials which should be convincing,\\nby which Moses could prove to the Jews in Egypt that he was no impostor\\nhimself, nor had he been deceived by a demon. Therefore Moses went on\\nobjecting as strongly as at first:\\n\\n\"And Moses answered and said, But behold they will not believe me, nor\\nhearken to my voice; for they will say, the Lord hath not appeared unto\\nthee.\"\\n\\nThen the being in the bush proceeded to submit his method of proof,\\nwhich was of a truth feeble, and which Moses rejected as feeble. A form\\nof proof which never fully convinced him, and which, in his judgment\\ncould not be expected to convince others, especially men so educated and\\nintelligent as the Egyptians. For the Lord had nothing better to suggest\\nthan the ancient trick of the snake-charmer, and even the possessor of\\nthe voice seems implicitly to have admitted that this could hardly be\\nadvanced as a convincing miracle. So the Lord proposed two other tests:\\nthe first was that Moses should have his hand smitten with leprous sores\\nand restored immediately by hiding it from sight in \"his bosom.\" And in\\nthe event that this test left his audience still sceptical, he was to\\ndip Nile water out of the river, and turn it into blood on land.\\n\\nMoses at all these three proposals remained cold as before. And with\\ngood reason, for Moses had been educated as a priest in Egypt, and he\\nknew that Egyptian \"wise men\" could do as well, and even better, if it\\ncame to a magical competition before Pharaoh. And Moses had evidently\\nno relish for a contest in the presence of his countrymen as to the\\nrelative quality of his magic. Therefore, he objected once more on\\nanother ground: \"I am not eloquent, neither heretofore nor since thou\\nhast spoken unto thy servant: but I am slow of speech, and of a slow\\ntongue.\" This continued hesitancy put the Lord out of patience; who\\nretorted sharply, \"Who hath made man\\'s mouth? or who maketh the dumb, or\\ndeaf, or the seeing, or the blind? Have not I the Lord?\\n\\n\"Now therefore go, and I will be with thy mouth, and teach thee what\\nthou shalt say.\"\\n\\nThen Moses made his last effort. \"0 my Lord, send, I pray thee, by the\\nhand of him whom thou wilt send.\" Which was another way of saying, Send\\nwhom you please', '<|endoftext|> a bonding to take place, this surrender\\nis essential. For the world to take the opinion that there is no God,\\nor that God accepts everyone is no surrender\\nat all. For the Buddhist to surrender his concept of God in order to\\nform such a union is again no surrender.\\nHowever if a Jew, or a Muslim were called to make such a compromise the\\nrequest would be rejected off-hand\\nbecause such a belief goes contrary to the very tenets of their\\nreligion.\\n\\nThe Christian churches are\\nfalling to the sway of Ecumenicalism, throwing out their basic tenets\\nand in so\\ndoing undermining the very foundation of the Christian religion. In\\nother words, it seems to me they are meeting\\nunder the banner of Christianity without having any form of\\nChristianity in their system of beliefs. Other of the\\nTraditional churches see themselves as refusing to compromise, however\\nin my observation these very churches\\nhave been compromising their beliefs for decades to the point that a\\npuff of wind will cause them to fall over the\\nprecipice of Ecumenicalism. And that wind, I suspect, will be in the\\nform of a universal anti-hate law which will\\nmake the preaching and holding of morally disparaging attitudes\\nillegal. And this will cause the Bible itself to\\nbecome just another book on the banned list of reading material.\\n\\nWhen, and if, the world\\nturns\\nto Ecumenicalism, the true Christian, unwilling to sacrifice His\\nposition with\\nGod, will become the outcast, the criminal, the person Jesus and the\\nApostles were. Christianity in its traditional\\nform will die, and the Christian who is Christian in deed and not in\\nname only will be forced underground, as\\nthey are in other countries, and as the Jews were in Nazi Germany.\\n\\n5That\\nat what time ye hear the sound of the cornet, flute, harp, sackbut,\\npsaltery, dulcimer, and all kinds of music,\\nye fall down and worship the golden image that Nebuchadnezzar the king\\nhath set up: 6And\\nwhoso falleth not\\ndown and worshippeth shall the same hour be cast into the midst of a\\nburning fiery furnace. (Dan\\n3:)\\n\\n12And\\nhe exerciseth all the power of the first beast before him, and\\ncauseth the earth and them which dwell\\ntherein to worship the first beast, whose\\ndeadly wound was healed...... saying to them that dwell on the earth,\\nthat they should make an\\nimage to the beast, which\\nhad the wound by a sword, and did live. 15And\\nhe had\\npower to give life unto the image of the beast, that the image of the\\nbeast should both speak, and cause that as\\nmany as would not worship\\nthe image of the beast should be killed.16And\\nhe causeth all, both small and\\ngreat, rich and poor, free and bond, to receive a mark in their right\\nhand, or in their foreheads: 17And\\nthat no man\\nmight buy or sell, save he that had the mark, or the name of the beast,\\nor the number of his name. (Rev 13:)\\n\\n6And\\nthou shalt say to the rebellious, even to the house of Israel, Thus\\nsaith the Lord GOD; O ye house of Israel,\\nlet it suffice you of all your abominations, 7In\\nthat ye have brought into\\nmy sanctuary strangers,\\nuncircumcised in heart, and uncircumcised in flesh, to be in my\\nsanctuary, to pollute it, even\\nmy house,\\nwhen ye offer my bread, the fat and the blood, and they\\nhave broken my covenant\\nbecause of all your\\nabominations. (Ezek 44:)\\n\\n30Also,\\nthou son of man, the children of thy people still are talking against\\nthee by the walls and in the doors of\\nthe houses, and speak one to another, every one to his brother, saying,\\nCome, I pray you, and hear what is\\nthe word that cometh forth from the LORD. 31And\\nthey come unto thee as the people cometh,\\nand they\\nsit before thee as my people, and they hear thy words, but they will\\nnot do them: for with their mouth they\\nshow much love, but their heart goeth after their covetousness.\\n(Ezek 33:)\\n\\n7Ye\\nhypocrites, well did Esaias prophesy of you, saying, 8This\\npeople draweth nigh unto me with their mouth,\\nand honoureth me with their lips; but their heart is far from me.', '<|endoftext|> read in Matthew 14: 22-27: \"And when the disclipes saw Him walking on the sea, they were terrified and said, It is a ghost! and they screamed out with fright.But instantly He spoke to them saying, \\'Take courage! I AM! Stop being afraid.\\'\"\\n\\nJESUS TREADS THE WINEPRESS AND THE ONE WHO TREADS THE WINEPRESS IS GODIsaiah 63: 1-4 Speaking of YHWH:\"Who [is] this that cometh from Edom, with dyed garments from Bozrah? this [that is] glorious in his apparel, travelling in the greatness of his strength? I that speak in righteousness, mighty to save. Wherefore [art thou] red in thine apparel, and thy garments like him that treadeth in the winefat? I have trodden the winepress alone; and of the people [there was] none with me: for I will tread them in mine anger, and trample them in my fury; and their blood shall be sprinkled upon my garments, and I will stain all my raiment For the day of vengeance [is] in mine heart, and the year of my redeemed is come. \" now compare this with Revelation 19: 13-15 speaking of Jesus:\" And he [was] clothed with a vesture dipped in blood: and his name is called The Word of God. And the armies [which were] in heaven followed him upon white horses, clothed in fine linen, white and clean. And out of his mouth goeth a sharp sword, that with it he should smite the nations: and he shall rule them with a rod of iron: and he treadeth the winepress of the fierceness and wrath of Almighty God. \"\\n\\nJESUS\\' WAY IS CLEARED, AND THE WAY IS CLEARED FOR GODIsaiah 40:3- foretelling of John the Baptist: \"Listen Someone is calling out in the wilderness: Clear up the way of YHWH you people! make the highways for our God through the desert plain straight\" This is fulfilled in Matthew 3: 3:\"Listen, someone is crying out in the wilderness \\'prepare the way of YHWH you people make his roads straight\\' ..now noone can doubt that John the Baptist cleared the way for Jesus- for he said so himself..yet the prophecy speaks of the way being cleared by John for...YHWH!\\n\\nJESUS IS THE ONE HUSBAND, AND THE ONE HUSBAND IS GOD2Corinthians 11:2- \"For I am jealous over you with godly jealousy: for I have espoused you to ONE husband, that I may present [you as] a chaste virgin to Christ\"Jeremiah 31:32- \"...I was an husband unto them, saith the LORD\"\\n\\nJESUS IS OUR LORD AND OUR ONLY LORD IS GODEphesians 4:4-6- \"There is one body, and one Spirit, even as ye are called in one hope of your calling One Lord, one faith, one baptism, One God and Father of all, who is above all, and through all, and in you all.\" Jude 1:4- \"For there are certain men crept in unawares, who were before of old ordained to this condemnation, ungodly men, turning the grace of our God into lasciviousness, and denying the only Lord God, and our Lord Jesus Christ.\"\\n\\nJESUS IS THE ONLY MASTER, AND THE MASTER IS GODMatthew 23:8- \"But be not ye called Rabbi: for ONE is your Master, Christ; and all ye are brethren\"Malachi 1:6- \"...and if I [be] a master, where [is] my fear? saith the LORD of hosts unto you, O priests, that despise my name. And ye say, Wherein have we despised thy name? \"\\n\\nJESUS IS THE GOOD SHEPARD, AND THE GOOD SHEPARD IS GODJohn 10:14- \"I am the good shepherd, and know my sheep, and am known of mine.\"Psalm 23:1- \"The LORD is my shepherd; I shall not want.\"\\n\\nIsa. 40: 10-11 -\"Behold YHWH shall come with a strong hand, and his arm shall rule for him. Behold, His reward is with Him, and His work before Him. He will feed His flock like a Shepherd: He will gather the lambs with His arm, and carry them in His bosom, and gently lead those who are with young.\"\\n\\nJESUS IS OUR SAVIOUR, AND OUR SAVIOUR IS GODActs 4:12- \"Neither is there salvation in any other: for there is none other name under heaven given among men, whereby we must be saved\"', '<|endoftext|>angs, as they whirled and spun hither and thither.\\n\\nWhen one is placed in such a position as was Fred, his imagination is\\nsure to be very active, and, time and again, he was sure that he heard\\nthe stealthy tread of a moccasin upon the leaves below. All this,\\nhowever, was not imagination; for he had not been on his perch more\\nthan half an hour, when, peering downward through the leaves, he saw the\\nunmistakable figure of an Indian, gliding along in the stealthy manner\\npeculiar to that race. The heart of the lad throbbed violently, and he\\ngrasped the limb more tightly, watching every movement of the red-skin.\\n\\n\"He must be looking for me,\" was his thought. \"He saw me in the tree,\\nand he has now come to kill or take me away.\"\\n\\nHe was sure that that particular Apache was not Lone Wolf, although he\\ncould not be certain that any advantage was to be reaped from that. The\\nchief was not likely to be more devoid of anything like mercy than was\\nthe greatest or humblest of his warriors.\\n\\nThe red-skin was on foot, and bore a rifle in his hand. Instead of\\nthe fanciful scalp-lock ornamenting his crown, his black, wiry hair\\nstraggled down around his shoulders, over which was thrown a dirty army\\nblanket, that had once belonged to the United States government. The\\nhideous paint upon his face was easily seen from the perch of the\\nlad, and the red-skin was as repulsive and dreaded an object as can be\\nimagined.\\n\\nThe scamp was moving along with that stealthy, cat-like tread which is\\ncharacteristic of all his race; but although directly under the tree\\nwhen first seen by the lad, he did not look up nor act in any way which\\nwould suggest that he suspected the presence of anyone over him. He did\\nnot hesitate in his movement, and thus it was that he was scarcely seen\\nwhen he disappeared in the wood beyond, and the boy was alone.\\n\\nFred was now fully satisfied that it would not do to leave the tree so\\nlong as a particle of daylight remained. Apaches were too plentiful in\\nthose parts.\\n\\n\"I s\\'pose they\\'ll hang around till night, though I can\\'t see what\\nthey\\'re going to make by it,\" said the boy to himself. \"They\\'ve tried to\\nclear out Mr. Barnwell and the rest of them, but could n\\'t begin to\\ndo it, and now it won\\'t do them any good to stay here. It\\'ll be pretty\\nrisky for me to try and get into the house after dark, but they know I\\nam out here and they will be looking for me. And then Mickey--\"\\n\\nAt the mention of the Irishman\\'s name, Fred suddenly stopped with a\\nstart, for he was reminded of a fact which had escaped him until that\\nmoment. Mickey O\\'Rooney had gone out on a little scout of his own, some\\nhours before, and he had not yet returned, so that his situation, in one\\nsense, was like his own. But he manifestly had greater advantage, for\\nhe was not only fully armed, but was mounted on one of the fleetest\\nmustangs of the West; so that, unless he ran into some trap, he need\\nfear no disturbance from them.\\n\\n\"I only wish I was with him,\" reflected Fred, \"mounted upon Hurricane.\\nI wouldn\\'t mind a little run into some of these Apaches that think they\\nare such wonderful riders.\"\\n\\nAs has been intimated in another place, young Munson had been furnished\\nwith one of the finest of prairie steeds--one whose speed, endurance,\\nand intelligence was extraordinary. There was naturally a great\\nattachment between the two, and Fred would have been off most of the\\ntime, skimming over the prairie, had he been allowed to do so, but\\nHurricane was in the group in the centre of the settlement, with the\\nothers, which the Indians had tried so hard to stampede, and he was\\nas difficult to reach, under the circumstances, as were his friends\\nthemselves.\\n\\n\\n\\nCHAPTER VIII. THE SWOOP OF THE APACHE\\n\\nThe afternoon dragged slowly by with Fred crouching, as he was, in the\\ntop of the tree and waiting for the time to come when he might descend\\nand make the attempt to rejoin his friends, who could not but be greatly\\nconcerned over his absence. At rare intervals, the spiteful crack of a\\nrifle reached his ear as before, and he knew that the white and red men\\nwere watching', '<|endoftext|> than meat, and the body than raiment? Behold the fowls of the air: for they sow not, neither do they reap, nor gather into barns; yet your heavenly Father feedeth them. Are ye not much better than they? Which of you, by taking thought, can add one cubit unto his stature? And why take ye thought for raiment? Consider the lilies of the field how they grow: they toil not, neither do they spin: and yet I say unto you, that even Solomon in all his glory was not arrayed like one of these.\\n\\n\"Wherefore, if God so clothe the grass of the field, which today is, and tomorrow is cast into the oven, shall he not much more clothe you? O ye of little faith? Therefore take no thought, saying, \\'What shall we eat?\\' or, \\'What shall we drink?\\' or, \\'Wherewithal shall we be clothed?\\' (For after all these things do the Gentiles seek): for your heavenly Father knoweth that ye have need of all these things. But seek ye first the kingdom of God, and his righteousness; and all these things shall be added unto you. Take therefore no thought for the morrow: for the morrow shall take thought for the things of itself. Sufficient unto the day is the evil thereof.\\n\\n\"Judge not, that ye be not judged. For with what judgment ye judge, ye shall be judged: and with what measure ye mete, it shall be measured to you again. Give, and it shall be given unto you: good measure, pressed down, and shaken together, and running over, shall men give into your bosom. And why beholdest thou the mote that is in thy brother\\'s eye, but considerest not the beam that is in thine own eye? Or how wilt thou say to thy brother, \\'Let me pull out the mote out of thine eye\\'; and, behold, a beam is in thine own eye? Thou hypocrite! First cast out the beam out of thine own eye; and then shalt thou see clearly to cast out the mote out of thy brother\\'s eye.\\n\\n_\"Give not that which is holy unto the dogs_ ,\\n\\n_Neither cast ye your pearls before swine_ ,\\n\\n_Lest they trample them under their feet_ ,\\n\\n_And turn again and rend you_.\\n\\n_Ask, and it shall be given you_ :\\n\\n_Seek, and ye shall find_ :\\n\\n_Knock, and it shall be opened unto you_ :\\n\\n_For every one that asketh receiveth_ ;\\n\\n_And he that seeketh findeth_ ;\\n\\n_And to him that knocketh it shall be opened_.\\n\\nOr what man is there of you whom if his son ask bread, will he give him a stone? Or if he ask a fish, will he give him a serpent? If ye then, being evil, know how to give good gifts unto your children, how much more shall your Father which is in heaven give good things to them that ask him? Therefore all things whatsoever ye would that men should do to you, do ye even so to them: for this is the law and the prophets.\\n\\n\"Enter ye in at the strait gate: for wide is the gate, and broad is the way, that leadeth to destruction, and many there be which go in thereat: because strait is the gate, and narrow is the way, which leadeth unto life, and few there be that find it.\\n\\n\"Beware of false prophets, which come to you in sheep\\'s clothing, but inwardly they are ravening wolves. Ye shall know them by their fruits. Do men gather grapes of thorns, or figs of thistles? Even so, every good tree bringeth forth good fruit; but a corrupt tree bringeth forth evil fruit. A good tree cannot bring forth evil fruit, neither can a corrupt tree bring forth good fruit. Every tree that bringeth not forth good fruit is hewn down, and cast into the fire. Wherefore by their fruits ye shall know them.\\n\\n\"A good man, out of the good treasure of the heart, bringeth forth good things: and an evil man, out of the evil treasure, bringeth forth evil things. But I say unto you, that every idle word that men shall speak, they shall give account thereof in the day of judgment. For by thy words thou shalt be justified, and by thy words thou shalt be condemned.\\n\\n\"Therefore whosoever heareth these sayings of mine, and doeth them, I will liken him unto a wise man, which built his house upon a rock: and the rain descended, and the floods came, and the winds blew, and beat', '<|endoftext|> die, kand you do not speak to warn the wicked to turn from his way, kthat wicked person shall die in his iniquity, but his blood I will require at your hand. lBut if you warn the wicked to turn from his way, and he does not turn from his way, lthat person shall die in his iniquity, mbut you will have delivered your soul.\\n\\nWhy Will You Die, Israel?\\n\\n\"And you, nson of man, say to the house of Israel, Thus have you said: \\'Surely our transgressions and our sins are upon us, and owe rot away because of them. pHow then can we live?\\' Say to them, qAs I live, declares the Lord GOD, rI have no pleasure in the death of the wicked, but that the wicked turn from his way and live; sturn back, turn back from your evil ways, sfor why will you die, O house of Israel?\\n\\nt\"And you, son of man, say to uyour people, vThe righteousness of the righteous shall not deliver him when he transgresses, wand as for the wickedness of the wicked, he shall not fall by it when he turns from his wickedness, vand the righteous shall not be able to live by his righteousness when he sins. Though I say to the righteous that he shall surely live, yet xif he trusts in his righteousness and does injustice, none of his righteous deeds shall be remembered, but in his injustice that he has done he shall die. 14Again, ythough I say to the wicked, z\\'You shall surely die,\\' yet aif he turns from his sin and does what is just and right, if the wicked brestores the pledge, cgives back what he has taken by robbery, and walks din the statutes of life, not doing injustice, he shall surely live; he shall not die. 16eNone of the sins that he has committed shall be remembered against him. He has done what is just and right; he shall surely live.\\n\\n\"Yet fyour people say, g\\'The way of the Lord is not just,\\' when it is their own way that is not just. 18hWhen the righteous turns from his righteousness and does injustice, he shall die for it. 19And iwhen the wicked turns from his wickedness and does what is just and right, he shall live by this. jYet you say, \\'The way of the Lord is not just.\\' O house of Israel, kI will judge each of you according to his ways.\"\\n\\nJerusalem Struck Down\\n\\nIn the ltwelfth year mof our exile, in the tenth month, on the fifth day of the month, na fugitive from Jerusalem came to me and said, o\"The city has been struck down.\" pNow qthe hand of the LORD had been upon me the evening before the fugitive came; and he had opened my mouth by the time the man came to me in the morning, so my mouth was opened, and I was no longer mute.\\n\\nThe word of the LORD came to me: r\"Son of man, the inhabitants of these swaste places in the land of Israel keep saying, t\\'Abraham was only one man, yet he got possession of the land; but uwe are many; the land is surely given us to possess.\\' Therefore say to them, Thus says the Lord GOD: vYou eat flesh with the blood and wlift up your eyes to your idols and xshed blood; shall you then possess the land? 26yYou rely on the sword, zyou commit abominations, and zeach of you defiles his neighbor\\'s wife; shall you then possess the land? Say this to them, Thus says the Lord GOD: aAs I live, surely those who are in bthe waste places shall fall by cthe sword, and whoever is in the open field I will give to cthe beasts to be devoured, and those who are in dstrongholds and in caves shall die by cpestilence. 28eAnd I will make the land a desolation and a waste, and fher proud might shall come to an end, and gthe mountains of Israel shall be so desolate that none will pass through. hThen they will know that I am the LORD, when I have made the land a desolation and a waste because of all their abominations that they have committed.\\n\\n\"As for you, ison of man, jyour people who talk together about you by the walls and at the doors of the houses, say to one another, each to his brother, \\'Come, and hear what the word is that comes from the LORD.\\' kAnd they come to you as people come, and they sit before you as my people, and they lhear what you say but they will not do it; for mwith lustful talk in their mouths', '<|endoftext|> at us, and so fled.  But\\ntwo men were hurt with the sling-plummets, and one, and he not\\ngrievously, with an arrow, and not one slain.\\n\\n\"Thus we came up on to the ridge, so that there was nothing between us\\nand the bare heavens; thence we looked south-east and saw the Romans\\nwisely posted on the ridge not far from where it fell down steeply to the\\nnorth; but on the south, that is to say on their left hands, and all\\nalong the ridge past where we were stayed, the ground sloped gently to\\nthe south-west for a good way, before it fell, somewhat steeply, into\\nanother long dale.  Looking north we saw the outer edge of Mirkwood but a\\nlittle way from us, and we were glad thereof; because ere we left our\\nsleeping-place that morn Thiodolf had sent to Otter another messenger\\nbidding him send yet more men on to us in case we should be hard-pressed\\nin the battle; for he had had a late rumour that the Romans were many.\\nAnd now when he had looked on the Roman array and noted how wise it was,\\nhe sent three swift-foot ones to take stand on a high knoll which we had\\npassed on the way, that they might take heed where our folk came out from\\nthe wood and give signal to them by the horn, and lead them to where the\\nbattle should be.\\n\\n\"So we stood awhile and breathed us, and handled our weapons some half a\\nfurlong from the alien host.  They had no earth rampart around them, for\\nthat ridge is waterless, and they could not abide there long, but they\\nhad pitched sharp pales in front of them and they stood in very good\\norder, as if abiding an onslaught, and moved not when they saw us; for\\nthat band of shooters had joined themselves to them already.  Taken one\\nwith another we deemed them to be more than we were; but their hauberked\\nfootmen with the heavy cast-spears not so many as we by a good deal.\\n\\n\"Now we were of mind to fall on them ere they should fall on us; so all\\nsuch of us as had shot-weapons spread out from our company and went forth\\na little; and of the others Heriulf stood foremost along with the leaders\\nof the Beamings and the Elkings; but as yet Thiodolf held aback and led\\nthe midmost company, as his wont was, and the more part of the Wolfings\\nwere with him.\\n\\n\"Thus we ordered ourselves, and awaited a little while yet what the\\naliens should do; and presently a war-horn blew amongst them, and from\\neach flank of their mailed footmen came forth a many bowmen and slingers\\nand a band of horsemen; and drew within bowshot, the shooters in open\\narray yet wisely, and so fell to on us, and the horsemen hung aback a\\nlittle as yet.\\n\\n\"Their arrow-shot was of little avail, their bowmen fell fast before\\nours; but deadly was their sling-shot, and hurt and slew many and some\\neven in our main battle; for they slung round leaden balls and not\\nstones, and they aimed true and shot quick; and the men withal were so\\nlight and lithe, never still, but crouching and creeping and bounding\\nhere and there, that they were no easier to hit than coneys amidst of the\\nfern, unless they were very nigh.\\n\\n\"Howbeit when this storm had endured a while, and we moved but little,\\nand not an inch aback, and gave them shot for shot, then was another horn\\nwinded from amongst the aliens; and thereat the bowmen cast down their\\nbows, and the slingers wound their slings about their heads, and they all\\ncame on with swords and short spears and feathered darts, running and\\nleaping lustily, making for our flanks, and the horsemen set spurs to\\ntheir horses and fell on in the very front of our folk like good and\\nvaliant men-at-arms.\\n\\n\"That saw Heriulf and his men, and they set up the war-whoop, and ran\\nforth to meet them, axe and sword aloft, terribly yet maybe somewhat\\nunwarily.  The archers and slingers never came within sword-stroke of\\nthem, but fell away before them on all sides; but the slingers fled not\\nfar, but began again with their shot, and slew a many.  Then was a horn\\n', '<|endoftext|>able how Jesus and the Devil became\\nso well acquainted with each other; for Jesus was a Jew by nation, and\\nstrictly obeyed the law of Moses; but Moses is completely silent as to\\nthe existence of any such personage as the Devil. At the time when it is\\nsaid Jesus came to the Jewish nation, they had, during their captivity,\\nembraced the theology of their conquerors; and on their return to the\\nland of their nativity, brought with them the-belief in the existence of\\ngood and bad angels, and also the doctrine of a future state of rewards\\nand punishments,--dogmas unknown to, and never taught by, Moses. It is\\nclear, then, that the very existence of a Devil never was a doctrine of\\nthe Old Testament, but on the contrary, it was borrowed from eastern\\nmythology; and Jesus, finding that the Jews professed to believe it,\\nfell in with it, as also a heaven and a hell, and a judgment to come,\\nwhich doctrines were all of heathen origin. The Old Testament is silent\\nas to what constitutes orthodox Christianity. Ye Christian ministers!\\nyour heaven and hell, by the teaching of which you gain wealth and live\\nlike princes, is nothing but an echo of by-gone ages, which had its\\norigin in the imagination of the priesthood of an antiquity anterior to\\nthe existence of Moses or of the Jewish nation!\\n\\nBut to return to the temptation of Jesus by the Devil. And here it may\\nbe asked, how it can now, or ever could, be considered a temptation at\\nall? If Jesus was what they say he professed to be, _the sent of God_,\\nhe knew well that the Devil had nothing to give him by way of inducement\\nto distrust his Father\\'s superintendence and care. Jesus might have said\\nto Satan, \"You lying old Devil, you know that you have no kingdom to\\nbestow; you likewise well know that you have not land enough whereon to\\nbuild a hovel, in which to shelter your favorite associates, the swine!\"\\nBut, on the contrary, Jesus seems to act with great respect towards the\\nDevil. He made no objections to follow Satan wherever he chose to lead\\nhim. We are ignorant of the object Jesus had in view by retiring into\\nthe wilderness; and how the Devil came to be acquainted with his\\ndestitute situation, we are also at a loss to conjecture. Likewise, we\\nhave yet to learn whether Satan resided among the Jews, or dwelt in the\\nregions of the air, as he is called \"the Prince and power of the air,\\nthe spirit which works in the hearts of the children of disobedience.\"\\n\\nThe number of forty years, or days, is repeatedly chosen by the writers\\nof the Old Testament, in which to perform something wonderful, and of\\ngreat importance. Thus, the Jews were forty years going from Egypt to\\nthe land of promise, during which time nearly all that came out of\\nbondage were destroyed for their disobedience against the God of Abram,\\nIsaac, and Jacob. Jehovah and Moses were forty days on Mount Sinai,\\npreparing ornaments for the Jewish worship, during which time Aaron and\\nthe rest of the Israelties returned back to worship the gods of their\\nformer oppressors; so that it appears, before the church of Jehovah in\\nthe wilderness was ready to sing his praise, and thank him for bringing\\nthem out of bondage, both Aaron and the people were singing and dancing\\nbefore the golden calves of Egypt! The number forty has been most\\nunfortunate for Jehovah\\'s plans; for, in addition to repeated failures\\nconnected with the number forty, it is recorded that Jehovah was grieved\\nforty years for the transgressions of his chosen people; and Jesus,\\nafter forty days\\' fasting, surrounded by devouring beasts and hungry\\nvultures, behold! the Devil came skulking along with brazen-faced\\nimpudence, and Jesus, the better to get rid of him, broke up his\\nsolitary abode. Thus, again, the number forty concluded without any\\napparent object being effected.\\n\\nWhoever wrote this account of Christ\\'s temptation, as if it was not\\nfoolish enough, has added, that after the Devil had withdrawn from\\nmaking Jesus such tempting offers to enlist into his service, angels\\ncame and ministered unto him. What the nature of the service was, which\\nthey performed, we know not; but one would suppose their first inquiry\\nought to have been, whether he did not wish to have his dinner as soon\\nas possible? The whole of this account is so contemptible, that I shall\\nnot give it any further attention.\\n', '<|endoftext|>\\ndon\\'t let your father know our plan till it has either succeeded or\\nfailed; for he is so impatient, and still so weak, that the suspense\\nwould probably kill him.\"\\n\\n\"It will be much the best,\" said Arthur; \"but I must go, for the\\nFrenchmen are all on deck,--so now or never.\"\\n\\nSo saying, he left the cabin. Hour passed after hour, and Travers saw no\\nmore of him. Captain Ridley awoke; and Travers gave him some gruel,\\nwhich he had boiled for his dinner. The sick man found great fault with\\nit, and inquired very peevishly for Arthur. Travers made him some vague\\nanswer, and Captain Ridley complained much of his absence, assured\\nTravers that he was the worst nurse in the world, and that it was a\\nshame for that boy to leave him, and at last grumbled himself to sleep\\nagain.\\n\\nTravers now began to be exceedingly alarmed; thinking that Arthur had\\nbeen taken in the attempt, and perhaps murdered. He looked at the sun,\\n(for his captors had spared him the trouble of keeping a watch,) and\\nthought it might be about four o\\'clock, when Arthur appeared at the\\ncabin-door, and with a pale cheek, but a look of determined courage,\\nbeckoned Travers, without uttering a word. He left the cabin, and\\nfollowed Arthur with a noiseless step. While they were ascending the\\ncompanion-ladder, Arthur turned round, and said in a low voice: \"Every\\nman in the ship is secured excepting two; one of whom is at the helm,\\nand the other in the shrouds: master them, and the ship is ours!\"\\n\\nThere was no time for questions; or Travers would have asked how all\\nthis came to pass: but Arthur hurried him on deck; and, going to the\\narm-chest, gave Travers a sabre, and armed himself with a musket.\\nTravers stepped to the steerage, and took the helmsman unawares; who\\nuttered a cry of astonishment at seeing a man standing near him in a\\nthreatening attitude, with a drawn sabre in his hand, and began, with a\\nloud voice, to implore for mercy. This supplication reached the ears of\\nhis companion in the shrouds, who, putting a stop to the Marseillaise\\nHymn, with which he was entertaining himself, began to descend with\\ngreat expedition. But Arthur stopped his progress by levelling his\\nmusket at him; and by his menaces made him understand, that if he did\\nnot remain where he was, he would receive the whole contents in his\\nbody. Now the French sailor did not know, nor did Arthur at the time\\nremember, that there was no charge in the musket. However, it had the\\neffect of intimidating the man, who made signs that he would obey, and\\nsupplicated with his hands for his life.\\n\\nTravers and Arthur had proceeded thus far with success; but they were at\\nthis moment in a most awkward predicament, for each held his man in\\ncheck, yet it was necessary to do something more. The steersman was a\\nstrong muscular fellow, and notwithstanding that, had at first been\\nfrightened by the suddenness of the occurrence; yet Arthur saw, by the\\nexpression of watchfulness that lurked in the turn of his eye, that he\\nonly waited till Travers was off his guard, to spring upon him.\\n\\nThere was a coil of strong rope, which lay about twelve paces from\\nArthur on the deck; of this he longed to make himself master: but he was\\nafraid of taking his attention from his prisoner above; for he knew how\\nsoon a sailor could swing himself from rope to rope, and stand on deck\\nin a moment. At last he lost all patience, and determined to trust to\\nthe man\\'s fears: so with one spring he seized the cord and gave it to\\nTravers, and resumed his guard with the musket, whilst Travers pinioned\\nhis prisoner, and bound him so strongly that escape was impossible. They\\nthen beckoned the man above to descend, and soon bound him safely.\\n\"Now,\" said Arthur, \"you must take the helm, my friend; whilst I go\\nbelow, and set at liberty our two shipmates, who are confined between\\ndecks.\"\\n\\nHe soon returned with the two English sailors, who could scarcely\\nbelieve that they were at liberty, and the ship in their possession.\\nTravers\\'s first care was to shift the sails and alter their course. They\\nthen went down to tell Captain Ridley what had happened. As soon as they\\ncame below', \"<|endoftext|>Générations\\n\\nGénérations is a French radio station based in Paris and created in 1992, dedicated to several genres such as hip-hop (rap music and R&B), soul music and disco.\\n\\nExternal links\\n  \\n\\nCategory:Radio stations in France\\nCategory:Radio in Paris\\nCategory:Radio stations established in 1992<|endoftext|>Again there was a day when the sons of God came to present themselves before the LORD, and Satan came also among them to present himself before the LORD.\\n\\n2:2\\n\\nAnd the LORD said unto Satan, From whence comest thou? And Satan answered the LORD, and said, From going to and fro in the earth, and from walking up and down in it.\\n\\n2:3\\n\\nAnd the LORD said unto Satan, Hast thou considered my servant Job, that there is none like him in the earth, a perfect and an upright man, one that feareth God, and escheweth evil? and still he holdeth fast his integrity, although thou movedst me against him, to destroy him without cause.\\n\\n2:4\\n\\nAnd Satan answered the LORD, and said, Skin for skin, yea, all that a man hath will he give for his life.\\n\\n2:5\\n\\nBut put forth thine hand now, and touch his bone and his flesh, and he will curse thee to thy face.\\n\\n2:6\\n\\nAnd the LORD said unto Satan, Behold, he is in thine hand; but save his life.\\n\\n2:7\\n\\nSo went Satan forth from the presence of the LORD, and smote Job with sore boils from the sole of his foot unto his crown.\\n\\n2:8\\n\\nAnd he took him a potsherd to scrape himself withal; and he sat down among the ashes.\\n\\n2:9\\n\\nThen said his wife unto him, Dost thou still retain thine integrity? curse God, and die.\\n\\n2:10\\n\\nBut he said unto her, Thou speakest as one of the foolish women speaketh. What? shall we receive good at the hand of God, and shall we not receive evil? In all this did not Job sin with his lips.\\n\\n2:11\\n\\nNow when Job's three friends heard of all this evil that was come upon him, they came every one from his own place; Eliphaz the Temanite, and Bildad the Shuhite, and Zophar the Naamathite: for they had made an appointment together to come to mourn with him and to comfort him.\\n\\n2:12\\n\\nAnd when they lifted up their eyes afar off, and knew him not, they lifted up their voice, and wept; and they rent every one his mantle, and sprinkled dust upon their heads toward heaven.\\n\\n2:13\\n\\nSo they sat down with him upon the ground seven days and seven nights, and none spake a word unto him: for they saw that his grief was very great.<|endoftext|>Evidence based decision making workshop NYC\\n\\nEvidence based decision making sounds easy enough and it is certainly based on lean principles that have become popular in the enterprise. But the essence of this issue is simply asking the right questions at the right time, and making sure that product teams and decision makers are aligned and not at odds. Join us for an extremely efficient half day where we run through several scenarios, field tested to help you and your team bring this type of thinking back inside your org or to improve what you are already doing.<|endoftext|>\\n34 So.3d 4 (2010)\\nFOSTER\\nv.\\nMcNEIL.\\nNo. 1D09-4277.\\nDistrict Court of Appeal of Florida, First District.\\nApril 30, 2010.\\nDecision Without Published Opinion Certiorari denied.\\n<|endoftext|>Vancouver, BC Real Estate For Sale\\n\\nBenefits of Detached Homes\\n\\nThere are many perks to choosing a house over a condo to raise a family, from the square footage to the freedom of customization, but the best one by far has to be the variety of homes on the market.\\n\\nWhile many condos blend together, single family detached houses each have their own unique personality and construction. Large backyards and quiet neighbourhoods offer a sense of peace that can't be found in the middle of the city.\\n\\nThe Benefits of Owning a House\\n\\nBecause Greater Vancouver has a heavy focus on condos, single family detached houses are highly sought after by couples who want to raise their children in their own backyard while still being close to the big city. There are many perks to choosing a house over a condo to raise a family, from the square footage to the freedom of customization, but the best one by far has to be the variety of homes on the market. While many condos\", '<|endoftext|>igs, and the rushing sound was terrible.\\n\\n\"I wish we were well out of this wood,\" said my master.\\n\\n\"Yes, sir,\" said John, \"it would be rather awkward if one of these branches came down upon us.\"\\n\\nThe words were scarcely out of his mouth when there was a groan, and a crack, and a splitting sound, and tearing, crashing down among the other trees came an oak, torn up by the roots, and it fell right across the road just before us. I will never say I was not frightened, for I was. I stopped still, and I believe I trembled; of course I did not turn round or run away; I was not brought up to that. John jumped out and was in a moment at my head.\\n\\n\"That was a very near touch,\" said my master. \"What\\'s to be done now?\"\\n\\n\"Well, sir, we can\\'t drive over that tree, nor yet get round it; there will be nothing for it, but to go back to the four crossways, and that will be a good six miles before we get round to the wooden bridge again; it will make us late, but the horse is fresh.\"\\n\\nSo back we went and round by the crossroads, but by the time we got to the bridge it was very nearly dark; we could just see that the water was over the middle of it; but as that happened sometimes when the floods were out, master did not stop. We were going along at a good pace, but the moment my feet touched the first part of the bridge I felt sure there was something wrong. I dare not go forward, and I made a dead stop. \"Go on, Beauty,\" said my master, and he gave me a touch with the whip, but I dare not stir; he gave me a sharp cut; I jumped, but I dare not go forward.\\n\\n\"There\\'s something wrong, sir,\" said John, and he sprang out of the dog-cart and came to my head and looked all about. He tried to lead me forward. \"Come on, Beauty, what\\'s the matter?\" Of course I could not tell him, but I knew very well that the bridge was not safe.\\n\\nJust then the man at the toll-gate on the other side ran out of the house, tossing a torch about like one mad.\\n\\n\"Hoy, hoy, hoy! halloo! stop!\" he cried.\\n\\n\"What\\'s the matter?\" shouted my master.\\n\\n\"The bridge is broken in the middle, and part of it is carried away; if you come on you\\'ll be into the river.\"\\n\\n\"Thank God!\" said my master. \"You Beauty!\" said John, and took the bridle and gently turned me round to the right-hand road by the river side. The sun had set some time; the wind seemed to have lulled off after that furious blast which tore up the tree. It grew darker and darker, stiller and stiller. I trotted quietly along, the wheels hardly making a sound on the soft road. For a good while neither master nor John spoke, and then master began in a serious voice. I could not understand much of what they said, but I found they thought, if I had gone on as the master wanted me, most likely the bridge would have given way under us, and horse, chaise, master, and man would have fallen into the river; and as the current was flowing very strongly, and there was no light and no help at hand, it was more than likely we should all have been drowned. Master said, God had given men reason, by which they could find out things for themselves; but he had given animals knowledge which did not depend on reason, and which was much more prompt and perfect in its way, and by which they had often saved the lives of men. John had many stories to tell of dogs and horses, and the wonderful things they had done; he thought people did not value their animals half enough nor make friends of them as they ought to do. I am sure he makes friends of them if ever a man did.\\n\\nAt last we came to the park gates and found the gardener looking out for us. He said that mistress had been in a dreadful way ever since dark, fearing some accident had happened, and that she had sent James off on Justice, the roan cob, toward the wooden bridge to make inquiry after us.\\n\\nWe saw a light at the hall-door and at the upper windows, and as we came up mistress ran out, saying, \"Are you really safe, my dear? Oh! I have been so anxious, fancying all sorts of things. Have you had no accident?\"\\n\\n\"No, my dear; but if your Black Beauty had not been wiser than we were we should all have been carried down the river at the']\n","layer 3\n","621 ['<|endoftext|>mer für Anhörungen zu Unregelmäßigkeiten im Bereich des Haushalts eingerichtet werden sollte, und zwar entweder beim Rechnungshof oder beim Gerichtshof. Herr van Hulten hat diesen Punkt im Laufe dieser Debatte meines Wissens nochmals aufgegriffen.\\nDas ist eine berechtigte Frage, und für die Nichtberücksichtigung der Vorschläge, dass die Kommission auf solche externen Einrichtungen zurückgreifen sollte, gibt es prinzipiell zwei Gründe. Zunächst hat der Ausschuss Unabhängiger Sachverständiger festgelegt, und meiner Ansicht nach zu Recht, dass ein solches Gremium auf interner Ebene geschaffen werden sollte, nicht zuletzt, weil die Verträge den anderen beiden Organen bei der Kontrolle der finanziellen Auswirkungen und der Rechtmäßigkeit der disziplinarischen Entscheidungen der Kommission sehr spezifische Aufgaben zugedacht haben. Es ergäben sich unhaltbare Interessenskonflikte, um nicht zu sagen, ein gewisses Maß an Verfassungsakrobatik, wenn einer der Höfe in die internen Verfahren der Kommission direkt einbezogen würde. Zudem wären solche Änderungen zweifellos nur bei einer gleichzeitigen Änderung der Verträge möglich. Zweitens würde eine Aufteilung eines Disziplinarverfahrens in einen finanziellen und einen das Verhalten betreffenden Aspekt und damit einhergehend eine Anhörung der Aspekte in getrennten Institutionen in der Praxis zu dem unerwünschten Effekt führen, dass das Disziplinarverfahren beträchtlich in die Länge gezogen wird.\\nIch hoffe, dass das Hohe Haus mir zustimmt, dass dies gewichtige Gründe sind, wie das Papier zur Disziplin heute Vormittag zeigte. In den meisten Mitgliedstaaten und allen internationalen Organisationen ist die Institution selbst für die Disziplinierung ihrer Mitarbeiter verantwortlich. Wir sind der festen Überzeugung, dass dies in den EU-Organen auch so bleiben sollte.\\nIch möchte mich nun den Fragen der Regierungen und des Personals zuwenden, die in den Berichten Lamassoure und Harbour behandelt wurden, und ich bedauere zutiefst, dass mir der begrenzte Zeitrahmen nicht erlaubt, die ausführliche Antwort zu geben, die diese Berichte verdienen. Zu diesem Zeitpunkt mag die Feststellung genügen, dass ich die beiden Berichte sehr begrüße.\\nHerrn Harbour danke ich für den äußerst positiven und durchdachten Ansatz, den er und seine Kollegen für die komplizierten Fragen der Modernisierung der Personalpolitik sowohl in der Kommission als auch in den anderen Organen der Europäischen Union gewählt haben. Mit dem Bericht stehen uns zusätzliche und äußerst nützliche Grundlagen für die Diskussion in vielen wichtigen Bereichen zur Verfügung. Außerdem bot die von Herrn Harbour organisierte öffentliche Anhörung zur Personalpolitik Gelegenheit, sich mit den im öffentlichen und im privaten Sektor üblichen Methoden und vorherrschenden Auffassungen vertraut zumachen und auf diese Weise wertvolle neue Einsichten zu gewinnen.\\nIch möchte auch Herrn Lamassoure für seine konstruktiven Einblicke und seine nützlichen Bemerkungen zum verfassungsrechtlichen Rahmen danken, in welchem die gegenwärtige Reform durchgeführt wird. Er verweist ganz richtig auf die Breite der Probleme und argumentiert, dass es von großem Nutzen gewesen wäre, wenn das noch nicht veröffentlichte Weißbuch über das Regierungshandeln bereits vor', '<|endoftext|>aten die Anforderungen zufriedenstellend erfüllen. Falls dem nicht so ist, müssen wir Maßnahmen ergreifen, um sicherzustellen, daß wir das von der Richtlinie geforderte hohe Maß an Umweltschutz auch praktisch umsetzen können. Leider hat die Kommission in der Vergangenheit das wohldurchdachte und von uns befürwortete System der Berichtspflicht der Mitgliedstaaten gegenüber der Kommission und dem Europäischen Parlament nur recht zögerlich genutzt. Unserer Ansicht nach kann dieses System der Berichterstattung jedoch am besten gewährleisten, daß diese Richtlinie - und hier möchte ich eine andere Metapher gebrauchen - nicht zusammen mit anderen Richtlinien auf die Abfalldeponie der Nichteinhaltung gekippt wird.\\nUnsere Änderungsanträge 14 und 16 spiegeln die Sorge des Ausschusses darüber wider, daß die Richtlinie zwei bedeutende Lücken aufweist. Erstens wären bereits existierende Abfalldeponien unter einer bestimmten Größe, die auf einer Insel liegen, von großen Teilen der Richtlinie ausgenommen. Unserer Meinung nach sollte der Betrieb dieser Deponien verboten werden, wenn kein öffentlich zugängliches Register über die dort abgelagerten Abfälle geführt wird. Zweitens bestehen wir darauf, daß die Mitgliedstaaten alle Abfalldeponien schließen, die nicht in Übereinstimmung mit der Abfallrahmenrichtlinie genehmigt worden sind. Es ist ein schlechtes Omen, daß diese Anlagen überhaupt noch in Betrieb sind. Die Standortwahl für Abfalldeponien ist ebenfalls ein äußerst umstrittener Aspekt. Es fällt nicht in unseren Zuständigkeitsbereich, in örtliche Planungsangelegenheiten einzugreifen, doch sind sich die Ausschußmitglieder darin einig, daß wir in unserer Leitlinie im Anhang den wünschenswerten Mindestabstand zwischen neuen Abfalldeponien und Wohngebieten detailliert festlegen sollten.\\nAls Berichterstatterin muß ich den Bericht im Namen des Ausschusses vorlegen, obwohl ich persönlich mit einigen Änderungsanträgen des Ausschusses nicht einverstanden bin, namentlich mit der Ablehnung einer zeitlichen Begrenzung der Haftung für durch Abfalldeponien verursachte Schäden. Ich wäre der Kommission dankbar, wenn sie sich zum Änderungsantrag 15 und seiner Umsetzbarkeit äußern könnte.\\nAbschließend möchte ich dem Parlament diese Richtlinie empfehlen. Die eigentliche Arbeit beginnt jedoch erst, wenn die Richtlinie angenommen ist, insbesondere in meinem Heimatland. Haben wir die Zielvorgaben der Richtlinie erst einmal akzeptiert, müssen Konzepte für die Wiederverwertung und Kompostierung von Abfällen - wir hoffen, daß bis Jahresende eine Richtlinie über die Kompostierung vorliegt - entwickelt werden, die funktionieren und eine gute Vermarktung der Recycling-Produkte ermöglichen. Die von uns produzierte Abfallmenge muß verringert werden. Wir sollten uns nicht scheuen zu überlegen, ob die Abfalldeponien nicht dadurch abgebaut werden können, daß wir mehr verbrennen. Wenn wir diesen Weg wählen, müssen wir auch die notwendigen Entscheidungen treffen und solche Müllverbrennungsanlagen bauen, wenngleich wir uns darüber im klaren sind, daß die Öffentlichkeit von dieser Notwendigkeit erst noch überzeugt werden muß.\\nHeute abend und morgen bei der Ab', '<|endoftext|> stattfindet und die für die Annahme des Entwurfs der Tagesordnung zuständig ist, vorgeschlagen werden. Früher konnte dies natürlich nicht geschehen. Im übrigen ist die Zahl meiner Mitarbeiter im Augenblick ausreichend.\\nHerr Colino, ich nehme an, Sie bitten um das Wort, da Sie persönlich angesprochen wurden.\\n\\nColino Salamanca\\nHerr Präsident! Eigentlich nur, weil Herr Provan meinen Namen genannt hat. In Artikel 60 ist zu lesen, daß, sobald über die Änderungsanträge abgestimmt worden ist, und vor der Abstimmung über den Vorschlag einer legislativen Entschließung - so wird es ausdrücklich gesagt - der Ausschußvorsitzende oder der Berichterstatter die Rücküberweisung an den Ausschuß beantragen können. Da es keinen Berichterstatter gab, habe ich dies als Vorsitzender des Ausschusses beantragt. Ich stimme darin überein, daß es hier in der Geschäftsordnung ein Auslegungsproblem gibt, ich habe aber diesen Antrag gleichwohl in Anwendung der Geschäftsordnung gestellt.\\n\\nDe Vries\\nHerr Präsident, wir haben jetzt 25 Minuten lang eine Verfahrensdebatte geführt. Ich möchte keinem der Kollegen das Recht absprechen, hier im Plenum Bemerkungen zur Anwendung der Geschäftsordnung vorzubringen. Meiner Ansicht nach sollten wir jedoch besser gemäß der Tagesordnung um 15.00 Uhr mit der Mitteilung der Kommission beginnen. Wir sollten erst die Mitteilung der Kommission anhören und dann anschließend, also um 16.00 Uhr, Gelegenheit zu Wortmeldungen zum Verfahrengeben, denn die Medien, die Kolleginnen und Kollegen, die für die inhaltliche Debatte gekommen sind, und der Kommissar haben ein Recht darauf, daß wir erst dieses wichtige politische Thema besprechen und danach unsere internen Angelegenheiten regeln. Ich möchte Ihnen also vorschlagen, Herr Präsident, daß wir exakt um 15.00 Uhr mit der Mitteilung der Kommission beginnen und eventuelle Bemerkungen zur Anwendung der Geschäftsordnung auf 16.00 Uhr vertagen, wenn wir mit der regulären Tagesordnung beginnen.\\n\\nDer Präsident\\nHerr De Vries, Sie wissen ebenso gut wie ich, daß Fragen zur Geschäftsordnung spontan gestellt werden, und wir können alle nichts anderes tun, als äußerte Disziplin walten zu lassen.\\n(Das Parlament genehmigt das Protokoll.)\\n\\nBegrüßung\\nDer Präsident\\nIch möchte Ihnen mitteilen, daß sich heute auf der Zuschauertribüne eine Gruppe von Abgeordneten des niederländischen Parlaments befindet, die von einer unserer Kolleginnen eingeladen wurde. Ich möchte die Kollegen aus dem niederländischen Parlament hiermit herzlich begrüßen.\\n\\nUrteil des Gerichtshofs in der Sache C/106\\nDer Präsident\\nNach der Tagesordnung folgt die Mitteilung der Kommission über die Folgemaßnahmen im Anschluß an das Urteil des Gerichtshofes in der Sache C/106 (Rechtsgrundlagen im Haushaltsplan).\\n\\nLiikanen\\nHerr Präsident, ein kürzlich vom Gerichtshof erlassenes Urteil hat ernsthafte Fragen über die Ausführung des Gemeinschaftshaushalts im Jahre 1998 und darüber hinaus aufgeworfen. Die Kommission weiß, welche Besorgnis diese Schwierigkeiten ausgelöst haben, und ich freue mich, Sie heute über den aktuellen Stand dieser Angelegenheit informieren zu können. Ich möchte jedoch gleich zu Beginn', '<|endoftext|>enigsten strenge Regel, nach der wir also morgen Abend hinter verschlossenen Türen Einblick in die Sache nehmen sollen. Allerdings muss gemäß der Vereinbarung zwischen dem Parlament und der Kommission darüber zwischen dem Präsidenten des Parlaments und dem der Kommission verhandelt werden. Ich möchte Präsident Cox und die Konferenz der Präsidenten mithin auffordern, für eine günstigere Regelung einzutreten.\\nMeine zweite Bemerkung gilt dem Treffen zwischen der Konferenz der Präsidenten, den Mitgliedern des Haushaltskontrollausschusses und dem Kommissionspräsidenten Prodi, das am Donnerstag nächster Woche hinter verschlossenen Türen stattfinden wird. Alle Pressevertreter in dem Raum unter uns erzählen mir allerdings, Herr Prodis Sprecher habe erklärt, diese Sitzung könne, sofern es das Parlament will, öffentlich abgehalten werden. Meiner Ansicht nach dürfte es unserer Würde entsprechen und auch in unserem Interesse liegen, wenn wir mit Nachdruck eine öffentliche Sitzung fordern. Meines Erachtens haben alle Bürger in Europa ein Anrecht darauf und wäre es kontraproduktiv, geschehe dies nicht. Ich darf Sie also bitten, Herr Präsident, diese beiden Fragen ganz nachdrücklich Herrn Cox zu übermitteln. Ich wäre Ihnen außerordentlich dankbar.\\n\\nDer Präsident.\\nHerr Staes, ich nehme Ihre Bemerkungen zur Kenntnis, die selbstverständlich an Präsident Cox weitergeleitet werden, aber ich erinnere Sie daran, dass dieses Verfahren nicht eine Entscheidung von Herrn Prodi ist, sondern ein Beschluss der Konferenz der Fraktionsvorsitzenden, einschließlich des Ihrigen, über das Verfahren zur Behandlung der Frage. Folglich werde ich Ihre Gedanken übermitteln, aber Sie sollen wissen, welches die Grundlage dafür war. Nein, vielen Dank, ich werde keine Diskussion darüber beginnen.\\nDas Wort hat Herr Parish zur Geschäftsordnung.\\n\\nParish (PPE-DE).\\nHerr Präsident! Ich habe eine Bemerkung zur Geschäftsordnung: Ihnen wird sicher die jüngste Erklärung der britischen Wahlkommission bekannt sein, wonach die Bevölkerung von Gibraltar aufgrund eines Beschlusses des Europäischen Gerichtshofs bei den nächsten europäischen Wahlen im Südwesten des Vereinigten Königreichs wählen soll. Werden Sie sich mir anschließen und das Endes dieses historischen Unrechts, mit dem der Bevölkerung von Gibraltar eine Stimme in Europa verweigert wurde, begrüßen? Ich möchte Sie ersuchen, im Namen dieses Parlaments an Herrn Peter Caruana, den Ersten Minister von Gibraltar, zu schreiben, seine Bürger herzlich willkommen zu heißen und sie zu ihrem harten Kampf um die Sicherstellung ihrer rechtmäßigen demokratischen Vertretung in Europa zu beglückwünschen.\\n\\nDer Präsident.\\nHerr Parish, ich nehme Ihre Bemerkung aufmerksam zur Kenntnis und werde mich aufrichtig freuen, wenn die Bürger von Gibraltar zum ersten Mal über das Parlament von Westminster abstimmen können.\\n\\nDer Präsident.\\nNach der Tagesordnung folgt die Vorlage des Entwurfs des Gesamthaushaltsplans für 2004 durch den Rat.\\nDas Wort hat zunächst Herr Magri, der amtierende Ratspräsident.\\n\\nMagri\\nHerr Präsident, meine sehr verehrten Damen und Herren Abgeordneten! Ich empfinde es als große Ehre und Privileg, Ihnen im Nahmen des Ratsvorsitzes den vom Rat am', '<|endoftext|>ausschusses erwägen sollte, der unmittelbar dem Verwaltungsrat gegenüber verantwortlich ist.\\nLara Comi\\nIch habe dafür gestimmt, dem gemeinsamen Unternehmen Artemis für das Haushaltsjahr 2009 Entlastung zu erteilen, da es seine Finanzen für eine Agentur in der Anlaufphase äußerst gut verwaltet hat. Deshalb denke ich, dass in Zukunft Verbesserungen erzielt und die im Rechnungsabschluss für dieses Haushaltsjahr berichteten Unzulänglichkeiten korrigiert werden können.\\nDiogo Feio\\nschriftlich. - (PT) Das gemeinsame Unternehmen Artemis wird eine gemeinsame technologische Initiative im Bereich der eingebetteten Informationstechnologie-Systeme um. Diese öffentlich-private Partnerschaft ist hauptsächlich auf die Unterstützung der Kofinanzierung von Forschungsinitiativen auf europäischer Ebene und die Zusammenarbeit zwischen den verschiedenen Akteuren in dem Bereich ausgerichtet. Wie der Berichterstatter zu Recht hervorhebt, wurde es entwickelt, um eine \"Forschungsagenda\" für die Entwicklung von Schlüsseltechnologien für eingebettete IKT-Systeme in verschiedenen Anwendungsbereichen festzulegen und umzusetzen und auf diese Weise die europäische Wettbewerbsfähigkeit und Nachhaltigkeit zu stärken und das Entstehen neuer Märkte und gesellschaftlich relevanter Anwendungen zu ermöglichen. Das Unternehmen steckt noch immer in Kinderschuhen, was bei uns große Hoffnungen für seine zukünftigen Leistungen weckt, und ich hoffe, dass es den getätigten Investitionen gerecht wird.\\nJuozas Imbrasas\\nschriftlich. - (LT) Ich habe dieses Dokument unterstützt, da sich der zuständige Ausschuss für die Bewilligung des Rechnungsabschlusses des gemeinsamen Unternehmens Artemis für das Haushaltsjahr 2009 entschieden hat. Der Rechnungshof hat erklärt, dass der Jahresabschluss für das Haushaltsjahr 2009 zuverlässig ist und dass die ihm zugrunde liegenden Transaktionen rechtmäßig und ordnungsgemäß sind. Im endgültigen Haushaltsplan des gemeinsamen Unternehmens für das Jahr 2009 waren Verpflichtungsermächtigungen in Höhe von 46 000 000 EUR und Zahlungsermächtigungen in Höhe von 8 000 000 EUR ausgewiesen. Die Verwendungsrate betrug bei den Verpflichtungsermächtigungen 81 % und bei den Zahlungsermächtigungen 20 %. Ich bin der Ansicht, dass sich das gemeinsame Unternehmen noch immer in der Anlaufphase befindet, und habe daher Verständnis für die geringe Verwendungsrate bei den Zahlungsermächtigungen.\\nGiovanni La Via\\nSowohl der Rechnungshof als auch der Haushaltskontrollausschuss haben eine befürwortende Stellungnahme über die Ausführung des Haushaltsplans des gemeinsamen Unternehmens Artemis für das Haushaltsjahr 2009 abgegeben. Aus diesen Gründen hat das Parlament heute für die Erteilung der Entlastung für das Haushaltsjahr 2009 gestimmt. Die durchgeführten Prüfungen belegten, dass die Rechnungsabschlüsse des gemeinsamen Unternehmens zuverlässig waren und die zugrunde liegenden Vorgänge als rechtmäßig und ordnungsgemäß angesehen werden können. Meiner Ansicht nach wäre es jedoch hilfreich, wenn das gemeinsame Unternehmen die Aufforderung zur Verbesserung seiner Dokumentation von IT-Prozessen und IT-Tätigkeiten sowie eine Aufzeichnung von IT-Risiken und zur', '<|endoftext|>-intensity changes, even after large cumulative dosages of macrocyclic GBCAs,\" Bennani-Baiti said. \"In other words, is contrast-enhanced breast MRI-based screening safe for women who are at high risk for developing breast cancer?\"\\n\\nThe study included 25 healthy women at high risk for breast cancer who had received more than six doses of macrocyclic GBCAs, along with 16 healthy control subjects with no exposure to any GBCA. The median age for all participants was 46 (± 9 years). On average, the women in the GBCA group received 9.5 cumulative doses (range, 6-23 doses).\\n\\nMRI brain scans\\n\\nAll women underwent unenhanced 3-tesla MRI brain scans with a dedicated head coil. The protocol included a T1-weighted axial magnetization-prepared rapid gradient-echo (MPRAGE) sequence with calculations for T1 maps and an axial 3D gradient-echo sequence.\\n\\nT1 signal intensities were measured for the dentate nucleus and the pons, which were used as the reference regions. In addition, the researchers calculated the dentate nucleus-to-pons ratio for respective signal intensities.\\n\\nBennani-Baiti and colleagues found no alterations in T1 signals from the dentate nucleus and, thus, no correlation with the number of GBCA doses received (p > 0.05). There also was no correlation based a woman\\'s high-risk cancer status or her age (p > 0.05).\\n\\nIn addition, the researchers found no changes in or correlation between T1 signal intensity and the dentate nucleus-to-pons ratio and the number of GBCA doses (p > 0.05). Again, the lack of correlation was evident regardless of breast cancer risk or age (p > 0.05).\\n\\n\"That\\'s why we conclude that the dentate nucleus does not display T1 signals after high cumulative dosages of a macrocyclic GBCA in healthy women at 3-tesla MRI,\" Bennani-Baiti said. \"It also raises the question: Is contrast-enhanced breast MRI screening safe for women who are at high risk for breast cancer? Yes, in regard to potential GBCA-associated brain signal alterations at 3-tesla MRI.\"<|endoftext|>[Preparation of liposome encapsulated daunorbicine and determination of daunorubicine of aqueous humor in rabbit eyes].\\nTo investigate the method of determination the concentration of daunorubicine(DNR) and liposome encapsulated daunorubicine(LDNR) of aqueous humor in rabbit eyes. After extracapsular lens extraction, 0.1 ml of 1 mg/ml DNA and LDNR were injected into the anterior chamber. At the 12, 24, 48 hours and 1 week after operation, the aqueous humor were aspirated to determine the concentration of DNR by high performance liquid chromatography(HPLC). At the 12, 24, 48 hours after operation, DNR were determined in all eyes, but at one week after operation, the DNR could only be detected in LDNR group. The concentration of DNR in LDNR group were higher than DNR group.<|endoftext|>/*\\nCopyright 2017 The Kubernetes Authors.\\n\\nLicensed under the Apache License, Version 2.0 (the \"License\");\\nyou may not use this file except in compliance with the License.\\nYou may obtain a copy of the License at\\n\\n    http://www.apache.org/licenses/LICENSE-2.0\\n\\nUnless required by applicable law or agreed to in writing, software\\ndistributed under the License is distributed on an \"AS IS\" BASIS,\\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\nSee the License for the specific language governing permissions and\\nlimitations under the License.\\n*/\\n\\npackage v1beta2\\n\\nimport (\\n\\t\"fmt\"\\n\\n\\tapps \"k8s.io/api/apps/v1beta2\"\\n\\t\"k8s.io/api/core/v1\"\\n\\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\\n\\t\"k8s.io/apimachinery/pkg/labels\"\\n)\\n\\n// StatefulSetListerExpansion allows custom methods to be added to\\n// StatefulSetLister.\\ntype StatefulSetListerExpansion interface {\\n\\tGetPodStatefulSets(pod *v1.Pod) ([]*apps.StatefulSet, error)\\n}\\n\\n// StatefulSetNamespaceListerExpansion allows custom methods to be added to\\n// StatefulSetNamespaceLister.\\ntype StatefulSetNamespaceListerExpansion interface{}\\n\\n// GetPodStatefulSets returns a list of StatefulSets that potentially match a pod.\\n// Only the one specified in the Pod\\'s ControllerRef will actually manage it.\\n//', '<|endoftext|>hebung großer Netze geführt. Im November 2000 reichte die Europäische Gemeinschaft beim US-Bezirksgericht für den Östlichen Bezirk von New York eine Zivilklage gegen Philip Morris und Reynolds wegen angeblicher Beteiligung am Zigarettenschmuggel in die Europäische Union ein. Zehn Mitgliedstaaten schlossen sich im Zeitraum von Januar bis April 2001 der Klage an.\\nDie reinen Fakten, die im Rahmen der Plädoyers vor dem Gericht gegen Philip Morris vorgebracht wurden, zwangen den Tabakgiganten zur Unterzeichnung eines Vergleichs mit der Europäischen Kommission. Diese mehrjährige Vereinbarung wurde am 9.\\xa0Juli 2004 unterzeichnet und hat die wirkungsvolle Bekämpfung des Schmuggels und der Fälschung von Zigaretten zum Ziel. Gleichzeitig enden damit auch die Rechtsstreitigkeiten zwischen der EU und Philip Morris. Gemäß der Vereinbarung muss Philip Morris über einen Zeitraum von 12\\xa0Jahren enorme Summen – bis zu 1,5\\xa0Milliarden US-Dollar – auf ein von der Europäischen Kommission verwaltetes Bankkonto einzahlen. Mit dieser Vereinbarung wird ein neuer Weg in der Betrugsbekämpfung eingeschlagen. Dank des Übereinkommens bündeln Philip Morris und die europäischen Behörden nun ihre Anstrengungen und arbeiten enger zusammen. In absehbarer Zeit wird dieser innovative Ansatz wahrscheinlich zum Abschluss ähnlicher Vereinbarungen mit den anderen beiden großen Tabakproduzenten British American Tobacco und Japan Tobacco führen.\\nDas Europäische Parlament und der Rat bilden zusammen die Haushaltsbehörde der Europäischen Union. Als Parlamentsabgeordnete sind wir äußerst besorgt über die Art und Weise, wie die Kommission und die Mitgliedstaaten mit diesen unerwarteten, aber beträchtlichen Mehreinkünften umgehen werden. Nach Aussagen von hohen Beamten im Rat wird der Löwenanteil der Gelder von Philip Morris in die Geldsäckel der Mitgliedstaaten fließen. Offenbar gehen 10\\xa0% an die Kommission, während die zehn Mitgliedstaaten, die sich der Klage angeschlossen haben, 90\\xa0% erhalten. Können Rat und Kommission diesen Verteilungsschlüssel bestätigen?\\nIn diesem Zusammenhang sieht es wirklich so aus, als benähmen sich die Mitgliedstaaten wie habgierige Opportunisten und mittelmäßige Buchhalter. Meiner Ansicht nach werden bei der Aufteilung 10\\xa0% zu 90\\xa0% die Anstrengungen der Kommission und von Olaf verkannt, denn was wird mit den Geldern passieren? Eigentlich sollten sie in erster Linie für die Betrugsbekämpfung verwendet werden. Mir ist sehr wohl klar, dass das so genannte Earmarking, das heißt die Zweckbindung bestimmter Mittel für bestimmte Aktivitäten, von der Haushaltsbehörde nicht gern gesehen wird, aber meiner Meinung nach ist es nur recht und billig, wenn sich Rat und Kommission vor diesem Parlament politisch dazu verpflichten, einen beträchtlichen Teil der Gelder für die Bekämpfung von Betrug und Fälschung einzusetzen. Ist die Kommission bereit, einen Aktionsplan vorzulegen sowie einen Vorschlag für die Schaffung einer Haushaltslinie, um dieses Problem zu lösen? Verwendungsmöglichkeiten gäbe es viele, zum Beispiel für eine intensivere grenzüberschreitende Zusammenarbeit, eine größere Zahl von Computern an den Grenzen, zusätzliches und gut ausgebildetes Kontrollpersonal, die Verstärkung der Zolldienste, Investitionen in Ermittlung und Fahndung, eine effektivere Verfol', '<|endoftext|>en Pakistanis.\\nZigmantas Balčytis\\nschriftlich. - (LT) Ich habe für diesen Bericht gestimmt. Eingereicht nach der beispiellosen Flutkatastrophe, die im letzten Sommer einen großen Teil des pakistanischen Territoriums verwüstet hat, strebt der Kommissionsvorschlag an, die autonomen Handelspräferenzen betreffend 75 Warenlinien, die für Pakistan von Bedeutung sind (überwiegend Textilwaren und Bekleidung) in Form von Zollbefreiungen auf dieses Land auszuweiten, mit Ausnahme eines Erzeugnissen (Äthanol), für das ein Zollkontingent gelten würde.\\nSlavi Binev\\nschriftlich. - (BG) Ich unterstütze den Vorschlag für eine Verordnung des Europäischen Parlaments und des Rates zur Einführung autonomer Handelspräferenzen für Pakistan in vollem Umfang. Handelspräferenzen sind für Pakistan immens wichtig, da sie für eine nachhaltige Entwicklung in einem Land sorgen werden, das in letzter Zeit unter einer Reihe von Naturkatastrophen zu leiden hatte. Zusätzlich zum Abschluss der Vereinbarung mit Pakistan muss die Europäische Union eine wichtige Rolle dabei spielen, Indien von der Unterstützung der Vereinbarung im Rahmen der Welthandelsorganisation zu überzeugen.\\nMaria Da Graça Carvalho\\nIch begrüße die Hilfe, die Pakistan von der Europäischen Union als weltweit größter Geberorganisation im Bereich humanitäre Hilfe nach den Naturkatastrophen, die die Wirtschaft zerstört und die Bevölkerung des Landes dezimiert haben, erhält. Die Handelspolitik der EU als eine Form der humanitären Hilfe und der Entwicklungshilfe einzusetzen, ist jedoch ein großer Fehler.. Meiner Ansicht nach hätte die Kommission derartige Maßnahmen nie vorschlagen dürfen, ohne zunächst die wirtschaftlichen und sozialen Auswirkungen auf die verschiedenen Regionen der EU zu quantifizieren. Eine der schwerwiegendsten Folgen dieser Maßnahmen könnte in Portugal sein, wo die Textil- und Bekleidungsindustrie, die mit insgesamt 160 000 Stellen 11 % der Ausfuhren ausmacht, von einem subventionierten Wettbewerb vonseiten Pakistans schwer getroffen werden würde.\\nMarielle De Sarnez\\nNach den schweren Überschwemmungen, von denen Pakistan im Sommer 2010 heimgesucht wurde, wollte die Europäische Union Hilfe in Form von außerordentlichen Handelspräferenzen darbieten. Zwar ist die Absicht hinter dieser Initiative lobenswert, es bleibt jedoch fraglich, wie hilfreich sie in der Praxis sein wird, und wir müssen uns fragen, ob diese wirtschaftliche Hilfe tatsächlich das pakistanische Volk und insbesondere die Kleinproduzenten und Landwirte, die von den Überschwemmungen am stärksten betroffen waren, erreichen wird. Der auf Handel basierende Hilfsplan der Kommission muss ein spezielles Verfahren durchlaufen: Er muss die Genehmigung des Parlaments jedoch auch die der WTO erhalten, da diese Handelspräferenzen von den grundlegenden internationalen Handelsregelungen abweichen. Das Parlament hat der Kommission gerade grünes Licht für eine Fortsetzung der Gespräche mit der WTO gegeben, jedoch auf einer Einschränkung ihrer Dauer und ihres Umfangs bestanden. Man könnte jetzt die Frage stellen, ob die Wahl dieses langsamen, in die Länge gezogenen Hilfsverfahrens statt anderer schnellerer und wirksamerer Formen der Hilfe, die Pakistan bereits erreicht hätten, weise gewesen ist.\\nAnne Delvaux\\nIch habe für', \"<|endoftext|>gangen sind und zu dem viele Europaabgeordnete aus verschiedenen Fraktionen und Ländern einen Beitrag geleistet haben, nicht zu destabilisieren. So wurde beispielsweise eines der wichtigsten Konzepte, nämlich das der standardmäßigen Marktgröße, von der PSE-Fraktion beigesteuert.\\nIch bin der aufrichtigen Überzeugung, dass der durch unseren Ausschuss erzielte Kompromiss für alle Mitgliedstaaten von Vorteil sein wird. Viele Menschen in meinem Land würden sagen, dass der Kompromiss nicht weit genug geht und ihre Bedenken nicht vollständig ausräumt. Ich hätte Artikel 25 gern gestrichen, aber ich sehe ein, dass dies weder machbar noch angebracht ist, und ich räume ein, dass eine Forderung nach vorbörslicher Transparenz notwendig ist. Meiner Ansicht nach kommt dieser Kompromiss den nationalen Interessen von Luxemburg, Frankreich, Italien, dem Vereinigten Königreich und eigentlichen allen Mitgliedstaaten zugute. Ich glaube, er dient den Interessen der Verbraucher.\\nIch musste Zugeständnisse machen. Ich habe mich beträchtlich von meinem ursprünglichen Standpunkt entfernt, und ich möchte allen im Ausschuss und in diesem Haus, die ebenfalls Zugeständnisse gemacht haben, recht herzlich danken. Ich kann die Plenaränderungsanträge 145, 148, 151, 156 und 157 befürworten und bin gern bereit, auch die anderen Plenaränderungsanträge zu diskutieren.\\nWir haben im Ausschuss eine sehr ernsthafte Debatte über den Begriff 'nicht professionell' geführt. Eine ganze Reihe von Interessengruppen aus ganz Europa erklärte, sie könnten den Kompromiss akzeptieren, wenn 'nicht professionell' gestrichen wird. Das ist geschehen. Uns liegt nunmehr ein ausgewogener Kompromiss vor, der eine vorbörsliche Transparenz ermöglicht und sich gleichzeitig auf, wie Herr Bolkestein sagte, 'pragmatische Weise' einiger der praktischen Probleme des ursprünglichen Vorschlags annimmt.\\nDer ursprüngliche Artikel 25 hätte der Liquidität erheblichen Schaden zugefügt, doch die Liquidität ist für das Wohlergehen unserer Märkte und unserer Wirtschaft von entscheidender Bedeutung. Der Kompromiss nimmt sich dieser praktischen Probleme an und versucht, die Liquidität dadurch vor potenziellem Schaden zu bewahren, dass kleine Banken ausgenommen werden, man sich auf Betreiber einer systematischen Internalisierung konzentriert und das Gegenparteiausfallrisiko gesenkt wird. Dies ermöglicht ein 'Price Improvement': Ohne Price Improvement ist der Kompromiss nicht umsetzbar. Nur durch Price Improvement ist es möglich, Kleinanlegern die günstigen Preise anzubieten, die sie verdienen. Die Internalisierung ist nicht mehr wirtschaftlich, wenn jedem derselbe Preis angeboten werden muss. Weshalb sollten wir, die beauftragt sind, die europäischen Bürger zu vertreten, ein Gesetz erlassen, das Unternehmen daran hindert, ihren Kunden günstige Angebote zu machen?\\nIch komme abschließend zu den Änderungsanträgen des Ausschusses für Geschäfte, die nur die Ausführung betreffen. Diese Änderungsanträge müssen unbedingt angenommen werden. Der Vorschlag der Kommission muss abgeändert werden, denn andernfalls würde er diese Geschäftstätigkeit vom Markt verdrängen, weil sie nicht mehr wirtschaftlich wäre. Meiner Ansicht nach sollten Investoren auch weiterhin die Möglichkeit haben, selbst über ih\", '<|endoftext|> Randlage. Zunächst einmal ist die Landwirtschaft primär eine Industrie, die das Essen auf den Tisch bringt - ohne das wir alle sterben würden - aber diese Regionen würden ohne Landwirtschaft ebenfalls sterben, sowohl wirtschaftlich als auch durch eine vermutliche Abwanderung der Bevölkerung. Daher begrüße ich alle Vorschläge zu ihrer Unterstützung.\\nIch möchte mich denen anschließen, die ihre Besorgnis über die Mercosur-Vorschläge geäußert haben. Diese könnten den Regionen in äußerster Randlage - und eigentlich jeder Region - enorme Schäden zufügen.\\nMeiner Ansicht nach ist es an der Zeit, dass die Europäische Union stärker wird und fairer mit ihren eigenen Landwirten umgeht. Wir waren nie dazu bestimmt, die Polizisten für die Landwirte innerhalb der Union und die gute Fee für die Landwirte in der übrigen Welt zu sein. Das geschieht hier: Es gäbe weniger strenge Regeln, weniger Transparenz und weniger Nachweispflicht für Lebensmittel, die in die Europäische Union gelangen, als für Lebensmittel, die in ihr produziert werden, und das wäre unfair gegenüber den Regionen in äußerster Randlage sowie gegenüber allen Regionen.\\nDacian Cioloş\\nHerr Präsident, bitte entschuldigen Sie meine Verspätung, aber ich wollte unbedingt an dieser Aussprache teilnehmen, da es meine erste ist und es um die erste Entscheidung geht, die als gemeinsamer Beschluss im Bereich Landwirtschaft gefällt wird. Ich möchte nochmals Herrn Alves und alle Dienste des Parlaments begrüßen und ihnen für die äußerst kooperative und wirksame Art der Zusammenarbeit mit der Kommission und mit dem Rat zur Erreichung dieses Beschlusses danken.\\nWir wollten eine schnelle Entscheidung, damit die Maßnahmen, die dieser Bericht aufführt, in den betroffenen Regionen schnell umgesetzt werden können. Einige Entscheidungen werden sogar rückwirkend angewendet. Deshalb - und hiermit antworte ich auch Herrn Tirolien - haben wir keine anderen Änderungsanträge vorgelegt. Wie bei einigen anderen Vorschlägen hätten wir in der Tat weitere Rechtfertigungen und Analysen benötigt, um so die Art und Weise zu bestimmen, in der sie eingeführt werden sollten. Wir wollten schnell vorgehen und hatten diesbezüglich mehrere Diskussionen mit Herrn Alves. Daher freut mich die Unterstützung, die dieser Vorschlag genießt, und ich hoffe, dass wir zukünftig mit dem Parlament auch bei anderen Themen in dieser Form zusammenarbeiten werden. Ich bin mir sogar sicher, dass wir dies tun können werden.\\nAls Agrarkommissar kann ich zudem allen Rednern versichern, dass die Verhandlungen mit dem Mercosur mehrmals erwähnt wurden. Ich kann Ihnen versichern, wie ich es bereits während der Debatten innerhalb der Gremien der Kommission zur Wiedereröffnung dieser Verhandlungen getan habe, dass ich äußerst sorgfältig prüfen werde, dass diese Verhandlungen im Interesse der europäischen Landwirtschaft fortgeführt werden. Wir müssen diese Verhandlungen natürlich in einem umfassenderen Rahmen berücksichtigen und dürfen sie nicht auf die Landwirtschaft beschränken; ich kann Ihnen jedoch zusichern, dass ich in den kommenden Monaten und Jahren dieser Verhandlungen sicherstellen werde, dass das europäische Landwirtschaftsmodell, das auf Qualität, Vielfalt', '<|endoftext|> bei gewissen Kulturen bleiben bestimmte Trocken- oder Halbtrockengebiete, so viele Investitionen man auch tätigt und so viele Änderungen man in der Vermarktung vornimmt, stets das, was sie sind.\\nMan kann nicht glauben, daß sich das hier zur Diskussion stehende Problem mit den knappen verfügbaren Fonds in den Programmen für die Entwicklung der ländlichen Räume lösen ließe. Hier ist die Lösung für diese Gebiete nicht zu suchen, wie dies der Kommissar und die gesamte Kommission offensichtlich tun.\\nEs sieht andererseits auch nicht so aus, als könnte eine Verlängerung dieser Beihilfen bis zur Umsetzung der in der Entschließung vorgeschlagenen Maßnahmen Probleme bei den Verhandlungen in der Welthandelsorganisation verursachen. Das wäre nicht einmal der Fall, wenn definitive Maßnahmen beschlossen würden.\\nIn dem Sektor ist ein Überangebot vorhanden, und der Gemeinschaftsschutz ist minimal. Wenn die geforderten Summen nicht hoch sind, wenn keine Probleme mit Drittländern entstehen, wenn dies die einzige Form zur Erhaltung des Lebensniveaus bestimmter Gebiete ist, Herr Kommissar, dann müssen diese Beihilfen weiterhin gezahlt werden.\\n\\nEsteve\\nHerr Präsident! Nach den Ausführungen von Herrn Jové und Herrn Fischler halte ich es für das Beste, meinen Beitrag methodisch zu ändern und unmittelbar auf den Kern der Sache, wie ich es sehe, zu kommen.\\nDie Hauptbegründung der Kommission lautet, daß dies vor zehn Jahren so beschlossen wurde; das heißt, vor zehn Jahren existierten bestimmte Bedingungen, wir haben ein Programm aufgestellt, und das ist ausgelaufen. Nach meinem Dafürhalten ist es gerade die Änderung der Bedingungen, die sich in den zehn Jahren vollzogen hat, die die Position der Kommission schwächt. Deshalb wäre es wichtig, sich gegenüber einer Vereinbarung aufgeschlossen zu zeigen, die auf der Initiative einiger Abgeordneter des Ausschusses für Landwirtschaft und ländliche Entwicklung und jetzt auch des Plenums beruht.\\nMeiner Ansicht nach gibt es drei Veränderungen. Zum ersten haben sich die Wettbewerbsbedingungen gewandelt, sie sind anders als vor zehn Jahren. Zum zweiten besteht nach Einschätzung des Agrarsektors, und ganz besonders durch ihn, ein wesentlich höheres Verantwortungsgefühl für die Umwelt als vor zehn Jahren. Es geht um einen Wirtschaftssektor, einverstanden, aber das Umweltbewußtsein ist viel stärker ausgeprägt als noch vor zehn Jahren. Und zum dritten wird, wenn diese Beihilfen jetzt gestrichen werden, der Verlust des in diesen zehn Jahren gewonnenen Terrains unumkehrbar sein.\\nDeshalb glaube ich, offen gesagt, daß es keinen Spielraum gibt, weder im Rahmen der ländlichen Entwicklung woanders, denn wir sprechen nicht über Gemüse oder andere Erzeugnisse, sondern über ein ganz spezifisches Produkt mit ganz spezifischen Bedingungen, die vor zehn Jahren analysiert wurden und die heute von neuem geprüft werden müssen.\\nAus diesem Grund halte ich es für absolut sinnvoll, einen neuen Beihilferahmen zu prüfen und bis dahin in jedem Fall und umgehend eine Verlängerung vorzusehen.\\n\\nMartinez\\nHerr Präsident, Herr Fischler, werte Kolleginnen und Kollegen! Wir sind nicht viele, nur die kleine mediterrane Familie, die versucht, die', '<|endoftext|> abzielt, die Entwicklung neuer Technologien mit einem höheren Potential für geringere Kohlenstoffemissionen durch eine höhere Energieeffizienz und die Nutzung erneuerbarer Energien zu beschleunigen, bedauere ich, dass die Europäischen Regionen immer noch keine genauer definierte Rolle in diese Strategie haben.\\nEs ist notwendig, regionalen Behörden eine korrekte Finanzierung zu garantieren, beispielsweise durch die Gewährleistung einer Finanzierung während der Testphase von Pilotprojekten, oder durch Investitionen während der Forschungs- und Testphase erneuerbarer Energieprojekte.\\nMeiner Ansicht nach ist es wichtig, beispielsweise geothermische Energie mit einzubeziehen. Hierbei handelt es sich um eine erneuerbare Energiequelle mit großem Erweiterungspotenzial in Vulkangebieten, die insbesondere für entlegene und Inselregionen der Union von Bedeutung ist, für die keine Ziele gesteckt wurden.\\nIn diesem Kontext müssen öffentliche und private Investitionen durch die Entwicklung von Energietechnologien erhöht werden, damit die gewünschten Ziele einer kohlenstoffemissionsarmen Wirtschaft erreicht und das im Klima- und Energiepaket erwähnte Marktversagen überwunden werden kann.\\nAndrás Gyürk\\n, schriftlich. - (HU) Meiner Ansicht nach ist es von Bedeutung, dass die Europäische Kommission bei der Erstellung ihres Strategieplans für Energietechnologie den Umfang der für die Forschung und Entwicklung von grünen Technologien benötigten Hilfe in Betracht gezogen hat. Dies ist umso wichtiger, da gegenwärtig Solarenergie, Bioenergie und Wasserstofftechnologie in den meisten Fällen noch nicht kommerziell profitabel sind. Wie Steven Chu, der US-Minister für Energie, zu Recht festgestellt hat, sind in der Forschung Fortschritte in der Größenordnung eines Nobelpreises erforderlich, damit grüne Technologien mit den herkömmlichen Technologien der fossilen Brennstoffe konkurrieren können. Ein schwerer Mangel des grünen Technologieplans besteht jedoch darin, dass wir nicht wissen, welche EU-Mittel zu seiner Durchführung verwendet werden. Wenn wir die Kosten in Höhe von 16 Milliarden EUR betrachten, die für die Solarenergieforschung als notwendig erachtet werden, oder die geschätzten 5 Milliarden EUR für wasserstoffbezogene Technologien, so handelt es sich hierbei um keine geringfügige Entscheidung. Gegenwärtig gibt es keine Hinweise darauf, dass der Finanzrahmen für die nächsten sieben Jahre mehr Gelder für die Forschung im Bereich der grünen Technologien zur Verfügung stellen wird. Wir sind uns darüber im Klaren, dass Unterstützung aus öffentlichen Mitteln kein Ersatz für die Bemühungen privater Investoren ist. Dennoch müssen die Europäische Union und ihre Mitgliedstaaten die Finanzmittel für die grüne Technologieforschung erhöhen. Die möglichen Einnahmen aus einem Emissionshandelssystem könnten dafür eine gute Basis darstellen. Die Einsätze sind nicht unbedeutend. Wir können nicht zulassen, dass die Pläne für die Energiepolitik und den Klimaschutz das gleiche Schicksal erleiden wie die Strategie von Lissabon mit ihren widersprüchlichen Ergebnissen.\\nJim Higgins  \\nschriftlich. - Um kohlenstoffemissionsarme Technologie zu einer praktischen Realität werden zu lassen, müssen wir den Mangel an Ingenieuren und anderem hochqualifizierten Personal beheben, das fortschrittliche Techn', '<|endoftext|>. Die Tatsache, dass der Bericht Hilfen pro Hektar fordert, ist positiv zu sehen. Das wird einer weiteren Intensivierung der Landwirtschaft entgegenwirken und gibt der Erreichung der Umweltziele eine realistischere Perspektive. So können wir unsere Landwirte belohnen.\\nJaroslav Paška\\n(SK) Wir wissen alle, dass die Gemeinsame Agrarpolitik der Europäischen Union ein sehr komplexes und sensibles Thema ist. Die fortdauernde Anwendung des sogenannten historischen Prinzips in Bezug auf Beihilfe für die Landwirtschaft - selbst nach der Erweiterung der EU - hat zu einem beträchtlichen Missverhältnis in der europäischen Wirtschaftspolitik geführt.\\nDaher ist es notwendig, so schnell wie möglich objektiv gerechte Kriterien in das Verteilungssystem der finanziellen Unterstützung für Landwirte einzuführen, da dies die richtigen Bedingungen für einen ordentlichen wirtschaftlichen Wettbewerb zwischen den Landwirten auf dem europäischen Binnenmarkt schaffen wird.\\nDie Gelder müssen ordnungsgemäß und ausgewogen verteilt werden, sodass die Landwirte in allen Ländern der EU das Recht auf ein gleiches Maß an Hilfen haben und gerecht miteinander konkurrieren können.\\nMeiner Ansicht nach sollten wir daher den Änderungsantrag Nummer 6 des eingereichten Berichts unterstützen, der helfen wird, dem Unterstützungsmechanismus für die europäische Agrarproduktion Gerechtigkeit zu verleihen.\\nAngelika Werthmann\\nHerr Präsident, sehr geehrte Kolleginnen und Kollegen! Die Agrarpolitik braucht einen kohärenten Rahmen. Dieser muss die gesamte EU stärken, aber sehr wohl die regionalen Unterschiede berücksichtigen. Gerade für mein Heimatland Österreich ist die zweite Säule besonders wichtig, wenn man dabei an spezifische Umwelt- und Investitionsprogramme denkt.\\nDie Agrarpolitik steht vor großen Herausforderungen. Die Weltbevölkerung wird Schätzungen zufolge auf 9 Milliarden Menschen ansteigen, und gleichzeitig werden wir mit den Auswirkungen des Klimawandels wie Wasserknappheit und Dürre konfrontiert. Um diese Probleme zu lösen, ist es notwendig, dass die EU nicht nur intern besser zusammenarbeitet, sondern weltweit kohärent agiert.\\nSeán Kelly\\nHerr Präsident! Aus landwirtschaftlicher Sicht war die heutige Diskussion von allen Seiten des Hauses her ermutigend. Ich begrüße besonders, dass auf die Ermutigung junger Leute zur Landwirtschaft ein Schwerpunkt gelegt wurde, was absolut wichtig ist; dass es keine Renationalisierung der GAP geben sollte; dass der Kommissar sagte, die beiden Säulen sollten erhalten bleiben, weil ohne die erste Säule auch die zweite Säule nicht nötig ist, da es unrentabel wäre, Landwirtschaft zu betreiben, und öffentliche Güter daher nicht garantiert würden; und, wie Frau Dodd sagte, müssen wir uns überlegen, was wir mit \"gerecht\" meinen, und dabei besonders die variierenden Kosten und die Kaufkraft in der ganzen Union berücksichtigen.\\nUnd nur Herr Lyon bezog sich auf die historische Grundlage. Ich glaube, es ist im Moment für die Landwirte sehr wichtig, dass wir ihnen ein deutliches Zeichen geben, was wahrscheinlich passieren wird, sodass man sie nicht wilden Spekulationen überlässt, und sie nicht wissen, ob sie die Bestände auf der Grundlage des historischen Modells kaufen oder verkaufen sollen. Ich', '<|endoftext|> Thema immer wieder angesprochen hat. Wir freuen uns sehr, dass Kommissar Monti in diesem Bereich Fortschritte erzielen konnte. Doch die Entwicklung des Anzeigers ist noch nicht abgeschlossen. Ich bin mir nicht ganz sicher, ob sich die GD Wettbewerb an vorderster Front befindet, was die Benutzerfreundlichkeit ihrer eigenen Website betrifft. Sicherlich wird es hier noch Verbesserungen geben. Vor einigen Tagen wollte ich mich im Internet über den bevorstehenden Wettbewerbstag informieren. Diese Website war nicht besonders übersichtlich.\\nIch möchte noch den Stahlbeihilfenkodex ansprechen. Wiederholt habe ich Kommissar Monti darauf hingewiesen, dass die Industrie hier Orientierungshilfen benötigt. Unserer Ansicht nach muss die derzeitige Regelung in einer bestimmten Form bestehen bleiben. Meine Hoffnung besteht darin, dass Kommissar Monti nach reiflichen Überlegungen zu dem Schluss kommen wird, dass er dieses Anliegen angesichts der Schwierigkeiten mit den USA unterstützen kann.\\n\\nRiis-Jørgensen\\nFrau Präsidentin, wie Herr Rapkay sagte, können wir wie gewohnt miteinander reden, jetzt, da \"die Familie unter sich \" ist. Zunächst möchte ich mich noch einmal bei Herrn Monti für seinen großartigen Einsatz in diesem Bereich bedanken, und auch bei Herrn Rapkay möchte ich mich vielmals bedanken. Wir sind nicht immer einer Meinung, aber ich bin mit dem Bericht sehr zufrieden, auch wenn wir über einige Dinge im Hinblick auf die morgige Abstimmung noch einmal diskutieren müssen.\\nIch möchte noch zu einigen konkreten Punkten etwas sagen. Zunächst zu einer Sache, mit der ich mich persönlich schon oft befasst habe, nämlich zum Vorschlag der Kommission eines Pakets für Schiffswerften. Im letzten Herbst wurde in diesem Parlament darüber diskutiert. Ich habe die vorgeschlagenen Beihilfen für Schiffswerften strikt abgelehnt und möchte deshalb die Kommission fragen, wie es in dieser Angelegenheit weitergeht. Es hat mich gefreut, dass bei der Ratskonferenz der Industrieminister Anfang Dezember nicht die notwendige Mehrheit für die Annahme des Kommissionsentwurfs zustande kam. Die Kommission war nicht sofort zur Abänderung ihres Vorschlags bereit, der auf den Ergebnissen des so genannten TBR-Berichts aufbaut, der von der Kommission halbjährlich erstellt wird. Ich bin natürlich besorgt, dass aus dem nächsten TBR-Bericht passend hervorgehen wird, dass mehr Schiffstypen unterstützt werden müssen, als im ursprünglichen Vorschlag der Kommission genannt worden sind. Ich bitte daher Kommissar Monti, folgende Frage zu beantworten: Wird derzeit ein neuer TBR-Bericht von der Kommission ausgearbeitet und, falls ja, kann der Kommissar darüber Auskunft geben, welche Schlüsse in dem Bericht gezogen werden.\\nMorgen werden wir im Parlament über einen Entwurf abstimmen, über den wir aus zeitlichen Gründen vor der Abstimmung nicht mehr diskutieren können. Das Thema dieses Entwurfs gehört zwar nicht in Ihren Zuständigkeitsbereich, Herr Monti, denn es geht darum, dass den Fluggesellschaften außerplanmäßig das Recht zugestanden wurde, Ankunft- und Abflugzeiten in den Flughäfen behalten zu dürfen, wozu sie aufgrund der normalen Vorschriften nicht berechtigt wären, weil sie diese Zeiten nicht ausreichend wahrgenommen haben. Wir erstellen also ein Sondergesetz, das jetzt', '<|endoftext|> Afghanistan äußern, wobei ich die humanitären Fragen, die von so großer Dringlichkeit sind, Herrn Nielson überlassen werde. Danach möchte ich noch kurz auf einen Verordnungsentwurf eingehen, den die Kommission heute angenommen hat.\\nMit der Troikareise verfolgten wir drei große Ziele. Erstens ging es uns vor allem darum, den von uns besuchten islamischen Ländern deutlich zu machen, dass die Kampagne gegen den Terrorismus keine Kampagne des Westens gegen den Islam ist. Sie ist keine Kampagne, die Europa und die USA gegen die ärmeren Länder der Welt führen. Vielmehr geht es um den Kampf anständiger Regierungen gegen all jene, die versuchen, ihre politische Ziele mit Mord und Chaos durchzusetzen. Das ist meines Erachtens ein Kampf zwischen all jenen, die sich für die Werte der Zivilisation auf der Grundlage verschiedener Religionen einsetzen, und jenen, die die Werte der Zivilisation schon immer bekämpft haben. Diesen Standpunkt haben wir in jedem von uns besuchten Land konsequent vertreten.\\nWenn wir weltweit darauf bestehen, dass Menschenrechte, einschließlich des Rechtes, nicht von Terroristen umgebracht zu werden, universelle Gültigkeit besitzen, dann müssen wir, wenn wir diesen Standpunkt weltweit erfolgreich vertreten wollen, meiner Ansicht nach darauf achten, dass wir nicht den Eindruck erwecken, als hätten wir diese Werte für uns allein gepachtet, als seien wir Europäer in dieser Hinsicht ohne Fehl und Tadel. Ganz besonders wichtig ist auch anzuerkennen, dass die Bedeutung der Menschenrechte nicht von dem Kontinent abhängt, auf dem man sich befindet. Folter ist Folter, egal in welchem Land. Wenn man als Journalist oder Herausgeber eingesperrt wird, weil man anderer Meinung ist als die Regierung, dann spielt das Land keine Rolle. Diese Rechte gelten weltweit. Meiner Ansicht nach schaden wir der Integrität unserer Argumente, wenn wir den Eindruck erwecken, als würden unterschiedliche Kulturen im Hinblick auf die Menschenrechte grundverschiedene Standpunkte vertreten.\\nZweitens wollten wir mit unseren Besuchen die Hoffnung vermitteln, dass die schrecklichen Ereignisse des 11. September Ausgangspunkt für eine positive Entwicklung sein können. Aus dem Unglück erwächst bisweilen die Möglichkeit für einen konstruktiven, positiven Neuanfang, für den Aufbau einer besseren Zukunft. So haben wir in Pakistan, im Iran und andernorts zum Ausdruck gebracht, dass wir jetzt - unter Berücksichtigung dieser entsetzlichen Ereignisse - die Chance haben, einige Türen und Fenster zu öffnen, die schon allzu lange verschlossen waren.\\nDrittens betrachten wir es zwar als Klischee, als Gemeinplatz, wenn behauptet wird, dass seit dem 11. September - so wie damals beim Fall der Berliner Mauer - nichts mehr so ist wie es einmal war, aber es stimmt tatsächlich. Es wird wirklich nichts mehr sein, wie es einmal war. Dazu können wir selbst einen Beitrag leisten, indem wir versuchen, dafür zu sorgen, dass nach den jüngsten schrecklichen Ereignissen der Multilateralismus, die internationale Zusammenarbeit, wesentlich effektiver funktioniert als sie seit 1940 je funktioniert hat. Dabei besteht die Hauptaufgabe darin, dafür Sorge zu tragen, dass in der UNO diskutierte Konventionen gegen Terrorismus von allen unterzeichnet und von allen umgesetzt werden. Das ist die Art von praktischen Herausforderungen, denen wir uns wochen-, monate- und jahrelang', '<|endoftext|>ines Erachtens nicht unbedingt in ihrem oder auch im Interesse der Mitgliedstaaten, diese Frist zu erreichen, ohne vorher einen ordnungsgemäßen Übergang mit minimalen Auswirkungen auf die Volkswirtschaften der bisherigen Mitgliedstaaten zu gewährleisten.\\nWir dürfen nicht vergessen, dass unser Hauptziel darin besteht, eine wirtschaftliche und soziale Situation zu schaffen, von der ausgehend die EU einer der Hauptakteure im Welthandel werden kann und die Länder Ost- und Mitteleuropas uneingeschränkt daran beteiligt sind und von einer ruhigen und stabilen europäischen Wirtschaft profitieren. In der Vergangenheit haben wir unter Beweis gestellt, dass dieses Ziel möglich ist, und als Bürger eines Mitgliedstaats, der von einem planmäßigen Übergang zur Mitgliedschaft profitiert hat, sehe ich einem erweiterten und friedlichen Europa mit großen Erwartungen entgegen.\\nJedoch kann durch die Erweiterung der Europäischen Union der Einfluss kleinerer Mitgliedstaaten mit wichtigen nationalen Interessen, die es zu schützen gilt, nicht geschwächt oder geschmälert werden. Aus irischer Sicht ist klar, dass wir unser Recht auf Ernennung eines Mitglieds der Europäischen Kommission, das die Kontrolle der Verwaltung der Gemeinsamen Agrar-, Fischerei, Verkehrspolitik oder anderer wichtiger EU-Politikbereiche übernimmt, nicht aufgeben wollen. Zudem müssen wir meiner Ansicht nach unbedingt die Kontrolle über Entscheidungen wahren, die unsere Steuer- und Sozialschutzpolitik betreffen.\\n\\nElles\\nHerr Präsident, ich wende mich an den Kommissionspräsidenten und den Ratspräsidenten auf Französisch, damit ich so gut wie möglich verstanden werde.\\nIch möchte nämlich in meinem Redebeitrag auf eine von meiner Arbeitsgruppe in unserer PPE-DE-Fraktion entwickelte Idee und nicht auf die Probleme meiner als \"konservativ \" bekannten Delegation eingehen. Wir haben beträchtliche Vorbehalte in zahlreichen Fragen, insbesondere zur Grundrechtecharta, und zwar aus mehreren Gründen. Darüber werde ich nicht sprechen, dies wird ein anderer Redner tun. Bei der erwähnten Idee geht es darum, sich auf das zu konzentrieren, was nach Nizza geschieht.\\nAus der Rede, die Präsident Chirac hier im Juli gehalten hat, wissen wir, dass sich zumindest drei große Themen abzeichnen, d. h. die Vereinfachung der Verträge, die Kompetenzabgrenzung zwischen europäischer, nationaler und regionaler Ebene, was ich nach einem amerikanischen Begriff - Nachtrag 10 der Verfassung der USA - als Rechte der Staaten bezeichnen möchte, und drittens das Gleichgewicht zwischen den Institutionen. Doch dabei muss man vielleicht vor allem die Rolle der nationalen Parlamente betrachten, d. h. wie unsere Institution künftig zu gestalten ist. Zu dieser Frage der Governance erwarten wir von der Kommission einen Bericht.\\nWäre es nicht angebracht, unsere Völker zu konsultieren, ehe wir weiter nach vorn schreiten, und sie einzubeziehen in das, was wir tun, anstatt sie auf ein Ergebnis warten zu lassen, über das sie sich dann in einem Referendum äußern sollen, während sie nicht wissen, wie es dazu kam? Ich stelle damit meine dritte Frage: Wie geht man an dieses Thema heran, welchen Zeitplan gibt es dafür, welches Verfahren soll angewendet werden, und welche Mitwirkungsmöglichkeiten wird es dabei geben', '<|endoftext|>ern kann, aber wir müssen sie auch daran erinnern, dass nicht mehr viel Zeit bleibt und es im Falle des Güterverkehrs, offen gestanden, schon fünf vor zwölf ist.\\nIch habe mich im Auftrag meiner Fraktion intensiver mit dem Bericht von Herrn Sterckx zur Eisenbahnsicherheit als mit den anderen Berichten beschäftigt. Unserer Ansicht nach müssen Vertreter des Sektors in sämtliche Maßnahmen im Bereich der Sicherheit einbezogen werden. In diesem Punkt unterscheiden wir uns von der PPE-DE-Fraktion. Unser Hauptziel besteht in der Erhöhung der Sicherheit bei gleichzeitiger umfassender Integration unseres europäischen Eisenbahnsystems. Wir müssen uns von den von mir erwähnten 15 verschiedenen Systemen lösen. Wir müssen jedoch das Mitspracherecht der Mitgliedstaaten gewährleisten und dafür Sorge tragen, dass höhere Standards in jedem Falle aufrechterhalten werden. Eine Verwässerung von Sicherheitsstandards kommt nicht in Betracht. Deshalb hat unsere Fraktion eine Reihe von Änderungsanträgen zum Bericht von Herrn Sterckx eingereicht.\\nWir alle unterstützen die Eisenbahn; einige von uns mit solcher Begeisterung, dass wir von unseren Kollegen oft belächelt werden. Ich hoffe, dass die Vorschläge der Kommission und die Reaktion des Parlaments von den Vertretern der Eisenbahnindustrie als ein aufrichtiger Versuch zur Sicherung der Zukunft des Schienenverkehrs verstanden werden. Zur Erreichung dieses Ziels bedarf es der Zusammenarbeit von Politikern, Regierungen, der Kommission und vor allem aller Seiten der Eisenbahnindustrie.\\n\\nPohjamo (ELDR).\\nHerr Präsident, Frau de Palacio, liebe Kolleginnen und Kollegen! Gestatten Sie mir zunächst, mich im Namen meiner Fraktion bei allen Berichterstattern zu bedanken, die an dem Eisenbahnpaket mitgewirkt haben. Sie haben eine wirklich gute Arbeit geleistet.\\nDie Entwicklung der Eisenbahnen ist trotz allem viel zu spät in Gang gekommen. Jetzt stellen solche Bereiche wie die Förderung des Wettbewerbs, sowohl im Güter- als auch im Personenverkehr, die Erweiterung der Interoperabilität und die Verbesserung der Sicherheit gewaltige Herausforderungen dar, die wirklich ein schnelles Handeln erfordern. Die Wettbewerbsfähigkeit der Eisenbahnen ist dramatisch zurückgegangen. Transporte wurden auf verstopfte Straßen und in Flugzeuge verlagert, weil es die Bahnen nicht geschafft haben, ihre Dienstleistungen schnell genug zu verbessern.\\nMit dem vorliegenden Eisenbahnpaket wird es uns gelingen, die Wettbewerbsfähigkeit der europäischen Eisenbahnen zu fördern, und eine verbesserte Wettbewerbsfähigkeit eröffnet den Unternehmen wie auch den Menschen die Möglichkeit, ein umweltfreundlicheres Transportmittel zu nutzen. Gleichzeitig können damit Staus abgebaut und Kurzstreckenflüge durch Eisenbahntransporte ersetzt werden, was zu einem besseren Gleichgewicht zwischen den verschiedenen Verkehrsträgern führen wird. Die Entwicklung der Eisenbahnen eröffnet neue Möglichkeiten, in stärkerem Maße auch intermodale Formen des Verkehrs zu nutzen, da wir uns gleichzeitig Gedanken über die Verbesserung der Interoperabilität von Häfen und Eisenbahnen machen.\\nAls Schattenberichterstatter habe ich die Arbeit von Herrn Savary bei der Ausarbeitung des Berichts sehr genau verfolgt. Auch Herr Savary hat eine', '<|endoftext|> hat, könnte sich natürlich mit der Feststellung zufriedengeben - einmal ist keinmal -, daß nationales Recht in so einem Fall in die Bresche springen sollte. Aber muß man eine derart heuchlerische Formulierung nicht verurteilen, hinter der sich im Grunde nur ein erstaunlicher Mangel an Mut verbirgt? Ob man nun das schreibt oder gar nichts, läuft eigentlich aufs gleiche hinaus. In diesem besonderen Fall hätte unsere Regelung mühelos über die in jedem unserer Mitgliedstaaten vorgesehenen Bestimmungen hinausgehen können.\\nWie ganz richtig auf Seite 19 des Anhangs zum zweiten Nordmann-Bericht steht, sind die in den Mitgliedstaaten getroffenen Bestimmungen doch dazu gedacht, die Entwicklung der Vermögenslage von Parlamentariern über den Zeitraum hin verfolgen zu können, wo sie das Amt, für das sie gewählt wurden, antreten, und dem Zeitpunkt, wo es abgelaufen ist, um sicherzustellen, daß die ihnen übertragenen Funktionen nicht im Verlauf ihres Mandats zu einer unangemessenen Bereicherung führen.\\nVon diesem Gedanken sollten wir uns leiten lassen. Er war das Leitmotiv des ersten Nordmann-Berichts und hat auch die Arbeitsgruppe inspiriert.\\nHerr Präsident, wir geben häufig beschwichtigende Erklärungen ab, und schreiten nur selten zur Tat. Das jedoch ist die Aufgabe, die uns in dieser neuen Debatte über die finanziellen Interessen gestellt wird. Der NordmannBericht ist in seiner derzeitigen Konsens-Fassung dieser Aufgabe nicht gewachsen. Aber unsere Fraktion ist bereit, sie in Angriff zu nehmen.\\n\\nVecchi\\nHerr Präsident, die Änderungen der Geschäftsordnung des Europäischen Parlaments, die von den beiden heute zur Debatte stehenden Berichten vorgeschlagen werden, zielen im wesentlichen darauf ab, sowohl hinsichtlich der Tätigkeit der Abgeordneten als auch bezüglich der Aktivitäten der Interessenvertreter und Assistenten die notwendige Transparenz zu gewährleisten.\\nDie Abgeordneten werden im wesentlichen verpflichtet -andere Kollegen haben dies bereits erwähnt-, jede finanzielle Unterstützung im Rahmen ihrer politischen Tätigkeit anzugeben und Geschenke zurückzuweisen, die ihr Handeln und ihre Position als Parlamentarier beeinflussen sollen. Für die sogenannten Lobbyisten wird die Bestimmung eingeführt, daß sie sich in ein spezielles Register eintragen, gewisse Verhaltensregeln beachten und einen Ausweis mit sich führen müssen, den sie in sämtlichen Parlamentsgebäuden sichtbar zu tragen haben.\\nUm dieses Thema geht es hier, und es stellen sich dabei zwei Fragen. Erstens: sind diese neuen Bestimmungen positiv oder nicht? Zweitens: sind sie ausreichend oder nicht? Meine Antwort auf die erste Frage lautet eindeutig \"ja\" . Trotz aller Schwierigkeiten, die sich aus dem Nebeneinanderbestehen verschiedener in den Mitgliedsstaaten existierender straf- und steuerrechtlicher Bestimmungen ergeben, wagt das Europäische Parlament hier einen Vorstoß und legt Regeln für mehr Transparenz und Moral fest, wie z.B. das Verbot, Geschenke anzunehmen, die das Vertrauen der Bürger in ihre gewählten Vertreter erhöhen sollen. Unserer Ansicht nach sind diese neuen Bestimmungen jedoch nicht ausreichend, sondern können nur als ersten Schritt zu einer umfassenderen und kohärenteren Regelung in diesem Bereich angesehen werden. Wir w', \"<|endoftext|>\\n\\nTamino\\nFrau Präsidentin, ich möchte mich meinen Kolleginnen und Kollegen anschließen und die Empörung der Fraktion Die Grünen über ein Urteil zum Ausdruck bringen, das nicht nur eine Beleidigung für die Menschen darstellt, die in den Tod gerissen wurden, sondern auch eine absolut unhaltbare Situation verdeutlicht. Ich möchte darüber hinaus Verständnis für die Reaktion der im Gebiet vom Monte Cermis lebenden Bevölkerung und der Angehörigen der Opfer bekunden. Dies erscheint mir geboten, ebenso wie mir eine Entschädigung der Angehörigen der Opfer geboten scheint, wenngleich keine Entschädigung der Welt die Toten ins Leben zurückbringen wird. All dies vorausgeschickt, halte ich es für berechtigt, daß wir uns fragen, wieso nahezu 50 Jahre nach dem Memorandum von London derartige Vorfälle überhaupt noch möglich sind.\\nIch möchte in Erinnerung bringen, daß ich bereits am 19. Februar letzten Jahres, als wir in diesem Hause über die Tragödie am Monte Cermis diskutierten, einen Entschließungsantrag einbrachte, indem ich eine Revision der durch das Memorandum von London gegebenen Situation forderte. Meiner Ansicht nach müssen wir nicht nur die Wiederaufnahme der Untersuchung und die Klärung der Frage nach möglichen Verantwortlichkeiten auf höherer Ebene verlangen, sondern uns auch fragen, ob die NATO-Stützpunkte aufrechterhalten werden müssen, als ob wir Kolonien wären, oder ob wir nicht vielmehr reagieren müssen, ob wir nicht die Änderung der gegenwärtigen Vorschriften fordern und schließlich der nationalen Rechtsprechung die Möglichkeit geben müssen, über diese Verbrechen zu richten.\\n\\nDell'Alba\\nFrau Präsidentin, der Zwischenfall am Monte Cermis ist zweifellos ein tragisches Ereignis, und der Eindruck, den man in Italien und in den übrigen Ländern Europas angesichts der Vorgänge im amerikanischen Justizwesen gewann, hat sicher bei allen einen bitteren Nachgeschmack hinterlassen: in erster Linie natürlich bei den Angehörigen der Opfer, aber auch bei all denen, die im Atlantischen Bündnis das sehen, was wir stets darin gesehen haben, nämlich eine Allianz, die 50 Jahre lang die Sicherheit unserer Länder garantiert hat.\\nIch halte es für richtig, daß wir als Europäisches Parlament, nachdem sich gestern das italienische Parlament bereits geäußert hat, darüber sprechen und dafür Sorge tragen, daß über diesen Fall wirklich gerichtet wird, bei dem noch so vieles - unter anderem auch geschützt durch die Vorschriften des Vertrages von 1951 - im Dunkeln liegt. Jedoch halte ich es weder für richtig noch für nutzbringend für uns Europäer, allein aufgrund dieser Vorfälle etwas in Frage zu stellen, was an anderer Stelle hätte diskutiert werden können. Eine solche Verquickung erscheint mir jedenfalls als gefährlich.\\n\\nVanhecke\\nFrau Präsidentin! Jeder in diesem Parlament kann sich wohl das Leid der Familienangehörigen der Opfer von Cavalese vorstellen und wird sich über alle politischen Meinungsverschiedenheiten hinweg der Empörung anschließen, die diese Menschen empfinden, wenn jetzt ein Jahr nach der Katastrophe der verantwortliche Pilot von einem amerikanischen Militärgericht ohne weiteres freigesprochen wird. Wir Politiker dürfen uns jedoch meines Erachtens nicht auf ziemlich unverbindliche Worte der moralischen Unterstützung oder der Kritik an dem Londoner Übe\", '<|endoftext|> Jarzembowski, der eine großartige Arbeit vollbracht hat.\\nMeine Damen und Herren, das Weißbuch über die europäische Verkehrspolitik vermittelt ein alarmierendes Bild von der Entwicklung des Schienengüterverkehrs. In den letzten zwanzig Jahren ist der Anteil dieses Segments - am gesamten Güterverkehr der Union - um die Hälfte, von 15 % im Jahre 1980 auf 8 % im Jahre 1999, zurückgegangen. In diesem Zeitraum verzeichnete die Qualität der Dienstleistungen für die Kunden keinerlei Verbesserungen, in einigen Staaten verschlechterte sie sich sogar. Es handelt sich also um ein äußerst dringliches Thema. Meiner Ansicht nach darf nicht bis 2008 gewartet werden, um den internationalen Frachtverkehr im gesamten europäischen Netz für den Wettbewerb zu öffnen.\\nAuch mit dem nationalen Verkehr müssen wir uns befassen. Daher werden gewisse Änderungen vorgeschlagen, die den in der Richtlinie 2001/12/EG vorgesehenen Zeitplan und die Modalitäten der Öffnung ersetzen, so dass ohne weiteren Verzug mit der Öffnung des gesamten Netzes für den nationalen und internationalen Frachtverkehr begonnen werden kann. In der Praxis würde diese totale Öffnung der Zugangsrechte im Rahmen des Frachtverkehrs bis 2006 wirksam werden, was ein Vorziehen dieser Öffnung des Gesamtnetzes um zwei Jahre bedeuten würde.\\nDer zweite Richtlinienvorschlag bezieht sich, wie kann es anders sein, auf die Eisenbahnsicherheit. Ich glaube, die Frage der Sicherheit im Verkehr ist ein Thema, das uns allen am Herzen liegt und uns alle bedrückt, ganz besonders zu diesem Zeitpunkt. Ich möchte auch Herrn Sterckx meinen Dank für seine Arbeit aussprechen.\\nWir müssen gewährleisten, dass die Integration des europäischen Eisenbahnnetzes nicht zu einem Absinken des maximalen Sicherheitsstandards in den verschiedenen Mitgliedstaaten der Union führt. Gleichzeitig jedoch müssen wir garantieren, dass durch die Errichtung von gemeinsamen Sicherheitsvorschriften jegliche Möglichkeit ausgeschlossen wird, dass im Ergebnis der Sicherheitsfragen der Markt Schaden erleiden und beim Zugang zu den Netzen eine diskriminierende Behandlung erfolgen kann. Die Errichtung eines Binnenmarkts für den Güterverkehr wäre ohne die Festlegung gemeinsamer Sicherheitsvorschriften nicht möglich.\\nFerner verändern die Öffnung der Märkte und das Ende der Monopole ganz wesentlich einen so wichtigen Faktor wie das System der Verantwortlichkeiten im Sicherheitsbereich, und deshalb ist die Schaffung eines klaren, transparenten und kohärenten Rahmens notwendig, der keinen Zweifel auf diesem Gebiet offen lässt.\\nDie Sicherheitsrichtlinie konzentriert sich auf vier Bereiche: Einsetzung nationaler Sicherheitsbehörden, getrennt von den Betreibern, mit klar abgesteckten Verantwortungsgebieten; Definition der Hauptelemente der Sicherheitssysteme gegenüber dem Infrastrukturbetreiber und den Eisenbahnunternehmen und Einrichtung eines Mechanismus zur Definition und Verabschiedung gemeinsamer Sicherheitsziele und -methoden - eine Aufgabe, die die Eisenbahnagentur übernehmen muss -, Errichtung eines gemeinsamen Systems für die Ausstellung, den Inhalt und die Gültigkeit der Sicherheitsbescheinigungen; und schließlich die Einführung des Prinzips unabhängiger technischer Untersuchungen bei Unfällen, wie das']\n","976 ['<|endoftext|> the time when men paid for their purchases in guineas, miraculous\\npreservations. Just as the life of a china vase is a perpetual escape from\\nthe stupidity of servant maids and the heaviness of clumsy fingers, so the\\nlife of these cream white oblongs, in which certain lights brought forth\\nmiraculous representations of flowers, festoons and birds, was a perpetual\\npreservation from the moth, from damp, from dryness, from the dust that\\ncorrupts.\\n\\nA house like Vernons exists not by virtue of its brick and mortar; to keep\\nit really alive it must be preserved in all its parts, not only from damp\\nand decay, but from innovation; one can fancy a gas cooker sending a\\nperpetual shudder through it, a telephone destroying who knows what\\nfragrant old influences; the store cupboards and still room are part of\\nits bowels, its napery, bed sheets, and hangings part of its dress. The\\nman knew what he was doing who left Miss Pinckney a life interest in\\nVernons, it was that interest that kept Vernons alive.\\n\\nShe was exercising it on the critical examination of some sheets when Phyl\\ncame into the room, now, with the wool she had purchased and the tale she\\nhad to tell.\\n\\nMiss Pinckney carefully put the sheet she was examining on one side,\\nopened the parcel and looked at the wool.\\n\\n\"I met Silas Grangerson,\" said Phyl as the other was examining the\\npurchase with head turned on one side, holding it now in this light, now\\nin that.\\n\\n\"Silas Grangerson! Why, where on earth has he sprung from?\" asked Miss\\nPinckney in a voice of surprise.\\n\\n\"I don\\'t know, but I met him in the street and we walked as far as the\\nBattery and--and--\"\\n\\nShe hesitated for a moment, then it all came out. To no one but Maria\\nPinckney could she have told that story.\\n\\n\"Well, of all the astounding creatures,\" said Miss Pinckney at last. \"Did\\nhe ask you to marry him?\"\\n\\n\"No.\"\\n\\n\"Just to run away with him--kissed you.\"\\n\\n\"He kissed me at Grangersons.\"\\n\\n\"At Grangersons. When?\"\\n\\n\"That night. I went into the garden and he came out from amongst some\\nbushes.\"\\n\\n\"Umph-- It\\'s the family disease-- Well, if I get my fingers in his hair I\\npromise to cure him. He wants curing. He\\'ll just apologise, and that\\nbefore he\\'s an hour older. Where\\'s he staying?\"\\n\\n\"No, no,\" said Phyl, \"you mustn\\'t ever say I told you. I don\\'t mind. I\\nwould have said nothing only for Mr. Pinckney.\"\\n\\n\"You mean Richard?\"\\n\\n\"Yes.\"\\n\\n\"What has he to do with it?\"\\n\\nPhyl did not hesitate nor turn her head away, though her cheeks were\\nburning.\\n\\n\"Silas Grangerson thinks I care for Mr. Pinckney, he said he would be even\\nwith him. I know he intends doing him some injury. I feel it--and I want\\nyou to warn him to be careful--without telling him, of course, what I have\\nsaid.\"\\n\\nMiss Pinckney was silent for a moment. She had already matched Phyl and\\nRichard in her mind. She had come to a very full understanding of her\\ncharacter, and she would have given all the linen at Vernons for the\\ncertainty that those two cared for one another.\\n\\nFrances Rhett rode her like an obsession. Life and nature had given Maria\\nPinckney an acquired and instinctive knowledge of character, and in the\\nunion of Richard and Frances Rhett she divined unhappiness, just as a\\nclever seaman divines the unseen ice-berg in the ship\\'s track. She smelt\\nit.\\n\\n\"Phyl,\" said she, \"do you care for Richard?\"\\n\\nThe question quickly put and by those lips caused no confusion in the\\ngirl\\'s mind.\\n\\n\"No,\" said she. \"At least-- Oh, I don\\'t know how to explain it--I care for\\neverything here, for Vernons and everything in it, it is all like a story\\nthat I love--Juliet and Vernons and the past and the present. He\\'s part of\\nit too. I want to have it always just as it is. I didn\\'t tell you, but\\nwhen that happened in the cemetery, I was looking at her grave; you never\\ntold', '<|endoftext|> different. She wondered if she could bear it, but she had to. Now she wanted to see, and she knew he had wanted her to. He had never told her, but now it was as though she had always known. The book was dedicated to her.\\n\\nFresh tears ran down her face as she read it, but they were not tears of grief. Tears of tenderness, of gratitude, of laughter, of loving. Those were the treasures he had given her, not sorrow. Luke had never been a man to tolerate sorrow. He had been too alive to taste even a whisper of death. And sorrow is death.\\n\\nTo Kezia, who stands by my side wherever I go. My equal, my solace, my friend. Brave lady, you are the bright light in a place I have long sought to find, and now at last we\\'re both home. May you be proud of this book, for now it is the best I can give you, with thanks and my love.\\n\\nL.J.\\n\\n\"... and now at last we\\'re both home.\" It was true, and it was late August by then, and she had one final test Marbella. And Hilary.\\n\\n\"My God, darling, you look divine! So brown and healthy! Where on earth have you been?\"\\n\\n\"Here and there.\" She laughed and brushed her hair from her eyes. It was longer now, and the harsh angularity of her face had melted again. There were small lines on either side of her eyes, from the sun, or whatever, but she looked well. Very well.\\n\\n\"How long can you stay? Your cable didn\\'t even give me a hint, naughty child!\"\\n\\nYes, she was back in that old familiar world. Dear, darling Hilary. But it amused her to be called a naughty child. Hell, why not? Her birthday had come and gone in late June. She was thirty now.\\n\\n\"I\\'ll be here for a few days, Aunt Hil, if you have room.\"\\n\\n\"That\\'s all? But darling, how awful, and of course I have room, how absurd.\" She was currently having room for at least fourteen others, not to mention the staff. \"\\'Why don\\'t you think about staying longer?\"\\n\\n\"I\\'ve got to get back.\" She accepted an iced tea from the butler. They stood near the tennis courts where the other guests played.\\n\\n\"Get back to where? My, Jonathan has improved his serve, hasn\\'t he?\"\\n\\n\"Undoubtedly.\"\\n\\n\"Of course, how silly of me. You don\\'t know him. Perfectly beautiful man.\"\\n\\nHe looked like a carbon copy of Whitney. It made Kezia smile.\\n\\n\"So where is it you\\'re going back to?\" Hilary returned her attention to Kezia, over a well-chilled martini.\\n\\n\"New York.\"\\n\\n\"At this time of year? Darling, you\\'re mad!\"\\n\\n\"Maybe so, but I\\'ve been away for almost five months.\"\\n\\n\"Then another month can\\'t possibly hurt.\"\\n\\n\"I\\'m going back to do some work.\"\\n\\n\"Work? What sort of work? Charity? But no one\\'s in town in the summer for heaven\\'s sake. Besides, you don\\'t work, do you?\" For a moment Hilary looked slightly confused. Kezia nodded.\\n\\n\"Yes, I do. Writing.\"\\n\\n\"Writing? What on earth for?\" She was quite bemused, and Kezia was trying hard not to laugh. Poor Aunt Hil.\\n\\n\"I guess I write because I enjoy it very much, as a matter of fact.\"\\n\\n\"Is this something new?\"\\n\\n\"No, not really.\"\\n\\n\"Can you write? Decently, I mean.\" But this time Kezia couldn\\'t help it; she laughed.\\n\\n\"I don\\'t know. I certainly try to. I used to write the Martin Hallam column. But that wasn\\'t my best work.\" Kezia wore a mischievous grin. Hilary gaped.\\n\\n\"You what? Don\\'t be insane! You... Good God. Kezia, how could you!\"\\n\\n\"It amused me. And when I had enough of it, I retired. And don\\'t look so upset, I never said anything mean about you.\"\\n\\n\"No, but you... I... Kezia, you really amaze me.\" She relieved the butler of another martini and stared at her niece. The girl was really quite strange. Always had been, and now this. \"In any case, I think you\\'re a fool to go back in August.\" Hilary had not yet recovered. \"And that column doesn\\'t run anymore.\" Kezia giggled; it was as though Hilary were trying to trap her into admitting that', '<|endoftext|> said. \"My parents have a summer house, but since every one of their friends has a house in the same square mile, it\\'s just like being back in the city, only cooler.\"\\n\\n\"Where is that?\" I asked.\\n\\n\"In Chicago. They\\'re still there, in spite of the winters. I\\'ve tried to get them out here, but they\\'re sure the place\\'ll shimmy down around their ears.\"\\n\\n\"Yes,\" I said with a grin. \"Half my friends in England assume that San Francisco collapses on a yearly basis.\"\\n\\n\"Flo said you\\'re in London?\"\\n\\n\"I do have a flat there, but we live on the south coast. I also spend a lot of time in Oxford.\"\\n\\n\"That\\'s right, she said you were a, whatchamacallit, bluestocking.\"\\n\\n\"She probably said I spent my life with my nose in a book.\"\\n\\n\"Something like that. Can\\'t manage it, myself. Books, I mean. Ever since I graduated, anything but a novel brings me all out in hives.\"\\n\\nHe had a nice laugh, pleasantly crooked white teeth, and—although he\\'d taken a minute to make the razor-sharp part down the middle of his hair and slick it into place—a nicely rakish blond stubble on his square cheekbones. He might not be much of a one for books, but in addition to being restful on the eyes, he was intelligent, thoughtful, and seemed to care a great deal for Flo. I was, theoretically, a member of the same \"jazz generation\" as the rest of Friday night\\'s party, but in truth I hadn\\'t known many of this sort of social animal with any intimacy, and hadn\\'t expected to find a solid foundation beneath the self-consciously blasé pleasure-seeker. Maybe it was because Donny was a little older; maybe he was just made of stronger stuff.\\n\\nHearing our voices, Flo re-appeared. \"Morning,\" she said, taking the chair between us. \"Is there any more coffee?\"\\n\\nDonny reached for her cup and stood up; as he went past, he mussed her already on-end hair affectionately. \"Not a morning girl, my Flossie.\"\\n\\n\"Hell, I\\'m full of pep,\" she protested, then yawned.\\n\\nHe poured her coffee, placed it in front of her, then started opening various cupboards and taking things out. \"How do you like what my old man calls \\'cackle berries\\'?\" He held up a pair of eggs.\\n\\nI placed a half-hearted objection, saying that I really ought to be doing the cooking for them, but Flo said, \"Donny loves to mess around in the kitchen. It\\'s going to drive the cook bananas, when we\\'re married.\"\\n\\n\"I didn\\'t know,\" I said. \"Congratulations.\"\\n\\n\"Oh, we haven\\'t set a date or got a ring or any of that hooey,\" she told me. \"When we do, Mummy will take over, and it\\'ll be just another rotten bore. We\\'ll probably elope, but right now we\\'re having too much fun. Plenty of time to be respectable when our livers give out.\"\\n\\nI shot a quick glance at Donny; he was breaking the eggs into a bowl, but from the side of his face, I thought perhaps the wild boy of the Blue Tiger might be more ready for the ring than his girl-friend was.\\n\\n\"Well, in any case,\" I said, \"it\\'s a good thing he likes to cook, because otherwise you\\'d be eating burnt food chipped from the pan. I am no chef.\"\\n\\nDonny scrambled the eggs with some herbs that I hadn\\'t noticed growing along the outer wall of the cabin—at least I assumed they were herbs and not some poisonous weed. The eggs tasted good, whatever the herbs\\' Latin names, eaten with sausages from the ice-box and toast heaped with Mrs Gordimer\\'s jam. We ate on the terrace, which gathered the morning sun nicely. When our plates were polished and the toast basket was empty (Flo having pressed the last pieces on me) I cleared the table and made more coffee, returning to find Flo stretched out on one of the deck-chairs with her face to the sun, eyes closed like a cat.\\n\\n\"I\\'m gonna bake in the sun all day,\" she declared.\\n\\n\"You\\'ll get horribly red and sore,\" Donny warned her.\\n\\n\"Oh, don\\'t be wet, Donny. I don\\'t care. I think I\\'ll just move down here to the sticks and turn into a turnip.\"\\n\\n\"A red turnip,\" he commented.\\n\\n\"There should', '<|endoftext|> tell her the deal.\\n\\n\"Hey, Mom?\"\\n\\n\"Yes, Jeremy.\" She doesn\\'t look up from her work.\\n\\n\"There\\'s actually a, ah, Halloween Dance tonight as part of school, so I\\'m going.\"\\n\\n\"Really?\" Mom asks, looking up. And just as her _really_ is ending, Dad slips through the curtain into the dining room, shirtless. He\\'s eating a giant hot dog in a too-small bun. \"Really?\" he says.\\n\\n\"Yeah!\" I look back and forth between Dad and Mom. I had expected, challenges.\\n\\n\"That\\'s wonderful!\" Mom gets up and hugs me. \"Who are you going with?\"\\n\\n\"Yeah, what\\'s up?\" Dad asks. \"Does she have, you know...\" Dad pantomimes breasts with his hands and hot dog.\\n\\n\"Stop it!\" Mom snaps. \"That is _not_ appropriate.\"\\n\\n\"You\\'d be surprised, son,\" Dad says. \"So many divorces that I handle stem from breasts. They\\'re incredibly important. Make sure that the girl—\"\\n\\n\"There isn\\'t a girl,\" I declare.\\n\\nSilence from Mom.\\n\\n\"Hmm,\" Dad chews. \"Are you gay?\"\\n\\n\"Stop it!\" Mom shrieks, scrambling toward Dad. He skitters out. \"Your father,\" she says, returning to her seat at the stacks of paper. \"Sometimes I really don\\'t know. So, in any case—\"\\n\\n\"I\\'m not gay. Don\\'t worry.\"\\n\\n\"I\\'m not,\" Mom smiles. \"It would be fine if you were, really. We\\'re good parents. But you\\'re going to a dance?\"\\n\\n\"Yeah.\"\\n\\n\"That\\'s great. Do you need money?\"\\n\\n\"Sure.\" I had no idea they\\'d give me money for this. I suppose I should be more social more often.\\n\\n\"Here,\" Mom presses bills into my hands that I\\'ll count later. \"Go to the dance—do you need a ride? Oh wait, I\\'m sure you wouldn\\'t want one from us. Take a car service!\"\\n\\n\"Yeah, I already called one.\"\\n\\n\"Well that\\'s great! Remember, don\\'t ever touch my car, Jeremy. But have fun at the dance! You\\'ll do fine.\"\\n\\n\"Yeah, for sure!\" Dad says from the living room, eating his hot dog on the Bowflex. \"Dance with girls!\"\\n\\n\"Thanks, Dad.\" I walk out to the porch and wait for the car service. When it comes, I stroll down the lawn dressed entirely in black, mask over the top of my head, not on. I get in the car and try to negotiate the wannabe-strawberry air-freshener smell.\\n\\n\"Where you goin\\'?\" the driver asks.\\n\\n\"Elks Club Lodge, Lefferts Road by the Friendly\\'s.\"\\n\\n\"T\\'anks.\" We slide down my street, take a turn past school and the field, which somehow has two fireflies in it, spinning in a lazy DNA spiral, this late in the year. I try my mask on.\\n\\n\"Oooh, tha\\'s cool,\" the driver says.\\n\\n\"Yeah?\"\\n\\n\"Yeah. You look like a l\\'il hooligan.\"\\n\\nHooligan? Hooligan doesn\\'t sound particularly dangerous or interesting. We ride in silence the rest of the way. I plan the night\\'s events: if Christine is there with Jake, I\\'ll pay a girl some of this money Mom gave me to distract Jake while I talk with Christine about how I feel about her (good plan). Then I\\'ll take off my mask and she\\'ll see who I am and she\\'ll be like—\\n\\n\"We here,\" the driver says. I pay him and step out.\\n\\nThe Elks Club Lodge has a snaking line in front of it nine trees long, comprised of kids dressed as pro wrestlers, kids dressed as members of Slipknot, kids dressed as Fidel Castro and Bill Clinton with Phillies in their masked mouths, kids dressed as giant condoms and Viagra pills. The line surprises me. I step to the back with my mask down.\\n\\n\"What\\'s this for?\" I ask the guy in front of me.\\n\\n\"Tickets, yo,\" he says over his shoulder, making a lip-smacking noise. He\\'s dressed as some sort of small tree. \"You need tickets for the dance.\"\\n\\nOh crap, it\\'s Rich. His whole face is green, so I couldn\\'t tell at first. I\\'d better be quiet so he doesn\\'t figure out who I am and torment me. I keep the mask on and it gets atrocious and spitty inside, but I think the anonymity', '<|endoftext|> pull it slowly away, and for the first time she met his dull and watery eyes. Saw his yellowed skin, his blackened lips, the tangled cascade of coarse hair whose locks bunched about his shoulders like throttled snakes. His face was like none she had seen, ever, more total in its noble ruin than any ravaged by disease or wound. And her heart shattered for the sufferings others must have heaped upon him, for no matter how powerful his shoulders or broad his back, both must surely have broken under the strain.\\n\\nGiselle groped inside for words, but there were none. We are all beautiful in the eyes of the Lord? How easy to say, with her own complexion like milk. The last thing Nomad needed was to hear sanctimonious platitudes.\\n\\nSo, instead, she stepped forward to where he stood atremble, reached up, and touched his face. Which soon dampened with his tears.\\n\\n\"There are hours yet before dawn,\" she said. \"Please share with me where you\\'ve come from.\"\\n\\n*\\n\\nIn the hour past dawn, Nomad refused to leave the stable with her, and no amount of coaxing would draw him out to join her in a walk to the rectory. Father Guillaume should be told, but moreover should be introduced to this wandering soul. Such conversations the two of them might have. What endless lifetimes of humanity had Nomad witnessed, as an outsider. If anything, humanity could learn from him, and benefit. Let it begin with her, and with the Church. Let it begin here.\\n\\n\"But why?\" he pleaded with her. \"You have your hopes and your optimisms, but these are born of your naivety. You have seen so little of the world, you have no way of knowing how much it can hate. Of hope and optimism I have none... because instead I have experience. I know the reception I\\'ll meet with.\"\\n\\n\"For everything and everyone, a place,\" she told him. \"This is what I believe and I believe because this is what I\\'ve seen. No one can be truly happy until they find that place. I am, because I have. I belong to God, and to the Church, and to Château-sur-Lac. And if I can help you find that place for your life, then it will prove that mine has fulfilled some of its purpose as well. Don\\'t you see?\"\\n\\nHe said he did, and that he dared not turn his back on her before she had her chance to try.\\n\\nGiselle ran from the stable with her cloak billowing behind her, into the fresh damp chill of morning. She raced along the path to the rectory, whose window was filled with the jaundiced glow of a lamp.\\n\\nHow unlikely she would be doing this if other circumstances had asserted themselves. That Nomad was nothing as she\\'d imagined was a blessed relief. His ugliness and profound misery were easy to contend with, compared to the handsome face and shy, seductive demeanor that might have been his. And had he possessed these, had he been that Parisian artist in self-imposed exile? Perhaps she would still be making this trip to the rectory, though to instead confess and mourn her broken vows.\\n\\nShe banged on the cottage door, and when it opened, Father Guillaume stood as she had never seen him. He\\'d already donned his cassock, but had yet to shave. His thin-jowled face seemed to sag, his graying hair was still mussed from the pillow. And behind his round spectacles...\\n\\n\"Have you been weeping?\" she asked.\\n\\n\"Yes.\" He peered at her as if only now realizing who it was. \"You\\'re out of breath. You too have heard?\"\\n\\nGiselle frowned. \"Heard what?\"\\n\\nFather Guillaume waved it aside briskly, almost gratefully, and wiped at his eyes. \"You\\'re out of breath. There must be a reason. Come in.\"\\n\\nShe crossed the threshold and they sat at the scarred old table where the Father took his meals when he preferred to dine alone, with his Bible or his meditations. A fresh log was beginning to blaze away in the fireplace, atop old embers.\\n\\n\"The man who\\'s been passing his nights in our stable,\" she began, \"the one who\\'s done so much with the horses, and left so much firewood behind for his keep... he\\'s no longer a stranger. I\\'ve just now left a conversation with him that lasted though half the night. Father, he\\'s more deserving of our pity and our help than anyone I\\'ve ever met. Ever.\"\\n\\nGiselle recounted the long and sorrowful story, of one man created by another, then rejected', '<|endoftext|>\\'d once seen that had a terrible curve to the right. She picked it up and took a good look at it, trying to picture the designers of such an item sitting around a table and deciding on the angle of the curve. She considered herself adventurous and fun in bed, but she couldn\\'t imagine Dean figuring out a way to make good use of this. Gee, guess it was a good thing he wasn\\'t here...\\n\\nIt penetrated her addled brain that the shower was still running.\\n\\nOdd. Surely the housekeeper wouldn\\'t be in there...Curious, a little unnerved—and if she let herself think about all that had happened to her since she got out of bed that morning, she could add crazed to the list—she stepped over a pile of wet clothes on the floor.\\n\\nHuh?\\n\\nTurning back, she crouched down to look at them, trying to get a clue as to who was in her shower. Levi\\'s, original fit, size 34x36. Hmm. Tall and lean. There was also a white Hanes Beefy T-shirt, size large, and a soft blue chambray overshirt, both smelling good enough that if she hadn\\'t given up men, she might have pressed her face against the material and inhaled.\\n\\nBut she had given up men. She\\'d written it in her journal and therefore it had become law.\\n\\nHe didn\\'t wear underwear.\\n\\nWhy the hell that intrigued her, she had no idea. Rising, shivering because her clothes had become iced to her skin, she knocked on the bathroom door.\\n\\nWhoever he was, he had the radio on; she could hear the broadcaster talking about the storm of the century—\\n\\nStorm of the century. That couldn\\'t be good. Pressing her ear to the door, she heard other disturbing words, such as \"No one is going anywhere, folks\" and \"I hope you\\'re all stocked up on whatever you need, because this one\\'s a doozy.\" At that, she twisted the handle on the door and pushed it open.\\n\\nThe bathroom was as amazingly detailed as the rest of the house. Even through all the thick steam, she could see the stunning granite countertops, the raw wood-framed mirrors, the small overstuffed day couch, the old-fashioned brass fixtures—\\n\\nAnd yet another gift basket, filled with more goodies. She looked at the vibrator she still had in her hand. What else could she possibly need? Well, besides a new groom, that is. A shame they didn\\'t come a dime a dozen in a gift basket such as this, selection ready.\\n\\nThe shower took up one full corner, all in clear glass, etched with the outline of the Sierras, which in fact did nothing at all to hide the tall, leanly muscled man standing in it.\\n\\nNaked.\\n\\nGloriously so, she might add. The water sprayed out of four different rain heads, massaging over him. He had his back to her, and what a fine back it was: broad, ropey shoulders, sleek, strong spine, smooth and tanned until, low on his narrow hips, his tan line abruptly ended.\\n\\nHe had a fabulous, mouthwatering butt, and Breanne took a moment to wonder at the man who wore a bathing suit in the sun but not underwear beneath his jeans.\\n\\nWater sluiced off him, and soap, too, and then, as if God had decided to bestow one tiny little favor on her shitty, rotten day, the guy dropped the soap.\\n\\nBreanne held her breath. Would he—\\n\\nYes. Yes, he would.\\n\\nBending for it, blissfully unaware that there were a pair of very curious female eyes on him, he clearly didn\\'t even consider his modesty. Every muscle in his body flexed as he doubled over, legs slightly spread, offering her an eye-popping view of his—\\n\\nOh, my.\\n\\nLifting her hand, she furiously fanned air to her face, because the front of him lived up to the back, and how. She wondered how old he was, thinking that body couldn\\'t be more than thirty, which was only two years older than herself. In any case, she stood there, rooted to the ground, her own wet misery forgotten, mouth hanging open, drool pooling, eyes locked on the backs of his well-defined thighs.\\n\\nAnd what was between them.\\n\\nBut then suddenly he whipped around, staring at her through the glass for one beat before shoving open the shower door, allowing steam and water to pour into the room as he glared at her with an ominous, thunderstruck expression on his face.\\n\\nMore than thirty, she thought inanely. Probably', '<|endoftext|> me and the rest of her class. Pretty intimidating.\"\\n\\nRegan sampled the tea, and the relative quiet now that Shane had Jason calmed down to bubbling coos. \"It seemed she was always in some lab, or the library.\"\\n\\n\"Sounds like a barrel of laughs.\"\\n\\n\"She was—is—a serious type, and tended to be shy. After all, she was years younger than anyone else in school. But we got to be friends. She\\'d have come for the wedding, but she was in Europe, or Africa.\" Regan waved vaguely. \"Somewhere.\"\\n\\nShane was thinking nostalgically of his own fifteenth year, when he had learned the intricacies of the back-hook bra. In the dark. \"It\\'s nice you\\'ve got a pal coming to visit.\"\\n\\n\"Well, it\\'s kind of a working visit for her.\" Regan gnawed her lip. She hadn\\'t mentioned Rebecca\\'s purpose, except to Rafe. She supposed if she was going to dragoon Shane into meeting her friend at the airport, she ought to make it clear.\\n\\nShe studied him as he made faces at the baby, then nuzzled Jason. All the MacKades were stunners, she thought, but there was something about Shane. Just an extra slice of charm, she supposed.\\n\\nHe had the looks, of course. That thick, midnight-black hair that he now wore in a stubby ponytail. The thin, bony, mouth-watering face, with its angles and planes, lush mouth, flashing dimple and thickly lashed green eyes. His shade of green was dreamy, the shade of an ocean at twilight.\\n\\nHe had the build—tall, rangy, muscled. Broad shoulders, narrow hips, long, long legs. It showed to advantage in jeans and work boots and flannel.\\n\\nHe had the charm. All four MacKades had it to spare, but Regan thought there was an extra dollop in Shane. Something about the way his eyes lingered on a woman, the quick, appreciative grin when he spoke to one, be she eight or eighty. That easygoing, cheerful manner that could explode into temper, then, just as quickly, edge away into a laugh.\\n\\nHe\\'d probably scare the hell out of poor, shy Rebecca.\\n\\n\"You\\'re awfully good with him,\" she murmured.\\n\\n\"You keep making babies, honey, I\\'ll keep loving them.\"\\n\\nAmused, she angled her head. \"Still not ready to settle down?\"\\n\\n\"Now why would I want to go and do that?\" He looked up from Jason, and his eyes danced with humor. \"I\\'m the last single MacKade. I\\'m honor-bound to hold the fort until the nephews start springing up.\"\\n\\n\"And you take your duty seriously.\"\\n\\n\"You bet. He\\'s asleep.\" Shane lowered his head and kissed Jason\\'s brow. \"Want me to put him down?\"\\n\\n\"Thanks.\" She waited until Shane had Jason settled in the antique cradle. \"Rebecca\\'s expecting me. I wasn\\'t able to catch her before she left for the airport.\" Frazzled all over again, Regan ran her fingers though her hair. \"The babysitter canceled, Rafe\\'s in Hagerstown getting building material. Cassie\\'s got a full house over at the inn, Emma\\'s got the sniffles, and I just couldn\\'t ask Savannah to help out.\"\\n\\n\"Last time I saw her, she looked ready to pop.\" To demonstrate the condition of Jared\\'s wife, Shane made a wide circle with his arms in front of his flat belly.\\n\\n\"Exactly. She\\'s too pregnant to drive a three-hour round trip, and with a furniture delivery being rescheduled for this afternoon, I didn\\'t know who else to call and impose on.\"\\n\\n\"It\\'s no trouble.\" To prove it, he kissed the tip of her nose. \"I don\\'t suppose she\\'s as pretty as you, is she?\"\\n\\nRegan chuckled at that. \"How am I supposed to answer that and not sound like a jerk? In any case, I haven\\'t seen her in...five years, I guess. The last time was on a quick trip to New York, and she was hip-deep in some paper she was writing. She\\'s four years younger than I am and has two doctorates. Maybe more. I can\\'t keep up.\"\\n\\nShane didn\\'t wince. He liked women with brains as much as he liked women without them. But he knew the old routine about smarts and wonderful personalities. He didn\\'t think he was going to be picking up a beauty queen at the airport.\\n\\n\"Psychiatry and U.S. history for sure,\" Regan continued. \"Kind of', '<|endoftext|>support with his mother and sisters. He stopped at the Works when he\\nleft the train, and found his father in his private office beyond the\\nbook-keeper\\'s picket-fence, which he penetrated, with a nod to the\\naccountant.\\n\\n\"Hello, Dan!\" said his father, looking up; and \"Hello, father!\" said\\nDan. Being alone, the father and son not only shook hands, but kissed\\neach other, as they used to do in meeting after an absence when Dan was\\nyounger.\\n\\nHe had closed his father\\'s door with his left hand in giving his right,\\nand now he said at once, \"Father, I\\'ve come home to tell you that I\\'m\\nengaged to be married.\"\\n\\nDan had prearranged his father\\'s behaviour at this announcement, but\\nhe now perceived that he would have to modify the scene if it were to\\nrepresent the facts. His father did not brighten all over and demand,\\n\"Miss Pasmer, of course?\" he contrived to hide whatever start the news\\nhad given him, and was some time in asking, with his soft lisp, \"Isn\\'t\\nthat rather sudden, Dan?\"\\n\\n\"Well, not for me,\" said Dan, laughing uneasily. \"It\\'s--you know her,\\nfather--Miss Pasmer.\"\\n\\n\"Oh yes,\" said his father, certainly not with displeasure, and yet not\\nwith enthusiasm.\\n\\n\"I\\'ve had ever since Class Day to think it over, and it--came to a\\nclimax yesterday.\"\\n\\n\"And then you stopped thinking,\" said his father--to gain time, it\\nappeared to Dan.\\n\\n\"Yes, sir,\" said Dan. \"I haven\\'t thought since.\"\\n\\n\"Well,\" said his father, with an amusement which was not unfriendly.\\nHe added, after a moment, \"But I thought that had been broken off,\" and\\nDan\\'s instinct penetrated to the lurking fact that his father must have\\ntalked the rupture over with his mother, and not wholly regretted it.\\n\\n\"There was a kind of--hitch at one time,\" he admitted; \"but it\\'s all\\nright now.\"\\n\\n\"Well, well,\" said his father, \"this is great news--great news,\" and he\\nseemed to be shaping himself to the new posture of affairs, while giving\\nit a conditional recognition. \"She\\'s a beautiful creature.\"\\n\\n\"Isn\\'t she?\" cried Dan, with a little break in his voice, for he had\\nfound his father\\'s manner rather trying. \"And she\\'s good too. I assure\\nyou that she is--she is simply perfect every way.\"\\n\\n\"Well,\" said the elder Mavering, rising and pulling down the rolling top\\nof his desk, \"I\\'m glad to hear it, for your sake, Dan. Have you been up\\nat the house yet?\"\\n\\n\"No; I\\'m just off the train.\"\\n\\n\"How is her mother--how is Mrs. Pasmer? All well?\"\\n\\n\"Yes, sir,\" said Dan; \"they\\'re all very well. You don\\'t know Mr. Pasmer,\\nI believe, sir, do you?\"\\n\\n\"Not since college. What sort of person is he?\"\\n\\n\"He\\'s very refined and quiet. Very handsome. Very courteous. Very nice\\nindeed.\"\\n\\n\"Ah! that\\'s good,\" said Elbridge Mavering, with the effect of not having\\nbeen very attentive to his son\\'s answer.\\n\\nThey walked up the long <DW72> of the hillside on which the house stood,\\noverlooking the valley where the Works were, and fronting the plateau\\nacross the river where the village of operatives\\' houses was scattered.\\nThe paling light of what had been a very red sunset flushed them, and\\nbrought out the picturesqueness which the architect, who designed\\nthem for a particular effect in the view from the owner\\'s mansion, had\\nintended.\\n\\nA good carriage road followed the easiest line of ascent towards this\\nedifice, and reached a gateway. Within it began to describe a curve\\nbordered with asphalted footways to the broad verandah of the house, and\\nthen descended again to the gate. The grounds enclosed were planted with\\ndeciduous shrubs, which had now mostly dropped their leaves, and clumps\\nof firs darkening in the evening light with the gleam of some garden\\nstatues shivering about the lawn next the house. The breeze grew colder\\nand stiffer as the father and son mounted toward the mansion which Dan\\nused to believe was like a chateau, with its Mansard-roof and dormer\\nwindows and chimneys. It now blocked', '<|endoftext|> the intoxicating perfume of champagne and the melody of Paris.\\n\\n\"We should go,\" she said in her everyday voice. Not a voice hoarse with singing or the smoke of an imagined nightclub. She turned toward the gate that they had left ajar.\\n\\n\"Sandrine,\" he said quickly, catching at her hand. \"I love you. You know that?\"\\n\\nShe stopped. \"I know.\"\\n\\n\"And when this is over, all of this, I\\'ll take you dancing every weekend. Every night if you want to.\"\\n\\nSandrine smiled. \"Would my feet even stand it?\" she whispered.\\n\\n\"Better times around the corner,\" he said. \"Like in all those ghastly English songs they\\'re always playing.\"\\n\\nThey stood together for a last moment, cheek to cheek, then Sandrine stepped back.\\n\\n\"We must go,\" she said quietly. \"We\\'ve been here too long.\"\\n\\nRaoul gripped her hand even more tightly. \"I mean it, when it\\'s over, I\\'m going to show you such a time . . .\"\\n\\n\"We\\'ll be all right,\" she said, her voice suddenly fierce. \"We\\'ll get through if we can just hold out for a little bit longer. We\\'ll be fine, you and me. All of us.\"\\n\\n\"Yes?\"\\n\\nShe heard the doubt in his voice and her heart cracked a little.\\n\\n\"Yes,\" she said firmly. \"Yes. Now, come on. You can walk me home, Monsieur Pelletier. And if you\\'re good, I might even let you come in for a cup of cocoa!\"\\n\\n\"Cocoa!\" He laughed. \"Now that\\'s too English for me! In any case, I should go to the bar and see if Bonnet and Yvette are there. Just in case she\\'s heard anything.\"\\n\\nThe smile faded from Sandrine\\'s face. \"Yes,\" she said quietly. \"That\\'s sensible. We should make sure nothing\\'s changed.\"\\n\\nTogether, with thoughts of the day ahead in their minds, they walked quietly, quickly through the sleeping streets of Carcassonne. The un-reliable moon lighting their way home.\\n\\n## ��\\n\\n## Codex XX\\n\\n## ��\\n\\nGAUL\\n\\nTARASCO\\n\\nJULY AD 344\\n\\nArinius stood with his brother-in-law, watching another sunrise over the Vallée des Trois Loups. Each day the soldiers did not come was a reprieve, though he knew the waiting was making the others careless. They were starting to take the threat less seriously.\\n\\nThe Tarascae had taken it in turns to keep watch through the short summer nights. Only a few hours of darkness between dusk and dawn. Each was armed. Those who had fought, either in the service of the Roman army or to defend their land, held swords or javelins, slings. Many were armed with clubs, knives, their weapons the spoils of war, skirmishes and ambushes, rather than campaigns or battles. Most of the villagers were guerrilla fighters, using the woods and the forests, untrained in the art of fighting but with a raw belligerence suited well to these lawless border lands.\\n\\nArinius had a heavy rectangular shield. His old hunting knife was in his right hand, though he prayed he would not be called upon to use it. He was prepared to fight to the death to protect his friends, their community, but he did not wish to take the life of another.\\n\\nHe knew he was being naïve—and that Lupa, had she been there, would have laughed at his moral distinction. She, more than him, was able to reconcile God\\'s commandments with the cruelties of the world in which they lived. For him, though, the gentleness of the gospels, the words of John and Luke sang more truly. His God was a God of light and redemption, not of vengeance and judgment.\\n\\nHe did not wish to kill another human being. Only God, he believed, had that right. And he had seen too much death in his youth, saw how it corrupted and despoiled all that was best in human nature, left a scar on the soul.\\n\\n\"A false alarm, do you think, _peyre_?\" one of the young men asked him.\\n\\nHe had tried so many times to make them address him by his name, feeling dishonest and humbled to be singled out and ranked above his station. And \" _peyre_ \" was a strange, local word, a hybrid, neither Latin nor any other language Arinius had come across. But they insisted and he had given up trying to stop them.\\n\\n\"Could it be a false alarm?\"\\n\\nArin', '<|endoftext|> it feels.\"\\n\\nRepenting, I walk back to the gate and look him in the eyes, feeling an urgent need for him to understand me.\\n\\n\"I\\'m not imagining things.\"\\n\\n\"I know,\" he whispers back, without breaking eye contact.\\n\\nWe stare at each other, and it\\'s clear that we are both feeling something—there\\'s a connection between us.\\n\\nStill speaking in a low voice, I tell him, \"I don\\'t know if I\\'m safe here.\"\\n\\nHis eyes shift to the dark bulk of the house behind me.\\n\\n\"What exactly is it that you\\'re afraid of?\" he asks, his expression becoming more intent.\\n\\n\"I have this feeling that won\\'t go away. The sensation that I\\'m being watched, constantly . . . and I\\'m afraid that the person behind it all is Alfred.\"\\n\\nI immediately realize how silly I must sound, but it\\'s too late to take it back.\\n\\n\"I can stay out here and check that nothing weird happens,\" he offers, suddenly every inch the solicitous young gentleman. \"If you feel like you\\'re in danger, you can always come over and find me. I won\\'t leave.\"\\n\\nOverwhelmed by his kindness, I move nearer to him, reaching the limit of the gate between our gardens. We\\'re so close that I can almost feel the warmth of his body next to mine.\\n\\n\"I can\\'t let you stay out here alone, though,\" I say, after the silence has drawn itself out for a few instants.\\n\\n\"Oh, I don\\'t mind,\" he reassures me.\\n\\nI consider his offer, and then a thought pops into my head.\\n\\n\"Tell you what—we could both spend the night out here, until the sun comes up. But I wouldn\\'t want you to feel that you have to . . .\"\\n\\n\"Sure,\" he answers, without hesitation.\\n\\nAnd so just like that, we find ourselves sitting with our backs propped against the two sides of the gate. The only thing illuminating our surroundings is the gently flickering candle that sits in a little pool of its own hardened wax on one of the stones of the path.\\n\\nI can hear him breathing, in and out, and the rhythm of it soothes me to the point that I close my eyes and start to sleep.\\n\\nWhen I wake up, it takes me a few moments to work out where I am. I turn around to check if Avery is still there and, disappointed to find that he\\'s not, I get up from the ground and brush my hands clean on my jeans.\\n\\n\"Hey!\" shouts a voice from behind me.\\n\\nSomehow I manage to spin around in time to catch the apple that\\'s flying through the air towards me.\\n\\nThere he is—Avery, walking this way through the dewy grass, another apple in his hand.\\n\\n\"I did tell you that I wouldn\\'t leave you,\" he says, with a wide smile on his face. \"Nice catch, by the way!\"\\n\\nI return his smile and thank him for the apple, and he takes a bite from his.\\n\\n\"You seemed pretty concerned last night,\" he says as soon as he has finished chewing. \"Would you like to talk about it?\"\\n\\nI reflect for a second and try to straighten out my thoughts, then, finally, let it all out.\\n\\n\"Maybe . . . maybe I\\'m crazy, but I\\'m starting to think that Alfred might be drugging me,\" I say. \"All the things that I see, all the weird things that have been happening to me . . . I can\\'t explain it, and it just feels natural to blame all of this on him.\"\\n\\n\"Why would he do that, though? I mean, what possible motive could he have? Have you thought about that?\" he asks.\\n\\n\"Well, I know that this will sound ridiculous, but I\\'m scared he might be up to something big.\"\\n\\n\"Like what?\"\\n\\n\"Like, where are the Blooms? You said it yourself—Mrs. Bloom didn\\'t like the idea of having him around.\"\\n\\n\"So what exactly are you saying?\" he asks, sounding intrigued.\\n\\n\"I don\\'t know what I\\'m saying,\" I admit. \"I just . . . I don\\'t know. That\\'s why I\\'m not sleeping. I need to keep my eye on him.\"\\n\\n\"I understand,\" he says affectionately, \"but don\\'t forget to take a break and catch your breath sometimes.\"\\n\\nI just nod.\\n\\n\"In any case,\" he adds, \"if you ever need me, you know where to find me.\"\\n\\nStill not entirely convinced that he\\'s taking my fears seriously, but grateful in any case to have him on my side, I thank', '<|endoftext|> the most impossible thing of all. How could she act naturally, with my eyes boring into her back, when she knew perfectly well I was a hundred meters behind her, hidden behind a dog or a trash can? So where did that leave her? All she could do was combine the three impossibilities, unable to settle on any of them, bouncing from one to another.\\n\\nEncouraged by my failures (let others be encouraged by success!), I started making it even more difficult. Instead of a distance of a hundred meters, I made it two hundred. I lost sight of her at once. The tailing was no longer visual but divinatory. This was a natural extension of my habit of giving instructions, which had ended up informing my relation to the world; everything had to be done with the utmost subtlety and finesse... The fact that I failed was secondary. The methodical imperative came first. Also, this way, the sense of pursuit was stronger, more intense... to the point where it all flipped around. When I lost Mom—and, increasingly, I made sure that this happened at the beginning of the outing—I started to feel that I was being tailed.\\n\\nThis feeling grew exponentially. I had the brilliant idea of telling Mom about it. My rashness was breathtaking. At first she paid no attention, but I insisted just enough to get her worried, before backing off. So many dreadful things had been happening... She asked me if I\\'d seen who was following me, if it was a man or a woman... I didn\\'t know how to explain that it wasn\\'t like that, I was talking about feelings, subtleties, \"instructions.\"\\n\\n\"You\\'re not going out any more unless I\\'ve got you by the hand!\"\\n\\nAround that time the gutter press was feasting on the bloodless cadavers of boys and girls, found raped in vacant lots... They had been completely drained of blood. A vampire plague was sweeping the land. Mom was a village girl, and though not completely ignorant (she had done a year of secondary school), she was naïve, easily taken in... So different from me! She not only believed what she read in the gutter press (if it came to that, I probably did too), but applied it to her own real life. That was the key difference, the abyss that separated us. I had a real life completely separate from beliefs, from the common reality made up of shared beliefs...\\n\\nAnyway, once, during one of our outings... I had completely lost Mom, and I didn\\'t know whether to keep going straight, or turn, or go back home (it was only two blocks away).\\n\\nThe thing was, we had just set out; Mom wouldn\\'t be back for a good half hour, and she\\'d be nervous and worried about me, and maybe cross because she couldn\\'t finish her shopping...\\n\\nA strange woman accosted me. \"Hello, César.\"\\n\\nShe knew my name. I didn\\'t know anyone and no one knew me. Where was she from? Maybe she lived in the tenement, or worked in one of the stores where Mom did her shopping. To me all ladies looked the same, so she could have been anyone, and I wasn\\'t too surprised not to be able to recognize her. The really strange thing was that she had spoken to me. Because it wasn\\'t just a question of her identity, but also, and above all, of mine. I was so convinced of my own invisibility, of the utter ordinariness of my features, that I felt this could only be a miracle. It must have something to do with the marks on my nose, I thought, raising my hand to touch them.\\n\\n\"What happened to your little nose?\" she asked with interest, smiling.\\n\\n\"I got bitten,\" I said, without going into details, not because I didn\\'t want to tell her the whole story (I promised myself I would, eventually), but to be polite, not to bore her, not to waste her time.\\n\\n\"How awful! Was it a friend, a naughty boy? Or a doggy?\"\\n\\nHer insistence annoyed me. It showed that she hadn\\'t appreciated my politeness. I was impatient to change the subject, to get things clear between us; then I would be able to tell her the story of the bite in graphic detail. I shrugged my shoulders impatiently, with a faint smile.\\n\\nAs if she had read my mind, she changed tack. \"Do you remember me?\"\\n\\nI nodded, with the same smile, but a little more relaxed and charming now. She gave a visible start, but regained control immediately. She smiled again, more broadly. \"Do you really remember?\"\\n\\nI had said yes simply to be polite, to reciprocate, since she knew me.\\n\\nI nodded again, but this time the', \"<|endoftext|>'s no major drugs battle – it's not as if you can say there's these pubs and there's those pubs where there are protection rackets.' None of the usual reasons, then, for violence between communities.\\n\\nTogether we drove through Croxteth, and Chris pointed out the school where all the gang members went. 'It's amazing,' he said. 'You've got forty or fifty kids all bordering on gang warfare that grew up as children together.' It was certainly a strange scenario. There seemed to be no reason for this divisive hatred. I wondered if I might be able to find out more. Chris didn't sound very hopeful. 'One thing that they have in common, other than the fact that they're extremely violent and they wear the same clothes, is they have a strict code of silence. Both factions. They will not grass on each other.'\\n\\nA code of silence. I was worried that this might be an obstacle in my quest to get close to some of the youth gangs of the city. Just a couple of days in, however, we got a lucky break. A group of gang members from Norris Green agreed to meet me at a secret location; what was more, they agreed to bring with them some of the weapons they used in their ongoing war with the Croccy Crew.\\n\\nI never got to see the faces of the Norris Green gang members. They all wore what appeared to be almost a regulation uniform: black trousers, black hoods and their faces covered by the high collars of their black anoraks. Consequently I couldn't tell by looking at them how old they were. Their voices, though, did not sound exactly elderly. As I interviewed them they sat in a line. Two of them carried samurai swords; a third was wielding an evil-looking weapon consisting of two curved blades shaped like horns around a central handle. It was the sort of thing you might expect to see in a medieval armoury, not in the fist of a young man from Liverpool in the twenty-first century.\\n\\nI asked them what would happen if one of the Croxteth Crew walked in at that moment. They answered almost in unison. 'We'd chop his head off. Stick this through his neck. And then I'd still carry on stabbing him even though his head weren't still on his neck.' Without seeing their faces, it was difficult to judge how much of this was bravado, but their voices were dripping with contempt and aggression. You certainly wouldn't want to be a Croxteth lad alone in the presence of these guys.\\n\\nI wanted to understand where this hatred came from. I put it to them that there wasn't much in the way of a drugs trade in the area, and they agreed with me. 'There was at one time,' I was told, 'but it's dying down now.'\\n\\nDid they know _why_ it was dying down? 'Because the people involved,' they told me, 'have all been nicked. Or shot.'\\n\\nAnd had any of them ever been shot at?\\n\\n'Yes,' they all replied immediately and at the same time. One of them had actually been hit in the top of his leg. It went through the bone and broke his leg. He didn't know exactly what weapon had been used to shoot him, but he thought it was a nine-millimetre pistol.\\n\\nSo if they weren't fighting over drugs, what _were_ they fighting over? What was at the root of it all?\\n\\n'It's just gangs. Two fucking different gangs, both arguing. It's like that everywhere in the world. Two gangs always fighting.'\\n\\nAnd do they see any end to it?\\n\\n'No. There won't be an end unless everyone fucking dies.'\\n\\nThey sounded pretty sure about that. With that thought in mind, I wanted to know how easy it was for a young gang member in Britain today to get their hands on a gun. How would they go about doing it?\\n\\n'Phone someone,' they answered evasively. 'Get it dropped off or go and pick it up.'\\n\\nAnd how long would that take?\\n\\n'About five minutes, if that.' They seemed confident that they could put their hands on any firearm they wanted from a nine-millimetre pistol to a shotgun to assault weapons. The idea of street gangsters in Liverpool packing AK-47S was a sobering one.\\n\\nI wondered if they used drugs. 'Only on the weekend,' they told me. And only marijuana. What about the harder stuff? Is there any crack out there, any smack? 'We don't touch that,' they told me forcefully. But people take it in the area. 'There's smackheads everywhere.' The gang members' opinions of such people, like most of their opinions, were robust. 'Horrible scumbags. Kill them too\", '<|endoftext|>, rain streaming down his long black hair, had met him by the horse lines with a bear hug of genuine delight. In a way, both of them knew it hadn\\'t really mattered.\\n\\nThis was another question entirely.\\n\\nAnd he knew that whatever he said, Moggin was going to die.\\n\\nThe worst of it was that Ari was perfectly right. Trapped between the floods, the mutiny that he could feel through his skin brewing in the violence of the tavern and the horrifying plethora of possible misfortunes, they couldn\\'t risk it. If he were still commander he wouldn\\'t even be asking the question.\\n\\nBut he wasn\\'t commander. He was a wizard unschooled, facing an enemy he knew was beyond him, and this man was a teacher.\\n\\nIf, that is, he wasn\\'t the enemy himself.\\n\\nQuietly, he turned back to Moggin. \"What were you doing the night I came in to kill you, if you aren\\'t a mage?\"\\n\\nThe scholar sighed, and ran his hand over the lower part of his face again, aged by two days\\' growth of gray stubble and disfigured by a swollen lip under which a side tooth could be seen to be missing. In a low, beaten voice he said, \"Trying to raise magic.\" He lifted his eyes to the Wolf\\'s again, wry and hopeless but with a kind of ironic amusement at himself. \"I knew it was stupid. Drosis had told me hundreds of times I hadn\\'t the smallest glimmering of it and that all the spells in the world weren\\'t going to work if I did them, but... I don\\'t know. The spells were there, in his books. For weeks, I\\'d been working the weather-spells, trying to summon storms—anything to end the siege. I knew what was coming... or I thought that I knew. I\\'m not sure what I would have done if I\\'d realized then...\"\\n\\nHe fell silent, staring down at his swollen hands. Sun Wolf knew what he himself would, have done, had he known in advance that the woman he loved and children he cherished would die as Moggin\\'s had. The scholar was, he guessed, his own age and, in those forty years, had lived in the contented comfort of his inherited riches. Without a doubt, he had never killed anyone and wouldn\\'t know how to go about it painlessly.\\n\\nAfter a time, Moggin sighed and pushed back his greasy hair. \"Well, I had to try—with what success you could see, because of course it didn\\'t rain a drop. And I must say I felt extremely foolish, standing there in the study in the middle of the night, muttering incantations with candles all around me—besides the fact that, if I was seen by anyone, it would cost me my life. Two or three people in town had already been lynched for witchcraft, and, of course, since I was Drosis\\' friend, there\\'d been talk about me for years. Rianna...\" He broke off, his jaw and his blistered hands clenching tight. \"My daughters used to be teased about it at school. But before the siege, it wasn\\'t a serious matter.\"\\n\\n\"That wasn\\'t weather-witching you were doing,\" the Wolf said softly.\\n\\n\"No.\" He shook his head. \"It was—was a spell to raise power out of the bones of the earth, to add to a wizard\\'s power in time of extreme need. In Drosis\\' books, it was surrounded by warnings, but by then I—I could see our defenses weren\\'t going to last.\" He looked over at Ari. \"It wasn\\'t to turn against your men, you know, Captain. I—I don\\'t think I could do that—even now I don\\'t think I could. It was just to get my family to safety. In any case I doubt it would have worked...\"\\n\\n\"It wouldn\\'t have,\" the Wolf said. \"Not if you weren\\'t mageborn to start with.\"\\n\\nMoggin made a rueful, broken sound that might have been a laugh. \"Even if I had been, you scotched that pretty effectively by telling the Duke—I barely got the marks rubbed out before his men returned. I was going to try it again the following night...\" He broke off suddenly, turning his face aside as it contorted again with grief, horror, and the effort not to weep. In bitter silence, he hugged himself, fighting not to remember the events of that last night with his family and their murders on the morrow.\\n\\nSun Wolf looked away, remembering the bodies on the terrace, and met Ari\\'s stony gaze.\\n\\n\"If he\\'s not mageborn he\\'s no threat to you,\" he said quietly.\\n', '<|endoftext|>. \"I\\'m talking about the last set. They\\'ve all set out to be full-fledged doctors, saving lives...\" She clasped her hands together and turned her head upward in feigned wanderlust. \"Surely, by now you\\'ve found at least one you like.\" she said, turning to Phoebe and out of her mock performance.\\n\\n\"Well, yeah, a few. I feel like most of \\'em just went along with Harrier, though. They\\'re all too aggressive with treatment, and that\\'s gonna put a lotta strain on a lotta people, includin\\' us.\" Phoebe spoke as she moved, organizing a stack of charts that she had been neglecting.\\n\\n\"Well, I happen to know that there\\'s at least one that you\\'re \\'interested\\' in.\" Denise nudged Phoebe\\'s side, a clear hint of her meaning.\\n\\n\"W-what? What are you talkin\\' about.\" Phoebe looked around frantically, her cheeks turning a deep shade of red.\\n\\n\"So, who is the lucky guy?\" Denise asked, her chin resting upon her interlaced fingers.\\n\\n\"I thought you knew all about him already.\" Phoebe retorted in a somewhat mocking tone.\\n\\n\"Oh, no, not at all. I\\'ve seen you talkin\\' with someone recently, but I got no clue who he is. I was just tryin\\' to get a reaction outta ya.\"\\n\\n\"Pfft. Some friend you are.\"\\n\\n\"Come on, seriously. I wanna know.\"\\n\\n\"You always wanna know.\" Phoebe raised her voice, genuinely aggravated with Denise\\'s prodding. \"Maybe I just want to keep this to myself for now, at least until I\\'m sure this is something I actually want.\"\\n\\n\"Watch your language, ladies. You\\'re on the clock.\" A stern voice arose from behind Phoebe. Turning to investigate, the pair watched as Dr. Harrier strode quickly around the corner.\\n\\n\"Sorry, Doctor.\" Denise offered in response. Harrier\\'s pace didn\\'t slow, and seconds later, she was back out of sight.\\n\\n\"Well, in any case, you\\'ll probably get to know him a whole lot better soon. We\\'re really hittin\\' things off. I\\'m just waitin\\' for him to ask me somewhere.\"\\n\\n\"You don\\'t think that\\'s a little archaic?\" Denise asked, skeptical.\\n\\n\"I think it\\'s romantic, and nice.\" Phoebe retorted, partly in jest.\\n\\n\"Well, just don\\'t wait too long. He might give up if you don\\'t seem interested.\"\\n\\n\"I don\\'t think I\\'ve gotta worry about that.\" Phoebe replied as a loud tone alerted her to a request for her help. She jogged around the desk before heading down the hall, toward the source of the page.\\n\\nAfter brief preparation, Phoebe entered the operating room to find the chief of surgery, Dr. Barlow, and the newly-christened Dr. Neuberry. The patient was an elderly woman, likely in her mid-70\\'s. Her abdominal region was exposed to the room, the rest of her covered with a blue blanket. Bright lights hung from swivels in the ceiling, allowing for each to be adjusted. Surgical instruments were laid out carefully on a rolling metal tray-table. The door clattered closed behind Phoebe as she entered, gloved hands held in such a way as to not contaminate them.\\n\\n\"What have we got?\" she asked, her voice muffled slightly by the mask.\\n\\n\"Foreign object in the stomach.\" The surgeon spoke with a deep baritone, almost stereotypical for his African-American heritage. \"It\\'s rather large, and the procedure should be relatively simple. As such, I\\'m allowing Dr. Neuberry to lead on this one. You and I are here to make sure everything goes smoothly.\" Dr. Barlow then turned to Hanson. \"You may proceed.\"\\n\\n\"Alright.\" Hanson said, stretching his hands inside the latex gloves. \"DuraPrep.\" Barlow set a short, sponge-tipped wand/syringe into his outstretched hand. Writing on the handle portion of the wand gave instructions for use, but Hanson went straight to work applying the sterilization liquid to the patient\\'s abdomen. As he went, an amber solution liberally coated the work area.\\n\\n\"Are you sure?\" Barlow\\'s tone was both scolding and questioning at once.\\n\\n\"Y-yes.\" Hanson replied, uncertain and unnerved.\\n\\nBarlow retrieved the requested blade and set it gingerly in Hanson\\'s hand. \"Thank you.\" Hanson said quickly. Phoebe could sense that something', '<|endoftext|> later, \"that Incarsyn did the most tactful thing he could. The business about \\'messages from my people\\' was all my granny\\'s second-best mail shirt, but as a reason for leaving, it would pass. If Osgard hadn\\'t been damn drunken fool enough to push it, people would have gotten used to the idea in six or ten months that he wasn\\'t coming back to wed Tazey, without ever having to insult Tazey by saying it out loud.\" He picked up his cards. \"Isn\\'t there anything in that deck below a nine?\"\\n\\n\"Stop complaining; you dealt this hand.\"\\n\\n\"Bloody Kaletha\\'s taught you how to hex decks.\"\\n\\n\"Yeah. And if you\\'d hung around with her long enough, you\\'d have learned it, too. How\\'s that for a crib?\"\\n\\n\"Damn Mother worshipper.\"\\n\\n\"At least I don\\'t worship sticks and old bottles, like some barbarian ex-commanders of mercenaries I could name but won\\'t, because they\\'re present. Fifteen two, fifteen four, and a pair is six plus those are all the same suit...\"\\n\\n\"I see \\'em.\"\\n\\n\"...and two for thirty-one...\" She moved the peg neatly around the cribbage board in the flickering ochre firelight.\\n\\nSun Wolf grumbled again, \"Damn Mother worshipper.\"\\n\\nIt was growing late, but few people had left the Hall. The storm still howled around the walls; the hot air was thick with dust and electricity and heavy with the unventilated stinks of torch smoke, cooking, and stale sweat. Underservants had taken up the trestle tables, but at least half of those who had eaten supper were still there. Now and then their voices would rise, sharp and angry, as the crackling air shortened tempers and made speech careless. Then silence would fall again as they all realized once more their unwillingness to leave, and the wind would moan among the rafters like the grieving damned.\\n\\nIt would be a long way, Sun Wolf reflected, down those dark corridors to rooms where they\\'d lie alone, listening to that wind and wondering whether Nexué and Egaldus had seen anything of their killer before they died. Even the lower servants and guards, whose dormitories opened off the main Hall, clustered still around the hazy pools of muddy torchlight, perfectly prepared to wait out the storm. Contrary to custom, the doors of both the Men\\'s Hall and the Women\\'s stood open. Upper servants—the chief cook, the dancing master, musicians, and clerks—who had their own chambers, nodded sleepily over games of cards and backgammon; the chief scribe was curled up, unabashedly asleep in a gloomy corner.\\n\\nSun Wolf stared moodily out past his unsatisfactory collection of fives, sixes, and unmatched royalty, wondering if it was the same in those halls on the fringes of the empty quarter which had been given over to Incarsyn and his retinue. He\\'d sized them up when he\\'d been taken through to Illyra\\'s quarters and knew them as hardened warriors who feared neither man nor the desert\\'s cruelty.\\n\\nBut this was different, this death which could be neither fought nor fled. The demons of Wenshar returned to his mind, the moony, phosphorescent forms that had flicked in the corner of his vision in the silence of the empty quarter, and the way those cold, glowing shapes had clustered during the storm, thick as bees at swarming time, beneath the windows of the temple in Wenshar.\\n\\nHe wondered where Kaletha was and exactly when in the confusion she had slipped from the Hall.\\n\\nStarhawk was looking inquiringly at him over her flat-folded hand of cards, the slight crease of pain more marked on her forehead. He laid his own cards down quietly. \"I\\'m going out to have a look around. The storm\\'s fading,\" he added, as she started to protest. \"The heart of it\\'s off south, anyway.\"\\n\\n\"Be careful.\" She said it casually, but in her eyes he saw she didn\\'t mean the storm.\\n\\nHe shook his head. \"I feel—I don\\'t know. I don\\'t sense any danger—not like last night. In any case, it\\'s not midnight yet, or anywhere near. The other attacks were all between midnight and dawn. I won\\'t be long.\"\\n\\n\"I seem to remember hunting you for two or three months after the last time you said that,\" Starhawk remarked, collecting the cards and shuffling them competently. \"But have it your own way.\" She was laying out a hand of solitaire as, cloaked in shadow and illusion, he drifted for the vestibule.\\n', '<|endoftext|>DEPENDENCIES}}\\n// Microsoft Visual C++ generated include file.\\n// Used by updater.rc\\n//\\n#define IDD_DIALOG 101\\n#define IDC_PROGRESS 1000\\n#define IDC_INFO 1002\\n#define IDI_DIALOG 1003\\n#define TYPE_CERT 512\\n#define IDR_PRIMARY_CERT 1004\\n#define IDR_BACKUP_CERT 1005\\n#define IDS_UPDATER_IDENTITY 1006\\n#define IDR_XPCSHELL_CERT 1007\\n#define IDR_COMCTL32_MANIFEST 17\\n\\n// Next default values for new objects\\n//\\n#ifdef APSTUDIO_INVOKED\\n#  ifndef APSTUDIO_READONLY_SYMBOLS\\n#    define _APS_NEXT_RESOURCE_VALUE 102\\n#    define _APS_NEXT_COMMAND_VALUE 40001\\n#    define _APS_NEXT_CONTROL_VALUE 1008\\n#    define _APS_NEXT_SYMED_VALUE 101\\n#  endif\\n#endif\\n<|endoftext|>Yang stared at Ozpin uncomprehendingly. Why was he here? She was looking for her friends, and for Ruby. Maybe he knew where they were.\\n\\nHe stared back at her, a grim look visible over his thin glasses. She wanted to say something, but found that she simply couldn\\'t. She simply stood, rooted to the spot, still staring at Ozpin with a bewildered look.\\n\\nHe drew in a deep sigh, then spoke, breaking the silence.\\n\\n\"Hello, Yang. You\\'re looking well this evening. Well, considering the circumstances, I suppose. I\\'m guessing you don\\'t have much of a clue as to what\\'s happened, do you? No idea how long you\\'ve been away?\"\\n\\nYang felt her jaw move as she tried to speak, but the muscles in her throat weren\\'t working well at the moment. She felt some annoyance at this fact, but mostly just felt stunned. There was something about the situation that she couldn\\'t quite wrap her head around. Nothing seemed to have changed too much, other than her friends being gone.\\n\\nShe shook her head, and Ozpin nodded. He spoke again, saying, \"That\\'s unfortunate. Well, in any case, allow me to explain what\\'s going on, at least from my perspective.\"\\n\\nHis shoulders dropped, and he seemed suddenly more tired than Yang had ever seen him, his face falling and back slumping over. \"Perhaps you should sit down. I don\\'t expect this to be a pleasant conversation for either of us.\"\\n\\nHe motioned toward Yang\\'s bed, and she followed his direction, still unsure of what to do. She was starting to come out of her stupor, but still couldn\\'t quite focus too well. She sat on her own bed, facing Weiss\\'s bed, and Ozpin walked over to lean against it, putting a shoulder against the wooden frame, and resting the rest of his weight on his cane.\\n\\n\"Well, to start with, you were proclaimed dead roughly a week ago. You were found in the Emerald Forest, and estimated to have been there for several days. You had several broken bones, indicating that you had sustained a heavy blow. The distance into the forest also indicated that it was the launching pads that had been used to move you, but your body hadn\\'t been touched, not even by natural creatures who would take advantage of your corpse. I thought there was something off about that, and opted to keep your body, just in case.\"\\n\\nYang raised an eyebrow and repeated the words, \"Just in case?\"\\n\\nOzpin nodded, and said, \"Yes, you see, I knew what was going to happen. It might come as a surprise to you, but this will not be the first time I\\'ve dealt with a situation like yours. When your body was retrieved, I was present, and saw the signs of what had happened. Doctors who examined you said that you showed signs that would suggest you bled to death, but the bite on your neck would have been too small to cause that kind of blood loss. I had your body set aside for further examination, and \"forgot\" schedule another examination.\"\\n\\nHe took a deep breath and continued, \"Your sister had gone missing that day as well, and at first I thought she was out looking for you. I had seen her earlier that day, and she seemed quite distressed. I generally try to refrain from taking too much interest when it comes to my student\\'s personal affairs, but when I saw the bite on your neck, it became clear that my intervention was necessary. I\\'m sure you\\'ve noticed that the city was rather empty tonight, I couldn\\'t risk anything happening, so I had that part of the city closed down so', '<|endoftext|> in slacks and a blouse and earrings, a jacket over her arm. She didn\\'t care for fried eggs, asked if they had any real coffee and settled for freeze-dried instant. Stick got up the nerve to ask her a few questions while she drank her coffee and read Shirley Eder and Earl Wilson. Her name was Marlys. She was twenty years old, not a brain surgeon, she worked in the office of a department store as a secretary.\\n\\nMarlys grabbed her jacket and purse, yelled into the bedroom, \"See you, sport,\" and was gone.\\n\\nWhen Frank came out in his jockeys with the empty glass, looking like he\\'d been through major surgery the night before, Stick said, \"What\\'s Rule Number Nine?\"\\n\\nFrank said, \"For Christ sake, lemme alone.\"\\n\\nHe looked terrible first thing in the morning, his hairdo mussed up and needing a shave, sad, wet eyes looking out of a swollen face. Stick could understand why the colored girl was anxious to leave. Frank\\'s bedroom probably smelled like a sour-mash still.\\n\\n\"Don\\'t feel so good, uh?\"\\n\\n\"I\\'m all right. Once I have some breakfast.\"\\n\\n\"You throw up yet? Get down there and make love to the toilet bowl?\"\\n\\nFrank didn\\'t answer. He turned the fire on under the pan of water.\\n\\n\"Rule Number Eight,\" Stick said. \"Never go back to an old bar or hangout. You go to Sportree\\'s.\"\\n\\n\"An old hangout. I\\'ve been there twice, three times.\"\\n\\n\"Rule Number Nine. Never tell anyone your business. You pick up a broad, her mother knows what you do.\"\\n\\n\"She doesn\\'t know me,\" Frank said, \"not by name. We never met.\"\\n\\n\"Never tell a junkie even your name,\" Stick said. \"The place is a dope store, full of heads. Rule Number Ten—you want another one? Never associate with people known to be in crime. Your friend Sportree—into many things, right? beginning with dope—and probably everybody else in the place.\"\\n\\nFrank jiggled the pan of water to make it boil faster. \"The guy\\'s a friend of mine. I talked to him for a while, then Marlys came in, we been getting to know each other.\"\\n\\n\"Marlys,\" Stick said. \"I thought you went out with Karen.\"\\n\\n\"I went out with Sonny, since we\\'re keeping records. I ran into her coming in, waited an hour while she changed into an identical outfit, and we went out, had dinner.\"\\n\\n\"Yeah?\"\\n\\n\"Yeah what?\"\\n\\n\"What happened?\"\\n\\nFrank looked over from the range. \"It\\'s a long, boring story. For your record, Sonny doesn\\'t kiss and hug on the first date. Maybe not on the second or third or fourth, either. Maybe she never does. Maybe not even if you married her.\"\\n\\n\"What\\'d you do, try and rape her?\"\\n\\n\"I bought her dinner. Forty-eight bucks with the tip. She takes a couple of bites of filet and leaves it. We come back here, it\\'s nighty-night time, that\\'s it.\"\\n\\n\"What\\'d you talk about?\"\\n\\n\"Her. What do you think? She\\'s in a couple of Chevy ads, you\\'d think she was a fucking movie star. I told her I\\'d been there already, used to take out a girl was in the movies. She isn\\'t even listening. You tell her something, she\\'s thinking about what she\\'s going to say next about herself. It\\'s not worth it. Forty-eight bucks—I say, You want to go somewhere else, hear some music? No. How about, I know a place we can see some interesting characters. No.\"\\n\\n\"So you went alone.\"\\n\\n\"I couldn\\'t find anybody and it was just as well I didn\\'t,\" Frank said, \"since I ran into Marlys.\"\\n\\n\"She must be pretty good.\"\\n\\nFrank looked over again as he took the water off the fire.\\n\\n\"Buddy, it\\'s all good. Like chili, when you\\'re in the mood. Even when it\\'s bad it\\'s good.\"\\n\\n\"I guess so,\" Stick said. \"Matter of degree.\" He waited a moment, then said it. \"I never done it with a colored girl.\"\\n\\n\"Or a Jewish girl, as I recall,\" Frank said. \"Only White Anglo-Saxon Protestants.\"\\n\\n\"No, my wife was a Catholic at one time, when we first got married. There was another girl I used to go with when I was about eighteen, she was a Catholic', '<|endoftext|> unrestful night was beginning to tell on me: fatigue made every insult more alarming, every new drop of information more portentous. Hoping to encourage him to share more of the latter, however upsetting his attitude, I proffered more detail: \"We\\'ve always valued education from a young age. I knew three languages well by the time I was twelve.\" I regretted that last as soon as I said it, and hoped he didn\\'t ask me which three. I supposed I could count my shoddy Latin, though my parents certainly wouldn\\'t have.\\n\\nSheldon nodded enthusiastically in the face of a theory confirmed. \"That sounds like Freddy. Always eager to learn—a little brusque, like your brother here, but that\\'s understandable, really. I didn\\'t think the intellect could come from his father\\'s side. Miss Laverne admitted that the man was a negro, obvious enough from the boy\\'s skin, and they\\'re hardly known for intellectual pursuits.\"\\n\\nCaleb stiffened, then took a slow swallow of scotch. \"Actually, my fiancée is negro. And she speaks five languages—I saw her pick up the last two in about six months, at the same time.\"\\n\\n\"Well, there are always exceptions. I don\\'t suppose she\\'d be interested in coming in? In any case, if Freddy is any indication, I commend you on what\\'s likely to be a profitable match.\" He smiled and put his glass down. \"And an unusual one, I imagine. Your skull structure is really extraordinary—whatever lineage you come from must be relatively isolated. A small group?\" He tilted his head invitingly.\\n\\nCaleb turned to me, teeth bared in a not entirely friendly grin. \"He wonders if we\\'re inbred, sister dear.\"\\n\\n\"Caleb...\" I said warningly.\\n\\nSheldon held up his hands. \"I don\\'t mean any offense. It\\'s as common in the highest lineages as in the low. Look at any aristocratic family, and you\\'ll see an astoundingly similar conformation—perhaps two noses or chins to choose from, but the skull shapes will be almost identical. Weak hearts may take them down young, but the advantages of their lines are still clear. I only meant that your bone structure is so very unusual—and in all my practice Freddy and his mother are the only examples I\\'ve seen. So it\\'s clear you keep to yourselves.\"\\n\\n\"We\\'ve tried.\" I breathed in sharply, out slowly. \"Please forgive my brother. Our neighbors in Massachusetts used to accuse us of incest.\" Caleb and I had spent hours debating how much or how little we could tell him—and before Caleb brought it up, I thought we\\'d agreed to avoid this part. Now I had little choice. \"Nor was that the worst of the libels. Eventually, those lies reached the government and brought soldiers down on Innsmouth in a massive raid. I don\\'t care to discuss the details, but they treated us harshly. Only my brother and I survived.\" No need to add: on land. Though the image of Sheldon meeting our grandfather and asking to examine his skull made me suppress a huff of amusement in spite of the tension.\\n\\n\"That\\'s why we\\'re here,\" I continued. \"To find any distant relatives who may have survived. The Lavernes are the first lead we\\'ve found.\"\\n\\nSheldon\\'s eyes had widened. He started to raise his drink, shook his head, put it back down. \"I\\'m sorry for your loss. I didn\\'t mean to pry into a painful subject. Of course I\\'ll put you in touch with Freddy and Miss Laverne. And surely you\\'ll want a better understanding of your type—with proper measurements, sketches, an understanding of developmental courses, it will be far easier to find more of your cousins.\"\\n\\n\"I know,\" I said. I ducked my head, shoulders stiff against the surrender. Caleb, his anger withered, looked at me anxiously.\\n\\nWe sat rigid while Sheldon bustled with rulers and measuring tape, a gridded notepad, and various oddly shaped metal contraptions. He seemed not completely oblivious to our discomfort, and filled the silence with murmured numbers and expressions of pleasure in our bones.\\n\\n\"Well, there,\" he said at last. He traded the pad for a larger sheet of thin paper, and began sketching. \"Thank you—I hope I\\'ll be able to find more of your kinfolk. At the very least, there are the Lavernes. Give me a moment to get this down, and I\\'ll write out a letter to assure her of your relationship.\"\\n\\n\"Thank you,\" I said, trying to sound grateful. I knew gratitude was warranted, for he offered a true gift, but', '<|endoftext|> footsteps padded softly past my prone, shivering body, I sensed the first tremors in the motor. A faint ticking which erupted into a ferocious roar, calming to a shuddering halt. Silence, everywhere. Honey was instantly roused from his sleep; he spoke to Kunichika in hushed, angry tones. When I approached them, Kunichika was standing at the side of the boat, peering into the inky depths of the water.\\n\\n\"Don\\'t worry,\" he said, beginning to unbutton his shirt as he prepared to dive overboard. \"It\\'s only a small thing, I\\'m sure.\"\\n\\nWE DRIFTED PLACIDLY on the windless sea, so slowly I could barely discern the boat\\'s gentle pirouettes. The flat and unbroken surface of the water spread silently around us; the empty horizon offered us no hope. The absence of gulls was strange, Kunichika said: we couldn\\'t have been far from land. The truth was that we might have been two miles or two thousand miles from our destination and we would not have known.\\n\\nNight brought relief from the scorching intensity of the sun. \"It also brings out the beast that lurks within every man,\" I said to Snow. \"Witness.\" I motioned at Kunichika, who was attempting to repair the boat. He tore at the machinery as if butchering a carcass. Sometimes he used tools, often he used his bare hands. When finally he gave up and sat down with his maps, the light from his lamp lit his grease-streaked face. \"He looks like an animal, one of those fox things—the ones people say are incarnations of ghosts,\" I said.\\n\\n\"You mean a civet cat,\" she replied.\\n\\n\"That\\'s the one.\" I searched the darkness for signs of light.\\n\\n\"Peter,\" Snow said, lowering her voice. She placed her hand on my forearm. \"I\\'m worried. About Johnny.\"\\n\\nMy arm tensed sharply at her unexpected touch, and I pulled away involuntarily for a brief moment before allowing her hand to settle once more. \"Really?\" I said, continuing to peer into the dark. \"It\\'s only seasickness, I expect.\"\\n\\n\"Come on, Peter,\" she said, her fingers gripping my arm. \"You know as well as I do that his fever has nothing to do with his body.\"\\n\\n\"Hasn\\'t it? I honestly can\\'t see what else it might be if it isn\\'t seasickness. Perhaps homesickness?\"\\n\\nShe turned to look at me, but still I looked into the infinite night. \"He hasn\\'t got a home—how can he be homesick? You know him better than anyone, I think, even better than I do. You\\'re very fond of him, aren\\'t you?\"\\n\\n\"We\\'ve become good friends, I suppose.\"\\n\\n\"You mean a lot to him, you know.\"\\n\\n\"Do I? Can\\'t think why.\"\\n\\n\"If anything happens\"—she stopped and laughed a gentle, snorting laugh—\"if anything happens to me, to us, you\\'d look out for Johnny, wouldn\\'t you?\"\\n\\nIt was a murky night, the moon a dab of white on the black paper sky. I said, \"Yes, of course.\"\\n\\nShe fell silent.\\n\\n\"Of course I would,\" I said, in a lighthearted voice, \" _if_ anything happened. I mean, we\\'re a long way from the war, and who knows—it might never get to the Valley. In any case I doubt very much I\\'ll be in a better position than you if we _are_ invaded.\"\\n\\n\"I don\\'t just mean the war,\" she said quietly.\\n\\n\"What, then?\"\\n\\n\"I don\\'t know—everything. I wish I could tell you about Johnny. I wish you could know everything, Peter.\" She drew her hand away, and instantly I wished she would touch me again.\\n\\n\"Tell me,\" I said. \"Please.\"\\n\\n\"Just promise you\\'ll help. Do it blindly, don\\'t ask why or when or anything else. Just think of Johnny, and promise.\"\\n\\nAnd so I did. I promised.\\n\\nHoney\\'s whisky-saturated body lay nearby. He had been snoring fitfully and now he began to mumble incoherently in the surly tones of a schoolboy. His legs kicked out and his fists jerked violently; his voice became compressed, prepubescent, demanding. I felt laughter well from within me, dancing from my stomach to my throat, and I could not stop. Snow began to laugh too, her shoulders shaking. It was only when I had stopped to draw breath that I realised she was no longer laughing but crying. I did not know what to do—my', '<|endoftext|> even as her justifications seemed logical and rational, a stab of completely irrational pain sliced through her heart at the wounded, betrayed expression on his face. He looked as if he were in physical pain, and she ached to take him into her arms, kiss him, and tell him it was all a lie. For a moment, she forgot the reason as to why she couldn’t.\\n\\nBut ah, there it was. This vulnerability of his, it was all but a lie. He seemed weak and hurt and wounded now, but the moment that she gave in, the moment that power returned to his hands, he would only use it to wound, to control her. And she could not allow that.\\n\\nSo she lied, and continued to lie. The words came easily now, flowing smoothly past her lips, so plausible that even she began to half believe them. “You’re not a fool, James. Surely even you must see that those...times...we were together...they meant nothing to me? A drop in the ocean, so to speak. And I can’t even say that I really enjoyed them - I don’t enjoy being forced.” A half truth...she had enjoyed it, involuntarily, but she wasn’t going to let him know that.\\n\\nThere was a long, grim silence, then, “You could be pregnant,” James said suddenly, a triumphant look in his eye.\\n\\n“I could,” Emma agreed. “But then again, I might not be. And even if I was, there’s no guarantee the baby is yours, James.” She watched his face, saw his eyes darken with pain, and rage, and felt the fist around her heart clench tighter. It was for the best, she told herself fiercely. She had to be strong. “Besides which, we do live in age where we can now get rid of such...inconveniences...” Not that she ever would, of course. But he didn’t have to know that.\\n\\n“You wouldn’t.” He ground out the words.\\n\\nShe shrugged. “Maybe I would, maybe I wouldn’t. In any case, it’s a moot point, James. I’ll deal with it if and when it happens.”\\n\\n“If you hurt our baby...” Emma opened her mouth to deny the existence of any such, but he cut her off. “Very well,” he bit off, rising to his feet. “If that is the way you wish it to be.” He inclined his head briefly to her, then, stiffly, walked out.\\n\\nAnd Emma closed her eyes against the irrational tears that seemed to seep out, no matter what she did.\\n\\n***\\n\\nHome, at last, finally. It had been more than two weeks since her departure from the Brandeworth Estate, and it seemed that those few days spent were destined to come back and bite her on the posterior, no matter how long it had been since she’d left. First there had been the small matter of her brother - she’d abandoned him there and taken their car, and so had had to come back and pick him up. Then it turned out Luc - her supposed fiance - had actually gone off to France to be married, when he had been supposed to be spending time with her and proving to the world just how unaffected she was by James. Hell, she should have had a month, at least, of respite from the world, supposedly as Luc’s impromptu fiance. Who knew, maybe James would be knocking on her door at any minute. And now, with this last little development she’d only recently discovered...well, she’d deal with it. She always did.\\n\\nShe dropped her keys on the table in the hallway and trudged to the small, cramped kitchen, dumping her groceries on the old watermarked bench. Feeling too fatigued to do much more than that, she went to her bedroom, ignored the hole in the floor, kicked off her shoes and flopped onto the bed, closing her eyes for a quick catnap.\\n\\nAlmost immediately, however, her eyes sprang open again. Creak, creak, creak. No, so she wasn’t imagining it. Kylie the Sex Kitten from upstairs was hard at work already. It wasn’t hard to imagine doing what, either.\\n\\nEmma groaned. It was bad enough at night, but even now? Didn’t the girl ever rest? Eat? Sleep? She glanced at the clock. Seven thirty. She ought to probably eat - after all, she couldn’t afford not to.\\n\\nIt was nine by the time she’d finished the dishes and tidied everything up. She went to take out the trash - then stopped halfway through the doors as the elevator doors opened, and a familiar, tall']\n","layer 4\n","733 ['<|endoftext|> right now, as to which of us has the indisputable right to an augmentation of square metreage.”\\n\\n“We’ve got more right than anybody,” decided Lyuba immediately. “Because there are three of us living together, and what’s more we’ve got a mother who’s single.”\\n\\n“The more so because I’m heterosexual,” added Pyotr.\\n\\n“Seems you’re a bit too literate,” Fonderviakin said to him.\\n\\n“No, Comrades, this approach is wrong, quantitative somehow,” said Anna Olegovna, and proudly shook her violet ringlets. “Let’s look at the qualitative side of the affair: here my Dmitry is already a young man, and it’s still on and on having to share a room with an old woman….”\\n\\nAt this point Anna Olegovna looked angrily at Fonderviakin and concluded just in case, “And don’t you even mention your preserved apples, Lyov Borisovich!”\\n\\n“Right!” Mitya spoke up. “Only let’s dispense with the demagoguery! Because now they’ve dragged some kind of conscience into it….”\\n\\nFurther development of the negotiations can be painlessly omitted, inasmuch as nothing else that was fundamentally new or meaningful was said, and in general the meeting yielded no decision whatsoever. The only outcome, which emerged independently of the will of its participants, consisted in it becoming clear to all of them, that even if Aleksandra Sergeyevna Pumpianskaya was perfectly healthy, she was obliged to die by morning.\\n\\nSometime after ten that evening, the people dispersed to their own rooms, and the apartment settled down. For a time, the drone of television sets could still be heard, and then even that ended. The time for things had arrived.\\n\\nPart Four\\n\\nApartment 12 was not yet asleep, however, but rather only just preparing to turn in. Yuliya Golova was sitting at her dressing table, getting herself ready for bed, Lyubov was making up the beds while, slowly and abhorrently, Pyotr undressed. At the Valenchiks’ it was like this: having placed a newspaper over her face, Vera was already lying in bed, whereas Genrikh Ivanovich, bent very low over the dining table, scribbled audibly over a paper with his pen. Fonderviakin sat in front of the turned-off television, cutting rubber lid liners for his jars out of a bathmat. Chinarikov was reading selected speeches of Cicerone in his room, while Belotsvetov—The Pharmacology Bulletin in his own. Anna Olegovna was rustling something unpleasantly behind the antique Chinese screen with which she partitioned herself off from Mitya at night, while Mitya messed around at his table, being mysteriously busy again with some sort of glass bits, components, and multicolored wiring. As for Aleksandra Sergeyevna Pumpianskaya, she was just sitting on a chair in the middle of the room, for boredom’s sake recalling one evening long ago: it was either nineteen-twelve or ‘thirteen—before the war, she was still young, her father, mother, and brothers were still alive; the whole family had gathered in the dining room for tea; it was late in the evening, the dining room was flooded with an even green light, because an electric bulb had been set into the chandelier of aquamarine glass; the grandfather clock, presented to her father for some jubilee celebration in honor of his pedagogical activities, ticked grandly; now and then silver teaspoons clinked in Kuznetsovsk teacups, beyond the window the wind howled; Sergey and Vladimir were playing mahjong, while Georgy read Teffi out loud, holding in his left hand a candlestick in the shape of a scooped out eggshell, on a semi-transparent stearin stub, and choking with laughter after every ten words…. Good Lord, what a marvelous and darling recollection!\\n\\nAt about half past ten, Fonderviakin telephoned someone; a little later Mitya Nachalov made a bit of noise in the corridor, then Belotsvetov shuffled through in the direction of the toilet, but no sooner had he turned to the right than he was dumbfounded, because the following scene unfolded before his very eyes: in the middle of the dark kitchen, in the pale parallelogram formed by the light from the street and the window, sat Pyotr Golova on a chamber pot, holding an unfolded newspaper up in front of him. Actually, there wasn’t anything so very astonishing about this scene—most likely, Pyotr was', '<|endoftext|> 2-128.\\n[34]  Exhibit P-33.\\n[35]  P.T.O. ¶ V. 2.\\n[36]  Exhibit P-33.\\n[37]  N.T. p. 1-25.\\n[38]  N.T. p. 2-29.\\n[39]  The last day of Commonwealth\\'s fiscal year.\\n[40]  N.T. p. 2-30.\\n[41]  N.T. p. 2-30.\\n[42]  N.T. pp. 3-64 to 3-69; Exhibit P-6, Minutes of the Meeting of the Board of Directors, Commonwealth Financial Corporation, February 13, 1967. Page 2, second paragraph reads as follows: \"Mr. Thal reported the management position on the dividend to be that he was reluctant to recommend payment of the prior preferred dividend because of objection raised by a representative of First Pennsylvania Bank and because of lack of availability of funds.\" Mr. Gerber was also present at that meeting.\\n[43]  N.T. p. 3-65, 66.\\n[44]  Exhibit P-11.\\n[45]  N.T. p. 1-52.\\n[46]  N.T. p. 3-72.\\n[47]  N.T. p. 2-30.\\n[48]  N.T. p. 2-31.\\n[49]  N.T. p. 2-63.\\n[50]  N.T. p. 2-134.\\n[51]  N.T. p. 3-72.\\n[52]  P.T.O. ¶ V. 2.\\n[53]  N.T. p. 2-136.\\n[54]  Exhibit P-34, N.T. p. 2-32.\\n[55]  Exhibit P-38.\\n[56]  N.T. p. 2-33.\\n[57]  See discussion re: Madison Agency, Inc., supra.\\n[58]  N.T. pp. 2-134, 135.\\n[59]  Even absent self-dealing, the cancellation of a debt for redemption of stock under conditions existent on August 31, 1967, was a breach of fiduciary duty. See discussion, re: Clark Insurance Co., infra.\\n[60]  P.T.O. ¶ V. 3.\\n[61]  P.T.O. ¶ V. 10.\\n[62]  P.T.O. ¶ V. 5.\\n[63]  N.T. pp. 1-95 to 97, 2-96.\\n[64]  P.T.O. ¶¶ V. 3, .5, .6, .7,; N.T. p. 1-75.\\n[65]  Exhibit D-2; N.T. p. 3-32.\\n[66]  N.T. p. 1-103.\\n[67]  N.T. p. 3-35.\\n[68]  P.T.O. ¶ V. 11; Exhibit P-16, P-17; N.T. p. 2-103.\\n[69]  N.T. p. 3-51.\\n[70]  N.T. pp. 3-52, 53.\\n[71]  A large number of the accounts were owned by Leopold Weiner, members of his family and friends of his. Leopold Weiner was the president of Safeguard (N.T. pp. 3-51, 52).\\n[72]  Exhibits P-21, 22.\\n[73]  P.T.O. ¶ V. 6.\\n[74]  Exhibit P-23.\\n[75]  N.T. p. 1-123.\\n[76]  N.T. p. 2-142.\\n[77]  e. g., Ledger sheets, cancelled checks, etc.\\n[78]  N.T. p. 3-8.\\n[79]  N.T. p. 3-8.\\n[80]  N.T. p. 2-37.\\n[81]  N.T. p. 2-38.\\n[82]  See discussion, re: Madison Agency, Inc., supra.\\n[83]  Exhibit P-35.\\n[84]  N.T. p. 2-36.\\n<|endoftext|>What is your name?\\n\\nWähle eine Antwort:\\n\\nMatthew Matt<|endoftext|>SPECIES SCHMECIES This swarm of diversely patterned Heliconius butter', '<|endoftext|> even those who said that Communism had been tried in the wrong country—that Russia had been far too backward to make those wonderful ideas work.\\n\\nThat was enough to bring an ironic smile and a shake of the head. He\\'d once been part of the organization called the Sword and Shield of the Party. He\\'d been through the Academy, had sat through all the political classes, learned the answers to the inevitable examination questions and been clever enough to write down exactly what his instructors wanted to hear, thus ensuring high marks and the respect of his mentors—few of whom had believed in that drivel any more than he had, but none of whom had found within themselves the courage to speak their real thoughts. It was amazing how long the lies had lasted, and truly Popov could remember his surprise when the red flag had been pulled down from its pole atop the Kremlin\\'s Spasskaya Gate. Nothing, it seemed, lived longer than a perverse idea.\\n**CHAPTER 24**\\n\\n**CUSTOMS**\\n\\nOne of the differences between Europe and America was that the former\\'s countries truly welcomed foreigners, while America, for all her hospitality, made entering the country remarkably inconvenient. Certainly the Irish erected no barriers, Popov saw, as his passport was stamped and he collected his luggage for an \"inspection\" so cursory that the inspector probably hadn\\'t noticed if the person carrying it was male or female. With that, Dmitriy Arkadeyevich walked outside and flagged a cab for his hotel. His reservation gave him a one-bedroom suite overlooking a major thoroughfare, and he immediately undressed to catch a few more hours of sleep before making his first call. His last thought before closing his eyes on this sunny morning was that he hoped the contact number hadn\\'t been changed, or compromised. If the latter, then he\\'d have to do some explaining to the local police, but he had a cover story, if necessary. While it wasn\\'t perfect, it would be good enough to protect a person who\\'d committed no crimes in the Republic of Ireland.\\n\\n\"Airborne, Airborne, have you heard?\" Vega sang, as they began the final mile. \"We\\'re gonna jump from the big-ass bird!\"\\n\\nIt surprised Chavez that as bulky as First Sergeant Julio Vega was, he never seemed to suffer from it on the runs. He was a good thirty pounds heavier than any other Team-2 member. Any bigger across the chest and he\\'d have to get his fatigue shirts custom-made, but despite the ample body, his legs and wind hadn\\'t failed him yet. And so, today, he was taking his turn leading the morning run. . . . In another four minutes they could see the stop line, which they all welcomed, though none of them would admit it.\\n\\n\"Quick time _—march!\"_ Vega called, as he crossed the yellow line, and everyone slowed to the usual one-hundred-twenty steps per minute. \"Left, left, your left your right your left!\" Another half minute and: \"Detail _. . . halt!\"_ And everyone stopped. There was a cough or two from those who\\'d had a pint or two too many the night before, but nothing more than that.\\n\\nChavez walked to the command position in front of the two lines of troopers. \"Fall out,\" he ordered, allowing Team-2 to walk to their building for a shower, having stretched and exercised all their muscles for the day. Later today they\\'d have another run through the shooting house for a live-fire exercise. It would be boring in content, since they\\'d already tried just about every possible permutation of hostages and bad guys. Their shooting was just about perfect. Their physical condition _was_ perfect, and their morale was so high that they seemed bored. They were so confident in their abilities, they\\'d demonstrated them so convincingly in the field, firing real bullets into real targets. Even his time with the 7th Light Infantry Division had not given him such confidence in his people. They\\'d gotten to the point that the British SAS troopers, who had a long, proud history of their own, and who\\'d initially looked upon the Rainbow teams with a great degree of skepticism, now welcomed them into the club and even admitted they had things to learn from them. And _that_ was quite a stretch, since the SAS had been the acknowledged world masters at special operations.\\n\\nA few minutes later, showered and dressed, Chavez came out to the squad bay, where his people were at their individual desks, going over intelligence information from Bill Tawney and his crew, and checking out photos, many of them massaged by the computer systems to allow for the years since they\\'d originally been taken. The systems seemed to get better on a daily basis as the software evolved. A picture taken from an angle was now manipulated by the computer into a straight-', '<|endoftext|> her pretty face. Smoking hot long island teen babe Jenna Ashley explains her faveorite way to take a dick and then sucks and gets her twat pounded<|endoftext|>The following is a report from skeptic Lukas Dion Pradityo in Jakarta, Indonesia, of an investigation he conducted after learning of four local individuals with claimed psychic abilities: two with a “sixth sense,” including one who can allegedly predict the eruptions of Mt. Merapi; one “witch doctor” who can supposedly diagnose illness by touch and cure by traditional medicine; and one allegedly clairvoyant Islamic teacher. Pradityo asked each of the claimants to bring their own magical object for the test, performed double-blind tests of the claimants’ abilities, and reported back to us.\\n\\nWhen I had set up the appointment by phone, I had asked all of the claimants if they were able to detect magical objects if it were hidden under a cup. All of them said yes, so I gave them a very brief overview of the experiment. Of the four claimants, two backed down: the sorcerer from Mt. Merapi and the witch doctor from Surabaya.\\n\\nOne of the claimants from Surabaya happened to be in Jakarta recently. He had a job interview the day before and was willing to meet me at my office the following day, the 26th of November. This claimant, whom I’ll call DD, was recommended by one of my coworkers. DD arrived at my office with his cousin at around noon, about an hour late for the appointment. After the introduction I began the preliminary interview. DD is only twenty-four years old, is single, and has a diploma in mechanical engineering from a respectable university in Surabaya. He is currently working in a construction company as a project engineer in Surabaya. He claims he has a sixth sense and has had it since he was around six years old. He can sense when there are ghosts, djinns, or other spirits around him when other people can’t see them. He is also a healer and specializes in sprained limbs and broken bones. He heals people by massaging them and praying at the same time. People are healed not because of him but because of the prayer and the power of Allah through his massages. I observed during the preliminary interview that DD was calm and even-headed when I asked him about his background. When I started to ask about his abilities, he started showing signs of nervousness by brushing his left hand through his hair numerous times.\\n\\nClaimant 1, Exhibit A Claimant 1, Exhibit A\\n\\nClaimant 1, Exhibit B Claimant 1, Exhibit B\\n\\nI had asked him to bring a magical object with him for the experiment. He showed me his ring. I photographed the ordinary-looking ring next to a Rp 200 coin (Claimant 1, Exhibit A & B). The ring became magical because he always wears it when he prays. It says it always protects him from harm. He claimed that during a fight the ring helped him defeat his opponent with just a few punches. I asked him if he can feel the aura of the ring with his hands and he said yes. I then asked him if he could feel the aura of the ring if I put a coffee cup on top of it and he also said yes. Finally, I asked him if he can detect the ring if I hid it under one of ten coffee cups and he also said yes, albeit with same hesitance. I then asked him if he is willing to perform the experiment and he also said yes, but with a lot of hesitance this time. I then explained the double-blind experiment to him and also stated that I have to record the experiment with a video camera. When I asked him how many times he can correctly pick the right cup out of ten tries, he finally balked and said that his powers aren’t that strong yet—that he was only an apprentice and would probably fail the test. I encouraged him to take the test just for fun without the video camera and he finally agreed.\\n\\nBy coincidence, my coworker who recommended DD was also at work that day, so I had asked him to be my assistant. After I explained the protocol to him, we started the double-blind experiment. The procedure is exactly the same as the one with the sorcerer in the article “A Mug of a Different Color”, but this time I used a meeting room for the experiment, a hallway for my coworker to hide behind, and another hallway to the toilet. DD was with me the whole time and we never saw my coworker during the course of the experiment.\\n\\nI am happy to report that even though my assistant and the claimant are old friends, the double-blind experiment still worked. Out of five tries, DD missed all of them! He then quit after the fifth try. Once again he said that he is still an apprent', '<|endoftext|> under her supervision, assisting her in the apprehension of the dangerous criminals.\\n\\n\"Does this make us, like, Deputy Huntresses now?\" Beryl asked humorously.\\n\\nEvie giggled lightly, bumping her with her shoulder from where they sat against a stall selling textiles. \"I don\\'t think you get a badge or anything.\"\\n\\n\"Yet another preview of what lies ahead of us,\" Lustre mused thoughtfully from the other side of Beryl. \"It will not always be the fighting of Grimm.\"\\n\\n\"Well, we kinda get a choice though, right?\" Evie asked with a trace of concern. \"I mean, I enjoy fighting Grimm and all, but this… Don\\'t get me wrong, I\\'m more or less okay with having… killed two of them, but…\"\\n\\n\"It\\'s not what we signed up for,\" Beryl agreed quietly. \"And yeah, I\\'d think we would have some choice in what we do. Unless we attach ourselves to an organization, like the Specialists in Atlas.\"\\n\\n\"Precisely,\" Lustre said softly.\\n\\nBeryl eyed where Pip and Merri stood near the officers in charge of the scene, reciting their depositions yet again. She was again reminded forcibly of her earlier epiphany and cleared her throat before finally voicing her thoughts.\\n\\n\"So, either of you notice anything about our fearless leader and our new friend?\" the cobalt-haired girl asked casually.\\n\\nEvie\\'s Faunus ears twitched as her brow furrowed. \"What do you mean?\"\\n\\n\"I mean, similarities.\"\\n\\n\"Well,\" her girlfriend began slowly, \"they\\'re about the same height, almost the same build though Merri is more willowy, still muscular but not as much as Pip… Um, both have long hair, kinda the same texture, maybe? But different colors, different eye color… and…\"\\n\\nShe trailed off as the pair turned in their direction to face another of the officers as he presented further question for them to answer. Beryl nodded slowly as she could practically see it dawn upon both of teammates what she herself had seen.\\n\\n\"Oh my Oum,\" Evie breathed.\\n\\n\"They have the same face,\" Lustre murmured. \"Same nose, same eye shape, same bone structure…\"\\n\\n\"So it\\'s not just me, right?\" Beryl asked with a small grin. \"They look like they\\'re related.\"\\n\\n\"Holy fucking Grimm balls,\" Evie sputtered suddenly. \"We gotta tell \\'em…\"\\n\\n\"Hold up, now,\" Beryl laughed, pulling her girlfriend back down beside her. \"We can do that when they finish up.\"\\n\\nThe three of them waited with barely-restrained impatience as the law enforcement officials finished with the other pair. Eventually, though, they were all allowed to leave, and they unhesitatingly took advantage of this to return to the cafe they were at earlier.\\n\\nWhile Pip and Merri stood at the counter to retrieve their drinks, Beryl grinned at the open-mouth stares that Evie and Lustre sported.\\n\\n\"I don\\'t know how I didn\\'t see it earlier,\" the Cat Faunus murmured. \"I mean, look how they stand, even!\"\\n\\n\"It is eerily similar,\" Lustre agreed. \"However, I do not think you should be remiss in discrediting dear Beryl\\'s observational skills. While she may miss things in the big picture, she is quite adept in noticing the finer details.\"\\n\\n\"Why thank you, partner,\" Beryl grinned.\\n\\n\"You are most welcome, partner,\" the silver-haired girl replied with a small smirk.\\n\\nThe others returned by that point and passed out the iced drinks. Humorously enough, Merri seemed to enjoy Iced Chai as much as Lustre did.\\n\\n\"See?\" the redhead stated cheerfully, hoisting her beverage cup up. \"Sisters!\"\\n\\n\"Hmm,\" Lustre smiled, tapping her cup against their new friend\\'s. \"Speaking of which…\"\\n\\nEvie and Lustre both turned to Beryl, wordlessly giving her the opportunity to reveal their suspicions as she was the first to notice.\\n\\n\"So, here\\'s the thing,\" Beryl began quietly after taking a sip from her cup. \"Pip, when you look at Merri, what do you see?\"\\n\\n\"Um… well…\" The blonde glanced over at Merri, eyebrows quirked upwards. \"...Not following you here.\"\\n\\n\"Beryl, dear, we do not have all day,\" Lustre spoke up in amusement at the identical looks of confusion on both Pip and their redheaded companion.\\n', '<|endoftext|> I find the strength to manage it?\"\\n\\nStonefur touched his tail-tip to her shoulder.\\n\\n\"As you said, my death was your mistake. But, we learn from our mistakes, and this has taught you how to be a better leader. Please don\\'t let my death be in vain. When you need to find the strength to keep going, find it in honoring my life,\" Stonefur rumbled. \"Do not fail me again, Leopardstar.\"\\n\\nLeopardstar\\'s paws trembled and her eyes begin to sting once more.\\n\\n\"I won\\'t,\" she whispered. \"I will try. For you. I\\'ve—I\\'ve missed you Stonefur.\"\\n\\nStonefur\\'s ears twitched backwards regretfully.\\n\\n\"I\\'ve missed our Clan as well,\" Stonefur murmured. \"I would be lying if I said that I didn\\'t often wish that… that things could\\'ve been different.\"\\n\\nThat you could still be alive... That I hadn\\'t killed you.\\n\\nHer stomach twisted as she looked down at the ground again.\\n\\n\"If it is any consolation though, Leopardstar,\" Stonefur said, giving a quiet sigh. \"I do forgive you.\"\\n\\nLeopardstar\\'s gaze flew back up to his. She wanted to say something to him, but strangely, she found it impossible to move. Her vision was fading around the edges and Stonefur\\'s form was blurring.\\n\\n\"I understand the magnitude of the sacrifice you are making with your kits, Leopardstar. Even if the rest of the Clan is ignorant of your pain, I know that you chose RiverClan, and I am grateful for it. Go back home and keep leading. But, first, there is something else you must attend to…\" Stonefur said as Leopardstar\\'s vision turned to black.\\n\\nLeopardstar awoke next to the now dim Moonstone to feel a contraction ripple down her side. She winced at the faint sting of pain it brought, but it faded quickly, only a warning of what was to come. She felt a jolt of panic.\\n\\nThe kits must be coming soon. I have to get going.\\n\\nLeopardstar rose to her paws, and moving as rapidly as possible, she headed back up the tunnel.\\n\\nLeopardstar was both surprised and grateful that her stomach somehow still felt full from the fish she ate in StarClan. She wouldn\\'t have time to hunt before the kits came, and she needed her strength to make it through giving birth. After she emerged from the cave, to her shock, she found dawn already breaking. She had somehow spent all night in StarClan\\'s hunting grounds. Leopardstar headed as quickly as she could away from Mothermouth. Thankfully, her contractions were light and far apart, at least for now, so she made good time as she searched for a place to have her kits.\\n\\nI didn\\'t think they would be here so quickly, I thought I would have at least had another day after the Moonstone to look for someone to care for them.\\n\\nBeyond Ravenpaw\\'s barn, there was a sparse cropping of two-leg dens Leopardstar could see in the distance. She headed that way, hoping to find kind kitty-pets, loners or even two-legs who would be willing to take pity on her poor kits.\\n\\nIt was far after sunrise, but not yet sun-high when Leopardstar made it to the cluster of two-leg dens. She had made the journey alright, having only to stop to rest a few times when the contractions were too strong. But, now that she was so close to the strange two-leg structures, her pelt prickled with unease, and she felt the urge to turn back.\\n\\nShe may have made a mistake coming here, but it was too late to change her mind. She let out a hissed breath as another powerful contraction wracked her body. The kits would be here soon, like it or not.\\n\\nLeopardstar crept through the yards, her jaw parted to scent the air for cats and two-legs alike. As Leopardstar walked past the fifth house, her nose picked up three cat scents—one male, two female, and one of the females had a hint of milk-scent on her. Leopardstar felt a jolt of relief.\\n\\nPerfect. Now I just have to pray that they are welcoming kitty-pets.\\n\\nLeopardstar followed the cat scent into one of the yards by a two-leg nest. She clawed her way under a holly bush there to hide her from sight from any passing two-legs. Her contractions were too powerful and too close together for her to continue now.\\n\\nLeopardstar collapsed down on her side, panting.', '<|endoftext|>peripheral discoverServices:nil];\\n\\nand his delegate\\n- (void)peripheral:(CBPeripheral *)peripheral didDiscoverServices:(NSError *)error\\n{\\n    NSLog(@\"Found service\");\\n    if (error) {\\n        NSLog(@\"Error: %@\", error);\\n    }\\n    \\n}\\n\\nbut it is never called.\\nHas someone any idea?\\nThank you very much!\\n\\nA:\\n\\nOk ok I got it,\\nthere were any software problem, I mean, not by iOS side. \\nSensortag has a wrong firmware and so it did\\'n work. \\nI\\'ve changed Sensortag and now everything works fine.\\nThank you anyway!\\n\\n<|endoftext|>Euphorbia ammak\\n\\nEuphorbia ammak is a species of plant in the family Euphorbiaceae. It is found in Saudi Arabia and Yemen.\\n\\nReferences\\n\\nammak\\nCategory:Vulnerable plants\\nCategory:Taxonomy articles created by Polbot<|endoftext|>18 year old sexy teen babe Sophie Leone gets her tight twat drilled by a jumbo sized hard cock after a yoga workout on a local gym.<|endoftext|>Financial impact of radiological reports on medical-legal evaluation of compensation for meniscal lesions.\\nTo evaluate any discrepancy between radiological reports for clinical purposes and for medicolegal purposes and to quantify its economic impact on repayments made by private insurance companies for meniscal injuries of the knee. The medical records obtained pertaining to 108 knee injury patients (mean age 43.3 years) assessed over a period of 12 months were analysed. Clinical medical reports, aimed at assessing the lesion, and medicolegal reports, drawn up with a view to quantifying compensation, were compared. Unlike reports for clinical purposes in reports for medicolegal purposes, in the evaluation of meniscal lesions, in addition to morphological features of lesions, chronological, topographical, severity and exclusion criteria were applied. To estimate the economic impact resulting from the biological damage, we consulted an actuarial table based on the 9-point minor incapacity classification system. Meniscal lesions not compatible with a traumatic event and therefore not eligible for an insurance payout were found in 56 patients. Of these, 37 failed exclusion criteria, while 19 failed to meet chronological criteria. This difference resulted in a reduction in compensation made by private insurance companies with savings estimated with a saving between euro 203,715.41 and euro 622,315.39. The use of a clinical report for medicolegal purposes can be a source of valuation error, as chronological and/or dynamic information regarding the trauma mechanism may be lacking. Therefore, the use of a full radiological appraisal allows a better damage\\'s assessment and an adequate compensation for injuries.<|endoftext|>1. Field of the Invention\\nThe invention relates to a magnetic-inductive flow meter, with at least one measuring tube for through flow of an electrically conductive medium, with a magnetic field generating apparatus for generating an alternating magnetic field which runs at least also perpendicular to the longitudinal axis of the measuring tube, with at least two measuring electrodes which especially contact the medium, and with an evaluation circuit, the magnetic field generating apparatus having at least one field coil and one coil power supply and the coil power supply preferably having a current controller and preferably one changeover bridge. The invention also relates to a method for operating a magnetic-inductive flow meter of the type as has been described above in particular.\\n2. Description of Related Art\\nGerman Patent Application DE 199 07 864 A1 and corresponding U.S. Pat. No. 6,453,754 B1 disclose a magnetic-inductive flow meter of the above described type. In this known magnetic-inductive flow meter the magnetic field generating apparatus can have one field coil or two field coils. This is why it was stated above that the magnetic field generating apparatus has at least one field coil. In the known magnetic-inductive flow meter, the magnetic field generating apparatus also has a current controller and a changeover bridge. But, because neither a current controller nor a changeover bridge is critical to operation, it was stated above that the magnetic field generating apparatus has preferably one current controller and preferably one changeover bridge.\\nMagnetic-inductive flow meters have been widely known in the prior art for decades. Reference is made by way of example to the literature citation Technical Flow Rate Measurement by Dr. Eng. K. W. Bonfig, 3rd edition, Vulcan-Verlag Essen, 2002, pp. 123 to 167, and moreover, to the literature citation Principles of Magnetic-Inductive Flow Rate Measurement by Cert. Eng. Friedrich Hoffmann, 3rd ed., 2003, a publication of the company KROHNE Messtechnik GmbH & Co. KG.\\nThe basic principle of a magnetic-inductive flow meter for measuring the flow rate of a flowing medium goes back to Michael Faraday who', '<|endoftext|> a plate of decorated cookies—gingerbread men and women, all wearing crowns atop hair colors not found in nature. She placed the plate on a tray along with the coffee carafe and cups. Cream and sugar for both of them, of course. When she arrived in the living room, Spunky sat motionless on the sofa, his limpid eyes fixed on Maddie.\\n\\n\"Thank God you\\'re here,\" Maddie said. \"I think he was planning to kill me.\"\\n\\n\"Nonsense,\" Olivia said as she placed the tray on the coffee table. \"Spunky is almost entirely nonviolent. Aren\\'t you, boy?\"\\n\\nSpunky\\'s ears twitched, but his concentration never wavered.\\n\\n\"Please tell me I can give him his tre—his t-r-e-a-t,\" Maddie said. Spunky yapped and jumped onto her lap. \"Hey, when did he learn to spell?\"\\n\\n\"My little boy,\" Olivia said fondly. \"He wants to go to Harvard, but I told him, Mommy can only afford in-state tuition. He\\'ll have to get a scholarship. Anyway, you\\'d better throw his treat onto the rug. It\\'s your only hope.\"\\n\\nMaddie threw the treat so hard it hit the living room wall and broke in half. Spunky hit the rug running and crunched his way through both pieces.\\n\\n\"Two seconds,\" Olivia said. \"A personal best.\" She selected a gingerbread queen with violet hair and settled back on the sofa. \"About Paine Chatterley\\'s death,\" she said. \"I think Del left out some details about the order in which Paine was drugged, drunk, dragged, drowned, and/or suffocated.\"\\n\\n\"As I understand it,\" Maddie said, \"Paine didn\\'t drown. The pills apparently didn\\'t kill him, either. Maybe he got really zonked on pills and alcohol, then suffocated accidentally? I can imagine someone in that condition getting dangerously tangled up in the bedclothes.\"\\n\\n\"Except how did he get into the tub? According to Del, the medical examiner insisted it was murder. So there has to be something else, something technical that Del didn\\'t think we needed to know.\"\\n\\n\"Geez, it almost sounds like Paine wouldn\\'t die, and his killer was desperate.\" Maddie dunked her gingerbread king\\'s green hair into her coffee and got it to her mouth before the cookie dissolved. \"Maybe Del didn\\'t think you needed all the details. As he keeps telling you, we aren\\'t police officers.\"\\n\\n\"Which reminds me,\" Olivia said, \"I\\'m not telling you any of this.\"\\n\\n\"Understood. Maybe Paine was already in the tub when someone came up behind him and strangled him.\"\\n\\nHaving gnawed through his own version of cookies, Spunky leaped onto the sofa and nestled between Maddie and Olivia for a warm nap. Gently stroking his ears, Olivia said, \"When Del called to tell me Paine was murdered, his last words to me were \\'I don\\'t want to find you facedown in a bathtub.\\' I might be overinterpreting, but I\\'m wondering...\"\\n\\n\"You\\'re wondering,\" Maddie said, \"why Paine would be facedown? If he was in the tub when he died, wouldn\\'t he have slid underwater faceup?\"\\n\\n\"Exactly. Although maybe Del wasn\\'t being literal.\"\\n\\n\"Livie, when have you known Del to be imprecise about his work?\"\\n\\n\"Point taken,\" Olivia said. \"Although Paine might have been trying to get out of the tub while he was being suffocated. I\\'d like to hear Hermione\\'s story.\"\\n\\n\"And isn\\'t it convenient,\" Maddie said, \"that Del wants you to babysit Hermione. Maybe you can get her to spill a few clues.\"\\n\\n\"I suppose we have to assume that Johns Hopkins School of Medicine knows what it\\'s doing,\" Olivia said, \"which would mean that the perfect suspect, Hermione, wouldn\\'t have the strength to get Paine into the tub after he was dead.\"\\n\\nMaddie reached for another member of the gingerbread royalty, this time with cobalt blue hair. \"What would be her motive? I mean, aside from the fact that Paine wasn\\'t the ideal husband. So far, the last of the Chatterleys have behaved like bankrupt freeloaders. Hermione is a thief. Paine drank, took pills, and slept a lot. I\\'m not confident there\\'s an inheritance for Hermione, except maybe the mansion and its contents.\"\\n\\n\"That\\'s something,\" Olivia said, \"though I don\\'t see much evidence that she cares about the house.\" Spunky', '<|endoftext|> by satisfying this specific need, the inventive circuit advantageously facilitates meeting the overall need through use of the image enhancement system disclosed herein.<|endoftext|>Who is your favorite TW Warhammer faction to play?\\n\\nWähle eine Antwort:\\n\\nDwarfs Empire Green Skins Vampire Counts Warriors of Chaos Beastmen<|endoftext|>Do you ever wonder what if the Doctor exists and walks among us? That ‘Torchwood’ is real and the television show ‘Doctor Who’ is just an elaborate cover up? If the answer to that is yes, ever wonder who he might be?\\n\\nWell, in the grand tradition of me not wanting to discern between fact and fiction, let me tell you exactly who I think the Doctor is. Last month I told you who I thought the Tenth Doctor was in real life. Well, this month I’ve chosen someone just as worthy.\\n\\nThe Eleventh Doctor: Bill Nye\\n\\nThe reason I chose Bill Nye as the Eleventh Doctor probably should go without saying, but I’ll say it anyway.\\n\\nBowties are cool.\\n\\nDuh.\\n\\nOkay, it’s more than that. The truth is, of all the scientists/innovative thinkers I have listed before, Bill Nye is closer to being my real life Doctor more so than anyone else. Bill Nye showed me the wonders of EVERYTHING at a very young age and didn’t treat it like it was something I couldn’t understand.\\n\\nI was excited to come home after school everyday and watch ‘Bill Nye the Science Guy’ because he was the first person who tried to teach science like it was something cool, which it totally is! That’s the whole point of ‘Doctor Who’. The show was originally conceived as a fun way to introduce people to history and science, and I think Bill Nye is a chip off the old TARDIS block.\\n\\nAlso, his sense of humor is Doctor-kooky. I will stand by Bill Nye forever if only just for this:\\n\\nI think we can all see the Doctor saying “Jello. You are a delicious dessert, but what are you?!”\\n\\nAnd of course, there is also this:\\n\\nI will never get enough of his jokes. Ever. He makes me love science.\\n\\nEven in his darkest hours, the Eleventh Doctor will always have a goofy side. Of course, this begs the question: does Bill Nye have a dark side? Not that we’ve seen on television anyway, though I think some of us may equate watching his dancing on ‘Dancing with the Stars’ to be the very height of Matt Smith’s Doctor:\\n\\nWe’ve only go one more Doctor left, and that’s Peter Capaldi! Do some time traveling of your own, and let us know who you think the twelfth Doctor will be in real life!<|endoftext|>. Suppose -m*s + 26 = -5*s. What is the remainder when 115 is divided by s?\\n11\\nSuppose 4*n - 8 = 6*n, -2*l = -n - 38. Suppose 36*q = -27*q + 504. Calculate the remainder when l is divided by q.\\n1\\nLet f(i) = -21*i + 141. Suppose 18*w + 90 = 36*w. Calculate the remainder when 141 is divided by f(w).\\n33\\nSuppose -l + 2*u = -28, -7*u - 16 = -3*u. Let i(y) = -y**2 + 362. Let w be i(0). Let a = w - 354. What is the remainder when l is divided by a?\\n4\\nLet l(x) = -x**3 + 2*x**2 - 7*x - 1. Let t be l(2). What is the remainder when 128 is divided by (-828)/(-30) - (-9)/t - 5?\\n18\\nLet p(i) = i**3 + 3*i**2 - i - 3. Let w be p(-3). Suppose 11*c - 5*c - 132 = w. Calculate the remainder when 64 is divided by c.\\n20\\nCalculate the remainder when 398 is divided by ((-10620)/(-240))/(9/12).\\n44\\nLet m(n) = 15*n**3 + 4*n**2 - 4*n + 3. What is the remainder when m(2) is divided by ((-1)/2 - 3)*((-190)/(-14) - 17)?\\n11\\nLet h = 15064 + -15020. What is the remainder when 8754 is divided by h?\\n42\\nLet w = -3476 + 3983. What is the remainder when w is divided by 248?\\n11\\nLet j(l) =', '<|endoftext|> almost forced. \"But your little gizmos did the trick. Good work, Zack.\"\\n\\nAs he watched the captain walk away, Decker frowned. Why did he have the impression there was something Strachan wasn\\'t telling him? He looked a little too uptight for what just happened as if there were more than just guns in the containers.\\n\\nHe shook off his thoughts and secured the shuttle hangar. Moments after he closed the door, the hyperjump warning blared through the ship. Zack felt the stomach-twisting burst of nausea that accompanied every shift to and from normal space while the lights flickered for a fraction of a second. Then, body and ship settled down as both sailed at many times the speed of light in their own bubble where everything was twisted and distorted.\\n\\nNext stop, Itrul. Oorah!\\n\\nDecker grimaced and returned to his cabin.\\n\\n|  |\\n\\n---|---|---\\n\\n# — EIGHT —\\n\\nThe ship lurched as the battle stations siren erased Decker\\'s highly charged dream of Raisa Darhad doing things a proper first officer shouldn\\'t do.\\n\\nWith a grunt, the gunner dropped out of his bunk and reached for his battledress, instinctively sure that this wasn\\'t a drill. Within seconds, he was dressed, armed and fully awake, the adrenaline already pumping through his bloodstream. He reached down and shook Kiani\\'s bare shoulder.\\n\\n\"Up and at \\'em, Nihao. Battle stations and it doesn\\'t sound like a drill.\"\\n\\n\"Huh?\" A sleepy voice grunted.\\n\\n\"It\\'s a great day to die, Mister Kiani,\" Zack grinned as he gave her a final shake, before leaving his cabin for the bridge.\\n\\nWhen he got there, the ship\\'s nerve center wallowed in pandemonium. An FTL torpedo, narrowly missing Shokoten, had forced her out of hyperspace. This deep within the Protectorate, there could be only one answer. Decker slipped into his seat and glanced over towards the command chair. Fifth Officer Sladek had the con.\\n\\n\"Where away, sir?\"\\n\\n\"I don\\'t know, Gunner,\" he rasped, fear making his eyes dart here and there. \"You have control of all defensive systems.\"\\n\\n\"Thank you, sir.\" At Zack\\'s touch, the tactical board came to life.\\n\\nFirst the shields.\\n\\nAll six shield generators were operational and at full power. Not bad for a civilian ship. Zack grunted with satisfaction. His status board showed all gun turrets ready and loaded, all missile launchers active and the fire control system standing-by.\\n\\nThe little modifications he\\'d made were paying off. This was the first time all defensive systems were up without any malfunctions.\\n\\nNow where was the bastard?\\n\\nFingers dancing over the console, Decker reached out across the cold void to find the unseen enemy that had forced them off course. He vaguely knew that the command crew had taken their stations and that the captain was asking for status updates from all departments except gunnery. He knew better than to disturb Decker when the former Marine was hunting.\\n\\n\"Navigation, current position?\" Strachan sounded worried beneath his composed exterior.\\n\\n\"Unknown. I have to recalculate our position before we can move. We\\'re not exactly following the standard star lanes.\"\\n\\n\"How long?\"\\n\\nThe fourth officer grimaced. \"Fifteen or twenty minutes at least. I need readings off a few major stars and triangulate.\"\\n\\n\"Damn. Engineering, status.\"\\n\\n\"No damage, sir,\" Sonoda\\'s voice sounded tinny and distorted over the intercom. \"But I\\'ll want to run a level two systems check before we jump. That torpedo was close.\"\\n\\n\"How long?\"\\n\\n\"Can\\'t tell yet.\"\\n\\n\"Then get on it.\"\\n\\n\"Aye, aye, sir. Engineering, out.\"\\n\\n\"Captain!\" Zack\\'s tone was just loud and urgent enough to cut through the hubbub.\\n\\n\"Yes, Mister Decker?\"\\n\\n\"I have a contact. Five hundred thousand kilometers off our port bow, turning and closing. Looks like a corvette-sized ship. No friend-or-foe transponder.\"\\n\\n\"Could it be friendly?\" Strachan\\'s tone showed he knew how naïve his question was.\\n\\n\"Not a chance, sir. Military vessels in the sector are too busy chasing the bad guys to bother with a merchant and they\\'d have a transponder.\"\\n\\n\"How do you know this is the one?\"\\n\\n\"Extrapolation, sir. Whoever\\'s shooting at us in hyperspace is bound to emerge a few seconds', '<|endoftext|>aspell.net/\"\\nlicense=(\\'custom\\')\\ndepends=(\"${MINGW_PACKAGE_PREFIX}-aspell\")\\nsource=(https://ftp.gnu.org/gnu/aspell/dict/fr/aspell-fr-${_pkgver}-${_rel}.tar.bz2\\n        001-unixy-dirs.patch)\\nsha256sums=(\\'f9421047519d2af9a7a466e4336f6e6ea55206b356cd33c8bd18cb626bf2ce91\\'\\n            \\'86f8671c97d27b24656d22edc215e75b8cab32733967f86bfc57b6680d2fdee5\\')\\n\\nprepare() {\\n  cd \"${srcdir}/aspell-fr-${_pkgver}-${_rel}\"\\n  patch -p1 -i ${srcdir}/001-unixy-dirs.patch\\n}\\n\\nbuild() {\\n  cd \"${srcdir}/aspell-fr-${_pkgver}-${_rel}\"\\n  ./configure\\n  sed -i \\'s/C\\\\:\\\\\\\\msys64\\\\\\\\/\\\\//\\' Makefile\\n  make\\n}\\n\\npackage() {\\n  cd \"${srcdir}/aspell-fr-${_pkgver}-${_rel}\"\\n  make DESTDIR=\"${pkgdir}\" install\\n\\n  install -D -m644 Copyright \"${pkgdir}${MINGW_PREFIX}/share/licenses/${_realname}/LICENSE\"\\n}\\n<|endoftext|>Burse\\n\\nBurse is a surname. Notable people with the surname include:\\n\\n Charlie Burse (1901–1965), African-American blues musician\\n Denise Burse (born 1952), American actress\\n Isaiah Burse (born 1991), American football wide receiver\\n Janell Burse (born 1979), American, women\\'s basketball player\\n Ray Burse (born 1984), American soccer goalkeeper\\n Raymond Burse, college administrator, lawyer and businessman\\n Tony Burse (born 1965), American football player\\n Walter Burse (1898–1970), second president of Suffolk University\\n\\nSee also\\n\\n \\n \\n Corporal (liturgy), which is required to be stored in a case named a burse\\n\\n Bourse (disambiguation)\\n Bursa\\n Purse (disambiguation)<|endoftext|>Current status of carbohydrate deficient transferrin, total serum sialic acid, sialic acid index of apolipoprotein J and serum beta-hexosaminidase as markers for alcohol consumption.\\nThe purpose of this paper is to present a brief review of the literature and to summarize the current status of four biochemical markers for alcohol consumption, carbohydrate deficient transferrin (CDT), total serum sialic acid (TSA), sialic acid index of apolipoprotein J (SIJ) and serum beta-hexosaminidase (beta-HEX). Of these markers, CDT has been the most widely studied, is currently thought to be the most accurate predictor of alcohol consumption, is most readily available and is the only test approved by the FDA for the identification of heavy alcohol use. TSA and SIJ have the potential to be useful markers, but have only recently been discovered, are not readily available and have not yet been studied comprehensively. Finally, the relationship between serum beta-HEX and heavy alcohol consumption has been studied for about 20 years, but the test is not readily available and has not been widely accepted or used as a marker for heavy alcohol consumption. These markers have the potential to be included in a combination of measurements to provide an accurate, more exact assessment of alcohol consumption in a variety of clinical and research settings.<|endoftext|>Which Switch bundle would you get?\\n\\nWähle eine Antwort:\\n\\n$250 Standard Edition $300 Bundle w/ 1x Game $350 Bundle w/ 2x Games and Pro Controller<|endoftext|>The present invention relates generally to retail store interior design, and more specifically to a novel and improved layout of the shelving and other means for holding and displaying goods for sale in a PrimeZone portion of the central space of the store.\\nThe present invention has broad applicability to many types of retail establishments in which a wide variety of goods have historically been placed on long rows of parallel racks or shelves orderly arranged most often within a central portion of a large open room defined by exterior walls. In most cases, special purpose rooms or areas are positioned around the central space and proximate the surrounding walls. Grocery stores selling packaged comestibles, household goods and other products are an example of such establishment, but many other types of retail stores follow a similar pattern and as will be apparent to the reader, the present invention has broad applicability.\\nAs generally illustrated in FIG. 1 of the present Drawing, a typical grocery store, schematically represented at 10, is usually configured', '<|endoftext|> an odd way, feels reminiscent of the opening moments in “Secretariat”: We hear Diane Lane’s smooth, crisp voice reading from the Book of Job as we watch a magnificent animal being loaded into a starting gate, its ears twitching, its nostrils flaring. Which itself recalls, to a degree, a very different moment, early in “The Social Network”: Jesse Eisenberg as Mark Zuckerberg sits with his lawyer across a table from his best friend and lawyer. Nobody is smiling.\\n\\nHow do these scenes connect? Each hints at a future.\\n\\nThen there’s “Fair Game,” opening Friday, which, in a nutshell, is the Valerie-Plame-Joe-Wilson-leaked- CIA-spy-identity tale. Director Doug Liman makes a curious decision: Rather than telegraph many details of the outcome, an outcome we knew we would get before entering the theater, he takes the “All the President’s Men” route and simply offers the story, piece by piece. Relatively speaking, compared with “Social Network,” “127 Hours” or “Secretariat,” “Fair Game” seems to play out in real time.\\n\\nAnd raises a question: How do movies based on real events wrestle with a preordained ending?\\n\\n“Fair Game” (Nov. 5)\\n\\nWhat’s the story? Plame-gate. The White House, in retaliation for a New York Times editorial written by Plame’s husband that dismisses claims that Iraq was trying to buy uranium (which led to the “smoking gun in the shape of a mushroom cloud” thing), the White House leaks Valerie Plame’s identity: CIA operative.\\n\\nAre the details well known? The details of the scandal, of course. Beyond that, not really.\\n\\nHow does the film handle the audience’s awareness of its inevitable ending? Doug Liman said the decision was made early on to do a lot of original reporting about Plame and “focus on the part of Valerie’s story that wasn’t known, the part that was still classified, and that became the bulk of the story. People forget, but she swore an oath, so when all this stuff happened, she could not talk about things. She could not say what she was doing on a day-to-day basis.” He said he started with the outcome, then worked backward. “In terms of suspense, we shifted that to other crises, like the question of whether or not these Iraqi scientists will get out of the country. What we didn’t want was a film full of things that everyone knows. I took that lesson from watching ‘Green Zone’ and Matt Damon running around going ‘Where are the WMDs?’ You’re in the audience thinking, ‘Yeah, there are no WMDs!’ I think that was in the back of mind, as an example of what not to do.”\\n\\nIs there ever a feeling that we’ll get something other than the ending we’re expecting? No, but then there are no winks at that ending either.\\n\\n“The Social Network” (now playing)\\n\\nWhat’s the story? Mark Zuckerberg creates Facebook. Or does he? Either way, the result is many lost friends and litigious Harvard classmates.\\n\\nAre the details well known? Yes, the vague outline.\\n\\nHow does the film handle the audience’s awareness of its inevitable ending? By being upfront. By framing Facebook’s birth as a business thriller by way of a character sketch — a thriller less reliant on traditional Grisham-esque tension than an ever-present chance of betrayal and, perversely, a different kind of cliffhanger: How many friends will Zuckerberg be left with? The first moments are a hint, focusing on Zuckerberg’s mean-spirited reaction to a breakup (suggesting there was little sociability left to lose). Screenwriter Aaron Sorkin and director David Fincher tinker with time, switching between Zuckerberg working on Facebook and the cold legalities that followed; Jesse Eisenberg’s motor-mouth delivery feels like an act of foreshadowing, so glib and devoid of niceties that you just know harsh ramifications will be inevitable. They also tinker with the details, to great effect: “I dramatized the fact that there were conflicting stories,” Sorkin told New York magazine — leaving the audience not with just an expected outcome but an argumentative one.\\n\\nIs there ever a feeling that we’ll get something other than the ending we’re expecting? If you really wondered, you must be on Friendster.\\n\\n“127 Hours” (Friday)\\n\\nWhat’s the story? In 2003, Aron Ralston, a young but experienced climber, fell into a canyon in Utah and was trapped beneath a boulder for more', \"<|endoftext|> boards he trod at St Paul's. They literally lay over a laboratory bench, the auditorium being a converted lecture theatre for the sciences.\\n\\nOnly eight weeks after Miller and Bacharach's school gig, they became BBC Radio starlets. Having sent up the Corporation, they were sent for and they found themselves on air. If not having your cake and eating it, this was surely the art of biting the hand and being fed. The _Radio Times_ listing for _Under-Twenty Parade_ (a series which promoted teenage talent on the Light Programme) announced: 'John Miller and Michael Bacharach, in their very first broadcast, take a friendly sideswipe at some of their fellow under-twenties . . . (practically no holds barred).' Clearly a hit, they were invited back several times in 1953–4.\\n\\nAnother glass wall, ultimately penetrable, crops up in these early recording sessions, as described by Miller:\\n\\nWe'd go downstairs into those airless basement studios, with the enormous cheese-grater microphones they had in those days. It was all basketwork tabletops, and you'd be sitting behind glass, unable to hear what the producers were saying until they'd mouth 'Sorry!' and switch on . . . I've been doing that ever since, in and out of BBC basement studios for more than fifty years.\\n\\nHe denies that he got a taste for it but he enjoyed these early sessions, and being paid a few pounds was another step towards independence.\\n\\nA fragment of Miller and Bacharach's _Under-Twenty Parade_ material has, remarkably, survived in the form of a rough transcript of studio takes. Though only a snippet, it is illuminating as regards Miller's subsequent West End performances and his longer-term creative style. As the transcript records, the double act parodied a panel of critics who were part of the programme. The pair aped the perky 'Hello, listeners', the critics' waffle, every little cough, the bad segues and the indecipherable 'talking together'. Then they joined the panel (for real) to discuss their techniques. During that exchange, the boys said that they generated routines by conversationally ad-libbing and had struggled with the BBC's request for a formal script. An improvisational approach, in the spirit of jazz, was to continue throughout Miller's career. Combining a musical ear with near-scientific observations, his adolescent comedy was serious-minded at root. 'We are interested', he said, 'in the sound pictures that are made by people . . . just the noises and the flux of noises . . . [And] even now', he told the panel, 'exactly the same rises and falls, exactly the same cadences are occurring.' That Miller was to spend his life tuned in to the rhythms of conversation was natural enough, given his upbringing amidst the intelligentsia, the chattering classes. The 'talking together' in this critics skit also interestingly foreshadows Miller's later approach to classic plays, radically overlapping lines of dialogue.\\n\\nThe _Under-Twenty Parade_ panel dubbed him a satirist for the first time on record, but then he and Bacharach proved wildly surreal as well. They performed a variation on the Miller-Korn skit 'Round the World with Radio', combining imitation and way-out imagination. Mingling BBC announcers, gale warnings and newsflashes, it ran like this:\\n\\nEr, er, that was 'Lift Up Your Socks' . . . Next week, 'A Short Gap' recorded anonymously . . . the South of England is going to move in a westerly direction . . . Now here is a police message, published Methuen at twenty-one shillings. There was an accident last night on the Great North Circular Road, when an elderly chrysanthemum was knocked down by a steamroller and received injuries from which the Chief Constable of Hertfordshire has since died . . . The police are anxious to interview a man with long blue hair – they have never seen a man with long blue hair.\\n\\n'Round the World with Radio' was also to provide further evidence of dialogic memory at work. It would be refined by Miller into a quirky Cambridge Footlights monologue – renamed 'Radio Page' and applauded by West End crowds – without Korn or Bacharach getting a writing credit.\\n\\nWhat is remarkable, more immediately, is this extract's sheer craziness. It is garbled, elided and dreamlike, with slivers of the everyday made strange by being miscategorized, everything playfully grafted into the wrong slots. Miller's own theory of comedy, expounded in later life, would home in on precisely that: laughter aroused by errors of classification.\\n\\nThe boys had clearly been influenced not only by the Marx\", '<|endoftext|>\\nAußerdem hängen griechische Banken stark von Refinanzierungsoperationen der EZB für die kurzfristige Finanzierung ab, denn das Land ist von den internationalen Geldmärkten abgeschnitten. Die Kommission übernimmt Verantwortung dafür, die makrofinanzielle Stabilität im Euroraum und der gesamten EU zu gewährleisten. In der Tat sind Banken in anderen EU-Staaten insbesondere durch ihren Besitz von Staatsschulden der griechischen Krise ausgesetzt, und Frankreich und Deutschland sind davon am meisten betroffen.\\nDiese Risiken sind im Hinblick auf das BIP zwar nicht besonders groß, sie werden aber wahrscheinlich hinsichtlich der Bilanz einzelner Banken an Bedeutung gewinnen. Zwischenzeitlich werden etwa 10 % der Bilanzen von griechischen Banken in Süd- und Osteuropa investiert, was andere Übertragungswege impliziert.\\nNikolaos Chountis\\n(EL) Herr Präsident, ich danke dem Herrn Kommissar für seine Antwort. Offensichtlich gibt es mit den Banken in Griechenland Probleme. Da ist die Liquidität, die vom griechischen öffentlichen Sektor produziert wurde, leider ohne sich auf die tatsächliche Wirtschaft zuzubewegen; aber was ich anmerken möchte ist, dass jedes Mal, wenn Griechenland bestimmte Maßnahmen, bestimmte Formen der Anleihen ankündigt, diese berühmten Ratingagenturen ankommen und die Kreditbewertung von Griechenland und den griechischen Banken herabstufen.\\nDas ist eine traurige Rolle. Es wurde zuvor eine Debatte geführt, und ich möchte sie nicht wiederaufbereiten. Diese Ratingagenturen, bei denen es sich um private US-Firmen handelt, sind wirklich unzuverlässig, und ich halte es für inakzeptabel, dass die Europäische Zentralbank und die europäischen Institutionen sie selbst heute für wichtig erachten. Folgende Frage und die zuvor gehörten Antworten kommen auf: Sicherlich, das Thema kann bis 2013 geregelt werden. Können die Europäische Union und die Institutionen gerade jetzt aufhören, diese Ratingagenturen zu berücksichtigen?\\nKarel De Gucht\\nMitglied der Kommission. - Wie ich gerade sagte, berücksichtigt die Kommission bei ihrer eigenen Analyse nicht nur die Ratingagenturen, sondern auch ihre eigenen Analysen. Die Europäische Kommission verfolgt die Ereignisse in der Öffentlichkeit und im Bankensektor in Griechenland sehr aufmerksam, also kommen wir zu unseren eigenen Schlüssen und machen dem Rat auf Grundlage dieser Schlüsse Vorschläge. Es gibt natürlich etwas anders, und das ist die Tätigkeit der Ratingagenturen. Dies sind private Unternehmen, die mit Hinblick auf die Finanzmärkte sehr einflussreich sind, aber das liegt natürlich nicht in der Verantwortung der Europäischen Kommission.\\nMorten Messerschmidt\\n(DA) Herr Präsident, wir sind alle sehr besorgt darüber, was wir tun können, um die sich aus der Finanzkrise ergebenden Probleme zu lindern. Herr Kommissar, ich habe neulich in den Medien gesehen, dass Sie vorgeschlagen haben, dass die Mitgliedstaaten in Zukunft ihre Haushaltsentwürfe der Kommission vorlegen sollten, bevor sie von den nationalen Parlamenten debattiert und verabschiedet werden. Ich möchte, dass Sie uns weitere Details darüber geben, wie die Kommission in Zukunft Gelegenheit bekommen wird, die Haushaltsentwürfe der Mitgliedstaaten vor den Parlamenten zu kommentieren. Das klingt extrem interessant. Ich möchte mehr darüber hören.\\nGeorgios Papanikolaou\\n(EL) Herr Präsident, Herr Kommissar, vielen', '<|endoftext|> warriors did we lose?\"\\n\\n\"About half,\" said Biiri. \"Twenty or so. It could have been worse.\"\\n\\n\"Yes,\" said Dagii, \"but it could have been better. I count ten dead elves.\"\\n\\n\"Five more fled at the end,\" said Keraal. \"Ekhaas forced seven away.\"\\n\\n\"Four archers lie dead in the dark. Plus three who tried to ambush us.\" Chetiin came strolling past Ekhaas.\\n\\nThe reaction from Keraal, Uukam, and Biiri was immediate. They grabbed for their weapons and dropped into defensive crouches, their ears back and their teeth bared. _\"Shaarat\\'khesh!\"_ snarled Uukam.\\n\\n\"Easy!\" Dagii said. \"He\\'s a friend. He\\'s—\"\\n\\n\"I\\'m Maanin,\" said Chetiin smoothly. \"I\\'m with Dagii to redeem the honor of the Silent Clans.\" He crossed his arms and waited. Slowly the three warriors lowered their weapons, though Keraal was the last to do so. His ears twitched and he looked to Dagii and Ekhaas, then nodded.\\n\\n\"Maanin,\" he said. He looked back to Dagii. \"One of the Silent Blades instead of one of the Silent Wolves?\"\\n\\n\"Do you want to argue with four more elves dead?\" Ekhaas asked him.\\n\\nKeraal\\'s eyes narrowed but he bent his neck in the slightest of nods.\\n\\n\"Maanin\\'s place here is not the issue,\" Dagii said. \"Ten elves dead here, four and three dead below the hill, twelve fled in fear or defeat.\" He put his hands on his hips and looked around at all of them. \"Twenty-nine Valaes Tairn sent against forty Darguuls. If not for Ekhaas\\'s song, I think that more than half our number would be dead right now. Don\\'t claim a victory here—claim a lesson learned.\"\\n\\nThe others had no response.\\n\\nDagii nodded. \"Uukam, Biiri, give the warriors a short time to celebrate, then order them back to discipline. The camp needs to be restored and sentries set again. It\\'s possible the elves may try their luck again. Keraal, pick out those who fought worst in the battle—they\\'re to collect the dead and bury them in the morning.\"\\n\\nKeraal\\'s ears flicked. \"Those who fought worst are already among the dead,\" he said with the ghost of a smile.\\n\\nDagii returned the smile, then jerked his head dismissing all three. When they had gone, he looked down at Chetiin. \"Maanin?\"\\n\\nThe goblin seated himself on the pack by the fire. \"You don\\'t want to be seen with Haruuc\\'s assassin, do you? Trying to defend my innocence to all your warriors would only raise more questions. Better that I be someone else for a while.\"\\n\\n\"You could have stayed in hiding,\" said Ekhaas. \"Keraal knows something isn\\'t right.\"\\n\\n\"Hiding isn\\'t always an advantage. Tell Keraal the truth later. When there are fewer things to concern him—and you.\" Chetiin glanced up at them. \"I followed the fleeing elves a short way. I doubt that they\\'ll return tonight, but the odd thing is that they had no horses.\"\\n\\nEkhaas narrowed her eyes. \"You told me that not all Valaes Tairn fight from horseback.\"\\n\\n\"They don\\'t,\" said Dagii, \"but all of them use horses for transportation. If they didn\\'t ride, their camp must be close.\" His smile became grim. \"We can scout them out.\"\\n\\n\"Marrow can track them by scent,\" Chetiin said.\\n\\nDagii nodded. \"Let me find some light armor. Something that won\\'t give us away.\" He looked at Ekhaas. \"You\\'ll come?\"\\n\\n\"Try to stop me.\"\\n\\n\"You should find some light armor and a less rattling weapon for Keraal and bring him too,\" said Chetiin.\\n\\nDagii\\'s ears rose at the suggestion. So did Ekhaas\\'s.\\n\\n\"He\\'s already suspicious of you,\" she said.\\n\\n\"Suspicions are like gardens—left untended, they grow wild.\" The goblin\\'s thin lips pressed together for a moment. \"But in this case, I like the idea of an extra sword at my side. The Valaes Tairn are cunning.\"\\n\\n\"I\\'ll find Keraal,\" said Dagii.\\n\\nKeraal, outfitted in leather with', '<|endoftext|>rava il segno di una vigoria arcana, ma potente, sotto alla quale ero lieta, ero orgogliosa di piegarmi da schiava. Quanto più il suo cuore appariva basso, tanto più il suo corpo splendeva bello.\"\\n\\nLa vicenda è nota al grande pubblico grazie alla trasposizione cinematografica di Luchino Visconti.\\n\\nA cura e con una prefazione di Carmen Margherita Di Giglio.\\n\\nRacconti dal medioevo bolognese\\n\\ndi Wolfango Horn, libro e ebook.\\n\\nVincitore del Premio Letterario Nemo 2013\\n\\nUn viaggio nella città di Bologna tra Cinquecento e Seicento: racconti di crimini che si intrecciano a intrighi, passioni, alleanze e lotte per la supremazia tra potenti famiglie, la presenza ineludibile dei domenicani della Santa Inquisizione, arroccati nella loro cattedrale di San Domenico, la passione diffusa tra i nobili per le arti, la magia, l\\'alchimia. Un percorso di alcune storie attraverso la Storia: la condanna al rogo della strega di Bologna, Gentile Budrioli, e l\\'inquietante immagine di un santo con fattezze di cane; il soggiorno bolognese del pittore Giorgione, la sua mania per l\\'alchimia, un misterioso dipinto, la strage dei Marescotti; un furto con destrezza nella chiesa di San Domenico, il viaggio di una preziosa reliquia fino a Malta, la misteriosa morte di Michelangelo Merisi, detto \"il Caravaggio\". E poi, alle porte di Bologna, l\\'inquisitore Felice Centino, ospite per una notte nel convento francescano di San Giovanni in Persiceto, si ritrova a indagare sull\\'omicidio del priore del convento, un convento votato allo studio di una singolare disciplina, l\\'astronomia mistica. In ogni racconto il fascino della creazione fantastica si intreccia con fatti curiosi e poco noti, ma reali e storicamente documentati, rendendo in tal modo vitali e affascinanti vicende tratte in gran parte da cronache ingiallite, dimenticate in polverosi archivi.\\n\\n<|endoftext|>Jasminlive toy MylaCharelle\\n\\nWhat we\\'ve got here? A sexy and naughty brunette girl with a hot ass that can twerk your mind a little. My name is Myla and coming in my room, you\\'ll be condemned to a game of pleasure where each of us will be the winner. Join me and let me whis<|endoftext|>We want you to be theHero of Freelancer.com\\n\\nCurrent Leaderboard\\n\\nFrom May 15, 2018 to June 19, 2018, we\\'re looking for the Hero of Freelancer.com.\\nPut your referral marketing skills to the test and show us how many friends you can invite to Freelancer.com!\\nThe winner will receive the fame and glory as the Hero of Freelancer.com AND\\n$20,000 cash. Weekly winners also stand to win $1,000 cash.\\n\\nRank\\n\\nName\\n\\nEarnings\\n\\n1\\n\\nrinsadsl\\n\\n$140 USD\\n\\n2\\n\\nsubhan05\\n\\n$100 USD\\n\\n3\\n\\ndarrelwilson\\n\\n$80 USD\\n\\nHow can I become a Hero?\\n\\nShare\\n\\nShare your signup link to your friends,\\nand they\\'ll get $20 USD when they sign up!\\n\\nRefer\\n\\nFor every person that signs up through your signup link, you\\'ll\\nget $20 USD to spend on Freelancer\\nonce they spend $50 USD on the site.\\n\\nEarn Points\\n\\nThe user who gets the most number of successful signups over from\\nMay 15, to June 19, 2018 will become\\nthe Hero of Freelancer.com and receive $20,000 cash prize.\\n\\nWe want to support the talent and creativity of extraordinary people like you!\\n\\nFreelancer.com is the world\\'s largest Freelancing marketplace\\nwith more than 28 million members from 247 countries. Millions of businesses\\nworldwide use', '<|endoftext|>\\nI tripped over a scruffy bush. \"But the bird changing to a girl, then to a flea, then back to a girl again? That wasn\\'t a surprise?\"\\n\\nYami gave me a little sideways smile. \"No.\" He shrugged one shoulder. \"Okay, maybe a little. But — \"\\n\\nHe stopped suddenly and held his arm out at his side. I almost ran into it.\\n\\n\" — but not a lot. This is why.\"\\n\\nHe lowered his arm. I caught my breath. The flat desert floor had come to an abrupt end. We were standing at the edge of a crescent-shaped cliff.\\n\\nTjala\\'s ears twitched.\\n\\n\"Grrrrrrrrrrrrrr.\"\\n\\n\"Ssssh.\" Yami held his hand on Tjala\\'s back to keep him still. \"Stay.\"\\n\\nThe dry creek bed ended at the edge of the cliff. I peeked over. The full moon was reflected below. The cliff walls dropped straight down to a pool of water.\\n\\n\"It\\'s a sacred place,\" said Yami. \"A spring, created by our spirit ancestors. They made the water and the cliff and all the caves along the cliff. And when they finished, they changed themselves into rocks and mountains and trees and stars and all the things on Earth and in the sky.\" He gave me his one-shoulder shrug and flashed a grin. \"And maybe fleas, too. Who knows?\"\\n\\nTjala stood at the edge of the cliff dead still, every muscle tensed. His ears pitched forward.\\n\\n\"Grrrrrrrrrrrrr.\"\\n\\n\"No, Tjala. Stay.\" Yami scratched Tjala\\'s head. He looked at me and motioned toward something below.\\n\\nI followed his gaze. The moonlight fell on a herd of large animals grazing in the grass along the water\\'s edge. Some were hunched over, eating. Some stood upright on their huge back legs, almost like humans, their long ears twitching. One of the smaller ones, a baby, turned and leaped into its mother\\'s pouch.\\n\\n\"Okay,\" I said. \"This is not South Dakota.\"\\n\\n\"South Dakota?\" Yami gave me a funny look. \"You are lost.\"\\n\\nNo kidding. I gazed down at the herd of kangaroos. Lost in Australia. About as far away from home as I could get without leaving the planet.\\n\\nBut the kangaroos! I stared at them. They were such an odd combination of parts: the face of a deer, the ears of a rabbit, the long, long tail of a rat stretching out behind them on the ground.\\n\\nWhen they bent over to eat, they were an awkward tangle of tail and legs, their big furry rumps higher than their heads. When they stood, they held their smaller front legs at their sides, like a human.\\n\\nAnd somehow all the odd and curious parts came together in a magnificent whole.\\n\\n\"I didn\\'t know they were so big,\" I whispered.\\n\\n\"These are reds,\" said Yami. \"Taller than my grandfather. This mob grazes here often.\"\\n\\n\"Mob?\"\\n\\nYami shrugged. \"A bunch of \\'roos. A mob.\"\\n\\nI nodded. A mob. I couldn\\'t take my eyes off them.\\n\\nAnd neither could Tjala.\\n\\n\"Grrrrrrrrrrrrr.\"\\n\\nThe kangaroos stopped grazing and looked up.\\n\\n\"Stay, Tjala.\"\\n\\nTjala turned his head toward Yami, then back toward the kangaroos. One of the bigger ones leaped. Its huge back feet thumped against the grass.\\n\\nTjala bounded along the edge of the cliff and scrambled down where the land began sloping toward the plain below.\\n\\n\"No!\" Yami raced after him. I followed.\\n\\nThe kangaroos bolted. They didn\\'t stampede like cattle. They hopped in all different directions, zigzagging across the grass, their hind feet thundering over the ground.\\n\\nTjala leaped onto the grassy plain and ran in circles around the \\'roos, nipping at their legs. The kangaroos kicked and swiped at him with their claws.\\n\\nYami climbed down a gully that cut through the side of the steep hill. I followed, stumbling around boulders and tripping over gnarled roots.\\n\\nThe mob had scattered. Tjala was still chasing one of the big \\'roos. It kicked at him, leaning back on its thick tail and raking Tjala\\'s nose with its hind claws.\\n\\nTjala howled.\\n', '<|endoftext|> once and thought he heard his dead brother shouting his name to come and get dinner.\\n\\nHis head was beating with a fantastic migraine that had suddenly erupted without warning. He wiped his eyes which were stinging dry like burning golf balls and looked at the bar, trying to do anything to get what he\\'d thought he\\'d seen from his head.\\n\\nWhat I saw, he wondered.\\n\\nSomething bad.\\n\\nHe was sure it was...\\n\\nA young woman with flowing blonde hair smiled back at him and the Salesman\\'s mouth lifted into a cracked smile.\\n\\nI could have a good time with that, he thought.\\n\\nShe smiled back at him. She looked early-twenties.\\n\\nHe wondered what was it about that stare. It was like she was undressing him with her eyes. She was trying to imagine what was behind his shirt and trousers. Which was crazy. No one would ever look at him like that. He might be horny but he wasn\\'t stupid. At fifty – six any good looks he might have held in his late teens had gone. Hidden behind a beer belly, a mask of wrinkled skin and a balding nest of hair.\\n\\nYet, it didn\\'t stop the punishing lust he had for her.\\n\\n\"I said, how long were you standing there?\"\\n\\nThe Salesman gasped.\\n\\n\"It isn\\'t a hard question, is it?\" she asked.\\n\\n\"Not long,\" he said gingerly.\\n\\nHe wanted to say something about what he saw, but then his head throbbed reputably.\\n\\nThe woman slowly took a sip from her glass, not bothering with the straw. He was sure she knew he wanted to fuck her. Right here, right now, on the bar if she liked. It didn\\'t matter to him. He had done it in stranger places. The hunger he felt for her was foreign to him. Sure, he\\'d had burning desires before, but this was almost overpowering to the point it was hurting just to look at her.\\n\\nHer tan looked real. No orange, or marks where it had faded or been washed off. Her skin was perfectly browned and he was sure it would taste as good as it looked.\\n\\n\"I said tell me what you saw when you walked in here?\"\\n\\nThe Salesman had almost forgotten what he\\'d saw, was almost convinced now it had all been sunstroke. All he was sure about was what he was seeing now. A young woman, no older than his bitchy, fat stepdaughter.\\n\\n\"I only just walked in when you turned around.\"\\n\\n\"Now, why don\\'t I believe you?\" she asked, provocatively.\\n\\nA cold draft blew over his body.\\n\\nPerhaps she was right. There was something else to remember.\\n\\nSomething about the way she looked at him was making him forget everything, like it was just pouring out of his head, including the migraine.\\n\\nGo to her.\\n\\nThe Salesman slowly moved across to the bar and sat down facing her.\\n\\nShe was drinking a glass of lemonade. Although it could have been gin and tonic, but the idea of tasting her lips and mouth sweetened with lemonade made him smile. It looked cold and the beads of icy sweat running down the glass made him thirsty.\\n\\n\"You want some?\" she asked as she pushed him the glass.\\n\\n\"Thanks,\" he replied, before taking a long drink from the glass.\\n\\nIt wasn\\'t lemonade. It wasn\\'t gin either. He wasn\\'t sure what it was but it tasted good and sweet.\\n\\nHe looked down and saw her tanned cleavage and then his eyes shifted to her crossed legs. There were secrets to be had in between those legs, he was sure.\\n\\n\"Do you like what you see?\" she asked, turning on her chair towards him.\\n\\nHe couldn\\'t stop staring at her breasts. Even if he tried, he couldn\\'t. Shit, this wasn\\'t like him. Yes, he was sexist and would take any pussy on offer, but he liked to think he had some reserve and some control- yet here he was, behaving like a dog in heat.\\n\\nThe Salesman tried and managed to look up into her tender inviting green eyes.\\n\\n\"Do you want to touch me, then?\" she asked, pushing a strand of her blonde hair behind her ear.\\n\\nHis hands shook. Before he could reach out she was pulling down her dress, revealing her firm, hand-sized breasts.\\n\\nHe wanted to touch her, grab those tits and...but there was a warning sign, echoing way off in his mind, it tried to tell him something was amiss.\\n\\nWhy is a young, fit woman offering a fat sweaty prick like you anything, so easy?\\n\\nHe didn\\'t care', '<|endoftext|>ından.\\n\\nEnglish: \\n(logo echoes)\\n(crowd chanting TSM TSM TSM TSM)\\n- Hey, guys, it\\'s DanucD,\\nand as most of you know\\nI\\'m a streamer for TSM.\\nLittle while ago we did ask you guys\\nwhat would you like to know about me,\\nso I\\'m super excited to answer\\nto everybody\\'s questions,\\nand also I would like to\\ngive a special shout out\\nto the best gear in gaming, Logitech G,\\nfor sponsoring this video,\\nso let\\'s get started.\\n(upbeat music)\\nFirst question is from LogitechGesport.\\nWhat is your all-time favorite\\nPUBG moment from your stream?\\nMy favorite moment is from\\nmy first chicken dinner.\\nI even remember the location of the circle\\nwhere the zone was ending,\\nhow many kills I had,\\nand the feelings which\\nI did receive back then\\nwas just unbelievable.\\nMy hands were shaking and I\\'m gonna just\\nremember this forever.\\nMerriljt513.\\n\\nGerman: \\n- Hey, Leute, es ist DanucD,\\nund wie die meisten von Euch\\nwissen,\\nIch bin ein Streamer für TSM.\\nVor kurzem haben wir Euch gefragt\\nwas würdest du gerne über mich wissen,\\nalso bin ich super aufgeregt\\nzu Antworten zu allen Fragen,\\nund auch ich möchte geben Sie\\neinen besonderen Schrei aus\\num die beste Ausrüstung\\nim Gaming, Logitech G,\\nfür das Sponsoring dieses\\nVideos, also lasst uns anfangen.\\nErste Frage ist von LogitechGesport.\\nWas ist dein allzeit-Favorit\\nPUBG Moment aus Ihrem stream?\\nMein lieblings Moment ist\\nvon mein erstes Hühnchen\\nAbendessen.\\nIch erinnere mich sogar\\nan den Ort des Kreises\\nwo die Zone endet, wie\\nviele tötet hatte ich,\\nund die Gefühle, die\\nIch habe damals erhalten\\nwar einfach unglaublich.\\nMeine Hände zitterten\\nund ich werde einfach\\nerinnere dich daran für immer.\\nMerriljt513.\\n\\nRussian: \\n- Привет, я - DanucD, и\\nкак многие из вас знают,\\nчто я стримерша TSM.\\nНекоторое время назад мы спрашивали вас,\\nчто бы вы хотели узнать обо мне\\nи я очень рада ответить на все вопросы,\\nа также я хотела бы поблагодарить\\nлучшее игровое оборудование от Logitech G\\nза спонсирование этого\\nвидео, давайте начнем.\\nПервый вопрос от Logitech G esport:\\n«Какой твой самый любимый момент\\nPUBG из своей трансляции?»\\n��юбимый момент - первый раз:\\nпобеда, победа, вместо обеда.\\n�� даже помню расположение круга\\nгде кончалась зона, скольких я уложила,\\nи те чувства, которые я тогда испытывала\\nни с чем не сравнимы.\\nУ меня дрожали руки и я\\nникогда этого не забуду.\\n\\nSpanish: \\n@Merriljt513.\\n\"¿Ves anime?\\n\"Si es así, ¿algún favorito?\"\\nEl único anime que he visto es Pokemon,\\ny no sé, ¿cuenta como anime?\\nPero definitivamente, eso\\nfue gran parte de mi infancia\\ne incluso estaba coleccionando\\npegatinas de Pokemon\\ne intercambiando con\\nmis compañeros de clase.\\nFueron buenos momentos.\\n@Spectralecho pregunta,\\n\"¿Qué habrías hecho', '<|endoftext|> you could try using my grain-free biscuit recipe instead.\\n\\nThe basic strawberry ice cream recipe is taken from my book, Coconut Milk Ice Cream and I simply added some extra strawberry bits and some crumbled shortbread.\\n\\nThis ice cream is:\\n\\nVegan\\n\\nDairy-free\\n\\nEggless\\n\\nNut-free\\n\\nYield: 1 quart Vegan Strawberry Shortbread Ice Cream Print The ultimate summer indulgence - this strawberry shortbread ice cream is vegan, dairy free and can be made gluten-free by using a gluten-free shortbread! Prep Time 15 minutes Total Time 15 minutes Ingredients 720 ml / 3 cups coconut milk, full-fat\\n\\n2 tbsp arrowroot powder\\n\\n120 ml / ½ cup maple syrup\\n\\n1 cup strawberries, hulled and chopped\\n\\noptional 1 tbsp alcohol (such as vodka, brandy etc.)\\n\\n1 tsp vanilla paste\\n\\n1/4 batch of vegan shortbread cookies, crushed into coarse crumbs Instructions Mix 60ml / ¼ cup coconut milk with the arrowroot powder in a small bowl and set aside. Pour the rest of the coconut milk into a blender with the strawberries and maple syrup and blend until smooth. Pour the mixture into a large saucepan and bring to a boil. As soon as the mixture begins to boil, stir in the arrowroot mixture to thicken the liquid. Remove from the heat and stir in the vanilla and alcohol. Chill the mixture in the fridge until very cold and churn in your ice cream maker, following the manufacturer\\'s instructions. During the last few minutes of churning, add the half of the shortbread crumbs, reserving the rest for decoration. Transfer the mixture to a freezer-safe container, sprinkle the rest of the shortbread crumbs on top and freeze for at least 4 hours or overnight. To serve, leave soften for a few minutes at room temperature before scooping. Serve with some extra shortbread crumbs in a cone or in a bowl. Enjoy!<|endoftext|>Q:\\n\\nIs there a stacked pie chart that I can use with ASP.NET?\\n\\nI am using ASP.NET and C#.  All of the pie chart controls that I see will only allow each category to be assigned one value.\\nFor example, I could make a list of email campaigns and associate each campaign with a number of messages sent.\\nBut what I want to do is show a pie chart which displays multiple values per campaign.  For example, each campaign would show the number of messages sent, number failed, and number pending.\\nIs there any solution for this kind of pie chart in ASP.NET?\\n\\nA:\\n\\nYou can use 2D stacked pie chart that allows you to visualize multiple attributes in separate \"doughnuts\" stacked inside a single chart. Something like this:\\n\\nIf you\\'re using Microsoft Chart Controls, then here is a post that describes how to do that. Essentially, you\\'ll just create three independent doughnut charts and place them over each other. If you\\'re using some other library, then you\\'ll need to clarify that in your question.\\n\\n<|endoftext|>Cuban outfielder Yoenis Cespedes has yet to play a game in the major leagues, and some scouts are already comparing him to former Los Angeles Dodgers All-Star Raul Mondesi. Personnel people with more active imaginations take a look at that sculpted 6-foot, 215-pound physique and those quick-twitch muscles and think more along the lines of Bo Jackson.\\n\\nRene Gayo, director of Latin American scouting for the Pittsburgh Pirates, prefers a more obscure comparison: He likens Cespedes to former Houston outfielder Jimmy \"The Toy Cannon\\'\\' Wynn, who made three All-Star teams and hit 291 home runs during a 15-year career in the 1960s and \\'70s.\\n\\nYoenis Cespedes, 26, played for Cuba during the World Baseball Classic in 2009. AP Photo/Gregory Bull\\n\\nFew people mention Pittsburgh as a prime candidate to sign Cespedes, given his perceived price tag, but Gayo\\'s opinion carries a lot of weight. He\\'s a respected voice in Latin scouting, and along with the Phillies\\' Sal Agostinelli, he has probably seen more of Cespedes than any big-time talent evaluator in the game. After watching Cespedes perform in several international tournaments, he\\'s convinced the young outfielder has the goods to be an impact player.\\n\\n\"He has great game skills,\\'\\' Gayo said. \"That\\'s why I like him. When they say \\'play ball,\\' he gets it done.\\n\\n\"When you watched Cuba play, he was definitely a guy who had a star next to his name. Just because a guy defects and is Cuban, it doesn\\'t mean he\\'s a big league prospect. This guy is the real deal.\\'\\'\\n\\n']\n","447 ['<|endoftext|> for Women in Transition merged with A Woman\\'s Place in 2010. Now, they\\'ll be known as Courage Connection. Both were domestic abuse facilities.\\n\\nLeaders say there\\'s still a bit of confusion in the community and they think a new name will give them a fresh start. They say they want to connect with the community and a new look to its website will help.<|endoftext|>Q:\\n\\nНужна ли запятая в предложении \"Думаешь как удивить ребенка на День рождения?\"\\n\\nПри проверке модератор ВК отклонил его, ссылаясь на то, что после слова \"думаешь\" нужна запятая. \\n\\nA:\\n\\nЗапятая нужна, потому что это сложноподчиненное предложение. Главное предложение состоит из одного слова \"думаешь\". ��апятая отделяет придаточное предложение. А \"день рождения\" пишется со строчной буквы. А еще, я бы предпочел \"в\" вместо \"на\".  \\nДумаешь, как удивить ребенка в день рождения? \\nСравните: \\nПригласить друзей на день рождения.\\nПриготовить подарок ко дню рождения.\\n\\n<|endoftext|>[Echography in the diagnosis of organic pathology of the hepatopancreaticoduodenal area after cholecystectomy].\\nPotentialities were studied of echography in the exploration of characteristics of the biliary system in those patients (n = 168) in the remote period following cholecystectomy who suffered from postcholecystectomy syndrome (PChES). More than one-third of the PChES patient population demonstrated different changes in the biliary tract, such as concrements, aerobilia, inflammatory process, etc. Pancreatic pathology was recorded in 28.57 percent, hepatic abnormalities--in 32.7 percent of PChES cases. Echography was proved to be a method of high informative value in a comprehensive evaluation of the condition of the biliary system and adjacent organs in postcholecystectomy patients.<|endoftext|>168 F.3d 1124\\nH & H BROKERAGE, INC., Appellee,v.VANLINER INSURANCE COMPANY, Appellant.\\nNo. 98-1398.\\nUnited States Court of Appeals,Eighth Circuit.\\nSubmitted Sept. 24, 1998.Decided Feb. 24, 1999.Rehearing and Rehearing En Banc Denied April 27, 1999.*\\n\\nPatrick J. Goss, Little Rock, AR, argued, for Appellant.\\nLarry Killough, Jr., Searcy, AR, argued, for Appellee.\\nBefore WOLLMAN, JOHN R. GIBSON, and MORRIS SHEPPARD ARNOLD, Circuit Judges.\\nMORRIS SHEPPARD ARNOLD, Circuit Judge.\\n\\n\\n1\\nH & H Brokerage (H & H) arranged for a shipment of goods owned by Singer Sewing Company (Singer) to be carried by R & R Trucking (R & R).  The shipment was stolen from R & R\\'s possession before it was delivered.  Singer submitted a claim to R & R\\'s insurance company, which denied the claim on the ground that R & R\\'s policy did not cover Singer\\'s damages.  Singer then demanded that H & H compensate it for its damages, and suspended its business with H & H until H & H should do so.\\n\\n\\n2\\nH & H contacted its own insurance carrier, Vanliner Insurance Company (Vanliner), which informed H & H that its policy did not cover the cost of lost goods if R & R\\'s insurance did not do so (such coverage is \"contingent cargo liability coverage\").  H & H then paid Singer and sued Vanliner under Arkansas law for breach of contract and the tort of bad faith.  A jury awarded approximately $84,150 to H & H (the amount that H & H had paid to Singer) for the lost goods, approximately $11,750 for H & H\\'s lost profits (from the temporary loss of Singer\\'s business), and $50,000 in punitive damages.  The trial court denied Vanliner\\'s motion for judgment notwithstanding the verdict (JNOV) and entered judgment for H & H.\\n\\n\\n3\\nVanliner appeals.  We can reverse only if \"after viewing the evidence in the light most favorable to the verdict, we', '<|endoftext|>visitor/opts/u64/val1/trailing\", &expect_fail, \"u64=5z\");\\n    add_test(\"/visitor/opts/u64/nonlist\",       &expect_fail, \"u64x=5-6\");\\n    add_test(\"/visitor/opts/u64/val2/errno\",    &expect_fail,\\n             \"u64=0xffffffffffffffff-0x10000000000000000\");\\n    add_test(\"/visitor/opts/u64/val2/empty\",    &expect_fail, \"u64=5-\");\\n    add_test(\"/visitor/opts/u64/val2/trailing\", &expect_fail, \"u64=5-6z\");\\n    add_test(\"/visitor/opts/u64/range/empty\",   &expect_fail, \"u64=6-5\");\\n    add_test(\"/visitor/opts/u64/range/minval\",  &expect_zero, \"u64=0-0\");\\n    add_test(\"/visitor/opts/u64/range/maxval\",  &expect_u64_max,\\n             \"u64=0xffffffffffffffff-0xffffffffffffffff\");\\n\\n    /* Test maximum range sizes. The macro value is open-coded here\\n     * *intentionally*; the test case must use concrete values by design. If\\n     * OPTS_VISITOR_RANGE_MAX is changed, the following values need to be\\n     * recalculated as well. The assert and this comment should help with it.\\n     */\\n    g_assert(OPTS_VISITOR_RANGE_MAX == 65536);\\n\\n    /* The unsigned case is simple, a u64-u64 difference can always be\\n     * represented as a u64.\\n     */\\n    add_test(\"/visitor/opts/u64/range/max\",  &expect_ok,   \"u64=0-65535\");\\n    add_test(\"/visitor/opts/u64/range/2big\", &expect_fail, \"u64=0-65536\");\\n\\n    /* The same cannot be said about an i64-i64 difference. */\\n    add_test(\"/visitor/opts/i64/range/max/pos/a\", &expect_ok,\\n             \"i64=0x7fffffffffff0000-0x7fffffffffffffff\");\\n    add_test(\"/visitor/opts/i64/range/max/pos/b\", &expect_ok,\\n             \"i64=0x7ffffffffffeffff-0x7ffffffffffffffe\");\\n    add_test(\"/visitor/opts/i64/range/2big/pos\",  &expect_fail,\\n             \"i64=0x7ffffffffffeffff-0x7fffffffffffffff\");\\n    add_test(\"/visitor/opts/i64/range/max/neg/a\", &expect_ok,\\n             \"i64=-0x8000000000000000--0x7fffffffffff0001\");\\n    add_test(\"/visitor/opts/i64/range/max/neg/b\", &expect_ok,\\n             \"i64=-0x7fffffffffffffff--0x7fffffffffff0000\");\\n    add_test(\"/visitor/opts/i64/range/2big/neg\",  &expect_fail,\\n             \"i64=-0x8000000000000000--0x7fffffffffff0000\");\\n    add_test(\"/visitor/opts/i64/range/2big/full\", &expect_fail,\\n             \"i64=-0x8000000000000000-0x7fffffffffffffff\");\\n\\n    g_test_add_func(\"/visitor/opts/range/unvisited\",\\n                    test_opts_range_unvisited);\\n    g_test_add_func(\"/visitor/opts/range/beyond\",\\n                    test_opts_range_beyond);\\n\\n    g_test_add_func(\"/visitor/opts/dict/unvisited\", test_opts_dict_unvisited);\\n\\n    g_test_run();\\n    return 0;\\n}\\n<|endoftext|>875 F.2d 172\\n28 Fed. R. Evid. Serv. 187\\nUNITED STATES of America, Appellee,v.Terrance Kenneth PROVOST, Appellant.\\nNo. 87-5351.\\nUnited States Court of Appeals,Eighth Circuit.\\nSubmitted Oct. 21, 1988.Decided May 15, 1989.Rehearing and Rehearing En Banc Denied June 22, 1989.\\n\\nRobert C. Riter, Jr., Pierre, S.D', '<|endoftext|> OF COLUMBIA CIRCUIT\\nArgued October 18, 1999Decided February 29, 2000Rehearing En Banc Denied May 2, 2000.\\n\\nAppeal of Orders of the Federal Communications Commission\\nLauren A. Colby argued the cause and filed the briefs for  appellant.\\nJames M. Carr, Counsel, Federal Communications Commission, argued the cause for appellee.  With him on the brief  were Christopher J. Wright, General Counsel, and Daniel M.  Armstrong, Associate General Counsel.  Pamela L. Smith,  Counsel, entered an appearance.\\nBefore:  Sentelle, Henderson, and Garland, Circuit  Judges.\\nOpinion for the Court filed by Circuit Judge Garland.\\nGarland, Circuit Judge:\\n\\n\\n1\\nAppellant Herbert Schoenbohm  operates an amateur radio station in the U.S. Virgin Islands.In 1992, he was convicted of a felony for fraudulently using  counterfeit access codes to obtain long distance telephone  services.1  In 1994, shortly before Schoenbohm\\'s amateur  radio licenses were due to expire, he filed a renewal application with the Federal Communications Commission (FCC).\\n\\n\\n2\\nAfter a series of hearings, an administrative law judge  (ALJ) denied Schoenbohm\\'s application.  On June 29, 1998,  the Commission affirmed the denial, finding that Schoenbohm\\'s fraud conviction, \"in combination with\" his misrepresentations and lack of candor during the renewal proceedings,  justified nonrenewal.  Herbert L. Schoenbohm, 13 F.C.C.R.  15,028, 15,028 (1998) [hereinafter Decision].  Schoenbohm  filed a petition for reconsideration, reiterating arguments he  had previously made and asking for the first time that the  FCC investigate allegations that some of his detractors may  have had improper ex parte contacts with the ALJ.  See J.A.  at 77.  The FCC denied reconsideration, restating its previous justifications for nonrenewal and rejecting the request for  an inquiry into the ex parte allegations.  See Herbert L.  Schoenbohm, 13 F.C.C.R. 23,774, 23,777 (1998) [hereinafter  Reconsideration Order].\\n\\n\\n3\\nSchoenbohm contends that the denials of both his renewal  application and his petition for reconsideration were arbitrary  and capricious agency actions, in violation of the Administrative Procedure Act, 5 U.S.C.      706(2)(A).  We affirm the  FCC\\'s refusal to renew Schoenbohm\\'s radio licenses and  conclude that we are without jurisdiction to review the rejection of his petition for reconsideration.\\n\\n\\n4\\n* We begin with the FCC\\'s denial of Schoenbohm\\'s renewal  application.  Before reaching the merits of that decision,  however, we must resolve a preliminary question of jurisdiction.  The Commission argues that Schoenbohm did not  appeal from its original decision to deny his renewal application, but only from its order denying his petition to reconsider  that decision.  Denial of a petition for reconsideration, the  agency correctly notes, is generally nonreviewable unless the  request for reconsideration was based on new evidence or  changed circumstances.  See ICC v. Brotherhood of Locomotive Eng\\'rs, 482 U.S. 270, 279-80 (1987);  Southwestern Bell  Tel. Co. v. FCC, 180 F.3d 307, 311 (D.C. Cir. 1999);  see also  Entravision Holdings, LLC v. FCC, 202 F.3d 307, 311 (D.C. Cir.1999) (holding that nonreviewability  in this context means lack of jurisdiction).\\n\\n\\n5\\nIt is true that the notice of appeal Schoenbohm filed in this  court characterizes his appeal as being from the order denying the petition for reconsideration.  See J.A. at 85.  It is also  true that in Southwestern Bell, where the petition for review  designated only the reconsideration order, we held both that  the reconsideration order was nonreviewable and that the  underlying order was not properly before us.  See Southwestern Bell, 180 F.3d at 313-14.  We did not, however, suggest  that the failure to designate an order in a petition for review  (or notice of appeal) is always fatal.  To the contrary, \"we  said in Southwestern Bell Telephone Co. v. FCC [that] a party  may demonstrate its intention to appeal from one order  despite referring only to a different order in its petition for  review if the petitioner\\'s intent \\'can be fairly inferred\\' from', '<|endoftext|> the below, I want to pick out the information about landmarks for every city (even if there is no landmark element or there are several) and ignore the information about stations.\\n<world>\\n    <city>\\n        <name>London</name>\\n        <buildings>\\n            <building>\\n                <type>landmark</type>\\n                <bname>Tower Bridge</bname>\\n            </building>\\n            <building>\\n                <type>station</type>\\n                <bname>Waterloo</bname>\\n            </building>\\n        </buildings>\\n    </city>\\n    <city>\\n        <name>New York</name>\\n        <buildings>\\n            <building>\\n                <type>station</type>\\n                <bname>Grand Central</bname>\\n            </building>\\n        </buildings>\\n    </city>\\n    <city>\\n        <name>Paris</name>\\n        <buildings>\\n            <building>\\n                <type>landmark</type>\\n                <bname>Eiffel Tower</bname>\\n            </building>\\n            <building>\\n                <type>landmark</type>\\n                <bname>Louvre</bname>\\n            </building>\\n        </buildings>\\n    </city>\\n</world>\\n\\nIdeally this would go into a dataframe that looks something like this:\\n London      Tower Bridge\\n New York    NA\\n Paris       Eiffel Tower\\n Paris       Louvre\\n\\nI assumed there might be a way to do this using the XML library and xpathSApply but I think I\\'m beaten.\\nAlso couldn\\'t think how to phrase the question without just referring to the example so feel free to edit to give a more descriptive question.\\n\\nA:\\n\\nAssuming the XML data is in a file called world.xml read it in and iterate over the cities extracting the city name and the bname of any associated landmarks :\\nlibrary(XML)\\ndoc <- xmlParse(\"world.xml\", useInternalNodes = TRUE)\\n\\ndo.call(rbind, xpathApply(doc, \"/world/city\", function(node) {\\n\\n   city <- xmlValue(node[[\"name\"]])\\n\\n   xp <- \"./buildings/building[./type/text()=\\'landmark\\']/bname\"\\n   landmark <- xpathSApply(node, xp, xmlValue)\\n   if (is.null(landmark)) landmark <- NA\\n\\n   data.frame(city, landmark, stringsAsFactors = FALSE)\\n\\n}))\\n\\nThe result is:\\n      city     landmark\\n1   London Tower Bridge\\n2 New York         <NA>\\n3    Paris Eiffel Tower\\n4    Paris       Louvre\\n\\n<|endoftext|>Osteochondrosis dissecans occurring in the knee and ankle of the same patient.\\nOsteochondrosis dissecans is a disease that is known to present in multiple joints. A literature search revealed no reports of this lesion appearing in the knee and ankle of the same patient. Such a clinical presentation is the basis for this report, which is intended to alert clinicians to include osteochondrosis dissecans in their differential diagnosis of knee and ankle pain. A short review of the literature and treatment alternatives is included.<|endoftext|>930 F.2d 116\\nProd.Liab.Rep.(CCH)P 12,804Mark T. KNOWLTON, et al., Plaintiffs, Appellees,v.DESERET MEDICAL, INC., Defendant, Appellant.\\nNo. 89-2139.\\nUnited States Court of Appeals,First Circuit.\\nHeard March 5, 1991.Decided April 19, 1991.Rehearing and Rehearing En BancDenied May 17, 1991.\\n\\nJeffrey S. Stern with whom Tina M. Traficanti, Ellen K. Wade and Sugarman, Rogers, Barshak & Cohen were on brief, Boston, Mass., for defendant-appellant.\\nTerrence D. Garmey with whom Smith & Elliott were on brief, Saco, Me., for plaintiffs-appellees.\\nBefore CYR, Circuit Judge, COFFIN and BOWNES, Senior Circuit Judges.\\nBOWNES, Senior Circuit Judge.\\n\\n\\n1\\nThe main issue on this appeal requires us to determine under Massachusetts law the duty to warn imposed on the manufacturer-seller of medical devices used during open-heart surgery and the closely related question of causation.  Plaintiffs-appellees Mark Knowlton and his mother, Bonnie B. Tetrault, brought suit for injuries from chemical burns incurred by Knowlton during open-heart surgery at Children\\'s Hospital in Boston.  The jury found that defendant-appellant Deseret Medical, Inc. was liable for', '<|endoftext|> appearance. Relaxer users then want to revitalize the color of their hair but are often reluctant to further assault hair that is already fragile with an oxidative dye procedure.\\nConsumers who have repeatedly oxidatively dyed or treated their hair with permanent wave processes may also have the same problem. Hair that has been permed may be fragile, dry, and in some cases, damaged. Applying oxidative color to such hair may only further promote damage to the hair. Yet, these consumers often wish to color their hair, and need a product that is mild, yet effective.\\nIn other cases, oxidative hair color users may desire to revitalize the color of the hair. However, for a variety of reasons, such users may be reluctant to undergo another oxidative hair color procedure. Generally, standard oxidative hair color is referred to as “Level 3” hair color. Level 3 hair color involves a process where the melanin fibers of the hair are both bleached or lightened, as well as colored with the oxidative dye. Level 2 hair color, on the other hand, refers to a hair color process where the hair is colored, but not bleached or lightened, with oxidative dyes. Another name for Level 2 hair color is “tone on tone” hair color. It would be most desirable for Level 3 hair color users to have a quick, efficient, mild, process for revitalizing the color of their oxidatively dyed hair using a Level 2 hair color, which is less invasive.\\nAccordingly, there is a need for a simple, user friendly, fast, and gentle method for coloring hair that is suitable for coloring First Grays, or coloring hair that has been chemically processed. Ideally, this method will provide tones on gray hair, for example, golden tones on brown hair, warm tones on red hair, or ashy tones on black hair.\\nIt is an object of the invention to provide a method and compositions for oxidatively coloring hair in about two to five minutes, preferably about two minutes.\\nIt is a further object of the invention to provide a hair color composition and process suitable for treating First Grays.\\nIt is a further object of the invention to provide a hair color composition and process for coloring hair that has been treated with lye-based hair relaxers.\\nIt is a further object of the invention to provide a hair color composition and process for coloring hair that is gentle, easy to use, fast, and suitable for hair that has been chemically processed such as by permanent waving, Level 3 hair color, and the like.\\nIt is a further object of the invention to provide a hair color composition and process for revitalizing the color of oxidatively colored (Level 3) hair color.\\nIt is a further object of the invention to provide a Level 2 hair color composition and process for revitalizing the color of hair that has been colored with Level 3 hair color.\\nIt is a further object of the invention to provide a hair color composition containing glyceryl esters, preferably lecithin, one or more surfactants, and one or more oxidative dyes.<|endoftext|>Q:\\n\\nIf $p(x+y)^2=5$ and $q (x-y)^2=3$, then the simplified value of $p^2(x+y)^2+4pqxy-q^2(x-y)^2$ is?\\n\\nIf $p(x+y)^2=5$ and $q (x-y)^2=3$, then the simplified value of $p^2(x+y)^2+4pqxy-q^2(x-y)^2$ is?\\n\\nAnswer: $2(p+q)$\\n\\nA:\\n\\n$$(x+y)^2 = 5/p$$\\n$$(x-y)^2 = 3/q$$\\n$$\\\\implies 4xy = 5/p - 3/q$$\\n\\n<|endoftext|>183 F.3d 816 (8th Cir. 1999)\\nLITTLE ROCK SCHOOL DISTRICT, PLAINTIFF,v.JAMES MAUNEY, MR. AND MRS., PARENTS OF J. M., DEFENDANTS.JAMES MAUNEY, MR. AND MRS., PARENTS OF J. M., THIRD PARTY PLAINTIFF-APPELLEE,v.STATE OF ARKANSAS, ARKANSAS DEPARTMENT OF EDUCATION, THIRD PARTY DEFENDANTS-APPELLANTS.\\nNo. 98-1721\\nU.S. Court of Appeals, Eighth Circuit\\nSubmitted: December 15, 1998June 14, 1999Rehearing and Rehearing En Banc Denied Aug. 10, 1999.*\\n\\nAppeal from the United States District Court for the Eastern District of Arkansas[Copyrighted Material Omitted][Copyrighted Material Omitted]\\nBefore Fagg, Heaney, and Wollman, Circuit Judges.\\n', '<|endoftext|>public void beforeChange(InetAddress endpoint, EndpointState currentState, ApplicationState newStateKey, VersionedValue newValue) {}\\n    public void onChange(InetAddress endpoint, ApplicationState state, VersionedValue value) {}\\n    public void onAlive(InetAddress endpoint, EndpointState state) {}\\n    public void onDead(InetAddress endpoint, EndpointState state) {}\\n\\n    public void onRemove(InetAddress endpoint)\\n    {\\n        closeSession(State.FAILED);\\n    }\\n\\n    public void onRestart(InetAddress endpoint, EndpointState epState)\\n    {\\n        closeSession(State.FAILED);\\n    }\\n\\n    private boolean maybeCompleted()\\n    {\\n        boolean completed = receivers.isEmpty() && transfers.isEmpty();\\n        if (completed)\\n        {\\n            if (state == State.WAIT_COMPLETE)\\n            {\\n                if (!completeSent)\\n                {\\n                    handler.sendMessage(new CompleteMessage());\\n                    completeSent = true;\\n                }\\n                closeSession(State.COMPLETE);\\n            }\\n            else\\n            {\\n                // notify peer that this session is completed\\n                handler.sendMessage(new CompleteMessage());\\n                completeSent = true;\\n                state(State.WAIT_COMPLETE);\\n            }\\n        }\\n        return completed;\\n    }\\n\\n    /**\\n     * Flushes matching column families from the given keyspace, or all columnFamilies\\n     * if the cf list is empty.\\n     */\\n    private void flushSSTables(Iterable<ColumnFamilyStore> stores)\\n    {\\n        List<Future<?>> flushes = new ArrayList<>();\\n        for (ColumnFamilyStore cfs : stores)\\n            flushes.add(cfs.forceFlush());\\n        FBUtilities.waitOnFutures(flushes);\\n    }\\n\\n    private void prepareReceiving(StreamSummary summary)\\n    {\\n        if (summary.files > 0)\\n            receivers.put(summary.cfId, new StreamReceiveTask(this, summary.cfId, summary.files, summary.totalSize));\\n    }\\n\\n    private void startStreamingFiles()\\n    {\\n        streamResult.handleSessionPrepared(this);\\n\\n        state(State.STREAMING);\\n        for (StreamTransferTask task : transfers.values())\\n        {\\n            Collection<OutgoingFileMessage> messages = task.getFileMessages();\\n            if (messages.size() > 0)\\n                handler.sendMessages(messages);\\n            else\\n                taskCompleted(task); // there is no file to send\\n        }\\n    }\\n}\\n<|endoftext|>986 F.2d 270\\n37 Fed. R. Evid. Serv. 25\\nUNITED STATES of America, Appellee,v.Louis BOYKIN, Appellant.\\nNo. 92-2125.\\nUnited States Court of Appeals, Eighth Circuit.\\nSubmitted Nov. 12, 1992.Decided Feb. 23, 1993.Rehearing and Rehearing En BancDenied April 21, 1993.\\n\\nStephen W. Cooper, St. Paul, MN, argued, for appellant.\\nCarol Ann Needles, Minneapolis, MN, argued (Thomas B. Heffelfinger and Carol A. Needles, Minneapolis, MN, on the brief), for appellee.\\nBefore JOHN R. GIBSON and MAGILL, Circuit Judges, and BOGUE,* Senior District Judge.\\nMAGILL, Circuit Judge.\\n\\n\\n1\\nLouis Boykin appeals from a jury conviction of several drug charges relating to distribution of crack and powder cocaine, the use of a firearm in connection with a drug trafficking crime, and possession of a firearm by a prior felon.   Boykin claims his right to a fair trial was violated by the delayed disclosure of perjury by a witness.   He also raises several other claims of error by the district court.1  We affirm.\\n\\nI. BACKGROUND\\n\\n2\\nOn April 24, 1991, Gary Pederson, a special agent with the Minnesota Bureau of Criminal Apprehension, acting undercover, approached Roy Prince to purchase powder cocaine from him.   Prince indicated that his source was named \"Louis\" or \"Louie,\" and was sixty-three years old.   At Prince\\'s directions, Pederson drove Prince to 1023 Dayton Avenue, in St. Paul, Minnesota.   Motor vehicle and license records revealed that appellant Louis Boykin, who was sixty-three years old, lived at this address.   Pederson gave Prince $1400 for the cocaine.   Prince entered the house with the money, returned to the car, and told Pederson that they would have to return in one hour.   When they returned, they parked the', \"<|endoftext|> station is 50% owned by the family that owns VP Group. The remaining 50% is owned by unnamed investors from the United Kingdom. CfC Stanbic Bank provided a loan of US$3.25 million, while the owners raised the remaining US$3.25. The power remaining over after sale to Kenya Power will be sold to the VP Group and some will be used internally by the power station.\\n\\nOther considerations\\nIn addition to producing electricity and heat, the plant will produce an estimated 35,000 tonnes of fertilizer annually, from the remnants of anaerobic digestion. In addition to the plant material generated at Gorge Farm Energy Park, more raw material will be sourced from the neighboring Van den Berg Roses Farm.\\n\\nSee also\\nKenya Power Stations\\nAfrica Power Stations\\nWorld Power Stations\\n\\nReferences\\n\\nExternal links\\n Website of Biojoule Kenya Limited\\n\\nCategory:Biofuel power stations in Kenya\\nCategory:Nakuru County\\nCategory:Central Province (Kenya)<|endoftext|>Q:\\n\\nCan I reformat an external hard drive to have the maximum amount space that was previously available?\\n\\nI set up my external hard drive that had 1.5TB of space as a recovery drive, and afterwards it showed that I have 32GB of space. Is there any way I can get my space back?\\n\\nA:\\n\\nWhich OS are you using, and how exactly did you set it up as a recovery drive? Also, I take it you no longer want to use it for recovery purposes?\\nIf you're using Windows 7 or older, go to Start / Run / diskmgmt.msc, right-click and delete all existing partitions on the drive. Then you can create a new simple volume and format as NTFS.\\nIn Windows 8 since there's no Start button any more, just press +X to bring up the Power User Menu and select Disk Management:\\n\\nIf you're using Linux, fire up GParted and do the same.\\n\\n<|endoftext|>Posts Tagged With 'RMMRP000'\\n\\nIf your MRP background jobs are running too long then you can use “Paralles Processing” option for your MRP process.You can choose the destination of application systems for parallel processing and number of sessions for the process easily via related transaction code…<|endoftext|>Restructuring health care financing in Chile.\\nThe current Chilean government adopted a neoclassical model of development and subsequently introduced various incentives for the privatization of medical care. This paper analyzes health care financing in Chile during the last decade and evaluates government efforts to minimize state-financed medical care. In so doing, this paper provides a framework for analyzing private vs public medical care delivery systems in developing countries. For this reason, the first section discusses the major attributes and issues of public and private delivery systems followed by a case study examining the origins, effectiveness and impact of the restructured health system in Chile.<|endoftext|>719 F.2d 902\\nUNITED STATES of America, Plaintiff-Appellee,v.David Frederick ELY, Defendant-Appellant.\\nNo. 82-2860.\\nUnited States Court of Appeals,Seventh Circuit.\\nArgued May 23, 1983.Decided Oct. 18, 1983.Rehearing and Rehearing En Banc Denied Nov. 16, 1983.As Amended Nov. 21, 1983.\\n\\nWendi Sloane Weitman, Kirkland & Ellis, Chicago, Ill., for defendant-appellant.\\nJanet L. Jannusch, Asst. U.S. Atty., Peoria, Ill., for plaintiff-appellee.\\nBefore CUDAHY, POSNER, and COFFEY, Circuit Judges.\\nPOSNER, Circuit Judge.\\n\\n\\n1\\nThis appeal raises questions relating to an indigent defendant's right to counsel of his choice, and to appellate review of the length of a sentence that is within statutory limits.\\n\\n\\n2\\nDavid Ely was indicted in 1979 along with two other men, Dawson and Griswold, for distributing and conspiring to distribute cocaine, in violation of 21 U.S.C. Secs. 841(a)(1), 846.  Ely was an intermediate distributor, Dawson his source, and Griswold a dealer whom Ely supplied with cocaine that he obtained from Dawson.  Griswold and Dawson pleaded guilty and were sentenced to 10 and 15 years in prison, respectively.  Dawson moved for a reduction of sentence under Rule 35(b) of the Federal Rules of Criminal Procedure, the motion was denied, he appealed, and this court affirmed.   United States v. Dawson, 642 F.2d 1060 (7th Cir.1981) (per curiam).  Ely failed to appear in court with the others and became a fugitive.  The government then filed a superseding indictment against him that included two counts of failing to appear, in violation of 18 U\", '<|endoftext|>+\\'|\\'-\\') term)*\\nterm: factor ((\\'*\\'|\\'@\\'|\\'/\\'|\\'%\\'|\\'//\\') factor)*\\nfactor: (\\'+\\'|\\'-\\'|\\'~\\') factor | power\\npower: atom trailer* [\\'**\\' factor]\\natom: (\\'(\\' [yield_expr|testlist_gexp] \\')\\' |\\n       \\'[\\' [listmaker] \\']\\' |\\n       \\'{\\' [dictsetmaker] \\'}\\' |\\n       \\'`\\' testlist1 \\'`\\' |\\n       NAME | NUMBER | STRING+ | \\'.\\' \\'.\\' \\'.\\')\\nlistmaker: (test|star_expr) ( comp_for | (\\',\\' (test|star_expr))* [\\',\\'] )\\ntestlist_gexp: (test|star_expr) ( comp_for | (\\',\\' (test|star_expr))* [\\',\\'] )\\nlambdef: \\'lambda\\' [varargslist] \\':\\' test\\ntrailer: \\'(\\' [arglist] \\')\\' | \\'[\\' subscriptlist \\']\\' | \\'.\\' NAME\\nsubscriptlist: subscript (\\',\\' subscript)* [\\',\\']\\nsubscript: test | [test] \\':\\' [test] [sliceop]\\nsliceop: \\':\\' [test]\\nexprlist: (expr|star_expr) (\\',\\' (expr|star_expr))* [\\',\\']\\ntestlist: test (\\',\\' test)* [\\',\\']\\ndictsetmaker: ( (test \\':\\' test (comp_for | (\\',\\' test \\':\\' test)* [\\',\\'])) |\\n                (test (comp_for | (\\',\\' test)* [\\',\\'])) )\\n\\nclassdef: \\'class\\' NAME [\\'(\\' [arglist] \\')\\'] \\':\\' suite\\n\\narglist: (argument \\',\\')* (argument [\\',\\']\\n                         |\\'*\\' test (\\',\\' argument)* [\\',\\' \\'**\\' test] \\n                         |\\'**\\' test)\\nargument: test [comp_for] | test \\'=\\' test  # Really [keyword \\'=\\'] test\\n\\ncomp_iter: comp_for | comp_if\\ncomp_for: \\'for\\' exprlist \\'in\\' testlist_safe [comp_iter]\\ncomp_if: \\'if\\' old_test [comp_iter]\\n\\ntestlist1: test (\\',\\' test)*\\n\\n# not used in grammar, but may appear in \"node\" passed from Parser to Compiler\\nencoding_decl: NAME\\n\\nyield_expr: \\'yield\\' [yield_arg]\\nyield_arg: \\'from\\' test | testlist\\n<|endoftext|>484 F.2d 1277\\nEdwin H. HELFANT, Appellant,v.George F. KUGLER, Attorney General of the State of NewJersey, et al., Appellees.\\nNo. 73-1386.\\nUnited States Court of Appeals,Third Circuit.\\nArgued Sept. 7, 1973.Decided Sept. 10, 1973.Rehearing En Banc Granted Jan. 11, 1974.\\n\\nMarvin D. Perskie, Perskie & Callinan, Wildwood, N. J., Patrick T. McGahn, Jr., Atlantic City, N. J., for appellant.\\nEdward C. Laird, State of N. J., Dept. of Law & Public Safety, Division of Law, George F. Kugler, Jr., Atty. Gen. of N. J., Trenton, N. J., for appellees.\\nBefore STALEY, ADAMS and GIBBONS, Circuit Judges.\\nOPINION OF THE COURT\\nPER CURIAM.\\n\\n\\n1\\nThis is an appeal from an order of the district court which (1) denied plaintiff\\'s motion for a preliminary injunction prohibiting the Attorney General of New Jersey and others from proceeding with the prosecution of an indictment pending in that state, and (2) granted the defendants\\' motion to dismiss the complaint for failure to state a claim upon which relief could be granted.  The district court held an evidentiary hearing on the motion for a preliminary injunction, but in view of its ruling on the defendants\\' motion made no findings of fact.\\n\\n\\n2\\nThe plaintiff-appellant Helfant is a member of the New Jersey bar and a former municipal court judge of that state.  His verified complaint alleges:\\n\\n\\n3\\n\"4. Some time before October 18, 1972 the State of New Jersey began a State Grand Jury Investigation, inter alia, into an alleged illegal withdrawal of an indictable criminal charge of atrocious assault and battery arising out of an incident occurring on March 17, 1968 in Egg Harbor City, Atlantic County, New Jersey, in which the [plaintiff] was alleged to have participated.  This State Grand Jury investigation was personally conducted by the defendant, Joseph A. Hayden, Jr., Deputy Attorney General of the State of New Jersey.\\n\\n\\n4', '<|endoftext|>, but none of your concern).\\n\\nand can i use this generated token in client side call without any risk that if any hacker gets it, they can do no harm??\\n\\nOf course not – it is an app access token, and can be used to do everything that can be done in the name of your app.\\nAn app access token is never to be used in client-side code, no matter how it was obtained.\\n\\n<|endoftext|>599 F.2d 185\\n101 L.R.R.M. (BNA) 2470, 86 Lab.Cas.  P 11,317\\nNATIONAL LABOR RELATIONS BOARD, Petitioner,v.INDIANA AND MICHIGAN ELECTRIC COMPANY, Respondent.\\nNo. 77-1685.\\nUnited States Court of Appeals,Seventh Circuit.\\nArgued Jan. 5, 1979.Decided May 21, 1979.Rehearing En Banc Denied July 11, 1979.\\n\\nL. Joseph Ferrara, NLRB, Washington, D. C., for petitioner.\\nJohn A. McGuinn, Washington, D. C., for respondent.\\n\\n\\n1\\nBefore TONE and WOOD, Circuit Judges, and EAST,* District Judge.\\n\\n\\n2\\nEAST, District Judge.\\n\\n\\n3\\nThe petitioner National Labor Relations Board (the Board) seeks enforcement of its order issued against the respondent Indiana and Michigan Electric Company (the Company) on May 11, 1977 and reported at 229 NLRB No. 95.  The Board reaffirmed its order in a supplemental decision and order issued on April 24, 1978 and reported at 235 NLRB No. 159.  We note jurisdiction of the proceeding under § 10(e) of the National Labor Relations Act (the Act), as amended 29 U.S.C. § 151, Et seq., and enforce the order.\\n\\nBACKGROUND FACTS:\\n\\n4\\nThe Company is an incorporated Indiana public utility which generates and sells electricity in Indiana and Michigan.  The Company and Local 1392, International Brotherhood of Electrical Workers, AFL-CIO (the Union) are presently parties to four collective bargaining agreements.  These agreements separately cover Company employees in the following four bargaining units in Indiana and Michigan: (1) South Bend, Benton Harbor and Twin Branch Generating Divisions; (2) Marion and Muncie Divisions; (3) Fort Wayne Division; and (4) General Office Transmission Construction and Maintenance Group.  The Fort Wayne Division unit was established in 1934 through the Company\\'s voluntary recognition, while the other three units were established between 1952 and 1971 through Board certification.\\n\\n\\n5\\nIn early 1971, the Union\\'s predecessor locals filed with the Board\\'s 25th Regional Office (the Regional Office), over Company opposition, unit clarification and amendment of certification petitions requesting establishment of a single company-wide bargaining unit.  The Regional Office dismissed these petitions.  In September, 1971, the predecessor locals merged into the Union.  The Company agreed to recognize the Union so long as the separate identities of the four bargaining units were maintained.\\n\\n\\n6\\nIn 1972, and again in early 1975, the Company filed with the Regional Office unfair labor practice charges alleging, in effect, that the Union was attempting to engage in a company-wide bargaining in derogation of the established four units.  In both cases, the Regional Office determined that the evidence did not support the charges and refused to issue unfair labor practice complaints.  In the 1972 case, the Board\\'s General Counsel upheld on appeal the Regional Office decision.\\n\\n\\n7\\nIn the 1975-76 collective bargaining cycle, the four then existing contracts expired on different dates between October 31 and December 31, 1975.1  The parties set separate schedules of contract renewal negotiations for each of the four units.\\n\\n\\n8\\nThe initial bargaining session was held on September 23 for the South Bend, Benton Harbor and Twin Branch Generating Divisions unit, whose existing contract expired first.  At that meeting, the Union suggested, as it had in the past, that negotiations be combined for all four units.  The Union repeated this suggestion at the next negotiating session on October 1 for the Marion and Muncie Divisions unit.  On each occasion, the Company rejected the Union\\'s suggestion.  At the September 23rd meeting, the Union made neither \"local\" demands relating to the South Bend, Benton Harbor and Twin Branch Generating Divisions unit nor economic demands.  In later bargaining sessions, the Union\\'s demands in the four units were very similar.\\n\\n\\n9\\nDuring the September and October negotiations, the Union was represented by a single bargaining committee consisting of nine to eleven members.  The committee consisted of Chester M. Herriman, the Union\\'s Business Manager; a union international representative; employee members of the specific unit to which the bargaining in question directly pertained; and employee members drawn from other units.  The employee representatives in the last category were called \"', '<|endoftext|>:\\n- \\'B. Assel\\'\\nbibliography:\\n- \\'mybib.bib\\'\\ntitle: \\'[ Dualité Holographique pour Théories des Champs Super-Conformes en 3 Dimensions]{}\\'\\n---\\n\\n[<span style=\"font-variant:small-caps;\">Thèse de doctorat de\\\\\\nl’Ecole Normale Supérieure</span>]{}\\\\\\n\\\\\\n\\\\\\n[Benjamin ASSEL]{}\\\\\\n\\\\\\n[<span style=\"font-variant:small-caps;\">Docteur de l’Ecole Normale Supérieure</span>]{}\\\\\\n\\n\\\\\\n[Soutenance le 5 juillet 2013, devant le jury composé de]{}\\\\\\n\\n  ----------------------------------------------------------------- --------------------\\n  Henning <span style=\"font-variant:small-caps;\">Samtleben</span>   Rapporteur\\n  Amihay <span style=\"font-variant:small-caps;\">Hanany</span>       Rapporteur\\n  Michela <span style=\"font-variant:small-caps;\">Petrini</span>     Presidente\\n  Dario <span style=\"font-variant:small-caps;\">Martelli</span>      Examinateur\\n  Jan <span style=\"font-variant:small-caps;\">Troost</span>          Examinateur\\n  Costas <span style=\"font-variant:small-caps;\">Bachas</span>       Directeur de thèse\\n  ----------------------------------------------------------------- --------------------\\n\\n\\xa0\\\\\\nThèse délivrée par l’*Ecole Normale Supérieure*, 45 rue d’Ulm, 75005 Paris *FRANCE*,\\\\\\nsuite à des recherches effectuées au *LPT-ENS*, 24 rue Lhomond, 75005 Paris *FRANCE*,\\\\\\ndans le cadre de l’*Ecole Doctorale de Physique de la Région Parisienne* ED107.\\n\\nPresentation {#presentation .unnumbered}\\n============\\n\\n\\\\[chap:intro\\\\]\\n\\nElements of AdS/CFT correspondence\\n==================================\\n\\n\\\\[chap:AdSCFT\\\\]\\n\\n 3d ${\\\\mathcal{N}}=4$ quivers and brane realizations\\n====================================================\\n\\n\\\\[chap:quivers\\\\]\\n\\nSupergravity solutions and the correspondence\\n=============================================\\n\\n\\\\[chap:sugra\\\\]\\n\\nTesting the correspondence : free energy calculations\\n=====================================================\\n\\n\\\\[chap:GKPW\\\\]\\n\\n Solutions with $(p,q)$-5branes and Chern-Simons SCFTs\\n======================================================\\n\\n\\\\[chap:SL2R\\\\]\\n\\nPerspectives {#perspectives .unnumbered}\\n============\\n\\n\\\\[chap:ccl\\\\]\\n\\n Appendices\\n===========\\n\\n\\\\[appendices\\\\]\\n<|endoftext|>954 F.2d 1263\\n34 Fed. R. Evid. Serv. 1264\\nCOAL RESOURCES, INC.;  No. 11 Coal & Construction, Inc.;Green Mountain Coal Company and Liquidating Trust,Plaintiffs-Appellees, Cross-Appellants,v.GULF & WESTERN INDUSTRIES, INC., Now named ParamountCommunications, Inc.;  the New Jersey Zinc Company;  JerseyKentucky Coal Company, Inc.;  Virginia Met Coal Company,Inc., Defendants-Appellants, Cross-Appellees.\\nNos. 90-3989, 90-3990.\\nUnited States Court of Appeals,Sixth Circuit.\\nArgued Sept. 19, 1991.Decided Jan. 29, 1992.Rehearing and Rehearing En Banc DeniedMarch 13, 1992.Order Clarifying Opinion April 22, 1992.\\n\\nVincent B. Stamp (argued and briefed), Nancy C. Cody, Dinsmore & Shohl, Cincinnati, Ohio, James K. Robinson (briefed), Honigman, Miller, Schwartz & Cohn, Detroit, Mich., and Catherine M. White, Cincinnati, Ohio, for plaintiffs-appellees, cross-appellants.\\nGerald W. Simmons, Jeffrey A. Lydenberg, and Jacob K. Stein (argued and briefed), Thompson, Hine & Flory, Cincinnati, Ohio, for defendants-appellants, cross-appellees.\\nBefore KENNEDY, RYAN and BOGGS, Circuit Judges.\\nKENNEDY, Circuit Judge.\\n\\n\\n1\\nDefendant Gulf and Western (\"G & W\") appeals from a jury verdict for plaintiff Coal Resources, Inc.  (\"CRI\") in CRI\\'s diversity breach of contract action against G & W raising numerous evidentiary issues.1  CRI cross-appeals the District Court\\'s denial of pre-judgment interest.   We REMAND to the District Court for a new trial unless CRI remits $226,563 of the awarded damages.\\n\\nI.\\n\\n2', '<|endoftext|> and $r_3 \\\\leq min(r_1,r_2,r_1-r_2)$  then the only way that $r_3 > 2^{k-1} $ is $(1)\\\\,\\\\,\\\\, min(r_1,r_2) > 2^{k-1} $ and $(2)\\\\,\\\\,\\\\,\\\\,a_1-a_2 > 2^{k-1}$. But here is the problem, someone told me that this directly implies that $ max(a_1,a_2) > 2^k $ and this is a contradiction, so the original statement is proven. Why do inequalities (1) and (2) imply that?\\n\\nA:\\n\\nJust note that min$(r_1,r_2)=r_2$. Thus (1) implies $r_2>2^{k-1}$ and (2) implies $r_1>r_2+2^{k-1}$ from which it follows that $r_1>2^k$.\\n\\n<|endoftext|>951 F.2d 872\\n22 Envtl. L. Rep. 20,655\\nC.C. GRISHAM, Individually and as next friend of Hallie C.Ormond;  Hallie Ormond;  Mass Merchandisers, Inc.;McKesson Corporation, Appellants,v.COMMERCIAL UNION INSURANCE COMPANY;  St. Paul Fire andMarine Insurance Company;  Aetna Casualty and SuretyCompany;  City Insurance Company;  Columbia CasualtyCompany;  Home Indemnity Company;  Transamerica InsuranceCompany, Appellees.\\nNo. 89-1481.\\nUnited States Court of Appeals,Eighth Circuit.\\nSubmitted April 30, 1991.Decided Dec. 9, 1991.Rehearing and Rehearing En Banc Denied Jan. 24, 1992.\\n\\nStephan G. Weil, Washington, D.C., argued (Jerold Oshinsky, Leon B. Kellner and Andrew M. Reidy, Washington, D.C., Charles R. Shaddox, San Antonio, Tex., and Michael H. Mashburn, Fayetteville, Ark., on brief), for appellants.\\nRoger E. Warin, Washington, D.C., argued (Walter B. Cox and Tim E. Howell, Fayetteville, Ark., Richard H. Gimer, Theodore A. Howard and Richard A. Ifft, Washington, D.C., Lisa Dickieson, James E. Rocap, III, Anne M. Coughlin, Thomas W. Brunner, Walter J. Andrews and Kirk J. Nahra, Washington, D.C., Michael F. Aylward, Boston, Mass., Mitchell L. Lathrop, Kathy P. Waring and Thomas P. Irving, San Diego, Cal., on briefs, for appellees James P. Whitters, III, Martha J. Koster and Lee H. Glickenhaus, Boston, Mass., filed amicus brief.\\nBefore ARNOLD, Circuit Judge, FLOYD R. GIBSON, Senior Circuit Judge, and WOLLMAN, Circuit Judge.\\nWOLLMAN, Circuit Judge.\\n\\n\\n1\\nOn March 8, 1991, we filed our opinion affirming the summary judgments entered by the district court1 in favor of appellee insurers.  927 F.2d 1039.   Appellants filed a petition for rehearing, with a suggestion for rehearing en banc, contending that the Supreme Court\\'s intervening decision in Salve Regina College v. Russell, --- U.S. ----, 111 S.Ct. 1217, 113 L.Ed.2d 190 (1991), which requires courts of appeals to review de novo district courts\\' determinations of state law, compels a result different from that reached in our March 8 opinion.   We granted rehearing by the panel and vacated our original opinion.   We now file this amended opinion, and we again affirm.\\n\\n\\n2\\nHallie C. Ormond, C.C. Grisham, Mass Merchandisers, Inc., and McKesson Corporation (collectively, Appellants) have sought coverage from the appellee insurers for various environmental claims arising from the ownership and operation of a wood treatment facility located near Omaha, Boone County, Arkansas (the \"Arkwood Site\").\\n\\n\\n3\\nThe Arkwood Site consists of approximately twenty acres of land.   From approximately 1964 or 1965 until January 1, 1985, when the wood treatment facility was closed, fence posts and other lumber products were treated at the Arkwood Site with creosote, pentachlorophenol (PCP), and other chemical preservatives.\\n\\n\\n4\\nDuring the twenty-plus years of treatment operations at the Arkwood Site, excess treatment fluid containing creosote, PCP, and other chemicals was generated in the normal course of', \"<|endoftext|> spots that may call a common function of showDropdown(). And let's say it requires jQuery for the animation. Where or how would be the best place to store the showDropdown function?\\nSay a simple function like:\\nfunction showDropdown(id) {\\n    var thisdropdown = $(id).find('.dropdown');\\n    $(thisdropdown).slideDown();\\n}\\n\\nI could create a UI folder, with the different js functions all being their own file. Then simply require them on any other files that are dependent on them. But regardless, those files will need to export their function to the global scope to be accessible correct?\\nI feel there is an obvious answer/setup as this must be fairly common item.\\nIn addition, I am writing this in a backbone app, but I don't believe that has any direct impact, more of a require.js question.\\n\\nA:\\n\\nCreate a util library or something like that:\\n// util.js\\n\\ndefine({\\n    showDropdown: function(id) {\\n        var thisdropdown = $(id).find('.dropdown');\\n        thisdropdown.slideDown();\\n    }    \\n});\\n\\nThen use it elsewhere:\\nrequire(['util'], function(util) {\\n\\n    util.showDropdown('my-id');\\n\\n});\\n\\n<|endoftext|>842 F.2d 868\\n25 Fed. R. Evid. Serv. 301\\nUNITED STATES of America, Plaintiff-Appellee,v.Alfredo RIOS, Defendant-Appellant.\\nNo. 87-1344.\\nUnited States Court of Appeals,Sixth Circuit.\\nArgued Jan. 25, 1988.Decided March 18, 1988.Rehearing and Rehearing En Banc Denied July 14, 1988.\\n\\nKenneth R. Sasse, Detroit, Mich., Joseph I. Stone (argued), New York City, for defendant-appellant.\\nMichael C. Leibson (argued), Asst. U.S. Atty., Detroit, Mich., for plaintiff-appellee.\\nBefore LIVELY, Chief Judge;  JONES and BOGGS, Circuit Judges.\\nPER CURIAM.\\n\\n\\n1\\nDefendant-appellant, Alfredo Rios, appeals his jury conviction for conspiracy to import cocaine.  For the reasons set forth below, we find his arguments to be without merit and, therefore, affirm his conviction.\\n\\nI.\\n\\n2\\nOn April 11, 1986, Alfredo Rios, the defendant, along with twenty-three others, was indicted by a federal grand jury sitting in the United States District Court for the Eastern District of Michigan.  Rios was charged only in Count Two of a thirteen count indictment.  Count Two alleged a conspiracy to import cocaine in violation of 21 U.S.C. Secs. 952, 960 and 963 (1982).  Count Two specifically alleged:\\n\\n\\n3\\n1.)   That from on or about January, 1981, until on or about December, 31, 1984, in the Eastern District of Michigan and elsewhere, Stephen A. Hagerman, John H. McCann, III, Roberto C. Jaramillo, Michael Canelas, Jose Cruz and Alfredo Rios, defendants herein, did knowingly, willfully and unlawfully combine, conspire, confederate and agree together and with other persons, both known and unknown to the grand jury, to commit an offense or offenses against the United States, that is, to knowingly, intentionally, and unlawfully import into the United States cocaine, a Schedule II Controlled Substance, contrary to Title 21, United States Code, Section 960;  all in violation of Section 963, Title 21, United States Code.\\n\\n\\n4\\n2.) It was part of said conspiracy that Roberto C. Jaramillo would use his position as a Columbia [sic] diplomat to assist Stephen A. Hagerman and John H. McCann, III in taking suitcases and other containers of cocaine through various Customs stations without the suitcases or containers being searched by Customs officials.\\n\\n\\n5\\n3.) It was further part of said conspiracy that Alfredo Rios, Roberto C. Jaramillo, Michael Canelas, Fernando Canelas and Jose Cruz would either act as sources of supply or introduce Stephen A. Hagerman and John H. McCann, III to sources of supply of cocaine in South America.\\n\\n\\n6\\nJ.App. at 8-9.\\n\\n\\n7\\nAs a result of various pretrial dispositions, including dismissals and guilty pleas, Rios was the only person named in Count Two to stand trial.1\\n\\n\\n8\\nOn November 3, 1986, Rios's jury trial commenced before the Honorable Barbara K. Hackett.  On November 12, 1986, a mistrial was declared when the jury was unable to reach a verdict.\\n\\n\\n9\\nDuring this trial, various motions were made by the defendant concerning the\", '<|endoftext|>\\nfrom the close co-operation of our three offices,\" EPO President Benoît\\nBattistelli said at the closing of the conference hosted by the EPO in Saint-Germain-en-Laye\\nnear Paris on\\n7-10 November.\\n\\nSignificant progress was made in all projects ranging from technical\\nstandards, statistical reports and discussions on patent law issues to moving\\nto finalising the report on differences in examination. Moreover, the three offices\\nagreed to prolong the Patent Prosecution Highway (PPH) agreements in relation to\\nwork done on PCT- and Paris-route applications, and also to improve on\\nuser-friendliness and pending times and conduct a study on quality in PPH\\nprocedures: all further requests voiced by representatives of the trilateral\\nindustry associations participating in the Trilateral User Day on 9 November where\\nthey shared their views on the projects pursued by the Trilateral Offices.\\n\\n\"The meeting with the users is very meaningful because it\\nconfirms that the three offices are going in the right direction, as their\\nstrong approval of the CCD clearly demonstrates,\" said JPO Commissioner Yoshiyuki\\nIwai. \"This will boost our work.\"\\n\\nLooking to future activities, the three heads of office also\\nindicated that many of their joint projects, including the CCD and statistical\\nreports, will need to be expanded to the IP5 co-operation to also include China\\nand South Korea: \"We need to graduate these items to IP5 level to offer\\nroom for new projects in our trilateral co-operation,\" said, citing improvements on the PCT as a subject for attention:\\n\"Addressing PCT questions both at agenda-setting and implementing level is\\na priority in the next months.\"\\n\\nWhile moving trilateral projects to IP5-level will certainly\\nfree up capacity on their joint agenda, the Trilateral Offices recognised the\\nneed for a dedicated long-term planning of their activities of up to seven\\nyears in order to achieve measurable results and enhanced public visibility of\\nthe results of their co-operation. They concluded that, after all, co-operation\\nbetween the EPO, JPO and USPTO remains pivotal for progress in patent\\nharmonisation at the global level.<|endoftext|>698 F.2d 915\\n1 Soc.Sec.Rep.Ser. 126, 11 Fed. R. Evid. Serv. 1869UNITED STATES of America, Appellee,v.Mabel HUCKABY, Appellant.\\nNo. 82-1650.\\nUnited States Court of Appeals,Eighth Circuit.\\nSubmitted Oct. 15, 1982.Decided Dec. 13, 1982.Rehearing and Rehearing En Banc Denied Jan. 6, 1983.\\n\\nSamuel A. Perroni, Stanley D. Rauls, William R. Wilson, Jr., Little Rock, Ark., for appellant.\\nGeorge W. Proctor, U.S. Atty., Robert J. Govar, Asst. U.S. Atty., Little Rock, Ark., for appellee.\\nBefore HEANEY and ROSS, Circuit Judges, and HENLEY, Senior Circuit Judge.\\nHEANEY, Circuit Judge.\\n\\n\\n1\\nMabel Huckaby appeals from her convictions on eight counts of violating the Medicaid Act by fraudulently obtaining a greater amount of Medicaid payments than she was due.  We affirm.\\n\\n\\n2\\nThe Federal Grand Jury for the Eastern District of Arkansas indicted defendant Mabel Huckaby on October 20, 1981.  The indictment alleged ten counts of Medicaid fraud in violation of 42 U.S.C. Sec. 1396h(a)(3).1   Specifically, the indictment charged Huckaby with concealing and failing to disclose the actual level of care that Cumberland Lodge Nursing Home provided to ten Medicaid recipients for the purpose of fraudulently securing Medicaid payments in greater amount than was due.  Huckaby pled not guilty at her arraignment, and a jury trial was held on March 9-16, 1982.\\n\\n\\n3\\nUnder the Arkansas Medicaid Plan, providers of long term care services to Medicaid recipients (providers) are reimbursed for the reasonable cost of long term care services.  The amount of the reimbursement depends upon the level of care the Medicaid recipient requires.  Each provider regularly submits a form identified as Arkansas Social Services Evaluation of Need for Nursing Home Care Form SS-703 (703) to assist Arkansas Social Services in identifying the level of care each Medicaid patient needs.  Based to a great degree on these forms, Arkansas Social Services classifies recipients as skilled care (class A), intermediate care (class B), or minimum care (class C).  A provider receives the most money per patient per day for class A patients, and the least for class C patients.  Arkansas Social Services reimburses the providers directly.\\n\\n\\n4\\nThe Cumberland Lodge Nursing Home (C', '<|endoftext|> course, all these fake error messages have one goal and that is to make you call a supposed “virus removal tech support” telephone number, 1-800-935-0823. We can surely tell you that calling this number will most likely not end well for you. It is possible that you will pay a lot of money for this call for starters. It can also happen that you will be tricked into buying a useless product. What’s more, these schemers may also get personal information out of you that can be used for targeted, customized advertising or even can be sold on the black market. We believe that you do not want to have first-hand experience of any of this; therefore, we suggest that you remove Clean PC Master from your PC.\\n\\nIf you finally decide that this piece of software has nothing to do on your system, we are here to tell you what you can do to sort this out. The bad news is that although this PUP does have an uninstaller, it seems to leave leftovers on your operating system. That is why we recommend manual removal in this case. Please only go for this method if you are aware of the potential risks of making a mistake while editing the Windows Registry database. You can use our step-by-step instructions below this article if you do not mind to get your hands a bit “dirty.” However, it is possible that there are a couple of malware infections on your system; therefore, you need to act now if you do not want to end up with a vulnerable or crippled PC. We suggest that you use a reliable anti-malware program that will not only take care of the present infections, but it will also protect your PC from future attacks.<|endoftext|>555 F.2d 671\\n95 L.R.R.M. (BNA) 2665\\nE. E. BENOIST et al., Plaintiffs-Appellants,v.BROTHERHOOD OF LOCOMOTIVE ENGINEERS et al., Defendants-Appellees.\\nNo. 77-1179.\\nUnited States Court of Appeals,Eighth Circuit.\\nSubmitted May 24, 1977.Decided May 26, 1977.Rehearing and Rehearing En Banc Denied June 10, 1977.\\n\\nCharles P. Todt and Susan M. Hammer, Clayton, Mo., filed brief for appellants.\\nRichard H. Kraushaar, Cleveland, Ohio, and John L. Rooney, St. Louis, Mo., filed brief for appellee Broth. of Locomotive Engineers.\\nJohn H. Haley, Jr., St. Louis, Mo., filed brief for appellee United Transp. Union.\\nAlbert E. Schoenbeck and Robert D. Tucker, St. Louis, Mo., and Martin M. Lucente, Chicago, Ill., filed brief for appellee Norfolk & Western R. Co.\\nBefore HEANEY, ROSS and WEBSTER, Circuit Judges.\\nPER CURIAM.\\n\\n\\n1\\nPlaintiffs appeal from the district court\\'s denial of their motion for an extension of time for filing their notice of appeal.\\n\\n\\n2\\nPlaintiffs\\' cause of action was dismissed without prejudice on December 29, 1976.  On February 1, 1977, the clerk of the district court received a notice of appeal on behalf of plaintiffs.  As it was received four days after the expiration of the 30 day time period allowed for filing notices of appeal, F.R.A.P. 4(a), plaintiffs\\' notice of appeal was marked \"lodged\" rather than \"filed.\"  Thereafter, on February 4, 1977, plaintiffs filed a motion for an extension of time for filing their notice of appeal, alleging excusable neglect.  On February 8, 1977, following a hearing, the district court denied the motion.  Plaintiffs now appeal from that denial, contending that the district court abused its discretion in finding no excusable neglect.1\\n\\n\\n3\\nPlaintiffs\\' claim of excusable neglect was premised on the following allegations:\\n\\n\\n4\\nA.  That Plaintiffs\\' attorney was out of town until January 13, 1977.\\n\\n\\n5\\nB. That the Plaintiffs\\' contact with the class member leader was attempted on numerous occasions by phone and was unsuccessful because he was out of town or on various work shifts and unavailable by phone.\\n\\n\\n6\\nC. That a letter was sent by Plaintiffs\\' attorney to the class member leader to set up a conference.\\n\\n\\n7\\nD. That other class members had to be reached by the class member leader in order to hold said conference.\\n\\n\\n8\\nE. That the members of the large class had to converge and obtain a necessary retainer.\\n\\n\\n9\\nF. That the class was so numerous as to make necessary appeal arrangements difficult.\\n\\n\\n10\\nG. That said appeal was prepared timely and placed in the office bin to be mailed timely; that said appeal was mailed Monday instead of Friday, one day late.\\n\\n\\n11\\nIn', \"<|endoftext|>\\n[!code-cpp[NVC_MFC_AxOpt#14](../mfc/codesnippet/cpp/using-an-unclipped-device-context_2.cpp)]\\n[!code-cpp[NVC_MFC_AxOpt#7](../mfc/codesnippet/cpp/using-an-unclipped-device-context_3.cpp)]\\n\\nThe code to remove this flag is automatically generated if you select the **Unclipped Device Context** option on the [Control Settings](../mfc/reference/control-settings-mfc-activex-control-wizard.md) page, when creating your control with the MFC ActiveX Control Wizard.\\n\\nIf you are using windowless activation, this optimization has no effect.\\n\\n## See also\\n\\n[MFC ActiveX Controls: Optimization](../mfc/mfc-activex-controls-optimization.md)\\n<|endoftext|>Q:\\n\\nPoint Sprite Alpha Blending\\n\\nI'm working on a paint app for Android that allows users to draw using their finger. It's built using OpenGL ES 2.0 using point sprite technique as well as an FBO for quick rendering. I am having an issue blending the individual point sprites together where the transparent regions are correctly rendered on the FBO but when the sprites overlap I can see the transparent areas being rendered on the previous sprite. Here's how it looks currently:\\n\\nThis is with this blending equation:\\nGLES20.glBlendFunc(GLES20.GL_ONE, GLES20.GL_ONE_MINUS_SRC_ALPHA);\\n\\nIf I change the drawing color to white or black it works perfectly:\\n\\nI've also tried this blending function:\\nGLES20.glBlendFunc(GLES20.GL_SRC_ALPHA, GLES20.GL_DST_ALPHA);\\n\\nWhich results in this:\\n\\nWhich is almost perfect but instead to white the main color should darken. Any ideas on what the correct blending function should be to achieve this?\\nNote:\\nI have an idea of how the blending function works by taking fractions of the source and destination color and in my case adding them together so it makes sense that the color would go towards white. So I'm wondering if what I would like to achieve can be done with blending function only or would I need something else? I can provide code from the fragment shader if necessary but it doesn't look like a fragment problem to me.\\n\\nA:\\n\\nOkay so I found out what was wrong. It wasn't the blending function after all but the fragment shader.. I had some logic to unpremultiply the pixels which was redundant as the blending function\\nGLES20.glBlendFunc(GLES20.GL_ONE, GLES20.GL_ONE_MINUS_SRC_ALPHA);\\n\\nalready handles premultiplied images. In addition to that, I had some code in the fragment shader to convert the image to grayscale and then to convert the grayscale into transparency and my color multiplications were wrong.\\nFinally I ended up leaving my original blending function unchanged (as above). It works properly and here's the result I was looking for:\\n\\n<|endoftext|>625 F.2d 738\\nFed. Sec. L. Rep.  P 97,545OHIO DRILL & TOOL COMPANY et al., Plaintiffs-Appellees,Cross-Appellants,v.Fred H. JOHNSON et al., Defendants-Appellants, Cross-Appellees.\\nNos. 77-3456, 77-3457.\\nUnited States Court of Appeals,Sixth Circuit.\\nArgued Oct. 3, 1979.Decided June 25, 1980.Rehearing and Rehearing En Banc Denied Sept. 17, 1980.\\n\\nCharles E. Brown, Crabbe, Brown, Jones, Potts & Schmidt, Ira O. Kane, Columbus, Ohio, Jeffrey E. Zink, Canton, Ohio, for Fred H. Johnson.\\nLyman Brownfield, Brownfield, Kosydar, Bowen, Bally & Sturtz, Terry L. Goodman, Columbus, Ohio, for Ohio Drill & Tool Co.\\nBefore EDWARDS, Chief Judge, CELEBREZZE, Circuit Judge, and CECIL, Senior Circuit Judge.\\nCELEBREZZE, Circuit Judge.\\n\\n\\n1\\nThis case is before the court on appeal from a judgment entered by the district court after remand finding defendants-appellants Johnson, Woodward, and Zink liable for breach of their fiduciary duty as officers and directors of Fidelity National Life Insurance Company.  Plaintiffs-appellees cross-appeal from the district court's determination that defendants did not violate § 10(b) of the Securities Exchange Act of 1934,\", '<|endoftext|>In view of the above, it is therefore, desirable to provide an efficient, economical and eco-friendly process for the preparation of dabigatran etexilate mesylate. In particular, the present inventors have found novel crystalline form of intermediates of Formula 2A, Formula 2B and Formula E having good physiochemical properties and useful for further processing.\\nTherefore, the present invention provides novel crystalline form of intermediates of dabigatran etexilate. In particular, the present invention provides crystalline form of compound ethyl 3-(3-amino-4-(methylamino)-N-(pyridin-2-yl)benzamido)propanoate of Formula 2A, ethyl 3-(2-((4-cyanophenylamino)methyl)-1-methyl-N-(pyridin-2-yl)-1H-benzo[d]imidazole-5-carboxamido) propanoate, of Formula 2B and 1-methyl-2-[N-(4-amidinophenyl)aminomethyl]benzimidazol-5-yl-carboxylic acid-N-phenyl-N-(2-ethoxycarbonylethyl)amide hydrochloride of Formula (E) as well as its process of their preparation and use thereof for the preparation of dabigatran etexilate mesylate.<|endoftext|>836 F.2d 1139\\n127 L.R.R.M. (BNA) 2360\\nThe UNITED STATES DEPARTMENT OF AGRICULTURE and the FarmersHome Administration Finance Office, St. Louis,Missouri, Petitioners,v.FEDERAL LABOR RELATIONS AUTHORITY, Respondent.American Federation of Government Employees, Intervenor.The UNITED STATES DEPARTMENT OF DEFENSE and Defense MappingAgency Aerospace Center, St. Louis, Missouri, Petitioners,v.FEDERAL LABOR RELATIONS AUTHORITY, Respondent.National Federation of Federal Employees, Intervenor.\\nNos. 86-2579, 87-1024.\\nUnited States Court of Appeals,Eighth Circuit.\\nSubmitted Sept. 1, 1987.Decided Jan. 15, 1988.Rehearing and Rehearing En Banc Denied Feb. 24, 1988 andApril 1, 1988.\\n\\nAl Daniel, Jr., Washington, D.C., for petitioners.\\nWilliam Persina & Joseph Henderson, Washington, D.C., for respondent.\\nBefore LAY, Chief Judge, HENLEY, Senior Circuit Judge, and MAGILL, Circuit Judge.\\nHENLEY, Senior Circuit Judge.\\n\\n\\n1\\nThese cases present the question whether federal agencies committed an unfair labor practice by refusing to release to labor unions the names and addresses of bargaining unit employees.  The agencies challenge rulings by the Federal Labor Relations Authority requiring disclosure of the names and addresses.  We affirm the Authority\\'s decisions, subject to one reservation.\\n\\n\\n2\\nThe president of the American Federation of Government Employees, Local 3354, requested in a letter to the Director of the Farmers Home Administration Finance Office (FmHA) a list of the names and home addresses of approximately 903 employees, the majority of whom were not union members.  The union asserted a need for the names and addresses for purposes of bargaining, dealing with unspecified problems, and conducting membership drives.  FmHA refused to disclose the information, claiming that, under the provisions of the Privacy Act, 5 U.S.C. Sec. 552a(b), the information could not be disclosed without the employees\\' consent.\\n\\n\\n3\\nThe president of Local 3354 then filed with the Authority an unfair labor practice charge against the FmHA.  In turn, the Authority\\'s General Counsel filed a complaint against the FmHA.  The administrative law judge ruled that the names and addresses were not subject to disclosure, as they were not \"necessary for a full and proper discussion, understanding, and negotiation of subjects within the scope of collective bargaining\" under 5 U.S.C. Sec. 7114(b) of the Federal Service Labor-Management Relations Act (FSLMRA).  The judge did not pass upon the agency\\'s claim that disclosure would violate the Privacy Act.\\n\\n\\n4\\nThe Authority affirmed the Administrative Law Judge\\'s decision.  The Authority also concluded that federal employees\\' privacy interests in their home addresses outweighed the union\\'s need for the information.  The union filed a petition for review with the District of Columbia Circuit pursuant to 5 U.S.C. Sec. 7123(a).  Before briefing was completed, the Authority moved for and was granted a remand in order to determine whether the \"routine use\" exception to the Privacy Act applied.  5 U.S.C. Sec. 552a(b)(3).\\n\\n\\n5\\nOn remand the Authority reversed its previous decision and determined that the names and home addresses must be disclosed to the union.  The Authority found that the requested information qualified for the \"routine use\"', \"<|endoftext|> 29 Aug 2014 | 2:36 PM ETReuters\\n\\nSHARES\\n\\nGetty Images\\n\\nPump jacks in an oil field over the Monterey Shale formation near Lost Hills, Calif.\\n\\nCrude oil prices notched a second straight month of losses, despite rising on Friday amid worries that the intensifying Ukraine crisis may bring more sanctions, and as U.S. data portended strong demand in the world's largest oil consumer.\\n\\nU.S. crude oil rose for a fourth straight session after data showed consumer confidence rose in August to a seven-year high, although consumer spending dipped by 0.1 percent.\\n\\nThe Institute for Supply Management-Chicago said its business barometer shot up to 64.3 this month from 52.6 in July. It was the index's biggest monthly point gain since July 1983 and pointed to continued strength in the manufacturing sector\\n\\nBrent crude oil rose after the government in Kiev said Russian troops had entered Ukraine in support of pro-Moscow rebels, intensifying a separatist war and prompting alarm among Kiev's Western allies, as well as fears of new sanctions that could target Russia's energy sector. Russia is Europe's biggest supplier of oil, coal and natural gas, meeting around a third of demand for all those fuels, according to EU data. It receives in return some $250 billion a year, or around two-thirds of government revenue.\\n\\nEven after Friday's increases, oil prices on both sides of the Atlantic were on track for their second straight monthly losses, of around 3 percent for August. The European benchmark oil contract had plunged more than 12 percent from a nine-month high in June to a 14-month low last week as weak demand led to an oil supply glut.\\n\\nBrent crudefor October delivery rose 70 cents to above $103 a barrel, and U.S. crude gained $1.41 to end the session at $95.96 a barrel. U.S. crude's discount to Brent narrowed to $7.66 a barrel, having touched $7.44, the smallest amount in two weeks.\\n\\nThe main cause for the recent fall in oil prices is that weakening demand is being met by rising production. Yet analysts expect oil prices to strengthen if the situation in Ukraine worsens.<|endoftext|>Q:\\n\\nDo archaea undergo the same horizontal gene transfer processes as bacteria?\\n\\nDo archaea also undergo processes like conjugation, trasformation, etc.? If not, do they have their own horizontal gene transfer methods? Can bacteria conjugate with archaea?\\n\\nA:\\n\\nWagner A, Whitaker RJ, Krause DJ, Heilers JH, van Wolferen M, van der Does C, Albers SV (2017) Mechanisms of gene flow in archaea. Nat Rev Microbiol 15: 492-501.\\n\\nThe exchange of genetic material is a major driving force for genome\\n  evolution across the tree of life and has a role in archaeal\\n  speciation, adaptation and maintenance of diversity.\\n\\nSoucy SM, Huang J, Gogarten JP (2015) Horizontal gene transfer: building the web of life. Nat Rev Genet 16: 472-482.\\n\\nHorizontal gene transfer (HGT) is the sharing of genetic material between organisms that are not in a parent-offspring relationship. HGT\\n  is a widely recognized mechanism for adaptation in bacteria and\\n  archaea.\\n\\nFuchsman CA, Collins RE, Rocap G, Brazelton WJ (2017) Effect of the environment on horizontal gene transfer between bacteria and archaea. PeerJ 29: e3865. \\n\\nPotential hotspots of horizontal gene transfer between archaea and\\n  bacteria include hot springs, marine sediments, and oil wells.\\n\\n<|endoftext|>198 F.3d 432 (4th Cir. 1999)\\nERNEST SUTTON BELL, Petitioner-Appellant,v.MACK JARVIS; ROBERT SMITH, Respondents-Appellees.\\nNo. 98-7002 (CA-97-232-5-H)\\nUNITED STATES COURT OF APPEALS FOR THE FOURTH CIRCUIT\\nArgued: June 11, 1999Decided: December 2, 1999Rehearing En Banc Granted.Opinion Vacated Feb. 23, 2000.\\n\\nAppeal from the United States District Court for the Eastern District of North Carolina, at Raleigh. Malcolm J. Howard, District Judge.[Copyrighted Material Omitted][Copyrighted Material Omitted]\\nCOUNSEL ARGUED: Kathryn L. Vanden Berg, NORTH CAROLINA PRISONER LEGAL SERVICES, INC., Raleigh, North Carolina, for Appellant. Ellen Bradshaw Scouten, Special Deputy Attorney General, NORTH CAROLINA DEPARTMENT OF JUSTICE, Raleigh, North Carolina, for Appellees. ON BRIEF: Michael F. Easley, Attorney General of North Carolina, NORTH\", '<|endoftext|>\\nHow do I use the Breaking News Toolkit? The most important first step is to subscribe to alerts, either via email or our Twitter feed. This will ensure that you are notified when a new edition of the Breaking News Toolkit is launched. The email notification you receive will include full information on how to access the various parts of the service. (See \"What tools are included?\" below)\\n\\nWhen will Breaking News Toolkit editions be released? Toolkit editions are released in response to news events which require EBU Member journalists to be deployed at short notice, to locations where infrastructure has been damaged or is limited, and often for long periods of time. This may include natural disasters, conflict zones or political events taking place in remote locations.\\n\\nWhat tools are included? Each edition will feature a private, secure \\'wiki\\' page editable by all users via EBU Login, a special page on the EuroRadio News exchange to allow the exchange of audio files and a unique Twitter hashtag to allow the community to exchange links and useful information.\\n\\nHow might the service be used? The \\'wiki\\' will be central point, which will function as a \\'virtual whiteboard\\' so that users can share useful practical information, such as the location of power points and internet connections, or to share experiences relating to the crossing of difficult or sensitive international borders.\\n\\nDo I require access to the internet to use the tools? No. Your editor at home can add your contact details to the database, and you become part of the community via mobile phone. Your editor will likewise have access to contact details of other journalists on the ground.<|endoftext|>\\n\\nAsk HN: Did opeid run out of steam? - ittan\\n\\nDid openid run out of steam? \\nIf so:\\n1. what were the lessons learnt?\\n2. What were the successful features?\\n3. What should openid have been?\\n======\\nbdfh42\\nWhat\\'s wrong with OpenID? We just implemented it on our new site and it works\\njust great.\\n\\nI suspect that many start=up sites just fail to notice it or feel they want\\nmore information about a user than they are guaranteed by the OpenID process.\\nWe request a new user\\'s email address but can manage just fine without it - we\\nalso provide a user profile page where users can opt to add more details about\\nthemselves to \"fill in the blanks\".\\n\\n~~~\\nittan\\nThere is nothing wrong with openID. just that it has not taken off on a large\\nscale as one would want. I suspect OAUTH to have become more prevalent.\\n\\n~~~\\nbdfh42\\nI can see OAUTH working for apps/mashups - but not sure how that goes for\\nhumans.\\n\\n------\\npkamb\\nThe lesson learned is that even very technical folk do not understand \"logging\\nin with a URL\".\\n\\n<|endoftext|>Russian opposition politician and critic Alexei Navalny’s bank accounts were frozen and his Moscow apartment seized as part of a lawsuit while he was recovering from a suspected poisoning in a Berlin hospital, his spokeswoman said on…\\n\\n2 days ago<|endoftext|>950 F.2d 501\\n34 Fed. R. Evid. Serv. 782\\nUNITED STATES of America, Plaintiff-Appellee,v.Sabrina LIMEHOUSE, also known as Sabrina White, Defendant-Appellant.\\nNo. 90-2967.\\nUnited States Court of Appeals,Seventh Circuit.\\nArgued Feb. 20, 1991.Decided Dec. 11, 1991.Rehearing and Rehearing En Banc Denied Jan. 9, 1992.\\n\\nCharles Guadagnino (argued), Office of the U.S. Atty., Milwaukee, Wis., for plaintiff-appellee.\\nCatherine M. Canright (argued), Foley, Pollack & Canright, Milwaukee, Wis., for defendant-appellant.\\nBefore WOOD, Jr., CUDAHY and EASTERBROOK, Circuit Judges.\\nCUDAHY, Circuit Judge.\\n\\n\\n1\\nSabrina Limehouse was convicted on two counts of knowingly and willfully conspiring and attempting to possess cocaine with intent to distribute.   She appeals her conviction on the grounds that she received ineffective assistance of counsel in violation of her rights under the Sixth Amendment, and that the evidence was insufficient to support her conviction.   We affirm.\\n\\n\\n2\\n* On May 2, 1989, a Federal Express employee inspected the contents of a box that had become partially opened during the shipping process and discovered a powdery white substance that she suspected to be cocaine.   The box had been shipped via Federal Express from Mel Johnson of 2445 South Barrington, Los Angeles to Sabrina White of 5674 North 65th Street, Milwaukee.   Federal Express immediately alerted the DEA to its discovery of the suspicious white substance.   Later that afternoon, after determining that the substance was', \"<|endoftext|>Ship TimeShip time indicates the typical number of business days it takes for your item(s) to leave our facilities but does not include transit time from our facilities to the final destination.Orders that contain multiple items with different ship times will be shipped out based on the item with the longest ship time.Please note: Ship time is determined based on the method of payment chosen.This item cannot be framed<|endoftext|>var http   = require('http')\\nvar fs     = require('fs')\\nvar toPull = require('../')\\nvar pull   = require('pull-stream')\\nvar port   = ~~(Math.random()*40000) + 1024\\nvar test   = require('tape')\\n\\nvar thisFile = fs.readFileSync(__filename, 'utf-8')\\n\\ntest('test http', function (t) {\\n\\n  var server = http.createServer(function (req, res) {\\n    pull(\\n      toPull(req),\\n      pull.reduce(function (b, s) {\\n          return b + s\\n        }, '', function (err, body) {\\n          t.equal(body, thisFile)\\n          t.notOk(err)\\n          res.end('done')\\n      })\\n    )\\n  }).listen(port, function () {\\n\\n    fs.createReadStream(__filename)\\n      .pipe(http.request({method: 'PUT', port: port}, function (res) {\\n        console.log(res.statusCode)\\n        var _res = toPull(res)\\n\\n        setTimeout(function () {\\n\\n          pull(\\n            _res,\\n            pull.collect(function (err, ary) {\\n              t.equal(ary.map(String).join(''), 'done')\\n              t.end()\\n            })\\n          )\\n\\n        }, 200)\\n\\n        server.close()\\n      }))\\n  })\\n\\n})\\n<|endoftext|>741 F.2d 1388\\n35 Fair Empl.Prac.Cas.  898,36 Empl. Prac. Dec. P 35,003, 239 U.S.App.D.C. 229\\nJames L. DRONENBURG, Appellant,v.Vice Admiral Lando ZECH, Chief of Naval Personnel, et al.\\nNo. 82-2304.\\nUnited States Court of Appeals,District of Columbia Circuit.\\nArgued Sept. 29, 1983.Decided Aug. 17, 1984.Rehearing En Banc Denied Nov. 15, 1984.\\n\\nAppeal from the United States District Court for the District of Columbia (Civil Action No. 81-00933).\\nStephen V. Bomse, San Francisco, Cal., with whom Steven M. Block, Leonard Graff, San Francisco, Cal., and Calvin Steinmetz, Washington, D.C., were on the brief, for appellant.\\nWilliam G. Cole, Atty., Dept. of Justice, Washington, D.C., of the Bar of the District of Columbia Court of Appeals, pro hac vice by special leave of the Court, with whom J. Paul McGrath, Asst. Atty. Gen., Anthony J. Steinmeyer, Richard A. Olderman, Attys., Dept. of Justice and Stanley S. Harris, U.S. Atty., Washington, D.C.  (at the time the brief was filed), were on the brief, for appellees.  Marc Johnston, Atty., Dept. of Justice, Washington, D.C., also entered an appearance for appellees.\\nCharles Lister and Arthur B. Spitzer, Washington, D.C., were on the brief, for amicus curiae urging remand.\\nBefore BORK and SCALIA, Circuit Judges, and WILLIAMS,* Senior District Judge, United States District Court for the Central District of California.\\nOpinion for the Court filed by Circuit Judge BORK.\\nBORK, Circuit Judge:\\n\\n\\n1\\nJames L. Dronenburg appeals from a district court decision upholding the United States Navy's action administratively discharging him for homosexual conduct.  Appellant contends that the Navy's policy of mandatory discharge for homosexual conduct violates his constitutional rights to privacy and equal protection of the laws.  The district court granted summary judgment for the Navy, holding that private, consensual, homosexual conduct is not constitutionally protected.  We affirm.\\n\\nI.\\n\\n2\\nOn April 21, 1981, the United States Navy discharged James L. Dronenburg for homosexual conduct.  For the previous nine years he had served in the Navy as a Korean linguist and cryptographer with a top-security clearance.  During that time he maintained an unblemished service record and earned many citations praising his job performance.  At the time of his discharge Dronenburg, then a 27-year-\", \"<|endoftext|> A common fear is that it could encourage more drug use. At one of the festivals where the Loop has provided a welfare service for a number of years, it hoped to introduce a testing tent (rather than only testing confiscated drugs), but couldn’t get permission, according to Measham, due to the fear that a drug-related death would generate bad press. “Our response was: ‘Yes, but what if there was a dangerous pill circulating with 75,000 people on site?’” Measham says. “You could get a lot more than one drug-related death. Then the question would be: ‘Why didn’t you have our drug safety testing on site? It’s shameful that the number of drug deaths has gone up in the UK when we have more information and evidence than ever before.”\\n\\nMeanwhile, the unpredictability of ecstasy (more so than other class A drugs) remains an uncomfortable reality. Even with the limitations of drug testing, the growing acceptance of this approach allows the sharing of advice and support that could save lives. It is a move that many are keen to embrace, from researchers to clubbers and police officers to parents.\\n\\nIt is just over a year since Emily died. That year has been punctuated by many similar tragedies. For her father, stories of other young people dying after taking drugs have brought back terrible memories. “For me, [every death] feels like another life lost that could have been avoided with better information,” he says. “From Emily’s side of things, if she could have tested [her drugs], would things have been different? Possibly, yes. Probably, even. But then, by doing that, you’re almost turning a blind eye to drug taking.”\\n\\nAs for how the family is coping, he tells me they are strong, but struggling. “There’s not a morning, afternoon or evening that goes by without us all thinking about Emily. She was a big personality in our house and left a big hole.”\\n\\n• This article was amended on 25 and 26 July 2017. A reference to a man dying and four others being hospitalised in Manchester is now thought to have been caused by the drug spice. This reference has been removed. The name of the PMA pill has been changed from red superman to pink. A sentence saying Fiona Measham was the only person to issue a warning has been changed to say one of few people.\\n\\n<|endoftext|>869 F.2d 1155\\n27 Fed. R. Evid. Serv. 685\\nCHARLES WOODS TELEVISION CORP., Appellant,v.CAPITAL CITIES/ABC, INC., Appellee.\\nNo. 88-2036.\\nUnited States Court of Appeals,Eighth Circuit.\\nSubmitted Dec. 14, 1988.Decided March 16, 1989.Rehearing and Rehearing En Banc Denied April 20, 1989.\\n\\nGary R. Cunningham, Springfield, Mo., for appellant.\\nThomas F. Connell, Washington, D.C., for appellee.\\nBefore ARNOLD, Circuit Judge, BRIGHT, Senior Circuit Judge and JOHN R. GIBSON, Circuit Judge.\\nBRIGHT, Senior Circuit Judge.\\n\\n\\n1\\nPlaintiff-appellant Charles Woods Television Corporation (Woods TV) recovered a jury verdict of $3.5 million ($1.5 million actual damages plus $2 million punitive damages) resting on fraudulent misrepresentations allegedly made by defendant-appellee Capital Cities/ABC, Inc. to induce Woods TV to purchase and improve a television station then affiliated with the American Broadcasting Company (ABC).1   Woods TV brought this action after ABC cancelled the affiliation.  The district court,2 however, rejected the jury verdict and granted appellee's motion for judgment n.o.v., or in the alternative, its motion for a new trial.  From the adverse judgment, Woods TV brings this appeal, alleging that the trial court erred in setting aside the verdict and entering judgment for Capital Cities/ABC based on the court's determination that Woods TV failed to create a submissible case of fraud under Missouri law.  Woods TV also questions on appeal certain evidentiary rulings of the trial court.  For the reasons discussed below, we affirm the judgment.3\\n\\nI. BACKGROUND\\n\\n2\\nTelevision station KMTC in Springfield, Missouri, became an ABC affiliate in 1966.  Federal regulations provide that affiliation agreements between networks and local stations cannot exceed two years and that either party may cancel an agreement upon six months' written notice.  47 C.F.R. Sec. 73.658(c) (1987).  ABC renewed KMTC's affiliation agreement without interruption through a renewal that became effective in January 1985.\\n\\n\\n3\\nOn January 11, 1985, Woods TV signed a contract to purchase KMTC from Midland Television Corporation (Midland) at a later date for $13 million.  The affiliation agreement between ABC and\"]\n","layer 5\n","285 ['<|endoftext|>*c**2 - 13*c - 16. Let b(m) = -7*m**4 + 9*m**3 + 13*m**2 - 9*m - 11. Let w(p) = 7*b(p) - 5*g(p). Factor w(s).\\n(s - 3)*(s - 1)*(s + 1)**2\\nSuppose -1/3*v**2 - 16/3 - 17/3*v = 0. What is v?\\n-16, -1\\nLet m(j) = -6*j**3 + 12*j**2 - 4*j + 4. Let f(g) = 11*g**3 - 24*g**2 + 7*g - 7. Let b(u) = -4*f(u) - 7*m(u). Find x such that b(x) = 0.\\n0, 6\\nFactor 26/7*x**2 + 46/7*x + 22/7 + 2/7*x**3.\\n2*(x + 1)**2*(x + 11)/7\\nLet b(x) be the second derivative of x**7/280 + x**6/30 + 3*x**5/40 - 8*x**3/3 + 2*x. Let h(j) be the second derivative of b(j). Factor h(t).\\n3*t*(t + 1)*(t + 3)\\nDetermine t, given that 0*t - 8/19*t**4 + 0 + 2/19*t**5 - 12/19*t**2 - 22/19*t**3 = 0.\\n-1, 0, 6\\nSuppose -6*j + 3*j = 0. Suppose -4*b - 5 + 37 = j. Factor b + r - 2 + 3*r**2 - 6*r - 4*r.\\n3*(r - 2)*(r - 1)\\nLet i(h) be the first derivative of -h**5/200 + h**4/24 + 2*h**3/15 + 21*h**2/2 + 26. Let b(l) be the second derivative of i(l). Factor b(c).\\n-(c - 4)*(3*c + 2)/10\\nLet s = 828 + -826. Suppose 0 - s*d**2 + 4/3*d + 2/3*d**3 = 0. What is d?\\n0, 1, 2\\nFactor 0*x**3 + 4/7*x**4 + 2/7*x**5 - 2/7*x + 0 - 4/7*x**2.\\n2*x*(x - 1)*(x + 1)**3/7\\nLet j(u) be the second derivative of u**3 + 5/6*u**4 + 3/10*u**5 + 0 + 8*u + 1/30*u**6 + 3*u**2. Let m(v) be the first derivative of j(v). Factor m(g).\\n2*(g + 1)*(g + 3)*(2*g + 1)\\nLet g be (-2 - 32/(-4))/1. Let o be 0*((-10)/g + 2). Find d such that -3/2*d + 3/2*d**2 + o = 0.\\n0, 1\\nFactor 26 + 1/4*p**2 - 105/4*p.\\n(p - 104)*(p - 1)/4\\nSuppose 0 = w + 4*d - 20, -2*w + 12 = -3*d + 4*d. Suppose w*b - 8 = -0. Find h such that 12*h - 15*h - 1 + 7 + 0 - 3*h**b = 0.\\n-2, 1\\nLet l(c) be the first derivative of 1/18*c**6 + 0*c**3 + 0*c + 2/15*c**5 - 3 + 0*c**2 + 1/12*c**4. Let l(z) = 0. Calculate z.\\n-1, 0\\nLet 63 - 36*n - 107*n**2 + 99 + 109*n**2 = 0. Calculate n.\\n9\\nLet l(h) be the third derivative of -h**5/90 - h**4/18 - h**3/9 + 85*h**2. Solve l(a) = 0 for a.\\n-1\\nFactor 21 - 30 + 25 + 3*s + s - 16*s**2 - 4*s**3.\\n-4*(s - 1)*(s + 1', '<|endoftext|>-6459, 829\\nWhat is u in 2*u**2/9 + 1617064*u/9 - 1617070/3 = 0?\\n-808535, 3\\nFactor -4*g**3 + 63016*g**2 - 261124388*g + 100531326128.\\n-4*(g - 7663)**2*(g - 428)\\nSuppose i**2/4 - 923*i/4 - 109365 = 0. Calculate i.\\n-345, 1268\\nLet -2*n**3 - 790612*n**2 + 3162480*n = 0. Calculate n.\\n-395310, 0, 4\\nSolve -k**2/6 + 135068*k - 810407/6 = 0 for k.\\n1, 810407\\nFactor -3*o**2 + 126918*o - 36428739.\\n-3*(o - 42017)*(o - 289)\\nWhat is f in -f**4/2 - 18621*f**3 + 1155497*f**2/2 + 633609*f - 1192736 = 0?\\n-37273, -2, 1, 32\\nFactor 5*a**3 - 2325*a**2 - 677010*a - 674680.\\n5*(a - 668)*(a + 1)*(a + 202)\\nDetermine u so that -2*u**3 - 61930*u**2 - 2227086*u - 6123942 = 0.\\n-30929, -33, -3\\nLet 3*u**5 + 1704*u**4 + 71820*u**3 + 638670*u**2 + 1688817*u + 1120266 = 0. What is u?\\n-523, -34, -7, -3, -1\\nSuppose 2500*h**5 - 25543400*h**4 - 93001044*h**3 - 102778408*h**2 - 40556416*h - 5233152 = 0. Calculate h.\\n-2, -1, -8/25, 10221\\nFactor 3*t**2 + 297643038*t + 7382614839155787.\\n3*(t + 49607173)**2\\nFactor 3*m**3 + 1235082*m**2 + 6175347*m + 4940268.\\n3*(m + 1)*(m + 4)*(m + 411689)\\nDetermine u, given that -2*u**2/3 + 148700*u/3 + 3125346 = 0.\\n-63, 74413\\nDetermine y so that 107368*y**2 - 430852*y + 5520 = 0.\\n345/26842, 4\\nDetermine b so that b**3/2 - 57889*b**2 + 1273467*b/2 - 1736505 = 0.\\n5, 6, 115767\\nFactor 2*u**2/7 - 362310*u - 10144712/7.\\n2*(u - 1268089)*(u + 4)/7\\nWhat is t in t**4/5 - 11887*t**3/5 + 1178897*t**2/5 - 2322137*t/5 + 1155126/5 = 0?\\n1, 98, 11787\\nFind f, given that -2*f**3/7 - 11669896*f**2 - 119163163569464*f = 0.\\n-20422318, 0\\nFactor -j**2 - 544749*j + 8716240.\\n-(j - 16)*(j + 544765)\\nWhat is c in -5*c**3 - 690718655*c**2 = 0?\\n-138143731, 0\\nDetermine h, given that -2*h**5/5 + 587398*h**4/5 + 587406*h**3/5 - 352438*h**2 - 2936996*h/5 - 234960 = 0.\\n-1, 2, 293700\\nFactor -5*l**2 - 127290*l + 2165375.\\n-5*(l - 17)*(l + 25475)\\nSolve -4*r**3/3 + 391844*r**2/3 - 391312*r/3 - 17240960 = 0 for r.\\n-11, 12, 97960\\nSolve z**5 + 303819*z**4 + 14885305*z**3 + 174667125*z**2 - 189856250*z =', '<|endoftext|> is i?\\n0, 1\\nFind v such that -12482/5 - 316/5*v - 2/5*v**2 = 0.\\n-79\\nLet i(z) be the first derivative of 3*z**3 - 12*z + 6*z**2 - 9 - 4*z**3 - 6 - 5. Find y such that i(y) = 0.\\n2\\nLet p(k) be the second derivative of 25/7*k**2 - 9*k + 1/42*k**4 + 0 - 10/21*k**3. Factor p(j).\\n2*(j - 5)**2/7\\nLet d be (0 - (-2)/(-4))/(13/(-78)). Let d - 1 + s**3 + 2*s - 2 - 3*s**2 = 0. What is s?\\n0, 1, 2\\nLet x(i) be the third derivative of -i**5/180 + 5*i**4/24 - 13*i**3/9 + 53*i**2. Factor x(p).\\n-(p - 13)*(p - 2)/3\\nLet f(u) be the first derivative of -2*u**6/9 - 8*u**5/5 - 8*u**4/3 + 8*u**3/9 + 6*u**2 + 16*u/3 - 50. Solve f(y) = 0.\\n-4, -1, 1\\nSuppose 6*f - 85 = 2*f + 3*h, 2*h - 68 = -3*f. Suppose -5*o - 2 + f = 0. Let -16*t**2 - o*t**4 - 4*t**5 + 20*t**2 + 6*t**3 - 2*t**3 + 0*t**5 = 0. Calculate t.\\n-1, 0, 1\\nSuppose -56/9*i + 16/3*i**3 + 4/9*i**5 + 2/9*i**2 - 8/3 + 26/9*i**4 = 0. Calculate i.\\n-3, -2, -1/2, 1\\nLet p(o) = 3*o**3 - 154*o**2 - 2320*o - 2178. Let y(t) = -4*t**3 + 158*t**2 + 2322*t + 2178. Let q(g) = 6*p(g) + 5*y(g). Factor q(b).\\n-2*(b + 1)*(b + 33)**2\\nDetermine k, given that -107*k**2 + 24 + 7*k**3 - 52 + 107*k + 21*k = 0.\\n2/7, 1, 14\\nFind j, given that -12/13*j**3 + 2/13*j**4 + 2/13*j**5 - 8/13*j**2 + 0 + 16/13*j = 0.\\n-2, 0, 1, 2\\nLet g(w) be the second derivative of w**7/63 - w**6/15 - w**5/6 + 5*w**4/6 + 4*w**3/9 - 4*w**2 + 257*w. Suppose g(i) = 0. Calculate i.\\n-2, -1, 1, 2, 3\\nLet n(h) = 6*h**2. Let c be n(1). Suppose 177*v - 146*v - 620 = 0. Factor -4*w**3 - v*w + 4*w**2 + c*w**2 + 6*w**2 + 8.\\n-4*(w - 2)*(w - 1)**2\\nSuppose 3*b - 2*n + 3 = 2*b, 0 = 2*b - 3*n + 5. Let l be ((-7)/(-3) - b) + 12/(-36). Factor 0 + 2*f**2 - 4/3*f - 2/3*f**l.\\n-2*f*(f - 2)*(f - 1)/3\\nLet c(p) = -p + 2. Let s be c(-2). S<|endoftext|>Cavacha\\n\\nCavacha is a type of rhythm found in the popular music of Zaire and Kenya. It is a fast-paced rhythm typically played on a drum kit, often with the snare drum or hi hat. Zairean bands such as Zaiko Langa Langa and Orchestra Shama Shama popularized this form of rhythm in the 1960s and 1970s.\\n\\nCavasha was created in 1971 by the member', '<|endoftext|>**2 - 3/2*n**5 + 3*n**b = 0. What is n?\\n-1, 1/3, 1\\nLet f(z) be the second derivative of 2*z**6/15 - 3*z**5/5 - 11*z**4/3 + 2*z**3 + 20*z**2 + z + 751. Solve f(l) = 0 for l.\\n-2, -1, 1, 5\\nLet c be (-2 + 1)/((-3695)/5173). Solve 2/5 + c*x**2 + 2/5*x**3 + 7/5*x = 0.\\n-2, -1, -1/2\\nLet m(r) be the second derivative of -1/45*r**5 - 2/9*r**3 + 0 + 0*r**2 - 13/54*r**4 - 44*r. Factor m(l).\\n-2*l*(l + 6)*(2*l + 1)/9\\nLet g(j) be the second derivative of -j**4/6 - 94*j**3/3 - 93*j**2 + 2*j - 81. Let g(m) = 0. What is m?\\n-93, -1\\nLet k be (-227)/908*(-1)/11. Let s(u) be the third derivative of 1/660*u**5 + 0*u + 20*u**2 + 5/66*u**3 - k*u**4 + 0. Factor s(z).\\n(z - 5)*(z - 1)/11\\nLet t = -2047 + 38867/19. Let f = 206/95 + t. What is u in 32/5*u**3 - 16/5*u - 16/5*u**5 - 4/5 - f*u**4 + 8/5*u**2 = 0?\\n-1, -1/4, 1\\nSuppose 4*j - 7*y = 7*j - 75, -61 = -4*j - 5*y. Factor 15/2*x**3 + 5/2*x**j - 15/2*x + 5/2*x**2 - 5.\\n5*(x - 1)*(x + 1)**2*(x + 2)/2\\nLet q(w) be the second derivative of -9*w**5/20 - 7*w**4/24 - 71*w - 8. Factor q(k).\\n-k**2*(18*k + 7)/2\\nLet 1/3*b**2 + 40 + 34/3*b = 0. What is b?\\n-30, -4\\nSolve 27/2*v**2 + 45/2 + 48*v = 0 for v.\\n-3, -5/9\\nLet v(y) be the first derivative of y**3/3 + 9*y**2/2 - 36*y + 1399. Factor v(f).\\n(f - 3)*(f + 12)\\nSuppose 0 = 23912*f - 23913*f - y + 2, 4*f - 4*y + 8 = 0. Suppose 23/3*d**3 - 1/3*d**5 + f + 4*d**2 + 0*d + 10/3*d**4 = 0. What is d?\\n-1, 0, 12\\nLet i(t) = -5*t**3 - 65*t**2 - 222*t - 150. Let z(r) = -335*r**3 - 4355*r**2 - 14875*r - 10045. Let o(n) = -135*i(n) + 2*z(n). Factor o(b).\\n5*(b + 1)*(b + 4)*(b + 8)\\nLet p(r) be the second derivative of 4*r**6/3 + 21*r**5 + 2405*r**4/24 + 175*r**3/2 + 125*r**2/4 + 2*r + 14. Factor p(z).\\n5*(z + 5)**2*(4*z + 1)**2/2\\nSolve 14 - 9/5*j - 1/5*j**2 = 0.\\n-14, 5\\nLet q(c) be the second derivative of -c**6/75 - c**5/5 + 4*c**4/5 + 3000*c. Find d, given that q(d) = 0.\\n-12, 0, 2\\nLet x = -2/8017 + 801706/24051. Let q', '<|endoftext|> = 0 for r.\\n-1/62, 7/3\\nFind k such that -3*k**5/7 - 522*k**4/7 - 219*k**3 + 1062*k**2/7 + 6180*k/7 + 4104/7 = 0.\\n-171, -2, -1, 2\\nFactor 2*o**2/13 + 11952*o/13 + 17856288/13.\\n2*(o + 2988)**2/13\\nSuppose 122*f**2/7 - 1696*f + 15360/7 = 0. Calculate f.\\n80/61, 96\\nSolve -t**5 + 15110*t**4 + 30223*t**3 + 15112*t**2 = 0 for t.\\n-1, 0, 15112\\nFactor -2*g**3 + 26520*g**2 - 132558*g + 106040.\\n-2*(g - 13255)*(g - 4)*(g - 1)\\nDetermine h so that -45*h**5 + 94380*h**4 - 877055*h**3 + 197980*h**2 + 793620*h - 375840 = 0.\\n-1, 2/3, 9, 2088\\nFind t, given that 16*t**2 - 924*t + 12528 = 0.\\n87/4, 36\\nSuppose 2*i**2/3 + 7348*i + 352192/3 = 0. What is i?\\n-11006, -16\\nFactor 4*p**2 - 65568*p + 268697664.\\n4*(p - 8196)**2\\nLet 5*n**5/6 - 3101*n**4/6 - 835*n**3/2 + 13025*n**2/6 + 4970*n/3 - 414 = 0. Calculate n.\\n-2, -1, 1/5, 2, 621\\nDetermine q so that q**5/3 + 16*q**4/3 - 247*q**3/3 - 550*q**2/3 = 0.\\n-25, -2, 0, 11\\nFactor s**4/7 + 34*s**3 - 2979*s**2/7 + 764*s + 3500.\\n(s - 7)**2*(s + 2)*(s + 250)/7\\nSuppose -3*l**2/7 - 8472*l/7 + 42435/7 = 0. Calculate l.\\n-2829, 5\\nFactor 1343281*z**2 - 1729228*z + 556516.\\n(1159*z - 746)**2\\nFind v, given that -2*v**4/17 + 4572*v**3/17 + 2*v**2/17 - 4572*v/17 = 0.\\n-1, 0, 1, 2286\\nSolve -4*r**5/3 + 179*r**4/3 - 580*r**3 + 2178*r**2 - 3312*r + 1485 = 0 for r.\\n3/4, 3, 5, 33\\nSolve 4*q**4 - 15868*q**3 + 268984*q**2 - 1517520*q + 2844000 = 0 for q.\\n5, 6, 3950\\nWhat is s in 20*s**3 + 256376*s**2 - 307676*s + 51280 = 0?\\n-12820, 1/5, 1\\nFactor 2*w**4 + 90*w**3 + 486*w**2 + 710*w + 312.\\n2*(w + 1)**2*(w + 4)*(w + 39)\\nWhat is j in -3*j**2 - 77696*j - 51796 = 0?\\n-25898, -2/3\\nFactor -h**4/4 - 279*h**3/4 - 24495*h**2/4 - 648025*h/4.\\n-h*(h + 49)*(h + 115)**2/4\\nLet -105*v**5 + 19325*v**4 - 889640*v**3 + 42320*v**2 = 0. Calculate v.\\n0, 1/21, 92\\nDetermine j so that 3*j**2 + 106263*j - 106266 = 0.\\n-35422, 1\\nFactor 3*w**2 + 46746*w + 182099043.\\n3*(w + 7791)**2\\nSolve 2*w**2/7 - 666*w/7 - 980 = 0', '<|endoftext|>*o**2 = 0.\\n-1/2, 365\\nLet c(u) = u**2 - 5*u - 33. Let d be c(9). Find s, given that 96*s - d*s**2 - 545 + 53 - 276 + 0*s**2 = 0.\\n16\\nLet h(r) = -5*r**3 - 3*r**2 - 3*r + 7. Let p(v) = 34*v + 303. Let q be p(-9). Let i(b) = 4*b**3 + 4*b**2 + 2*b - 7. Let k(l) = q*h(l) - 4*i(l). Factor k(u).\\n-(u - 1)*(u + 1)*(u + 7)\\nLet t(y) be the first derivative of -147/4*y**4 - 1596*y**3 - 1350*y**2 + 29 - 384*y. Let t(r) = 0. Calculate r.\\n-32, -2/7\\nLet p(s) be the third derivative of s**7/105 - 2*s**6/15 - 8*s**5/5 + 64*s**4/3 + 1024*s**3/3 - 1187*s**2. Solve p(f) = 0.\\n-4, 8\\nLet w be -14*(((-1862)/35 - 5) + -4). Let y = -868 + w. Determine a so that 2/5*a**3 - 12/5 + 0*a**2 - y*a = 0.\\n-2, -1, 3\\nLet s = 36482/1147875 - -2/9183. Let j = 383/250 - s. Factor j*r + 0 - 1/4*r**2 - 5/4*r**3.\\n-r*(r - 1)*(5*r + 6)/4\\nLet u be ((-372)/(-24) - 15)*(-56)/(-566). Let t = 7652/5943 - u. Factor -t*k**2 + 22/21*k + 4/21.\\n-2*(k - 1)*(13*k + 2)/21\\nLet m(j) be the third derivative of -j**6/720 - 187*j**5/360 - 277*j**4/72 - 92*j**3/9 - 2*j**2 - 441*j - 3. Factor m(f).\\n-(f + 1)*(f + 2)*(f + 184)/6\\nSuppose 3 = -3*h, -7*h + 9*h - 8 = -5*y. Suppose 7*j = 2*j + 5, y*z + j = 9. Factor -2*l + 657*l**4 - 9*l**3 - 7*l**2 + z - l**5 - 662*l**4 - 4.\\n-l*(l + 1)**3*(l + 2)\\nLet c(p) be the second derivative of p**6/240 + 19*p**5/160 + 9*p**4/8 + 8*p**3/3 - 16*p**2 + 540*p + 2. Factor c(f).\\n(f - 1)*(f + 4)*(f + 8)**2/8\\nLet d be (2 + (-2 - 2))*13. Let q = d - -29. Factor -b**2 + 2*b**q - b**4 + 2*b**4 - 8*b + 6*b.\\nb*(b - 1)*(b + 1)*(b + 2)\\nSuppose 299 - 150*c**4 - 102*c**2 - 485*c + 61*c**2 - 143*c**2 + 31 - 5*c**5 + 4*c**2 + 490*c**3 = 0. What is c?\\n-33, -1, 1, 2\\nFactor 3/8*p**3 + 63/4*p + 0 + 69/8*p**2.\\n3*p*(p + 2)*(p + 21)/8\\nLet k(p) be the first derivative of -p**3/18 + 29*p**2/12 + 31*p/3 + 1475. Factor k(s).\\n-(s - 31)*(s + 2)/6\\nLet f be (1/15)/((-1)/(-143)) - (9 - (-138)/(-18)). Determine z so that 1/5 + f*z**2 - 22/5*z - 4*z**3 = 0.\\n1/20, 1\\n', \"<|endoftext|>d. Let q(v) = 5*l(v) + 4*x(v). Determine r, given that q(r) = 0.\\n-1, 0, 1\\nLet g(t) = -t**3 + t**2 + 12*t + 5. Let l(b) = b**3 - b**2 - 18*b - 8. Let n(x) = -8*g(x) - 5*l(x). Suppose n(m) = 0. What is m?\\n-1, 0, 2\\nFind i, given that 8/11*i + 0 + 42/11*i**3 - 18/11*i**4 - 32/11*i**2 = 0.\\n0, 2/3, 1\\nLet x(m) be the first derivative of m**5/80 - m**4/16 + m**2/2 + 4*m - 4. Let s(c) be the first derivative of x(c). Suppose s(r) = 0. Calculate r.\\n-1, 2\\nSuppose 55*x = 53*x + 10. Let p(u) be the first derivative of 0*u**2 + 2 + 2/5*u**x + 0*u - 1/9*u**6 + 0*u**3 - 1/3*u**4. Factor p(w).\\n-2*w**3*(w - 2)*(w - 1)/3\\nLet x(a) = -a**3 + 2*a**2 + 3*a - 3. Let u be x(2). Let v = 12 - u. Factor t**3 - 3*t**2 + 4*t + t**3 + v*t**2.\\n2*t*(t + 1)*(t + 2)\\nLet v(r) be the third derivative of 0*r**4 + 0*r - 1/1344*r**8 - 1/480*r**6 + 0 - 4*r**2 + 0*r**3 + 0*r**5 + 1/420*r**7. Factor v(t).\\n-t**3*(t - 1)**2/4\\nSuppose -l + 3*d + 23 = -2*d, 3*d = -4*l. Let a be (2/8)/(29/174). Determine h, given that 2*h**4 + 0 + a*h**l - 1/4*h - 3/4*h**2 = 0.\\n-1, -1/4, 0, 1/2\\nLet j(c) be the first derivative of -c**6/1440 - c**5/240 - c**4/96 - c**3/3 + 6. Let u(n) be the third derivative of j(n). Factor u(y).\\n-(y + 1)**2/4\\nDetermine i so that -82 - 169 - 2*i**2 + 36*i + 89 = 0.\\n9\\nLet b(c) be the first derivative of c**3/12 + 7*c**2/4 + 49*c/4 + 14. Find q, given that b(q) = 0.\\n-7\\nLet l = 0 - -4. Let u(k) be the first derivative of 4/3*k - 10/9*k**3 + 2/5*k**5 + 1/6*k**l - 1/3*k**2 + 2. Solve u(s) = 0.\\n-1, 2/3, 1\\nDetermine u so that 2/5 + 2/5*u**2 - 4/5*u = 0.\\n1\\nLet c(k) be the third derivative of k**10/529200 - k**8/35280 + k**6/2520 + k**5/30 + k**2. Let z(s) be the third derivative of c(s). Factor z(m).\\n2*(m - 1)**2*(m + 1)**2/7\\nLet 4*w**3 + 8/9 + 8/9*w**2 - 2/3*w**5 - 16/9*w**4 - 10/3*w = 0. What is w?\\n-4, -1, 1/3, 1\\nLet m(i) = 8*i**5 + 2*i**4 + 4*i**3 + 4*i**2. Let a(b) = b**5 + b**3 + <|endoftext|>I love this red head AJ (ex Corbin Fisher). He's so innocent looking! He's got one the most inviting love holes in the\", '<|endoftext|> p**2 + 1. Let k(v) = -m(v) + 2*w(v). Determine b so that k(b) = 0.\\n-1, 0, 1, 2\\nLet m(s) = -s**2 - 17*s - 25. Let a be m(-12). Suppose -a*l = -32*l. Find t such that l + 2/3*t - 1/3*t**2 = 0.\\n0, 2\\nLet j(f) be the first derivative of f**3/3 + 4*f**2 - 9*f + 22. Determine g, given that j(g) = 0.\\n-9, 1\\nLet y(c) = -2 + c**2 - 8 + 9 - 5*c + c. Let a(d) = -3*d**2 + 11*d + 3. Let u(v) = -4*a(v) - 11*y(v). Factor u(t).\\n(t - 1)*(t + 1)\\nLet v(r) be the third derivative of -r**10/50400 - r**9/25200 - 13*r**4/12 - 2*r**2. Let i(h) be the second derivative of v(h). Factor i(p).\\n-3*p**4*(p + 1)/5\\nLet u(n) be the first derivative of -n**3/3 - 9*n**2/2 + 10*n + 1. Let w be u(-9). Find v, given that 4 + 12*v**2 + v**2 + 7*v**3 + w*v**2 + 20*v = 0.\\n-2, -1, -2/7\\nLet s = 2467/11223 + 3/1247. Factor -2*f**4 - 28/9*f**2 - s + 32/9*f**3 + 4/3*f + 4/9*f**5.\\n2*(f - 1)**4*(2*f - 1)/9\\nSuppose -3 = -3*m + 3. Suppose -2*n = -0*k + 2*k - 100, 54 = k + m*n. Solve -8*r + 6*r**2 + 50 - k - 2*r**2 = 0.\\n1\\nSolve 8*r**4 - 5*r**4 - 24*r**2 - 151*r**3 + 144*r + 136*r**3 = 0 for r.\\n-3, 0, 4\\nLet j(i) be the first derivative of i**6/90 + 11*i**5/45 + 19*i**4/18 + 2*i**3 + i**2/2 - 2*i - 43. Let s(o) be the second derivative of j(o). Factor s(a).\\n4*(a + 1)**2*(a + 9)/3\\nLet z(l) be the first derivative of l**5/60 - l**4/3 + 8*l**3/3 - 3*l**2 + 8. Let w(s) be the second derivative of z(s). What is m in w(m) = 0?\\n4\\nLet n be 1 + -3*(-20)/(-108). Let q = 16/9 - n. Factor 2/9*j**4 + q*j**2 - 8/9*j - 8/9*j**3 + 2/9.\\n2*(j - 1)**4/9\\nLet x(r) be the third derivative of -r**7/3360 + r**6/320 + 5*r**4/12 + 22*r**2. Let k(w) be the second derivative of x(w). Factor k(i).\\n-3*i*(i - 3)/4\\nLet w(j) be the second derivative of -j**7/70 + 3*j**6/25 - 21*j**5/50 + 4*j**4/5 - 9*j**3/10 + 3*j**2/5 + 223*j - 2. Find p, given that w(p) = 0.\\n1, 2\\nLet b(t) be the first derivative of -2*t**5/55 + 4*t**4/11 + 16*t**3/33 - 96*t**2/11 - 288*t/11 + 59. Let b(z) = 0. Calculate z.\\n-2, 6\\nLet f(o) = -o**2 - 12*o - 15. Let u be f(-', '<|endoftext|>, 2\\nLet s be 1062/12*-4*10/(-12). Factor -290*d - 5*d**3 + s - 492 - 538 - 85*d**2 + 0*d**3 - 165*d.\\n-5*(d + 3)*(d + 7)**2\\nLet n(b) be the third derivative of 5*b**8/336 + 470*b**7/21 + 49141*b**6/4 + 7739551*b**5/3 + 153321485*b**4/24 - 4*b**2 - 10*b + 1. Factor n(t).\\n5*t*(t + 1)*(t + 313)**3\\nLet m(f) be the first derivative of 2*f**3/39 + 257*f**2/13 + 169. Suppose m(t) = 0. What is t?\\n-257, 0\\nLet q = -20389 - -20395. Let o(n) be the second derivative of 1/30*n**q - 7/3*n**3 - 1/10*n**5 - n**4 + 0 - 5/2*n**2 - 32*n. Solve o(k) = 0.\\n-1, 5\\nLet c = -10983 - -32951/3. Factor -14/15*w - c*w**2 + 4/5.\\n-2*(w + 2)*(5*w - 3)/15\\nLet c(z) = -2*z**2 - 58*z - 40. Let v = 108 + -107. Let w(l) = 3*l + 1. Let h(i) = v*c(i) + 8*w(i). Factor h(u).\\n-2*(u + 1)*(u + 16)\\nLet g(n) be the second derivative of n**6/240 + 19*n**5/160 + 5*n**4/32 - 343*n**3/48 - 85*n**2/4 - 2522*n. Let g(b) = 0. Calculate b.\\n-17, -5, -1, 4\\nLet r = -193/191 + 22351/382. Suppose -45/2*d + 75*d**2 + 0 + 10*d**4 + r*d**3 = 0. Calculate d.\\n-3, 0, 1/4\\nLet w(v) = -25*v**3. Let r(l) = 198*l**3 - 57*l**2 - 171*l + 100. Let y(t) = -5*r(t) - 40*w(t). Factor y(a).\\n5*(a + 4)*(a + 25)*(2*a - 1)\\nLet i(y) = -6 - 11*y**2 + 12 + 9*y - 61*y - 67*y. Let j(x) = 100*x**2 + 1070*x - 55. Let k(h) = 55*i(h) + 6*j(h). Solve k(f) = 0 for f.\\n-25, 0\\nLet j(v) be the first derivative of -648*v - 1/6*v**3 - 18*v**2 + 14. Factor j(r).\\n-(r + 36)**2/2\\nLet b(t) be the third derivative of t**7/105 - 13*t**6/80 - 7*t**5/60 + 13*t**4/16 + 5*t**3/6 - 247*t**2 - 2*t. Find y such that b(y) = 0.\\n-1, -1/4, 1, 10\\nLet t(c) = -3*c**2 - c. Suppose -4*u + 18 = i, u - 5*i - 10 = -4*u. Let v(p) = 4*p**2 + 2*p. Let a(x) = u*v(x) + 5*t(x). Factor a(b).\\nb*(b + 3)\\nLet m(i) be the third derivative of i**6/180 - 53*i**5/360 + 101*i**4/144 - 11*i**3/18 + 1160*i**2. Suppose m(a) = 0. Calculate a.\\n1/4, 2, 11\\nSuppose 8*w + 4*b = 10*w - 112, -4*w = 5*b - 159. Let t be w/40 + 27/108. Find g, given that -1/5*g', '<|endoftext|>3.\\n-2*z*(z - 1)**2*(z + 1)\\nFactor 4/3 - 1/3*m**3 - m**2 + 0*m.\\n-(m - 1)*(m + 2)**2/3\\nLet j(y) = y**3 + 11*y**2 - 15*y + 3. Let a(b) = -16*b**2 + 3*b - 4 + 4*b - 2*b**3 + 15*b. Let g(n) = -5*a(n) - 8*j(n). What is u in g(u) = 0?\\n1, 2\\nLet w(v) be the second derivative of -v**7/420 - v**6/60 - v**5/30 - v**2 - 4*v. Let n(j) be the first derivative of w(j). Suppose n(s) = 0. What is s?\\n-2, 0\\nFactor -6 + 12 - 5*r**3 + 15*r**2 - 26.\\n-5*(r - 2)**2*(r + 1)\\nSuppose 0 = -2*u + 7*u. Let j(g) be the first derivative of -1 - 1/2*g**2 + 0*g + u*g**3 + 1/4*g**4. Find v such that j(v) = 0.\\n-1, 0, 1\\nLet j = -14 - -14. Let t(x) be the third derivative of -1/210*x**7 + 0 + 1/24*x**4 + j*x**3 + 0*x - 1/120*x**6 + 1/60*x**5 + 2*x**2. Factor t(f).\\n-f*(f - 1)*(f + 1)**2\\nLet a(s) be the first derivative of s**7/2520 + s**6/1080 - s**5/360 - s**4/72 + 2*s**3 + 6. Let z(y) be the third derivative of a(y). Factor z(g).\\n(g - 1)*(g + 1)**2/3\\nLet -6/7*b**2 - 4/7*b - 2/7*b**3 + 0 = 0. Calculate b.\\n-2, -1, 0\\nLet x(d) be the third derivative of -d**5/210 + 4*d**3/21 - 17*d**2. Factor x(t).\\n-2*(t - 2)*(t + 2)/7\\nLet y(x) be the second derivative of x**5/40 + x**4/8 + x**3/4 + x**2/4 - 12*x. Factor y(a).\\n(a + 1)**3/2\\nWhat is j in 48/5*j + 21/5*j**5 + 3/5*j**2 - 69/5*j**3 + 12/5 - 3*j**4 = 0?\\n-1, -2/7, 1, 2\\nFactor -45*k**2 - 16*k**3 - 3*k**4 - 10 - 35*k + 7*k**3 - 16*k**3 - 2*k**4.\\n-5*(k + 1)**3*(k + 2)\\nLet v(u) be the second derivative of -u**6/120 + u**4/16 - u**3/12 - 13*u. Solve v(y) = 0 for y.\\n-2, 0, 1\\nFactor 2*f**2 + 13 + 7 + 12*f + 5 - 7.\\n2*(f + 3)**2\\nLet a = 182 + -179. Let h(t) be the first derivative of -1/8*t**4 - 1/20*t**5 + 0*t - 3 - 1/12*t**a + 0*t**2. Suppose h(r) = 0. What is r?\\n-1, 0\\nDetermine u, given that 0 + 4/5*u**4 + 4/5*u**5 - 4/5*u**2 - 4/5*u**3 + 0*u = 0.\\n-1, 0, 1\\nSuppose r = 2*p + 8, 2*r + 2*p = -2*p + 8. Let k = 8 - r. Solve -8*f**4 - 11*f**k - f + 4*f**2 + 4*f**3 - 18*f**3 = 0 for f.\\n-1,', '<|endoftext|>?\\n-1075, -3, 0, 1, 19\\nLet -2*y**2/19 - 118426*y/19 + 10912120/19 = 0. Calculate y.\\n-59305, 92\\nSuppose 2836*h**4/7 + 1531520*h**3/7 + 206787600*h**2/7 + 5832000*h/7 = 0. Calculate h.\\n-270, -20/709, 0\\nFind x such that -5*x**4 - 1696580*x**3 + 5*x**2 + 1696580*x = 0.\\n-339316, -1, 0, 1\\nLet 2*n**2/17 + 4283414*n/17 + 188466344/17 = 0. Calculate n.\\n-2141663, -44\\nSuppose 36*q**4 + 5444*q**3 + 143156*q**2 - 115876*q - 32760 = 0. Calculate q.\\n-117, -35, -2/9, 1\\nDetermine o so that -3*o**3/4 + 6945*o**2/4 - 96597*o/4 - 103545/4 = 0.\\n-1, 15, 2301\\nWhat is g in 13870*g**3 + 5617356*g**2 - 16974450*g - 7344 = 0?\\n-408, -3/6935, 3\\nSolve -2*i**3/13 - 18782*i**2/13 + 225672*i/13 = 0 for i.\\n-9403, 0, 12\\nDetermine w so that -12*w**3/13 + 34*w**2/13 + 108268*w/13 - 90240/13 = 0.\\n-94, 5/6, 96\\nSuppose v**4/6 - 74*v**3/3 - 3409*v**2 + 222*v + 61335/2 = 0. Calculate v.\\n-87, -3, 3, 235\\nFactor -2*m**2/11 - 1243632*m/11 + 48504690/11.\\n-2*(m - 39)*(m + 621855)/11\\nDetermine j, given that -2*j**5 - 6962*j**4 - 6076052*j**3 - 30220328*j**2 - 12026960*j + 48330304 = 0.\\n-1738, -4, -2, 1\\nFind s such that -8*s**5 - 1556*s**4 - 41424*s**3 + 112604*s**2 - 24256*s - 45360 = 0.\\n-162, -35, -1/2, 1, 2\\nFactor 3*x**2/7 + 2413413*x/7 - 4826838/7.\\n3*(x - 2)*(x + 804473)/7\\nFind w such that 2*w**4/9 - 1642592*w**3/9 + 112420091536*w**2/3 + 1349060809600*w/9 + 1349067380000/9 = 0.\\n-2, 410650\\nFind v such that -2*v**4/5 + 78646*v**3/5 - 773031126*v**2/5 - 464400734*v + 21651479864/5 = 0.\\n-7, 4, 19663\\nLet -5015547*d**4/4 + 260973964809*d**3/2 - 13579259521922751*d**2/4 + 10502133264429*d - 8122299267 = 0. What is d?\\n2/1293, 52033\\nWhat is q in q**5/3 - 21*q**4 - 157*q**3/3 + 14945*q**2 - 148824*q = 0?\\n-27, 0, 13, 24, 53\\nFactor y**3 + 33022*y**2 - 42593885*y - 85319850.\\n(y - 1245)*(y + 2)*(y + 34265)\\nSolve -d**3 - 132530*d**2 + 12732292*d + 25994696 = 0.\\n-132626, -2, 98\\nFactor n**5/3 + 76*n**4 + 448*n**3 + 2674*n**2/3 + 741*n + 222.\\n(n + 1)**3*(n + 3)*(n + 222)/', '<|endoftext|>Determine v, given that -135*v**2 - 26 + 314*v - 27*v**3 - 71*v - 9*v**4 + 998 + 12*v**4 = 0.\\n-3, 3, 12\\nLet x(l) be the third derivative of l**9/18900 - l**8/8400 - l**7/1575 + 35*l**4/24 + 15*l**2 - 2. Let d(v) be the second derivative of x(v). Solve d(z) = 0.\\n-1, 0, 2\\nLet c(x) be the second derivative of -x**8/30240 + x**7/1620 - x**6/405 - 4*x**5/135 - 35*x**4/6 + 14*x. Let v(r) be the third derivative of c(r). Factor v(a).\\n-2*(a - 4)**2*(a + 1)/9\\nLet v be (4 - 3) + (16 - 888/56). Let l(h) be the first derivative of 8/7*h**2 - 10/21*h**3 + 1/14*h**4 - v*h + 43. Factor l(k).\\n2*(k - 2)**2*(k - 1)/7\\nSolve -29*s**3 + 200 + 3426*s**2 - 440*s - 2*s**4 - 3144*s**2 - 15*s**3 + 4*s**4 = 0 for s.\\n1, 10\\nSolve 18/7*u**4 - 258/7*u**2 + 2/7*u**5 + 240/7 + 92/7*u - 94/7*u**3 = 0.\\n-12, -2, -1, 1, 5\\nLet s(r) be the first derivative of -r**6/24 - 9*r**5/20 - 3*r**4/2 - 4*r**3/3 - 13. Factor s(h).\\n-h**2*(h + 1)*(h + 4)**2/4\\nSuppose -212 = -2*c - 2*t, -5*c - 3*t = -234 - 296. Let r be 4/22 - c/(-22). Factor -x**4 - 40*x**3 + x**5 - 4*x**2 + 39*x**3 + r*x**2.\\nx**2*(x - 1)**2*(x + 1)\\nLet c = 2759 - 2752. Let q(m) be the third derivative of 0*m + 0*m**5 + 0*m**4 + 0*m**3 - 1/1575*m**c + 0 + 1/2520*m**8 + 0*m**6 + 17*m**2. Factor q(a).\\n2*a**4*(a - 1)/15\\nLet w be -9*(-30 - 19136/(-672)). Suppose -12/7*i**2 + 153/7*i**4 - 3*i**5 + 360/7*i - w - 42*i**3 = 0. Calculate i.\\n-1, 2/7, 2, 4\\nLet y(v) = -9*v - 43. Let x be y(-7). Suppose 39*c - 29*c = x. Factor 0 + 2/7*r**c + 6/7*r**4 + 0*r + 6/7*r**3 + 2/7*r**5.\\n2*r**2*(r + 1)**3/7\\nSolve 57/2*u**2 - 89/6*u**3 + 1/6*u**4 + 0 + 87/2*u = 0 for u.\\n-1, 0, 3, 87\\nLet f(h) be the third derivative of 116*h**7/105 + 5*h**6/3 + 13*h**5/30 - h**4/3 - h**2 + 1919. Factor f(o).\\n2*o*(2*o + 1)**2*(29*o - 4)\\nWhat is n in 6*n**2 - 8/5*n**5 + 22*n**4 + 0*n + 0 + 148/5*n**3 = 0?\\n-1, -1/4, 0, 15\\nLet u(x) be the second derivative of 1/20*x**5 - 1/6*x**3 - 17*x**2 + 0 + 17/6*x**4 + 86*x. Let u', '<|endoftext|> = 0. What is c?\\n-2/7\\nLet x(r) be the first derivative of r**5/20 + 3*r**4/16 + r**3/12 - 3*r**2/8 - r/2 + 11. Let x(c) = 0. What is c?\\n-2, -1, 1\\nSolve -2*v**3 - 2*v + 2813*v**2 - 4 - 2821*v**2 - 8*v = 0 for v.\\n-2, -1\\nSuppose w = -p + 3*p - 5, 3*p = 4*w. Factor 19*a**2 - a + 0*a - a**4 - 18*a**2 + a**w.\\n-a*(a - 1)**2*(a + 1)\\nLet c(q) = q**2 - 11. Let h = 3 - 6. Let t(i) = 6. Let s(y) = h*c(y) - 5*t(y). Factor s(r).\\n-3*(r - 1)*(r + 1)\\nLet o be -2 + 3 + 3/(-5). Let n be 1/((-20)/(-16) - 1). Solve -2/5*b**2 + 2/5*b**n + o*b + 0 - 2/5*b**3 = 0.\\n-1, 0, 1\\nLet z(x) be the first derivative of -3/2*x**2 + 0*x**3 + 1/108*x**6 - 2 - 7/270*x**5 + 0*x + 1/54*x**4. Let l(a) be the second derivative of z(a). Factor l(i).\\n2*i*(i - 1)*(5*i - 2)/9\\nLet l = 47/150 - -1/50. Let g(s) be the first derivative of -17/9*s**3 + 2 + l*s**2 + 0*s + 10/9*s**6 + 4*s**4 - 53/15*s**5. Find w such that g(w) = 0.\\n0, 1/4, 2/5, 1\\nLet h(u) be the second derivative of -u**6/30 + u**5/15 + u**4/3 - 3*u**2 - 8*u. Let o(m) be the first derivative of h(m). Let o(a) = 0. What is a?\\n-1, 0, 2\\nLet c = 973/2 - 486. Factor -3/4 + c*n**2 + 5/4*n.\\n(n + 3)*(2*n - 1)/4\\nSuppose q + 5*g = -5 - 7, 2*q - 6 = 5*g. Let v be (10/(-225))/(q/10). Factor 2/9*w - 2/9 - 2/9*w**3 + v*w**2.\\n-2*(w - 1)**2*(w + 1)/9\\nLet m(l) be the first derivative of 11*l**4/4 - 5*l**3/2 + l**2/2 + 3. Factor m(r).\\nr*(2*r - 1)*(11*r - 2)/2\\nLet a(z) be the first derivative of 2*z**5/55 - 4*z**3/33 + 2*z/11 - 21. Factor a(g).\\n2*(g - 1)**2*(g + 1)**2/11\\nFind d, given that 0 + 30/7*d**4 + 12/7*d - 57/7*d**3 - 12/7*d**2 = 0.\\n-1/2, 0, 2/5, 2\\nLet y(l) be the second derivative of -3*l**5/100 - 3*l**4/20 - l**3/5 - 16*l. Factor y(h).\\n-3*h*(h + 1)*(h + 2)/5\\nLet x be 1*(-2 - (2 + -6)). Suppose -4*w + c = -2*w - 14, -w - 4*c = x. Factor 4*i**2 + 5*i**3 + 2*i**5 - 6*i - i**3 + 2 + 0*i**2 - w*i**4.\\n2*(i - 1)**4*(i + 1)\\nSuppose -9*i**4 + 20*i + 7*i**4 - 8*i**2 + 15', '<|endoftext|> = 0. Let j be 1 + x/4*-2. Factor 1025*w**3 + 283*w**4 + 403*w**4 + 150*w**2 + 184*w + 249*w**3 + 16 + 606*w**j.\\n2*(w + 1)*(7*w + 2)**3\\nFactor 6/7*t**2 - 4/7*t**3 - 8/7 + 8/7*t - 2/7*t**4.\\n-2*(t - 1)**2*(t + 2)**2/7\\nLet l(u) be the first derivative of 0*u**3 + 1 + 0*u - 1/60*u**5 + 1/2*u**2 - 1/24*u**4. Let y(r) be the second derivative of l(r). Solve y(h) = 0.\\n-1, 0\\nLet l(c) be the third derivative of 0*c + 1/4*c**4 + 0*c**3 + 0 + 6*c**2 + 1/20*c**5. Factor l(d).\\n3*d*(d + 2)\\nFind p, given that 0*p**2 - 4/5 - 2/5*p**3 + 6/5*p = 0.\\n-2, 1\\nWhat is c in 0 + 1/2*c**2 - 1/2*c**4 + 1/4*c**3 - 1/4*c**5 + 0*c = 0?\\n-2, -1, 0, 1\\nLet c(o) = o**2 - 23*o + 60. Let p be c(20). Let t(f) be the second derivative of 0 - 4*f - 1/48*f**4 + 0*f**2 + 1/80*f**5 + p*f**3 + 1/60*f**6. Factor t(j).\\nj**2*(j + 1)*(2*j - 1)/4\\nLet l(s) be the second derivative of -s**6/1260 - s**5/140 - s**4/42 + 2*s**3/3 - 3*s. Let g(j) be the second derivative of l(j). Factor g(d).\\n-2*(d + 1)*(d + 2)/7\\nLet n(y) = -y**2 - 4*y + 7. Suppose 0 = 3*l - 2*u + 7, l + 2*u + 21 = -2*u. Let q be n(l). Solve -2*h - 4*h**2 + q*h - 2*h - 2*h**3 = 0.\\n-1, 0\\nLet g(i) be the first derivative of -80*i**6/3 + 88*i**5 - 215*i**4/2 + 365*i**3/6 - 35*i**2/2 + 5*i/2 - 21. Solve g(y) = 0.\\n1/4, 1\\nFactor -m - 9*m - m**4 - m**4 + 8*m**2 + 2*m**3 + 2*m.\\n-2*m*(m - 2)*(m - 1)*(m + 2)\\nLet l(n) be the third derivative of n**5/25 - n**4/40 - 4*n**2. Let l(m) = 0. Calculate m.\\n0, 1/4\\nLet q be (-3)/6 + 5 + (-6)/(-84). Let r = 6 - 4. Solve 22/7*u - q*u**2 + r*u**3 - 4/7 = 0 for u.\\n2/7, 1\\nLet b(i) be the third derivative of -i**7/180 + i**6/45 + 17*i**5/360 - i**4/24 + 3*i**2. Factor b(d).\\n-d*(d - 3)*(d + 1)*(7*d - 2)/6\\nLet z = 0 + -2. Let k(b) = b**3 + b**2 - 3*b - 2. Let j be k(z). Factor j*r**3 + 0 + 0*r + 2/5*r**4 - 2/5*r**2.\\n2*r**2*(r - 1)*(r + 1)/5\\nLet w = 2 + 2. Find g such that -12*g**3 + 8*g**3 - 4*g**2 + 8*g**3 - 4*g + 4*', '<|endoftext|>\\n-1, 4/163, 1, 5\\nDetermine d so that -4*d**3 - 16500*d**2 + 331524*d - 315020 = 0.\\n-4145, 1, 19\\nFind v, given that -3*v**2 + 1239918*v - 128116387227 = 0.\\n206653\\nDetermine b, given that b**3/3 - 97*b**2 - 2380*b/3 - 1196 = 0.\\n-6, -2, 299\\nSolve -57*a**5 - 48*a**4 + 276*a**3 + 258*a**2 - 219*a - 210 = 0.\\n-35/19, -1, 1, 2\\nFactor -4*y**2/5 - 4388*y/5 - 47784/5.\\n-4*(y + 11)*(y + 1086)/5\\nSuppose 570*p**4 - 2427*p**3/2 - 4690*p**2/3 + 1327*p/6 + 1 = 0. Calculate p.\\n-1, -1/228, 2/15, 3\\nFind v such that v**2/3 + 5425*v/3 + 1808 = 0.\\n-5424, -1\\nWhat is s in -s**4 + 128*s**3 + 4165*s**2 + 3256*s - 24180 = 0?\\n-26, -3, 2, 155\\nDetermine c, given that -2*c**4/5 - 4*c**3/5 + 24*c**2/5 - 28*c/5 + 2 = 0.\\n-5, 1\\nSuppose -2*t**4 + 10844*t**3 + 10846*t**2 = 0. What is t?\\n-1, 0, 5423\\nSolve -v**3 - 531*v**2 - 5730*v - 5200 = 0.\\n-520, -10, -1\\nSuppose -9*r**3 - 41132*r**2 - 50261*r - 9138 = 0. What is r?\\n-4569, -1, -2/9\\nWhat is c in -4*c**5 + 156*c**4 - 920*c**3 + 640*c**2 + 4224*c - 4096 = 0?\\n-2, 1, 4, 32\\nFactor -2*t**2/9 + 9656*t/9 - 19288/3.\\n-2*(t - 4822)*(t - 6)/9\\nDetermine q so that 2*q**2 - 1198*q = 0.\\n0, 599\\nSuppose -x**5/5 - 281*x**4/5 - 23941*x**3/5 - 115875*x**2 - 3097386*x/5 - 2541672/5 = 0. What is x?\\n-123, -28, -6, -1\\nSuppose -2*s**2 - 150*s + 5252 = 0. What is s?\\n-101, 26\\nDetermine x, given that x**4/7 - 45*x**3/7 + 116*x**2/7 + 60*x = 0.\\n-2, 0, 5, 42\\nFactor 3*m**3/7 + 225*m**2/7 + 258*m + 1584/7.\\n3*(m + 1)*(m + 8)*(m + 66)/7\\nFactor -m**5 - 3075*m**4 - 21494*m**3 - 55244*m**2 - 61368*m - 24544.\\n-(m + 1)*(m + 2)**3*(m + 3068)\\nLet g**5/6 + 194*g**4/3 + 773*g**3/6 + 193*g**2/3 = 0. What is g?\\n-386, -1, 0\\nLet 2*h**5 + 2150*h**4 + 324334*h**3 - 148912214*h**2 = 0. Calculate h.\\n-631, 0, 187\\nDetermine q, given that -q**3 - 420*q**2 - 41925*q + 462250 = 0.\\n-215, 10\\nLet 4*u**4/7 + 1240*u**3/7 - 19392*u**2/7 + 35048*u/7 - 16900/7 = 0. What is u?\\n-325, 1, 13\\nFactor p**2/6 - 44183*p/2 - 66275/3.\\n(', \"<|endoftext|> 40. Factor 12*f**4 - 1 - 28*f**5 + 1 + 32*f**w.\\n4*f**4*(f + 3)\\nLet v(g) be the second derivative of g**6/72 + 7*g**5/12 + 65*g**4/24 + 41*g**3/3 + 2*g - 4. Let y(b) be the second derivative of v(b). Factor y(h).\\n5*(h + 1)*(h + 13)\\nLet i(w) be the firs<|endoftext|>---\\nabstract: 'Amyloid fibers are aggregates of proteins. They are built out of a peptide called $\\\\beta$–amyloid (A$\\\\beta$) containing between 41 and 43 residues, produced by the action of an enzyme which cleaves a much larger protein known as the Amyloid Precursor Protein (APP). X–ray diffraction experiments have shown that these fibrils are rich in $\\\\beta$–structures, whereas the shape of the peptide displays an $\\\\alpha$–helix structure within the APP in its biologically active conformation. A realistic model of fibril formation is developed based on the seventeen residues A$\\\\beta$12–28 amyloid peptide, which has been shown to form fibrils structurally similar to those of the whole A$\\\\beta$ peptide. With the help of physical arguments and in keeping with experimental findings, the A$\\\\beta$12–28 monomer is assumed to be in four possible states (i.e., native helix conformation, $\\\\beta$–hairpin, globular low–energy state and unfolded state). Making use of these monomeric states, oligomers (dimers, tertramers and octamers) were constructed. With the help of short, detailed Molecular Dynamics (MD) calculations of the three monomers and of a variety of oligomers, energies for these structures were obtained. Making use of these results within the framework of a simple yet realistic model to describe the entropic terms associated with the variety of amyloid conformations, a phase diagram can be calculated of the whole many–body system, leading to a thermodynamical picture in overall agreement with the experimental findings. In particular, the existence of micellar metastable states seem to be a key issue to determine the thermodynamical properties of the system.'\\naddress:\\n- '$^1$Dipartimento di Fisica, Università di Milano, Via Celoria 16, I-20133 Milano, Italy.'\\n- '$^2$INFN, Sezione di Milano, Via Celoria 16, I-20133 Milano, Italy.'\\n- '$^3$The Niels Bohr Institute, University of Copenhagen, 2100 Copenhagen, Denmark.'\\n- |\\n    $^4$ Istituto di Chimica del Riconoscimento Molecolare, CNR,\\\\\\n    Via Mario Bianco 9, Milano 20131, Italy.\\nauthor:\\n- 'G. Tiana$^{1,2}$, F. Simona$^1$, R. A. Broglia$^{1,2,3}$ and G. Colombo$^4$'\\ntitle: 'Thermodynamics of $\\\\beta$–amyloid fibril formation'\\n---\\n\\nAmyloid fibers are aggregates of proteins or of fragments of proteins displaying rod–like shape. The mechanism which trigger proteins to leave their biologically active conformation and aggregate is, in general, unknown.\\n\\nThe formation of amyloid fibres [@foot1] from monomeric proteins moved to the centre of the scientific stage when it was found to be associated with Alzheimer’s disease (AD) and encephalopathies such as bovine spongiform encephalopathy (BSE, “mad cow” disease) in animals and Creutzfeld–Jakob disease (CJD) in humans. The brain of people with the memory disorder are studded with abnormal structures called plaques, which are made out of amyloid fibers. In this case, the aggregate is built out of a peptide containing from 41 to 43 residues, called $\\\\beta$–amyloid (A$\\\\beta$). This peptide is produced by the action of an enzyme, the $\\\\beta$–secretase which cleaves a much larger protein known as the amyloid precursor protein (APP). This process takes place in everyone, not just people with AD. But people with AD have an increased A$\\\\beta$ production. It has been suggested that this excess $\\\\beta$–amyloid production may lead to fibril formation because, having higher concentration of protein will increase the likelihood that any partially folded intermediates will be able to attach to each other and aggregate.\\n\\nRecent studies have suggested that oligomeric fibrillation intermediates (protofibrils) rather than fibrils themselves are pathogenic, but the mechanism by which they cause neuronal death remains a mystery. The possibility that a molecular species other than the amyloid fibril could be pathogenic is testified by the fact that oligomeric species rich in $\\\\beta$–sheet structure (protofibrils)\", '<|endoftext|> t so that -t**2/2 + 190470*t - 18139410450 = 0.\\n190470\\nLet -v**3 + 870040*v**2 - 189242400400*v = 0. Calculate v.\\n0, 435020\\nWhat is m in -3*m**3/4 - 1029*m**2 - 8223*m/4 - 2055/2 = 0?\\n-1370, -1\\nDetermine l so that l**3/5 - 14*l**2 + 697*l/5 + 20172/5 = 0.\\n-12, 41\\nFactor w**2 - 34424*w + 296252944.\\n(w - 17212)**2\\nFactor -3*l**2 - 402*l - 1560.\\n-3*(l + 4)*(l + 130)\\nSuppose 5*q**4/3 - 13510*q**3/3 + 3046495*q**2 - 6061500*q - 9112500 = 0. What is q?\\n-1, 3, 1350\\nFind o, given that 2*o**2 + 7916*o + 7914 = 0.\\n-3957, -1\\nSuppose 2*s**5 - 9*s**4 - 469*s**3 + 723*s**2 + 467*s - 714 = 0. What is s?\\n-14, -1, 1, 3/2, 17\\nLet t**3/5 + 2822*t**2/5 - 33972*t/5 + 102024/5 = 0. Calculate t.\\n-2834, 6\\nSolve 4*n**5 - 9*n**4 - 3*n**3 + 10*n**2 = 0.\\n-1, 0, 5/4, 2\\nFactor 5*d**5 + 270*d**4 - 855*d**3.\\n5*d**3*(d - 3)*(d + 57)\\nFind f such that 5*f**3 - 29965*f**2 + 1251915*f - 13121955 = 0.\\n21, 5951\\nFactor -5*w**4 + 1620*w**3 - 188990*w**2 + 9358740*w - 166868645.\\n-5*(w - 109)**2*(w - 53)**2\\nDetermine g, given that 2*g**5/5 + 37*g**4/5 + 129*g**3/5 - 346*g**2/5 - 248*g/5 + 192/5 = 0.\\n-12, -8, -1, 1/2, 2\\nFactor 3*t**5/4 + 14715*t**4/4 + 4512906*t**3 + 4509228*t**2.\\n3*t**2*(t + 1)*(t + 2452)**2/4\\nFind p such that -27*p**3 - 12747*p**2 - 1505208*p - 167088 = 0.\\n-236, -1/9\\nSolve 3*q**2/7 + 293169*q/7 - 586350/7 = 0 for q.\\n-97725, 2\\nSolve -2*v**4 - 1562*v**3 - 317884*v**2 - 5007256*v - 8755440 = 0 for v.\\n-382, -15, -2\\nWhat is q in 7648658874112*q**4 - 5546078784*q**3 + 1340496*q**2 - 108*q = 0?\\n0, 3/12412\\nSuppose -3*z**4 - 1500*z**3 - 4482*z**2 - 4476*z - 1491 = 0. Calculate z.\\n-497, -1\\nWhat is g in -11*g**5 - 147*g**4 - 7352*g**3/11 - 12196*g**2/11 - 3744*g/11 - 320/11 = 0?\\n-5, -4, -2/11\\nFactor -3*w**2/5 - 114048*w/5 - 1083912192/5.\\n-3*(w + 19008)**2/5\\nFactor -7*t**2/6 + 5323*t/2 - 2281/3.\\n-(t - 2281)*(7*t - 2)/6\\nDetermine j so that j**2 + 44642*j + 498227041 = 0.\\n-22321\\nSolve 10*y**5/11 + 4*y**4 -', '<|endoftext|> be the second derivative of b(n). Factor l(c).\\n-3*c**2*(c - 2)*(c + 1)/4\\nLet u = 12465/51251 + 2/967. Let f = u + 333/371. Factor f*o**2 + 2/7 - 10/7*o.\\n2*(o - 1)*(4*o - 1)/7\\nLet j be -36 + 1105/25 + -7. Factor -11/5*w + 6/5 + j*w**2 - 1/5*w**3.\\n-(w - 3)*(w - 2)*(w - 1)/5\\nLet d(t) be the second derivative of -3*t - 25 + 26/33*t**3 - 25/11*t**2 - 1/66*t**4. Factor d(z).\\n-2*(z - 25)*(z - 1)/11\\nLet j(k) = 2*k**4 + 23*k**3 + 149*k**2 + 324*k + 275. Let g(z) be the first derivative of -z**4/4 + z**3/3 + z - 33. Let p(u) = 5*g(u) - j(u). Factor p(y).\\n-2*(y + 3)**3*(y + 5)\\nSuppose -62*n + 25*n = -24*n. Let c(f) be the third derivative of 1/1050*f**7 + 0 + n*f - 1/100*f**5 - 2/15*f**3 - 7*f**2 + 1/15*f**4 - 1/300*f**6. Factor c(z).\\n(z - 2)*(z - 1)**2*(z + 2)/5\\nLet f be ((-130)/(-6175))/(15/1425). Let 62/3*z + 1/3*z**f + 961/3 = 0. Calculate z.\\n-31\\nLet r(m) be the second derivative of 0 + 3*m**2 - 1/2*m**4 - 1/4*m**3 - 235*m + 3/40*m**5. Let r(u) = 0. What is u?\\n-1, 1, 4\\nLet x = -669989 + 669991. Factor 3/2 - 11/4*o + 3/2*o**x - 1/4*o**3.\\n-(o - 3)*(o - 2)*(o - 1)/4\\nLet m(t) be the third derivative of -t**7/210 - t**6/30 + t**5/60 + t**4/6 + 107*t**2. Factor m(u).\\n-u*(u - 1)*(u + 1)*(u + 4)\\nLet s(v) be the first derivative of -1681*v**4/28 - 11234*v**3/7 - 1641*v**2/14 - 20*v/7 + 7707. Let s(p) = 0. What is p?\\n-20, -1/41\\nLet a = 1075716/5 - 215142. Factor a*t**3 + 18/5*t + 24/5*t**2 + 0.\\n6*t*(t + 1)*(t + 3)/5\\nLet a = 267166 + -267161. Determine w, given that 0 + 17/4*w**3 + w - w**4 - a*w**2 = 0.\\n0, 1/4, 2\\nLet q = -19221 + 19223. Let l = 494/7 + -70. Solve 4/7 + 1/7*j**q - l*j = 0 for j.\\n2\\nLet d(v) be the second derivative of -5/2*v**3 + 0 + 1/40*v**6 - 30*v + 3*v**2 + 9/8*v**4 - 21/80*v**5. Determine c, given that d(c) = 0.\\n1, 2\\nLet s(b) = -2*b**2 - 19*b - 3. Let n be s(-9). Let k = 4 + n. What is x in 7*x - k*x**2 + 8 + 13*x - 8*x**2 - 10*x**2 = 0?\\n-2/7, 1\\nLet i(m) be the first derivative of 5*m**4/4 - 25*m**3 - 180*m**2 - 380*m + 2125. Factor i(l).', '<|endoftext|>*l - 18)/4\\nFactor -3*o**2 + 1110*o + 2232.\\n-3*(o - 372)*(o + 2)\\nFactor 3*r**4 - 201*r**3 - 2007*r**2 - 3399*r - 1596.\\n3*(r - 76)*(r + 1)**2*(r + 7)\\nFactor -3*k**4 - 78*k**3 - 756*k**2 - 3234*k - 5145.\\n-3*(k + 5)*(k + 7)**3\\nFactor -2*t**4 - 22*t**3 + 24*t**2 + 512*t - 512.\\n-2*(t - 4)*(t - 1)*(t + 8)**2\\nFactor 2*p**3/9 + 68*p**2/3 + 504*p - 3888.\\n2*(p - 6)*(p + 54)**2/9\\nLet 3*v**3 + 18*v**2 - 648*v = 0. Calculate v.\\n-18, 0, 12\\nFactor -c**2/4 - 77*c/4 - 19.\\n-(c + 1)*(c + 76)/4\\nSolve -f**2/3 + 12 = 0 for f.\\n-6, 6\\nFind f, given that -16*f**4 + 140*f**3 - 176*f**2 - 164*f + 168 = 0.\\n-1, 3/4, 2, 7\\nLet 2*o**4/13 - 64*o**3/13 + 418*o**2/13 + 484*o/13 = 0. What is o?\\n-1, 0, 11, 22\\nFactor 3*s**5 + 33*s**4 + 138*s**3 + 276*s**2 + 264*s + 96.\\n3*(s + 1)*(s + 2)**3*(s + 4)\\nSolve -20*y**2 - 728*y + 444 = 0.\\n-37, 3/5\\nFactor -2*m**3/7 - 4*m**2 - 26*m/7.\\n-2*m*(m + 1)*(m + 13)/7\\nLet 18*v**4 + 84*v**3 - 176*v**2 - 448*v/3 + 256 = 0. What is v?\\n-6, -4/3, 4/3\\nSolve -g**3/2 + 634*g**2 - 400685*g/2 - 403225 = 0 for g.\\n-2, 635\\nFactor -2*l**3/13 - 166*l**2/13 - 164*l/13.\\n-2*l*(l + 1)*(l + 82)/13\\nSolve -5*n**3 + 115*n**2 - 510*n = 0 for n.\\n0, 6, 17\\nFactor -i**2/4 + 81*i/2 - 6561/4.\\n-(i - 81)**2/4\\nSuppose -3*i**4/5 - 102*i**3/5 - 288*i**2/5 + 11718*i/5 + 11907/5 = 0. What is i?\\n-21, -1, 9\\nLet 4*k**2 - 12*k - 16 = 0. What is k?\\n-1, 4\\nFactor p**3/2 - 87*p**2/2 + 828*p - 4536.\\n(p - 63)*(p - 12)**2/2\\nSuppose -2*h**2/7 + 5374*h/7 = 0. Calculate h.\\n0, 2687\\nWhat is o in -1881*o**3 + 3756*o**2 - 1869*o - 6 = 0?\\n-2/627, 1\\nLet 18*k**4/5 - 401*k**3/5 + 297*k**2/5 + 86*k/5 = 0. Calculate k.\\n-2/9, 0, 1, 43/2\\nFactor 2*w**3/9 - 128*w**2/9 + 14*w.\\n2*w*(w - 63)*(w - 1)/9\\nLet -v**4 - 22*v**3 + 25*v**2 + 46*v = 0. Calculate v.\\n-23, -1, 0, 2\\nSuppose 5*a**5 - 150*a**4 - 5*a**3 + 150*a**2 = 0. What is a?\\n-1, 0, 1, 30\\nSolve 2*a**3 + 45', '<|endoftext|> = 0?\\n-163, 0\\nFactor l**3/4 + 1383*l**2/4 - 2769*l/4 + 1385/4.\\n(l - 1)**2*(l + 1385)/4\\nDetermine s so that -s**3 - 252*s**2 - 16125*s - 31250 = 0.\\n-125, -2\\nFactor 100600900*u**2/3 - 80240*u/3 + 16/3.\\n4*(5015*u - 2)**2/3\\nSolve -3*b**4 + 24*b**3 - 21*b**2 = 0 for b.\\n0, 1, 7\\nSuppose 14*l**4 - 316*l**3 = 0. Calculate l.\\n0, 158/7\\nFactor 2*s**4/21 + 2*s**3 + 26*s**2/7 + 38*s/21.\\n2*s*(s + 1)**2*(s + 19)/21\\nLet -t**4/8 + 435*t**3/8 + 437*t**2/8 - 435*t/8 - 109/2 = 0. Calculate t.\\n-1, 1, 436\\nFind b, given that -3*b**2/2 + 216*b + 435/2 = 0.\\n-1, 145\\nSolve 2*f**3 - 2*f**2 - 34*f - 30 = 0 for f.\\n-3, -1, 5\\nFactor v**2 + 40*v + 39.\\n(v + 1)*(v + 39)\\nSolve 4*j**2 + 972*j + 3824 = 0 for j.\\n-239, -4\\nSuppose -8*c**5 - 124*c**4 - 564*c**3 - 900*c**2 - 324*c = 0. What is c?\\n-9, -3, -1/2, 0\\nSolve -l**3 - 299*l**2/4 + 75*l/4 = 0 for l.\\n-75, 0, 1/4\\nFactor -4*a**3 - 40*a**2 - 32*a + 256.\\n-4*(a - 2)*(a + 4)*(a + 8)\\nFactor -2*u**5 - 60*u**4 + 576*u**3 - 1216*u**2.\\n-2*u**2*(u - 4)**2*(u + 38)\\nFactor 529*q**2 - 138*q + 9.\\n(23*q - 3)**2\\nSuppose 4*p**5 - 184*p**4 + 2284*p**3 - 3688*p**2 - 2288*p + 3872 = 0. Calculate p.\\n-1, 1, 2, 22\\nLet -5*y**2 + 7*y/3 + 4/3 = 0. What is y?\\n-1/3, 4/5\\nDetermine b, given that 2*b**2/21 + 22*b/7 - 20/3 = 0.\\n-35, 2\\nDetermine h so that -h**4/2 - 216*h**3 - 645*h**2 - 644*h - 429/2 = 0.\\n-429, -1\\nFactor c**4 - 7*c**3 + 5*c**2 + 7*c - 6.\\n(c - 6)*(c - 1)**2*(c + 1)\\nSuppose 3*n**3 - 1119*n**2 + 1116*n = 0. Calculate n.\\n0, 1, 372\\nFactor -5*t**5 - 25*t**4 - 35*t**3 - 15*t**2.\\n-5*t**2*(t + 1)**2*(t + 3)\\nFactor -2*k**3 + 1936*k**2/5 - 93314*k/5 - 37636/5.\\n-2*(k - 97)**2*(5*k + 2)/5\\nFactor -y**3/3 - 302*y**2/3 - 22801*y/3.\\n-y*(y + 151)**2/3\\nLet 6*w**3 + 73*w**2 + 245*w + 196 = 0. What is w?\\n-7, -4, -7/6\\nSuppose -15*k**5 + 140*k**4 + 445*k**3 + 410*k**2 + 120*k = 0. What is k?\\n-1, -2/3, 0, 12\\nFactor n**3/10 - 19*n**2']\n","577 ['<|endoftext|>\\n\\nHis words stinging more than a slap would have, Marge felt her eyes fill with tears. Snatching her purse up from the counter, she hurried out the back door.\\n\\nA moment later Jeff heard the engine of her car roar and the wheels spin as she jammed it into gear. Wishing he could take back the last words he\\'d uttered, he stood up from the table, knocking the chair over in his hurry, and went to the back door.\\n\\nToo late.\\n\\nHis mother\\'s car was already disappearing down the driveway, lost in a cloud of dust.\\n\\n\"Shit,\" Jeff said softly to himself. Going back to the table, he righted the chair, settled onto it once again, and began shoving the pancakes into his mouth. When the back door opened a moment or two later, he barely even heard it, but he did hear the words Vic Costas was speaking.\\n\\n\"I\\'ll take the keys to the station wagon,\" the farmer said in a voice whose quietness bespoke his authority.\\n\\nJeff looked up at him in surprise.\\n\\n\"I heard you talking to your mother,\" Costas told him. \"Your mother\\'s a good woman, and she works hard to take care of you. That\\'s the thanks you give her? Talking to her that way?\" He shook his head. \"Not on my farm. And boys like you don\\'t use my car, either.\" He held his hand out.\\n\\nJeff hesitated, and for just a moment wondered what would happen if he refused. But as big as he was, Vic Costas was two inches taller, with wide shoulders and the muscles of a man who had been working the land all his life. As the farmer\\'s eyes, so dark they looked black, fixed on him, Jeff reached into his pocket, pulled out the keys to the rusting Mercury, and handed them over.\\n\\n\"You apologize to your mother,\" Costas told him. \"And you think about how you treat her.\" Without another word, he turned and left the house.\\n\\nLeft alone again, Jeff finished the stack of pancakes, then made another. Drenching them with Karo syrup, he wolfed them down, then poured a bowl of cereal, and ate that, too.\\n\\nBefore he was finally finished, he\\'d scrambled half a dozen eggs and drunk half the can of pineapple juice his mother had opened for Ben that morning.\\n\\nAnd now something else was happening to him.\\n\\nHe was starting to feel restless.\\n\\nHe began pacing through the house, then went out into the yard.\\n\\nIt seemed hot—way too hot even for the end of June.\\n\\nHe moved over into the shade of one of the olive trees Mr. Costas had planted years ago when he\\'d decided to experiment with producing domestic olive oil, and dropped down to the ground, leaning his back against the tree\\'s trunk.\\n\\nA hornet settled on his leg.\\n\\nJeff stared at it, instantly remembering the horse he\\'d watched die in the Owens\\' corral yesterday.\\n\\nA cold shiver of fear made his spine tingle, and he moved his right hand slowly toward the hornet, preparing to brush it away in a motion so quick the insect would have no time to plunge its stinger through his skin.\\n\\nHis hand hovered in midair, but when he tried to flick the hornet away, his arm refused to respond to the order of his brain.\\n\\nHis hand remained where it was.\\n\\nA second hornet settled on his leg, and then a third.\\n\\nJeff felt a lump of fear growing in his throat, and once more tried to flick the insects away, but once again found himself unable to make his hand obey.\\n\\nThe hornets began to move on his skin.\\n\\nTo move in a pattern that captured his attention.\\n\\nThe focus of his eyes began to narrow, until it felt as though he were looking through a long tube, and all he could see was the hornets.\\n\\nThey kept moving on his skin, repeating the same pattern over and over.\\n\\nThen an image came into his mind.\\n\\nJulie!\\n\\nHe saw a vision of Julie perfectly clearly.\\n\\nJulie was smiling at him, and beckoning to him.\\n\\nIt was almost like a dream, except that Jeff knew he was wide-awake.\\n\\nAs the hornets rose from his leg and flew off, quickly disappearing into the distance, Jeff Larkin stood and began walking.\\n\\nMoving quickly with long, steady strides, he set off across the field, heading northeast toward the Owen farm.\\n\\nTo the hills beyond the farm.\\n\\nThe hills, and Julie.\\n\\nKevin stepped out onto the porch, waving and yelling at Jeff Larkin, but the other boy didn\\'t seem either', '<|endoftext|>, who was half Lebanese and the only one among us who spoke Arabic, closed his eyes to concentrate on what they were saying. \"The rebels are amassing nearby,\" he said. \"The troops are saying they want to move us to a safer place.\"\\n\\n\"That\\'s a promising sign,\" I said.\\n\\nSeveral soldiers approached us, and one by one they tied blindfolds around our eyes and refastened our arms behind our backs. A large, muscular soldier lifted me like a pillow into his arms and loaded me into the back of the armored personnel carrier—a vehicle resembling a giant tin beetle. I tried to remain as still as possible, to draw as little attention to myself as I could, when I felt a soldier climb into the vehicle and position himself with his front pressing tightly against my back. There was a lot of movement, and soon I heard Steve\\'s voice: \"Is everybody here?\"\\n\\nOne by one we all answered yes.\\n\\nThe vehicle began to move, and within seconds the soldier spooning my back started tracing his fingers across my body. I prayed he wouldn\\'t find my money belt with my passport. I squirmed and pleaded, \"Please, don\\'t. Please. I have a husband.\" He covered my mouth with his salty fingers and ordered me not to speak as he continued groping me. I could taste the salt and mud from his skin on my lips as he continued grabbing at my breasts and butt, clumsily tracing my genitals over my jeans.\\n\\nI knew that the armored personnel carrier, a common military vehicle used to transport troops, was full of men, and I wondered how long I would have to endure this torment before someone came to my rescue. I heard one of my colleagues groan in pain—I thought it was Anthony but later learned it was Steve getting a bayonet shoved in between his butt cheeks, not quite ripping through his pants—and I knew we were all being abused simultaneously.\\n\\n\"Please. You are Muslim,\" I said. \"I have a husband. Please.\" He ignored my words and kept his hands on my breasts for the thirty minutes or so we drove, until miraculously another soldier pulled me into the protection of his embrace. He was trying to shield me from the groping. The salty-fingered guy pulled me back against him. The savior pulled me back. Someone had a conscience.\\n\\nThe vehicle finally slowed and pulled over to the side of the road. The door opened, and I was roughly pushed out. With our arms tied and eyes blindfolded, they shifted us to the back of a cramped Land Cruiser. Inside, Anthony was moaning loudly.\\n\\n\"My shoulders,\" he said aloud, his voice drenched in pain. \"My arms are bound so tightly, it\\'s killing my shoulders.\"\\n\\nMy shoulder with the titanium plate that reset my collarbone after my car accident also ached. Anthony and Steve began to speak a smattering of Arabic to a soldier, pleading with him to retie our arms in front, rather than behind our backs. One by one the soldier untied our arms, and the relief was immediate. I was eerily calm in the back of the truck: My hands now tied in front, the close proximity to my colleagues, and the hope that we would all remain together were enough to get me through the night.\\n\\nI kept my eyes closed under the blindfold and tried to slow my breath, to distract myself from my fear, my thirst, my need to pee. That\\'s when I felt another hand on my face, caressing my cheek like a lover. Slowly he ran his fingers over my cheeks, my chin, my eyebrows. I lowered my face into my lap. He raised it, tenderly, and continued with his caresses. He ran his hands over my hair and spoke to me in a low, steady voice, repeating the same phrase over and over. I kept my face down, ignoring his touch, his words. I didn\\'t understand what he was saying.\\n\\n\"What is he saying, Anthony?\"\\n\\nAnthony took his time answering. \"He\\'s telling you that you will die tonight.\"\\n\\nI was numb. Since the moment we\\'d been taken that morning, I\\'d resigned myself to the likelihood that I was going to die, and every minute since then had felt like a gift. I focused on the moment, on staying alive, on not getting overwhelmed by emotion.\\n\\nTyler suddenly said, \"I need some fresh air. Anthony, could you please ask them if I can step outside for some fresh air?\"\\n\\nTyler\\'s request was strange to me; he had endured the previous hours without so much as a whimper, and now he was asking for fresh air. I would later learn that Saleh, the soldier who kept telling me I would die as he caressed my cheeks, had told Tyler repeatedly that he was', \"<|endoftext|> knee struck the corner of a trough and sent her sprawling into the snow. Vrinna's imperial sword whisked through the air, guided by her battle-honed thoughts; she could have killed Kira effortlessly, had that been her aim.\\n\\nInstead, she used her sword to batter Virtue's Grace to one side, then she took Kira by surprise by actually grabbing the blade at the unsharpened base near the hilt. Kira tried to pull it away from her, using her mind as well as her out-of-practice muscles to twist the sword from Vrinna's grasp, but she was concentrating so hard on regaining control that she never even noticed the pommel of Vrinna's sword before it crashed into the side of her head.\\n\\nShe fell with Virtue's Grace still in her hand, but she could do nothing with it. The gray sky above her went darker and the ground swung beneath her like a triffon going into a dive.\\n\\n<Now you're going to tell me why you want me to stay away from Onfar's Circle,> said Vrinna viciously, <and I'm going to hurt you until you do.>\\n\\nKira saw a flash of light as the blow landed, and then her head snapped to one side with so much force that she was sure her neck must be broken. Hot pain like the touch of a brand zipped across her face a moment later.\\n\\n<I will beat it out of you,> said Vrinna. <Believe me: I know just how much I can hit you before you pass out.>\\n\\nKira tried to lift Virtue's Grace, but Vrinna's fist smashed into her stomach and expelled the remaining breath from her body. She heard the clang of her sword hitting the ground. She instinctively reached for it once more, but Vrinna's fist streaked through the snow again and Kira had a moment to anticipate where the punch was going to land before the pain crashed through her. She tasted blood, and her swollen left eye didn't blink with the right one.\\n\\n<What are you hiding?> Vrinna repeated.\\n\\n<Nothing.> Kira's groping hand found an overlooked iron rod under the snow and she had a moment of pure pleasure as she imagined the pulpy sound Vrinna's head would make when the metal smashed into it. <It's all in your imagination. You've made this whole thing up out of your jealousy.>\\n\\n<I'm not making it up.> Vrinna grabbed Kira's coat at the neck and hauled her up to her knees, then cuffed her on the back of her head and dropped her down again. Kira managed to turn her face to one side in time to keep her nose from shattering on the stone paving slabs, but the side of her head hit the ground and white light blazed in front of her eyes again. She had lost the iron rod and she was beginning to wonder if she would survive this encounter despite Vrinna's assurances.\\n\\n<What are you hiding at Onfar's Circle?>\\n\\n<Onfar's Circle? Where's that again?>\\n\\nThe enraged captain leaned in and kicked her in the stomach, and now Kira didn't know whether she should be trying to protect her face or her stomach; maybe it was too late, because her mouth had filled with blood. She spat it out and, coughing, tried to crawl away, but Vrinna picked her up by the back of her coat and shook her like a helpless kitten, repeating the same words over and over again until they no longer made any sense.\\n\\nFinally the shaking stopped and Kira was thrown back onto the ground. For a moment she just lay there, shuddering violently; then she told herself she had to escape this madwoman and tried to crawl back to the anvil so she could use it to get to her feet.\\n\\nBut pain lanced through her like a spear-thrust; it burst under her right breast and knocked her back again and she ended up back on the ground with her forehead pressed against the freezing iron, fighting for breath.\\n\\nA dark shape swelled in front of her, and out of it came Vrinna's fist once again... \\nChapter 24\\n\\nRho left Kira's apartment with the map in his pocket. He watched dawn lighten the sky above Arregador House's famous green-glass atrium as he made his way back to his room, where he threw himself down on the bed—but sleep remained elusive, creeping up to him with promises of oblivion, but then disappearing the moment he closed his eyes. After committing Kira's little map to memory, he had nothing to do but wait until midday and the opening of Eowara's tomb. Eventually the walls of\", \"<|endoftext|>\\nBecause nowadays Skyrim is the popular game, not Neverwinter Nights.\\n\\nWe fight self-centered, self-serving crusades. Sometimes goals will align, such as the desire to see P.T. preserved. It's a popular, fresh new game – historians and players alike want to see it preserved, reason why this subject is getting so much talk & coverage.\\n\\nHowever, most of the time they don't. Very few people care about decade-old mods, about dnd, about old interviews, about Stuard Smith. About gaming history.\\n\\nThey, the heroes\\n\\nWhen it comes to defending gaming history, we are not heroes.\\n\\nWe are those mindless background NPCs, repeating the same scripts over and over again. Occasionally an event triggers and we do some clunky animations and scripted interactions – posing with torches and pitchforks for the camera, then returning to the basic loop when the cutscene ends.\\n\\nThe real heroes are out there, facing incredible odds, facing real risks, sacrificing part of their lives to safe-guard our history for future, more deserving generations.\\n\\nThey are the ones battling against giant, powerful foes to secure the legal right to protect games.\\n\\nThey are the ones spending their own money to backup our history into somewhere safe.\\n\\nThey are the ones searching for our elders and trying to learn from them.\\n\\nThey are the ones risking jail by preserving our abandoned games.\\n\\nFor decades they have been fighting, alone and unappreciated. We owe them more than we can imagine. We can't let all their effort come to the spotlight only when it aligns with our own interests.\\n\\nWe can't allow gaming history to only matter when we want to play P.T. again.\\n\\nThere's a lot more at stake, and a lot more that each of us could be doing.\\n\\n--------------\\n\\nI will end this exceedingly long rant here (seriously, sorry for the length and thanks for reading).\\n\\nOriginally I went on, listing ways to do more. I would talk about things like showing more respect towards our history, about little things like using screenshots in the correct aspect ratio, about not diminishing old games to promote new ones, about the value of our history. But I already wrote about that. And honestly, those are nothing but the consequence of caring.\\n\\nApathy is death. Is what allow us to abandon our history. But passion is what's preserving it.\\n\\nIt was passion that led people to save the NWN mods, to find the dnd creators, to stand up for what they love. I know, it was passion for RPGs that motivated me to start a book dedicated to the history of CRPGs (passion and a lot of anger – I'll admit I'm not a nice person). If you care, if you are passionate about games, I'm sure that you can think of a few ways to help, no matter how big or small. That's really all there is to it.\\n\\nAnd please, whenever possible, show your support for people like the EFF, Rolo Kipp, Carey Martell, the CRPG Addcit, Matt Barton and countless other heroes out there. And especially to Brewster Kahle and the folks at the Internet Archive. We can't even comprehend how important their work is.<|endoftext|>In recent years, the use of double pane or double profile structures has become more common in order to substantially reduce heat transfer through, e.g., window, doors, façades and other building structures. Typically, such structures include an outer metal profile or frame, an inner metal profile or frame and one or more insulating strips or struts for maintaining the inner and outer profiles or frames in a spaced relationship. In addition, such insulating strips or struts are often made of a material exhibiting low conductivity in order to substantially minimize heat transfer from a warm side to a cold side of the composite structure.\\nHowever, as discussed in U.S. Pat. No. 6,035,600, in the event that one of the metal frames is subjected to a significantly different temperature environment than the other, thermal expansion of the warmer frame results in a displacement force between the respective frames of the composite section. As a result, the composite structure may bend or flex due to relative longitudinal displacement of the respective frames. This is known in the art as a “bimetal effect”, although it is not necessary for the frames to be comprised of different metals. Rather, it only refers to the different thermal expansions of the metal frames caused, e.g., by the metal frames being at different temperatures.\\nHeat sources causing a unilateral temperature rise include, e.g., temperature differences between a room interior and the outside air (e.g., in winter) or incident solar radiation upon the outer frame (e.g., in summer) that causes\", '<|endoftext|>\\n\\nIn working a puzzle, I’ve always preferred to start with the edge pieces. They’re usually easily identified by shape, and then together they create a framework within which the more difficult, more subjective, meaning-based sections of the puzzle can find their proper places. In this study we’ve already been looking at edge pieces – paying attention to the beginning and end of the Mazzaroth; and the beginnings and endings of Jubilee cycles.\\n\\nThe clearest correlation I’m seeing from the observations of this study is the year 1407/1406 BC. This year is known historically to be a pre-exile Jubilee year, and scholars have identified it according to the chronological cues of Scripture to be the one which marked the Israelites’ entrance into the promised land back when the nation of Israel had its beginning. And its astronomical markings are clear. It can be characterized in general terms as a Jubilee period which was marked both beginning and end by Venus/Regulus or Venus/Spica conjunctions, with the Jubilee year also being marked by a double or triple conjunction of one of the other visible planets with Regulus or Spica. If we look for all other Jubilee periods marked in this way for the time span from 5200 BC to 4200 AD, we end up with the following relatively short list, in which the number of Jubilees from -1406 to each point is shown at the end of each entry:\\n\\nNow, we also find the number “seven” deeply entrenched in the patterns that we’ve been studying here. The period which turns out to be so significantly marked, the Jubilee cycle, is made up of a seven of sevens. Suppose we take this one level higher, focusing in on the points which fall at a boundary between sevens of Jubilees, counting from the -1406 occurrence. These occurrences are shown in bold in the above list, and looking at just these occurrences we now get a very short list:\\n\\nNotice that these four points mark out two overlapping periods of 70 Jubilees each, with the portion that belongs to both time periods being the time span of Israel’s existence – from the crossing of the Jordan to the fall of Samaria. I think this may well be the most basic framework to be found, upon which all the rest can eventually find its proper place. For the overall starting and ending points of this marked time span, the Saturn and Venus correlations shown on this chart had left us with both -4150 and -4003 as reasonable starting points, and with both 1889 and 2036 as reasonable ending points. But the observations of Restoring the Timetable of Sabbath and Jubilee Years, displayed graphically in the chart Saturn, Venus, Jubilee correlation, suggest -4150 and 2036 as the more likely endpoints of this marked time span, and now we see this “sevens of Jubilees” perspective giving us the same answer.\\n\\nI still prefer not to make any strong claims regarding overall starting and ending points – but to be true to what the analysis seems to be telling us, I need to accept as a hypothesis anyway that -4150 could be marking the beginning of man’s life on earth, the creation of Adam and Eve on day 6 of the Creation account, and 2036 could be marking the end date when the Messiah is likely to return and begin His millennial reign. But certainly we can also say that any future dates are ultimately in the Father’s hands, and His choice of timing isn’t going to be dependent on our interpretations and partial understandings of things. Whatever He has decided and decreed is what we can expect Him to do. And just to add a bit of healthy ambiguity to our expectations, note that the fall of Samaria, according to the best available scholarship on its chronology, didn’t happen right at a Jubilee, but about 2 1/2 years before.<|endoftext|>3 Unusual Tips That Successful People Use to Create Habits\\n\\nYou want to change your life, but you can’t seem to change one habit. You endlessly browsed articles on productivity tips. And you found some tips you’ve implemented, but after a week or two you end up going back to your old self.\\n\\nIt’s killing you inside that you can’t change little things in your life. You genuinely want to be better. Every once in awhile you come across an inspiring motivation article or quote. And like before, you tell yourself it’s going to be different this time. “I will change.”\\n\\nBut the truth is that you haven’t learned the mistakes you’ve made the last time. We tend not to examine thoroughly why we failed before. And we repeat the same mistakes over and over. Just going through the same cycle of failure. Below, I have provided three tips that have helped me', '<|endoftext|>oe was added by: Makozoe\\n<diogenes_> then try re-installing sddm.\\n<user|16698> done :/\\n<diogenes_> user|16698, systemctl status sddm see if it shows any errors also xorg logs, btw any GPU drivers were installed before the upgrade?\\n<user|16698> in logs I just go Auth: sddm-helper exited with 11\\n<user|16698> (but stille running)\\n<user|16698> my driver for my intel GPU is i915\\n<user|16698> (mesa drivers)\\n<unknownTX> evening all... :) well pre-evening here\\n<oerheks> :-)\\n<unknownTX> man, been moving files off my 2TB drive to 2 othere drives , so i can repair the 2TB beast\\n<unknownTX> dont EEEEEEVER use exFAT\\n<mario_> list\\n<jhunold> !list | mario_\\n<ubottu> mario_: jhunold: No warez here! This is not a file sharing channel (or network); read the channel topic. If you\\'re looking for information about me, type Â« /msg ubottu !bot Â». If you\\'re looking for a channel, see Â« /msg ubottu !alis Â».\\n<oerheks> exfat is not the issue, ubuntu or linux as whole does not give complete set of filecheck+repair utils\\n<oerheks> work in progress\\n<oerheks> mario_, https://torrent.ubuntu.com/tracker_index\\n<ivan_> hi\\n<sharmarran> I have tried everything recommended and so far, none of them work. Can someone please tell me how to permanently enable boot numbers lock on focal fossa?\\n<sharmarran> I have tried everything recommended and so far, none of them work. Can someone please tell me how to permanently enable boot numbers lock on focal fossa?\\n<genii> Repeating every 7-10 minutes instead of every 2 minutes would be better :)\\n<user|19575> Hola\\n<sharmarran> genii myob\\n<genii> sharmarran: So, numlock on after user logs in, or numlock when login screen comes up?\\n<genii> sharmarran: To set it for your user: System Settings -> Input Devices -> Keyboard   ..then on the right of the screen, a section called NumLock on Plasma Startup    with 3 choices: Turn on  - Turn off - Leave unchanged. Choosing \"Turn on\" here, and hitting \"Apply\" button in bottom right of the window should change it\\n<sharmarran> genii I have been told this before, and there is no such option on my keyboard settings.\\n<sharmarran> I have tried everything recommended and so far, none of them work. Can someone please tell me how to permanently enable boot numbers lock on focal fossa?  Please if someone can answer this question directly, I would much apit. cheers\\n<sharmarran> I have tried everything recommended and so far, none of them work. Can someone please tell me how to permanently enable boot numbers lock on focal fossa? If someone can answer this question, I would very much appreciate it. cheers\\n<genii> sharmarran: PLease stop spamming, or I will be forced to remove yuo from the channel, thanks.\\n<sharmarran> genii I am 66 years old and require a bit more respect. thank you! And I have no idea what you mean by spamming. Also, I would appreciate it, if someone else could answer this question for me. cheers\\n<genii> sharmarran: Spamming is repeating the same content over and and over close togther in time. And I am not a young man either.\\n<IrcsomeBot> <da_ni_el> @sharmarran, for login screen, create the file /etc/sddm.conf   if not exist and add: â\\x80¦ [General] â\\x80¦ Numlock=on\\n<sharmarran> genii I am a woman, not a man. Please stop talking to me. thank you. I am new to unbuntu, and i do not appreciate being threatened. If this is how you treat people looking for help, then I will look elsewhere. However, I will lodge a complaint if you continue to be rude to me.\\n<sharmarran> i do not care who you are, you have no right to be rude to users\\n<genii> You are welcome to lokk elsewere, but we are indeed try', '<|endoftext|>.\\n\\nBut occasionally the dispatchers have to veer from the script to calm distraught callers or stabilise an aggressive situation. \"You get strange reactions from people under pressure,\" Griffiths says. \"Some are completely deadpan, almost robotic until the ambulance comes and then they break down. Some are abusive and some simply scream and you have to use repetitive persistence, asking the same question over and over, to get through to them. The most frustrating thing is when somebody rings on a mobile to say their friend has been shot, then they put the phone down. People assume you know where they are.\"\\n\\nThe two dozen staff on each shift sit in pods before two computer screens, one to interpret and act upon the clinical data and one displaying a map of London. On it, coloured circles denote ambulances en route – amber signifies help on its way, red shows the crew has arrived at the scene or are returning to hospital.\\n\\nThe first call of Griffiths\\' shift is from a carer who has found her elderly charge on the floor with a suspected stroke. Within minutes a moving orange circle shows an ambulance on its way.\\n\\n\"Some people here are superstitious and think that certain chairs attract more trauma,\" Griffiths says. \"I\\'m a bit of a trauma magnet. The air ambulance crews get sick of me.\"\\n\\nThe biggest event he has had to cope with was the London riots: \"There were a lot of assaults.\" Other cases stick in his mind because they are so unusual. \"A man called because his hand was stuck behind a radiator and he knew his central heating was about to come on,\" he says. \"Another man called because his wife had gone into labour [Griffiths has delivered five babies over the phone]. He was perfectly calm until he realised the baby was going to be born on his new sofa. He began shouting that he hadn\\'t paid it off yet, and his mother-in-law had to send him from the room.\"\\n\\nThis evening\\'s shift is proving unusually quiet. A woman calls because her brother has a nose bleed and an assault victim rings for a second time because his bleeding chin is staining his carpet. Both cases are ranked low priority by the computer. The casualties will probably get a call from a clinical team dedicated to non-urgent maladies.\\n\\n\"We get a lot of trivial calls – people who have seen a fox run over. But we have to understand that for them it\\'s a frightening experience and we direct them to a more suitable source of help,\" he says. \"Then you get people who have experienced real trauma such as the second world war, who don\\'t like to bother us. My trainer took a call from an elderly lady who had fallen in her bathroom on a Friday evening. She kept herself alive over the weekend by drinking bath water and rang us on the Monday to ask if we were open.\"\\n\\nIt would be understandable if the continual stream of disasters that filters through Griffiths\\' headphones made him nervous about life\\'s unpredictability. Instead it makes him sanguine. \"It\\'s inevitable that accidents happen and if one occurred around me I\\'d switch into work mode,\" he says. \"Friends find me unsympathetic if they are unwell because I\\'m used to so much worse.\"\\n\\nHe has, however, no desire to put himself on the scene of a crisis and train to be an ambulance technician or paramedic. \"I can deal with blood and guts,\" he says. \"But the smell of vomit undoes me. I\\'d rather be safely on the end of a telephone line.\"\\n\\nCurriculum vitae\\n\\nPay £23,861-£27,569\\n\\nHours Four 12-hour day shifts followed by three days off then four 12-hour night shifts followed by seven days off. \"I can\\'t imagine a nine-to-five job.\\n\\nWork-life balance \"12-hour shifts can make the weeks seem to disappear – going home and only having time to eat and wind down before sleep starts calling. On my days off I more than make up for any missed social events or downtime, doing as much as I can before getting back into my shift pattern. I share a house with six friends so there\\'s always someone to around talk to if I\\'ve had a difficult day and there\\'s a lot of support at work.\"\\n\\nBest thing Seeing the difference made to such a large volume of people every shift.\\n\\nWorst thing In winter, having to wake up for night shifts in the darkness, going home in the darkness and not seeing sunlight for a week!\\n\\nOvertime\\n\\nAt the end of a gruelling shift, Glen enjoys reading books, \"mostly science fiction or fantasy, never medical dramas\". Glen also likes going to the cinema or watching films at home with friends, computer gaming and outdoor activities such as airsofting and paintballing. \"I\\'m', '<|endoftext|>List\" title=\"Navigation\">\\n<li><a href=\"../../../../../../overview-summary.html\">Overview</a></li>\\n<li><a href=\"package-summary.html\">Package</a></li>\\n<li>Class</li>\\n<li class=\"navBarCell1Rev\">Tree</li>\\n<li><a href=\"../../../../../../deprecated-list.html\">Deprecated</a></li>\\n<li><a href=\"../../../../../../index-files/index-1.html\">Index</a></li>\\n<li><a href=\"../../../../../../help-doc.html\">Help</a></li>\\n</ul>\\n</div>\\n<div class=\"subNav\">\\n<ul class=\"navList\">\\n<li><a href=\"../../../../../../com/c77/androidstreamingclient/lib/rtp/package-tree.html\">Prev</a></li>\\n<li><a href=\"../../../../../../com/c77/androidstreamingclient/lib/tests/package-tree.html\">Next</a></li>\\n</ul>\\n<ul class=\"navList\">\\n<li><a href=\"../../../../../../index.html?com/c77/androidstreamingclient/lib/rtp/buffer/package-tree.html\" target=\"_top\">Frames</a></li>\\n<li><a href=\"package-tree.html\" target=\"_top\">No Frames</a></li>\\n</ul>\\n<ul class=\"navList\" id=\"allclasses_navbar_top\">\\n<li><a href=\"../../../../../../allclasses-noframe.html\">All Classes</a></li>\\n</ul>\\n<div>\\n<script type=\"text/javascript\"><!--\\n  allClassesLink = document.getElementById(\"allclasses_navbar_top\");\\n  if(window==top) {\\n    allClassesLink.style.display = \"block\";\\n  }\\n  else {\\n    allClassesLink.style.display = \"none\";\\n  }\\n  //-->\\n</script>\\n</div>\\n<a name=\"skip-navbar_top\">\\n<!--   -->\\n</a></div>\\n<!-- ========= END OF TOP NAVBAR ========= -->\\n<div class=\"header\">\\n<h1 class=\"title\">Hierarchy For Package com.c77.androidstreamingclient.lib.rtp.buffer</h1>\\n<span class=\"strong\">Package Hierarchies:</span>\\n<ul class=\"horizontal\">\\n<li><a href=\"../../../../../../overview-tree.html\">All Packages</a></li>\\n</ul>\\n</div>\\n<div class=\"contentContainer\">\\n<h2 title=\"Class Hierarchy\">Class Hierarchy</h2>\\n<ul>\\n<li type=\"circle\">java.lang.Object\\n<ul>\\n<li type=\"circle\">com.c77.androidstreamingclient.lib.rtp.buffer.<a href=\"../../../../../../com/c77/androidstreamingclient/lib/rtp/buffer/MinDelayRtpMediaBuffer.html\" title=\"class in com.c77.androidstreamingclient.lib.rtp.buffer\"><span class=\"strong\">MinDelayRtpMediaBuffer</span></a> (implements com.c77.androidstreamingclient.lib.rtp.buffer.<a href=\"../../../../../../com/c77/androidstreamingclient/lib/rtp/buffer/RtpMediaBuffer.html\" title=\"interface in com.c77.androidstreamingclient.lib.rtp.buffer\">RtpMediaBuffer</a>)</li>\\n<li type=\"circle\">com.c77.androidstreamingclient.lib.rtp.buffer.<a href=\"../../../../../../com/c77/androidstreamingclient/lib/rtp/buffer/TimeWindowRtpMediaBuffer.html\" title=\"class in com.c77.androidstreamingclient.lib.rtp.buffer\"><span class=\"strong\">TimeWindowRtpMediaBuffer</span></a> (implements com.c77.androidstreamingclient.lib.rtp.buffer.<a href=\"../../../../../../com/c77/androidstreamingclient/lib/rtp/buffer/RtpMediaBuffer.html\" title=\"interface in com.c77.androidstreamingclient.lib.rtp.buffer\">RtpMediaBuffer</a>)</li>\\n</ul>\\n</li>\\n</ul>\\n<h2 title=\"Interface Hierarchy\">Interface Hierarchy</h2>\\n<ul>\\n<li type=\"circle\">com.biasedbit.efflux.session.RtpSessionDataListener\\n<ul>\\n<li type=\"circle\">com.c77.androidstreamingclient.lib.rtp.buffer.<', '<|endoftext|>Error opening %s image\\\\n\", tname);\\n        tsk_error_print(stderr);\\n        tsk_error_reset();\\n        return 1;\\n    }\\n\\n    if ((fs = tsk_fs_open_img(img, 32256, (TSK_FS_TYPE_ENUM) 0)) == NULL) {\\n        fprintf(stderr, \"Error opening %s image\\\\n\", tname);\\n        tsk_error_print(stderr);\\n        tsk_error_reset();\\n        return 1;\\n    }\\n\\n    if (testfile(fs, 31)) {\\n        fprintf(stderr, \"%s error (non-resident)\\\\n\", tname);\\n        return 1;\\n    }\\n\\n    if (testfile(fs, 32)) {\\n        fprintf(stderr, \"%s error (resident)\\\\n\", tname);\\n        return 1;\\n    }\\n\\n    tsk_fs_close(fs);\\n    tsk_img_close(img);\\n    return 0;\\n}\\n\\nint\\ntest_ntfs_comp()\\n{\\n    TSK_FS_INFO *fs;\\n    TSK_IMG_INFO *img;\\n    const char *tname = \"ntfs-comp-1\";\\n    char fname[512];\\n\\n    snprintf(fname, 512, \"%s/ntfs-comp-1.img\", s_root);\\n    if ((img = tsk_img_open_sing((const TSK_TCHAR *)fname, (TSK_IMG_TYPE_ENUM) 0, 0)) == NULL) {\\n        fprintf(stderr, \"Error opening %s image\\\\n\", tname);\\n        tsk_error_print(stderr);\\n        tsk_error_reset();\\n        return 1;\\n    }\\n\\n    if ((fs = tsk_fs_open_img(img, 0, (TSK_FS_TYPE_ENUM) 0)) == NULL) {\\n        fprintf(stderr, \"Error opening %s image\\\\n\", tname);\\n        tsk_error_print(stderr);\\n        tsk_error_reset();\\n        return 1;\\n    }\\n\\n    if (testfile(fs, 34)) {\\n        fprintf(stderr, \"%s error (both)\\\\n\", tname);\\n        return 1;\\n    }\\n\\n    if (testfile(fs, 32)) {\\n        fprintf(stderr, \"%s error (sparse)\\\\n\", tname);\\n        return 1;\\n    }\\n\\n    tsk_fs_close(fs);\\n    tsk_img_close(img);\\n    return 0;\\n}\\n\\n\\nint\\nmain(int argc, char **argv)\\n{\\n    if (argc != 2) {\\n        fprintf(stderr, \"missing test image root directory\\\\n\");\\n        return 1;\\n    }\\n    s_root = argv[1];\\n\\n    if (test_fat12())\\n        return 1;\\n    if (test_fat_slack())\\n        return 1;\\n    if (test_fat_recover())\\n        return 1;\\n    if (test_ntfs_fe())\\n        return 1;\\n    if (test_ntfs_comp())\\n        return 1;\\n    if (test_ntfs_slack_ads())\\n        return 1;\\n\\n    printf(\"Tests Passed\\\\n\");\\n    return 0;\\n}\\n<|endoftext|>Pages\\n\\nBack to strangers, again.\\n\\nRemember when we first knew each other? When we first met? When we were finally together? When you cheated on me? Since the first day I knew you, I\\'ve never thought that you\\'ll be the one who is hard for me to forget. I\\'ve never thought you\\'ll be that stranger who used to be everything to me. And I\\'ve never thought you\\'ll change into someone I hate. You keep making the same mistakes over and over again since last 2 years. And funny how I keep forgiving you again and again even though I know you don\\'t deserve my apology. You wanna know why I keep forgiving you? Because I still want you in my life. I don\\'t wanna lose you. I wanna have you at my side forever. But then, I should realize that not everything\\'s gonna do the same as what I\\'m gonna do. What I don\\'t understand is, why do you never take everything you did as a lesson? Why? When I forgive you, you keep doing the same mistakes again and again and again. Why? I guess that you don\\'t really mean your \"sorry\". But still, I forgive you.\\n\\nI don\\'t', '<|endoftext|>\" title=\"class in com.google.web.bindery.requestfactory.apt\"><span class=\"typeNameLink\">Prev&nbsp;Class</span></a></li>\\n<li><a href=\"../../../../../../com/google/web/bindery/requestfactory/apt/DeobfuscatorBuilder.html\" title=\"class in com.google.web.bindery.requestfactory.apt\"><span class=\"typeNameLink\">Next&nbsp;Class</span></a></li>\\n</ul>\\n<ul class=\"navList\">\\n<li><a href=\"../../../../../../index.html?com/google/web/bindery/requestfactory/apt/ClientToDomainMapper.UnmappedTypeException.html\" target=\"_top\">Frames</a></li>\\n<li><a href=\"ClientToDomainMapper.UnmappedTypeException.html\" target=\"_top\">No&nbsp;Frames</a></li>\\n</ul>\\n<ul class=\"navList\" id=\"allclasses_navbar_top\">\\n<li><a href=\"../../../../../../allclasses-noframe.html\">All&nbsp;Classes</a></li>\\n</ul>\\n<div>\\n<script type=\"text/javascript\"><!--\\n  allClassesLink = document.getElementById(\"allclasses_navbar_top\");\\n  if(window==top) {\\n    allClassesLink.style.display = \"block\";\\n  }\\n  else {\\n    allClassesLink.style.display = \"none\";\\n  }\\n  //-->\\n</script>\\n</div>\\n<div>\\n<ul class=\"subNavList\">\\n<li>Summary:&nbsp;</li>\\n<li>Nested&nbsp;|&nbsp;</li>\\n<li>Field&nbsp;|&nbsp;</li>\\n<li><a href=\"#constructor.summary\">Constr</a>&nbsp;|&nbsp;</li>\\n<li><a href=\"#method.summary\">Method</a></li>\\n</ul>\\n<ul class=\"subNavList\">\\n<li>Detail:&nbsp;</li>\\n<li>Field&nbsp;|&nbsp;</li>\\n<li><a href=\"#constructor.detail\">Constr</a>&nbsp;|&nbsp;</li>\\n<li><a href=\"#method.detail\">Method</a></li>\\n</ul>\\n</div>\\n<a name=\"skip.navbar.top\">\\n<!--   -->\\n</a></div>\\n<!-- ========= END OF TOP NAVBAR ========= -->\\n<!-- ======== START OF CLASS DATA ======== -->\\n<div class=\"header\">\\n<div class=\"subTitle\">com.google.web.bindery.requestfactory.apt</div>\\n<h2 title=\"Class ClientToDomainMapper.UnmappedTypeException\" class=\"title\">Class ClientToDomainMapper.UnmappedTypeException</h2>\\n</div>\\n<div class=\"contentContainer\">\\n<ul class=\"inheritance\">\\n<li>java.lang.Object</li>\\n<li>\\n<ul class=\"inheritance\">\\n<li>java.lang.Throwable</li>\\n<li>\\n<ul class=\"inheritance\">\\n<li>java.lang.Exception</li>\\n<li>\\n<ul class=\"inheritance\">\\n<li>java.lang.RuntimeException</li>\\n<li>\\n<ul class=\"inheritance\">\\n<li>com.google.web.bindery.requestfactory.apt.ClientToDomainMapper.UnmappedTypeException</li>\\n</ul>\\n</li>\\n</ul>\\n</li>\\n</ul>\\n</li>\\n</ul>\\n</li>\\n</ul>\\n<div class=\"description\">\\n<ul class=\"blockList\">\\n<li class=\"blockList\">\\n<dl>\\n<dt>All Implemented Interfaces:</dt>\\n<dd>java.io.Serializable</dd>\\n</dl>\\n<dl>\\n<dt>Enclosing class:</dt>\\n<dd><a href=\"../../../../../../com/google/web/bindery/requestfactory/apt/ClientToDomainMapper.html\" title=\"class in com.google.web.bindery.requestfactory.apt\">ClientToDomainMapper</a></dd>\\n</dl>\\n<hr>\\n<br>\\n<pre>public static class <span class=\"typeNameLabel\">ClientToDomainMapper.UnmappedTypeException</span>\\nextends java.lang.RuntimeException</pre>\\n<dl>\\n<dt><span class=\"seeLabel\">See Also:</span></dt>\\n<dd><a href=\"../../../../../../serialized-form', '<|endoftext|> off across the flats, at the edge of the town, an electric car went by, stringing out a long row of diamond sparks on the overhead wires.\\n\\n\"Say, Miss Trina,\" said McTeague, after a while, \"what\\'s the good of waiting any longer? Why can\\'t us two get married?\"\\n\\nTrina still shook her head, saying \"No\" instinctively, in spite of herself.\\n\\n\"Why not?\" persisted McTeague. \"Don\\'t you like me well enough?\"\\n\\n\"Yes.\"\\n\\n\"Then why not?\"\\n\\n\"Because.\"\\n\\n\"Ah, come on,\" he said, but Trina still shook her head.\\n\\n\"Ah, come on,\" urged McTeague. He could think of nothing else to say, repeating the same phrase over and over again to all her refusals.\\n\\n\"Ah, come on! Ah, come on!\"\\n\\nSuddenly he took her in his enormous arms, crushing down her struggle with his immense strength. Then Trina gave up, all in an instant, turning her head to his. They kissed each other, grossly, full in the mouth.\\n\\nA roar and a jarring of the earth suddenly grew near and passed them in a reek of steam and hot air. It was the Overland, with its flaming headlight, on its way across the continent.\\n\\nThe passage of the train startled them both. Trina struggled to free herself from McTeague. \"Oh, please! please!\" she pleaded, on the point of tears. McTeague released her, but in that moment a slight, a barely perceptible, revulsion of feeling had taken place in him. The instant that Trina gave up, the instant she allowed him to kiss her, he thought less of her. She was not so desirable, after all. But this reaction was so faint, so subtle, so intangible, that in another moment he had doubted its occurrence. Yet afterward it returned. Was there not something gone from Trina now? Was he not disappointed in her for doing that very thing for which he had longed? Was Trina the submissive, the compliant, the attainable just the same, just as delicate and adorable as Trina the inaccessible? Perhaps he dimly saw that this must be so, that it belonged to the changeless order of things—the man desiring the woman only for what she withholds; the woman worshipping the man for that which she yields up to him. With each concession gained the man\\'s desire cools; with every surrender made the woman\\'s adoration increases. But why should it be so?\\n\\nTrina wrenched herself free and drew back from McTeague, her little chin quivering; her face, even to the lobes of her pale ears, flushed scarlet; her narrow blue eyes brimming. Suddenly she put her head between her hands and began to sob.\\n\\n\"Say, say, Miss Trina, listen—listen here, Miss Trina,\" cried McTeague, coming forward a step.\\n\\n\"Oh, don\\'t!\" she gasped, shrinking. \"I must go home,\" she cried, springing to her feet. \"It\\'s late. I must. I must. Don\\'t come with me, please. Oh, I\\'m so—so,\"—she could not find any words. \"Let me go alone,\" she went on. \"You may—you come Sunday. Goodbye.\"\\n\\n\"Goodbye,\" said McTeague, his head in a whirl at this sudden, unaccountable change. \"Can\\'t I kiss you again?\" But Trina was firm now. When it came to his pleading—a mere matter of words—she was strong enough.\\n\\n\"No, no, you must not!\" she exclaimed, with energy. She was gone in another instant. The dentist, stunned, bewildered, gazed stupidly after her as she ran up the extension of B Street through the rain.\\n\\nBut suddenly a great joy took possession of him. He had won her. Trina was to be for him, after all. An enormous smile distended his thick lips; his eyes grew wide, and flashed; and he drew his breath quickly, striking his mallet-like fist upon his knee, and exclaiming under his breath:\\n\\n\"I got her, by God! I got her, by God!\" At the same time he thought better of himself; his self-respect increased enormously. The man that could win Trina Sieppe was a man of extraordinary ability.\\n\\nTrina burst in upon her mother while the latter was setting a mousetrap in the kitchen.\\n\\n\"Oh, mamma!\"\\n\\n\"Eh? Trina? Ach, what has happun?\"\\n\\nTrina told her in a breath.\\n\\n\"Soh soon?\" was', '<|endoftext|> is very different. When I was a medical student and a resident, I\\'d tell my supervising physicians what I had seen and accomplished, but only rarely did they actually observe me with a patient. My mentor George Engel suggested that we imagine what would happen if piano lessons were that way—you\\'d just report to your teacher what you had done well and where you perceived there were problems. You certainly wouldn\\'t get to Carnegie Hall that way.\\n\\nBrothers Stuart and Hubert Dreyfus at the University of California, Berkeley, also observed professionals in a variety of fields. They developed a model in which they described a hierarchy from novice, to competent, proficient, and expert, later adding a level for master. For the Dreyfus brothers, expertise involved making automatic what for novices would be deliberate and effortful. The Dreyfuses suggested that experts could then reserve their cognitive resources for more complex tasks. For example, the nurse who took my blood pressure before a recent visit to my doctor was talking to me throughout. An expert, she could easily divide her attention between the automatic task and the (hopefully more interesting) interpersonal interaction, whereas a nursing student would have had to devote her full attention to what she was hearing through the stethoscope. Because these tasks become so automatic, experts, according to the Dreyfus brothers, often have difficulty describing exactly what they do.\\n\\nExpertise is not merely automatic, though it also includes the ability to alternate—effortlessly—between automatic and effortful cognitive processing. When a nurse in my dentist\\'s office took my blood pressure two days after I saw my doctor, she was chatting just like the previous nurse. Then, suddenly she stopped. She took my pressure again, this time paying closer attention (I was not looking forward to the dental procedure, and my body let us know it). She slowed down. She noted an unusually high blood pressure. She switched gears.\\n\\nNot every nurse would. While the ten-thousand-hours formula might work for developing basic skills, only if the practice is mindful will people learn to switch from automatic to effortful, to slow down when they should. Mindless practice, in contrast, leads to being an \"experienced non-expert,\" repeating the same mistakes over and over, without the insight to know why. Conversely, \"true experts\" are mindful and adaptive; they recognize when something\\'s amiss before others do. They observe and respond to context, then switch gears, slowing down and improvising. It\\'s like jazz.\\n\\n### VOLUNTARILY BRINGING BACK A WANDERING ATTENTION\\n\\nCultivating and sustaining attention is the sine qua non of good care. Over 120 years ago, William James devoted one of the first chapters of his Principles of Psychology to attention. James described—remarkably accurately—how attention works, setting the stage for future research. But he didn\\'t know how to cultivate it. He said, \"The faculty of voluntarily bringing back a wandering attention, over and over again, is the very root of judgment, character, and will. . . . An education which should improve this faculty would be the education par excellence. But it is easier to define this ideal than to give practical directions for bringing it about.\"\\n\\nAttention training is now common practice. It takes remarkably little to augment your capacity to attend. Even after a week of meditating thirty minutes a day, executive attention improves—if you recall, executive attention helps to reduce and reconcile conflicts between competing demands on your attention (such as someone talking to you when you\\'re trying to add up a column of numbers). After eight weeks of practice you\\'d likely have better sustained focus (top-down attention) and you\\'d be less likely to be derailed by the unimportant. With longer practice, some studies suggest that you\\'d be able to manage your precious cognitive resources more effectively and switch among mental tasks more quickly. You would be better able to remember key information, even when asked to multitask in highly stressful environments. With practice, you\\'d be more likely to notice and name your emotions, allowing you to respond more intelligently to strong feelings; you\\'d feel less frustrated when under high cognitive load; and you\\'d ruminate less about the past and worry less about the future. You\\'d become more present and more mentally fit.\\n\\nIf you continued practicing, you\\'d become more aware of how your mind works. You could more readily identify when you are focused or distracted, when you\\'re being curious and when you\\'re more shut down. You\\'d become a connoisseur of types and qualities of your states of attending and distraction—just as the Inuit become connoisseurs of snow and sommeliers become connoisseurs of wine. Functional brain imaging might show thickening of the gray matter in the brain, deeper folds of the brain (gyrification), and increased connectivity. Studies done by psychologist Al Kaszniak', '<|endoftext|>=\"../../../../../../../../../help-doc.html\">Help</a></li>\\n</ul>\\n</div>\\n<div class=\"subNav\">\\n<ul class=\"navList\">\\n<li><a href=\"../../../../../../../../../com/google/android/apps/common/testing/ui/espresso/matcher/BoundedMatcher.html\" title=\"class in com.google.android.apps.common.testing.ui.espresso.matcher\"><span class=\"strong\">Prev Class</span></a></li>\\n<li><a href=\"../../../../../../../../../com/google/android/apps/common/testing/ui/espresso/matcher/PreferenceMatchersTest.html\" title=\"class in com.google.android.apps.common.testing.ui.espresso.matcher\"><span class=\"strong\">Next Class</span></a></li>\\n</ul>\\n<ul class=\"navList\">\\n<li><a href=\"../../../../../../../../../index.html?com/google/android/apps/common/testing/ui/espresso/matcher/PreferenceMatchers.html\" target=\"_top\">Frames</a></li>\\n<li><a href=\"PreferenceMatchers.html\" target=\"_top\">No Frames</a></li>\\n</ul>\\n<ul class=\"navList\" id=\"allclasses_navbar_bottom\">\\n<li><a href=\"../../../../../../../../../allclasses-noframe.html\">All Classes</a></li>\\n</ul>\\n<div>\\n<script type=\"text/javascript\"><!--\\n  allClassesLink = document.getElementById(\"allclasses_navbar_bottom\");\\n  if(window==top) {\\n    allClassesLink.style.display = \"block\";\\n  }\\n  else {\\n    allClassesLink.style.display = \"none\";\\n  }\\n  //-->\\n</script>\\n</div>\\n<div>\\n<ul class=\"subNavList\">\\n<li>Summary:&nbsp;</li>\\n<li>Nested&nbsp;|&nbsp;</li>\\n<li>Field&nbsp;|&nbsp;</li>\\n<li>Constr&nbsp;|&nbsp;</li>\\n<li><a href=\"#method_summary\">Method</a></li>\\n</ul>\\n<ul class=\"subNavList\">\\n<li>Detail:&nbsp;</li>\\n<li>Field&nbsp;|&nbsp;</li>\\n<li>Constr&nbsp;|&nbsp;</li>\\n<li><a href=\"#method_detail\">Method</a></li>\\n</ul>\\n</div>\\n<a name=\"skip-navbar_bottom\">\\n<!--   -->\\n</a></div>\\n<!-- ======== END OF BOTTOM NAVBAR ======= -->\\n<p class=\"legalCopy\"><small>Copyright &#169; 2014. All rights reserved.</small></p>\\n</body>\\n</html>\\n<|endoftext|>Q:\\n\\nHow to check for normal distribution using Excel for performing a t-test?\\n\\nI want to know how to check a data set for normality in Excel, just to verify that the requirements for using a t-test are being met.  \\nFor the right tail, is it appropriate to just calculate a mean and standard deviation, add 1, 2 & 3 standard deviations from the mean to create a range then compare that to the normal 68/95/99.7 for the standard normal distribution after using the norm.dist function in excel to test each standard deviation value.\\nOr is there a better way to test for normality?\\n\\nA:\\n\\nYou have the right idea.  This can be done systematically, comprehensively, and with relatively simple calculations.  A graph of the results is called a normal probability plot (or sometimes a P-P plot).  From it you can see much more detail than appears in other graphical representations, especially histograms, and with a little practice you can even learn to determine ways to re-express your data to make them closer to Normal in situations where that is warranted.\\nHere is an example:\\n\\nData are in column A (and named Data).  The rest is all calculation, although you can control the \"hinge rank\" value used to fit a reference line to the plot.\\nThis plot is a scatterplot comparing the data to values that would be attained by numbers drawn independently from a standard Normal distribution.  When the points line up along the diagonal, they are close to Normal; horizontal departures (along the data axis) indicate departures from normality.  In this example the points are remarkably close to the reference line; the largest departure occurs at the highest value, which is about $1.5$ units to the left of the line.  Thus we see at', '<|endoftext|> of a group, or clique. Kids are so harsh on each other, and the one that goes around on their own is a bit of a target. I would be introspective and generally happy in my own company, but that doesn’t fly so well in the school years, all group and gang stuff. Although funnily enough, at that stage i had plenty of friends. No big, big pal but plenty of guys to hang out with.<|endoftext|><!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\\n<!-- NewPage -->\\n<html lang=\"en\">\\n<head><link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"/glide/apple-touch-icon.png\"><link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"/glide/favicon-32x32.png\"><link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"/glide/favicon-16x16.png\"><link rel=\"manifest\" href=\"/glide/manifest.json\">\\n<!-- Generated by javadoc (1.8.0_144) on Mon Dec 04 08:57:28 PST 2017 -->\\n<title>com.bumptech.glide.manager Class Hierarchy (glide API)</title>\\n<meta name=\"date\" content=\"2017-12-04\">\\n<link rel=\"stylesheet\" type=\"text/css\" href=\"../../../../stylesheet.css\" title=\"Style\">\\n<script type=\"text/javascript\" src=\"../../../../script.js\"></script>\\n</head>\\n<body>\\n<script type=\"text/javascript\"><!--\\n    try {\\n        if (location.href.indexOf(\\'is-external=true\\') == -1) {\\n            parent.document.title=\"com.bumptech.glide.manager Class Hierarchy (glide API)\";\\n        }\\n    }\\n    catch(err) {\\n    }\\n//-->\\n</script>\\n<noscript>\\n<div>JavaScript is disabled on your browser.</div>\\n</noscript>\\n<!-- ========= START OF TOP NAVBAR ======= -->\\n<div class=\"topNav\"><a name=\"navbar.top\">\\n<!--   -->\\n</a>\\n<div class=\"skipNav\"><a href=\"#skip.navbar.top\" title=\"Skip navigation links\">Skip navigation links</a></div>\\n<a name=\"navbar.top.firstrow\">\\n<!--   -->\\n</a>\\n<ul class=\"navList\" title=\"Navigation\">\\n<li><a href=\"../../../../overview-summary.html\">Overview</a></li>\\n<li><a href=\"package-summary.html\">Package</a></li>\\n<li>Class</li>\\n<li class=\"navBarCell1Rev\">Tree</li>\\n<li><a href=\"../../../../deprecated-list.html\">Deprecated</a></li>\\n<li><a href=\"../../../../index-all.html\">Index</a></li>\\n<li><a href=\"../../../../help-doc.html\">Help</a></li>\\n</ul>\\n</div>\\n<div class=\"subNav\">\\n<ul class=\"navList\">\\n<li><a href=\"../../../../com/bumptech/glide/load/resource/transcode/package-tree.html\">Prev</a></li>\\n<li><a href=\"../../../../com/bumptech/glide/module/package-tree.html\">Next</a></li>\\n</ul>\\n<ul class=\"navList\">\\n<li><a href=\"../../../../index.html?com/bumptech/glide/manager/package-tree.html\" target=\"_top\">Frames</a></li>\\n<li><a href=\"package-tree.html\" target=\"_top\">No&nbsp;Frames</a></li>\\n</ul>\\n<ul class=\"navList\" id=\"allclasses_navbar_top\">\\n<li><a href=\"../../../../allclasses-noframe.html\">All&nbsp;Classes</a></li>\\n</ul>\\n<div>\\n<script type=\"text/javascript\"><!--\\n  allClassesLink = document.getElementById(\"allclasses_navbar_top\");\\n  if(window==top) {\\n    allClassesLink.style.display = \"block\";\\n  }\\n  else {\\n    allClassesLink.style.display = \"none\";\\n  }\\n  //-->\\n</script>\\n</div>\\n<a name=\"skip.navbar.top\">\\n<!--   -->\\n</a></div>\\n<!-- ========= END', \"<|endoftext|>]\\n        public void OnTextViewClosed_ForAnyTextBufferWithTracker_RemovesTextView()\\n        {\\n            // Arrange\\n            var textView1 = Mock.Of<ITextView>();\\n            var textView2 = Mock.Of<ITextView>();\\n            var buffers = new Collection<ITextBuffer>()\\n            {\\n                Mock.Of<ITextBuffer>(b => b.ContentType == RazorCoreContentType && b.Properties == new PropertyCollection()),\\n                Mock.Of<ITextBuffer>(b => b.ContentType == NonRazorCoreContentType && b.Properties == new PropertyCollection()),\\n            };\\n\\n            // Preload the buffer's properties with a tracker, so it's like we've already tracked this one.\\n            var documentTracker = new DefaultVisualStudioDocumentTracker(Dispatcher, FilePath, ProjectPath, ProjectManager, WorkspaceEditorSettings, Workspace, buffers[0], ImportDocumentManager);\\n            documentTracker.AddTextView(textView1);\\n            documentTracker.AddTextView(textView2);\\n            buffers[0].Properties.AddProperty(typeof(VisualStudioDocumentTracker), documentTracker);\\n\\n            documentTracker = new DefaultVisualStudioDocumentTracker(Dispatcher, FilePath, ProjectPath, ProjectManager, WorkspaceEditorSettings, Workspace, buffers[1], ImportDocumentManager);\\n            documentTracker.AddTextView(textView1);\\n            documentTracker.AddTextView(textView2);\\n            buffers[1].Properties.AddProperty(typeof(VisualStudioDocumentTracker), documentTracker);\\n\\n            var editorFactoryService = Mock.Of<RazorEditorFactoryService>();\\n            var documentManager = new DefaultRazorDocumentManager(Dispatcher, editorFactoryService);\\n\\n            // Act\\n            documentManager.OnTextViewClosed(textView2, buffers);\\n\\n            // Assert\\n            documentTracker = buffers[0].Properties.GetProperty<DefaultVisualStudioDocumentTracker>(typeof(VisualStudioDocumentTracker));\\n            Assert.Collection(documentTracker.TextViews, v => Assert.Same(v, textView1));\\n\\n            documentTracker = buffers[1].Properties.GetProperty<DefaultVisualStudioDocumentTracker>(typeof(VisualStudioDocumentTracker));\\n            Assert.Collection(documentTracker.TextViews, v => Assert.Same(v, textView1));\\n        }\\n\\n        [ForegroundFact]\\n        public void OnTextViewClosed_UnsubscribesAfterLastTextViewClosed()\\n        {\\n            // Arrange\\n            var textView1 = Mock.Of<ITextView>();\\n            var textView2 = Mock.Of<ITextView>();\\n            var buffers = new Collection<ITextBuffer>()\\n            {\\n                Mock.Of<ITextBuffer>(b => b.ContentType == RazorCoreContentType && b.Properties == new PropertyCollection()),\\n                Mock.Of<ITextBuffer>(b => b.ContentType == NonRazorCoreContentType && b.Properties == new PropertyCollection()),\\n            };\\n            var documentTracker = new DefaultVisualStudioDocumentTracker(Dispatcher, FilePath, ProjectPath, ProjectManager, WorkspaceEditorSettings, Workspace, buffers[0], ImportDocumentManager);\\n            buffers[0].Properties.AddProperty(typeof(VisualStudioDocumentTracker), documentTracker);\\n            var editorFactoryService = Mock.Of<RazorEditorFactoryService>();\\n            var documentManager = new DefaultRazorDocumentManager(Dispatcher, editorFactoryService);\\n\\n            // Populate the text views\\n            documentTracker.Subscribe();\\n            documentTracker.AddTextView(textView1);\\n            documentTracker.AddTextView(textView2);\\n\\n            // Act 1\\n            documentManager.OnTextViewClosed(textView2, buffers);\\n\\n            // Assert 1\\n            Assert.True(documentTracker.IsSupportedProject);\\n\\n            // Act\\n            documentManager.OnTextViewClosed(textView1, buffers);\\n\\n            // Assert 2\\n            Assert.False(documentTracker.IsSupportedProject);\\n        }\\n    }\\n}\\n<|endoftext|>Q:\\n\\nDon't repeat yourself vs do only one thing in a method\\n\\nI am currently writing some test cases in python. I often end up calling the same two or three lines of code at the start of a test case in order to get the program I am testing going. For example:\\ntest_something_foo():\\n    call_method_a(x)\\n    call_method_b(y)\\n    # test some stuff\\n\\ntest_something_bar():\\n    call_method_a(x)\\n    call_method_b(y)\\n    # test some other stuff\\n\\nThis means I am repeating those two lines together over and over. So I thought to extract like so:\\n\", '<|endoftext|> and choose the right EMS best practices for your business?\\n\\nFirst, familiarize yourself with patient feedback, employee input and outcomes. That’s the best way to begin to find the measurable successes and failures of your organization. Once you learn the level of overall satisfaction with your EMS system, you have the feedback needed to create, improve or update methods of delivering an accessible, integrated, seamless, accountable and responsive service to all stakeholders.\\n\\nWhat are some EMS best practices that your organization can begin to consider?\\n\\nDeployment: Set service reliability standards and meet them consistently. Measure response times accurately. Match supply and demand more efficiently. Consider technology to help create, manage or enhance deployment.\\n\\nOperations: Ensure work environments are designed for long-term shifts and the best possible patient care. Give supervisors tools, resources or open channels of communication to fix issues. Bring scheduling and employee communication online. Logistics: Centralize deployment facilities. Help employees focus their activities on what they do best. Streamline restocking processes. Implement a cloud-based ordering system that delivers what you need, rather than a warehouse full of unneeded supplies.\\n\\nMaintenance: Pursue preventative maintenance. Implement green initiatives, such as solar-charging systems or bio-fuels. Consider technology that provides cloud-based and wireless-accessed ways to stay in contact with your field supervisors, staff and network.\\n\\nHuman Resources: Create streamlined policies and procedures that link to C.A.A.S, C.A.M.T.S. or A.C.E. Provide academy-style orientation programs for employees. Consider policies on social networking and its impact on workplace safety and well-being. Set up cloud-based access for benefits management and administration. See all EMS best practices—including my suggestions for education, quality improvement, billing, communications, EMS systems design and others—from my best practices presentation for the OAMTA’s 2009 annual conference.\\n\\nWhy does EMS need best practices?\\n\\nYour employees, your patients and your community expect and deserve the best level of care that reflects an effective and efficient EMS system design, one that is equally focused on employee well-being, patient care and financial sustainability. All three are possible for any forward-focused EMS system. At the close of my presentation in Las Vegas, I reminded participants of Albert Einstein’s famous quote: “The definition of insanity is doing the same thing over and over and expecting different results.” This doesn’t have to be reality for your EMS organization. I urge you to take necessary action to apply best practices. Please contact me with any questions or concerns about how to enhance or improve your current EMS system.<|endoftext|>{\\n\\t\"name\": \"Flying Bear Ghost 4S\",\\n\\t\"version\": 2,\\n\\t\"inherits\": \"flyingbear_base\",   \\n\\t\"metadata\": {\\n\\t\\t\"visible\": true,\\n\\t\\t\"author\": \"oducceu\",\\n\\n\\t\\t\"platform\": \"flyingbear_platform.obj\",\\n\\t\\t\"platform_texture\": \"flyingbear_platform.png\",\\n\\n\\t\\t\"quality_definition\": \"flyingbear_base\"\\n\\n\\t},\\n\\n\\t\"overrides\": {\\n\\t\\t\"machine_name\": \\t\\t{ \"default_value\": \"Flying Bear Ghost 4S\" },\\n\\t\\t\"machine_width\": \\t\\t{ \"default_value\": 255 },\\n\\t\\t\"machine_depth\": \\t\\t{ \"default_value\": 210 },\\n\\t\\t\"machine_height\": \\t\\t{ \"default_value\": 210 },\\n\\n\\t\\t\"machine_steps_per_mm_x\": \\t{ \"default_value\": 80 },\\n\\t\\t\"machine_steps_per_mm_y\": \\t{ \"default_value\": 80 },\\n\\t\\t\"machine_steps_per_mm_z\": \\t{ \"default_value\": 400 },\\n\\t\\t\"machine_steps_per_mm_e\": \\t{ \"default_value\": 400 },\\n\\n\\t\\t\"machine_max_feedrate_x\": \\t{ \"value\": 200 },\\n\\t\\t\"machine_max_feedrate_y\": \\t{ \"value\": 200 },\\n\\t\\t\"machine_max_feedrate_z\": \\t{ \"value\": 20 },\\n\\t\\t\"machine_max_feedrate_e\": \\t{ \"value\": 70 },\\n\\n\\t\\t\"acceleration_enabled\": \\t{ \"value\": false },\\n\\t\\t\"jerk_enabled\": \\t\\t{ \"value\": false },\\n\\n\\t\\t\"machine_max_acceleration_x\": \\t{ \"value\": 1000 },\\n\\t\\t\"machine_max_acceleration_y\": \\t{ \"value\": 1000 },\\n\\t\\t\"machine_max_acceleration_z\": \\t{ \"value\": 100 },\\n\\t\\t\"machine_max_acceleration_e', '<|endoftext|></head>\\n<body>\\n<script type=\"text/javascript\"><!--\\n    try {\\n        if (location.href.indexOf(\\'is-external=true\\') == -1) {\\n            parent.document.title=\"Uses of Class org.eclipse.rdf4j.query.algebra.evaluation.iterator.JoinIterator (Eclipse RDF4J 3.3.0 API)\";\\n        }\\n    }\\n    catch(err) {\\n    }\\n//-->\\n</script>\\n<noscript>\\n<div>JavaScript is disabled on your browser.</div>\\n</noscript>\\n<!-- ========= START OF TOP NAVBAR ======= -->\\n<div class=\"topNav\"><a name=\"navbar.top\">\\n<!--   -->\\n</a>\\n<div class=\"skipNav\"><a href=\"#skip.navbar.top\" title=\"Skip navigation links\">Skip navigation links</a></div>\\n<a name=\"navbar.top.firstrow\">\\n<!--   -->\\n</a>\\n<ul class=\"navList\" title=\"Navigation\">\\n<li><a href=\"../../../../../../../../overview-summary.html\">Overview</a></li>\\n<li><a href=\"../package-summary.html\">Package</a></li>\\n<li><a href=\"../../../../../../../../org/eclipse/rdf4j/query/algebra/evaluation/iterator/JoinIterator.html\" title=\"class in org.eclipse.rdf4j.query.algebra.evaluation.iterator\">Class</a></li>\\n<li class=\"navBarCell1Rev\">Use</li>\\n<li><a href=\"../package-tree.html\">Tree</a></li>\\n<li><a href=\"../../../../../../../../deprecated-list.html\">Deprecated</a></li>\\n<li><a href=\"../../../../../../../../index-all.html\">Index</a></li>\\n<li><a href=\"../../../../../../../../help-doc.html\">Help</a></li>\\n</ul>\\n</div>\\n<div class=\"subNav\">\\n<ul class=\"navList\">\\n<li>Prev</li>\\n<li>Next</li>\\n</ul>\\n<ul class=\"navList\">\\n<li><a href=\"../../../../../../../../index.html?org/eclipse/rdf4j/query/algebra/evaluation/iterator/class-use/JoinIterator.html\" target=\"_top\">Frames</a></li>\\n<li><a href=\"JoinIterator.html\" target=\"_top\">No&nbsp;Frames</a></li>\\n</ul>\\n<ul class=\"navList\" id=\"allclasses_navbar_top\">\\n<li><a href=\"../../../../../../../../allclasses-noframe.html\">All&nbsp;Classes</a></li>\\n</ul>\\n<div>\\n<script type=\"text/javascript\"><!--\\n  allClassesLink = document.getElementById(\"allclasses_navbar_top\");\\n  if(window==top) {\\n    allClassesLink.style.display = \"block\";\\n  }\\n  else {\\n    allClassesLink.style.display = \"none\";\\n  }\\n  //-->\\n</script>\\n</div>\\n<a name=\"skip.navbar.top\">\\n<!--   -->\\n</a></div>\\n<!-- ========= END OF TOP NAVBAR ========= -->\\n<div class=\"header\">\\n<h2 title=\"Uses of Class org.eclipse.rdf4j.query.algebra.evaluation.iterator.JoinIterator\" class=\"title\">Uses of Class<br>org.eclipse.rdf4j.query.algebra.evaluation.iterator.JoinIterator</h2>\\n</div>\\n<div class=\"classUseContainer\">No usage of org.eclipse.rdf4j.query.algebra.evaluation.iterator.JoinIterator</div>\\n<!-- ======= START OF BOTTOM NAVBAR ====== -->\\n<div class=\"bottomNav\"><a name=\"navbar.bottom\">\\n<!--   -->\\n</a>\\n<div class=\"skipNav\"><a href=\"#skip.navbar.bottom\" title=\"Skip navigation links\">Skip navigation links</a></div>\\n<a name=\"navbar.bottom.firstrow\">\\n<!--   -->\\n</a>\\n<ul class=\"navList\" title=\"Navigation\">\\n<li><a href=\"../../../../../../../../overview-summary.html\">Overview</a></li>\\n<li><a href=\"../package-summary.html\">Package</a></li>\\n<li><a href=\"../../../../../../../../org/eclipse/rdf4j/query/algebra/evaluation/iterator/JoinIterator.html\" title=\"class in org.eclipse.rdf4j.query.algebra', '<|endoftext|>umping Iron, the entire audience at bodybuilding’s premier championship could fit inside a school bus. Its biggest star, Arnold Schwarzenegger, was barely getting by as a pinup model for brown-wrapper men’s mags. “It was a tiny little world,” Charlie Butler, Pumping Iron’s director, would say. “So he was the king of 300 people.”\\n\\nUntil the 1970s, gyms were big, open warehouse spaces that allowed skillful movement, range of motion, and body-weight exercise. But functional movement is murder on profit margins.\\n\\nBut behind the beefcake, drama was brewing. Lou Ferrigno, the deaf and brooding Brooklyn giant with the domineering dad, was determined to dethrone Arnold, the golden prince of Venice Beach. Ferrigno was tormented, hungry, and huge. Arnold was handsome, charming, and diabolical. Surrounding them was a crazy court of knights and jesters, all oiling each others’ backs while looking for a spot to sink the knife. Butler couldn’t believe his luck. He’d stumbled across the spiciest of melodramas, a Macbeth in banana hammocks played out by a hard-partying pack of near-naked men. It made an amazing movie and a nice bit of stage magic; we saw Lou and Arnold and Franco and believed we were being shown the path to amazing fitness, when actually we were witnessing for the first time what anabolic steroids could do to the human body.\\n\\nLooking back, the fraud should have been obvious. Didn’t it seem weird that every man in the film was more developed than any other man on the planet had ever been? But that’s why Pumping Iron was such a sensation. No one had ever seen a body like Arnold’s, and for good reason: The drugs hadn’t existed. Nobody can pack that much muscle mass onto a human frame by natural means, as Harvard researcher Dr. Harrison Pope would prove in his exposés of bodybuilding techniques; it’s just not physically possible. If you really want to look like Arnold, you’d better invest in injectables and find a vein.\\n\\nWe weren’t shown that, of course. Pumping Iron didn’t film the furtive injections of Dianabol and estrogen, the man-breasts and shrunken testicles, the home experimentation with drugs linked to cancer, dementia, uncontrollable anger, and strokes. Instead, we were delivered a new male body fantasy—supersize me—and a new standard of fitness: What you look like is more important than what you can do.\\n\\nInstead, you isolate one body part and tear it down, repeating the same movement over and over until the muscle begins to tear. Basically, you’re injuring yourself; the soreness and swelling you feel is an emergency reaction as blood rushes in to immobilize the damaged area. Pain, perversely, was now a selling point. In the short term, all you did was temporarily pump the muscle up like a balloon. In the long term, you ignored many important surrounding muscles. This leads to imbalances that will inevitably leave you injured as soon as you put your new physique into action playing an actual sport. But so what? Isolation got you huge, and that’s what mattered. Feel the burn. Get big!\\n\\nThe timing couldn’t have been better. Just as gyms began pushing the stay-put approach, the perfect stay-put device fell into their laps. In 1970, a bizarre character from Florida showed up at the Mr. America competition with his pet invention, the “Blue Monster.” Arthur Jones was a chain-smoking high school dropout turned big-game hunter who’d married six wives, shot 63 elephants, and spent his downtime trying to overfeed his 14-foot alligator to Guinness World Record size. He was also a self-taught mechanic who’d built an exercise machine with a kidney-shaped cam. Because the gear also resembled a seashell, Jones renamed his creation the Nautilus.\\n\\nNautilus machines were ideal for keeping people stationary. They were so compact that you could fit four people into a small space without worrying they’d smack into each other. You didn’t even need to carry a weight over from a rack; you just sat on a padded seat and reached for smooth plastic handles. “The idea of a health club really changed. It became big business. It was Arthur Jones that started that,” a Nautilus colleague would recall in an obituary after Jones died in 2007. “Mr. Jones’ invention,” the article went on to say, “led to the ‘machine environment’ that is prevalent today in health clubs.”\\n\\nOkay. But given modern lifestyles, isn’t the gym better than nothing?\\n', '<|endoftext|>, so there’s no distinct breaking point between one language and the next language that develops from it. Therefore, it’s impossible to say that one language is really older than any other one; they’re all as old as humanity itself. That said, each of the languages Here has a little something special—something ancient—to differentiate it from the masses.”\\n\\nSubscribe to our Mailing List\\n\\nFollow beSpacific\\n\\nSearchable Database – Over 40,000 Postings\\n\\nSearchable database of over 40,000 postings!\\n\\nSupport beSpacific\\n\\nResearch updates provided daily since 2002, with an emphasis on primary sources.\\n\\n2016 Awards for BeSpacific\\n\\nAmerican Bar Association\\n\\nBeSpacific: “No one better has her finger on the pulse of the legal information world than Sabrina Pacifici, law librarian and author of the blog BeSpacific,” writes blogger Robert Ambrogi. “Launched in 2002, BeSpacific is one of the longest-running legal blogs and, remarkably, Sabrina seems more prolific today than ever. She posts multiple items every day, covering the gamut of law, technology and knowledge discovery and topics ranging from cybersecurity to legal research to government regulation to civil liberties to IP and more. For me, BeSpacific is one of my daily must-reads and has been for 14 years straight.”\\n\\nPages\\n\\nLLRX\\n\\nSabrina is also the solo Editor, Publisher and Founder of LLRX.com® – Legal, technology and knowledge discovery resources on the “moving edge” for Librarians, Lawyers, Researchers, Academic and Public Interest Communities – launched in 1996.<|endoftext|>Q:\\n\\nPHP Laravel will deployment overwrite existing data\\n\\nI want to deploy my Laravel application. I created some new Models and Migrations but I\\'m dreading that when I deploy the changes the existing data on the production site will be deleted, is that so? And how about the .env file with the DB settings?\\n\\nA:\\n\\nTake a backup of your production side, import it locally and run migration locally to test.\\nIf possible, always make a backup of your production database before migrations.\\n\\n<|endoftext|>Q:\\n\\nDon\\'t repeat yourself vs do only one thing in a method\\n\\nI am currently writing some test cases in python. I often end up calling the same two or three lines of code at the start of a test case in order to get the program I am testing going. For example:\\ntest_something_foo():\\n    call_method_a(x)\\n    call_method_b(y)\\n    # test some stuff\\n\\ntest_something_bar():\\n    call_method_a(x)\\n    call_method_b(y)\\n    # test some other stuff\\n\\nThis means I am repeating those two lines together over and over. So I thought to extract like so:\\ntest_something_foo():\\n    call_method_a_and_b(x,y)\\n    # test some stuff\\n\\ntest_something_bar():\\n    call_method_a_and_b(x,y)\\n    # test some other stuff\\n\\ncall_method_a_and_b(x, y):\\n    call_method_a()\\n    call_method_b()\\n\\nBut I am not sure if this is a good idea. On the one hand it solves the \"don\\'t repeat yourself\" principle, but doesn\\'t my method \"call_method_a_and_b()\" violate the principle of \"a method should do one thing, and one thing only\". How do you reconcile those two seemingly conflicting design principles??\\n\\nA:\\n\\nThis is what setUp is for. It is executed automatically before running each test, and can be used to initialize class fields and properties or set up the environment (in a case of integration and system tests).\\nAs for the one thing principle, it is perfectly fine to have a method A which calls methods B and C if the method A is acting on a different level of abstraction than B and C.\\nWhat would be a violation of one thing principle is to put the bodies of the method B and C inside the method A.\\nExample: in order to create a product, you need to:\\n\\nStore the product in the database,\\nStore the product image on disk.\\n\\nThose two actions can be put in a method createProduct implemented like this:\\ndef createProduct(self):\\n    self.db.storeProduct(product_model)\\n    self.moveImage(product_model.image_upload_path)\\n\\nThe method createProduct performs one thing: it creates a product. On the other hand, if the method actually went in the details of database manipulation and files storage, then', '<|endoftext|>:1.122 serial=13 reply_serial=11\\n<jibel> didrocks, what do you mean?\\n<didrocks> -> hum, NameOwnerChangedâ\\x80¦\\n<jibel> didrocks, just plug/unplug?\\n<didrocks> jibel: just print the traffic with plug/unplug, without cheese running\\n<didrocks> yes\\n<jibel> k\\n<jibel> http://paste.ubuntu.com/25777619/\\n * didrocks tries something which may crash my session, brb if that\\'s the case\\n<krashekspress> updated big\\n<jibel> didrocks, ^\\n<krashekspress> *bug\\n<krashekspress> hahaha\\n<willcooke> thanks krashekspress\\n<jibel> it crashed :)\\n<willcooke> lol\\n<krashekspress> I should be working, but this is fun :)\\n<didrocks> ok, confirming, gnome-session launches gnome-session-binary, but even if this latter is killed (or it crashed), your session terminates\\n<didrocks> so, it\\'s not a crash of that component at least\\n<didrocks> jibel: ok, no traffic for inhibiting or towards gnome-session-binary\\n<jibel> interested by an strace of cheese?\\n<duflu> didrocks, FYI those MUTTER env vars actually cause the interesting logging to happen in journalctl. The one in /tmp is not useful\\n<didrocks> jibel: sure (I need to jump on the SRU though), but also, mind trying \"systemd-inhibit echo foo\"\\n<didrocks> duflu: well, they could for some case, but yeah, agreed\\n<didrocks> jibel: and tell me if \"foo\" is printed right away\\n<duflu> also, you need to remember to look for gdm3 messages before gnome-shell. Sincew gdm3 is also a mutter shell\\n<didrocks> or there is a delay\\n<didrocks> duflu: hum, gdm3 is launching g-s, no?\\n<duflu> didrocks, yes. But gdm3 is also a standalone \"shell\" of sorts, using mutter\\n<jibel> didrocks, it\\'s printed immediately\\n<duflu> Call it a DM then. I don\\'t mind\\n<didrocks> duflu: interesting, I didn\\'t see this part of code, I only looked at gdm3 launching gnome-session, which launch gnome-shell as the gdm user in the \"gdm\" mode\\n<jibel> didrocks, http://people.canonical.com/~j-lallement/junk/cheese.strace\\n<didrocks> jibel: which line is it blocking during the delay?\\n<duflu> didrocks, I realize when I was doing the font work... it instantly improved the login screen too\\n<didrocks> great!\\n<vithiri> Hmm. We\\'ve still got a task bar at ubuntu.com today. :)\\n<duflu> (but only because Ubuntu introduces more sane defaults for hinting and subpixel)\\n<willcooke> vithiri, yeah :(  working on getting that fixed\\n<vithiri> willcooke: Ah, sounds great!\\n<dupondje> mmm. Upgraded to 17.10, but seems like there is some minor bug that causes me to be unable to save OpenVPN settings in gnome-control-center. When running in verbose mode it gives me \\'Invalid setting IPv4\\'. Works fine with nm-connection-editor. I file a bug against gnome-control-center right?\\n<andyrock> dupondje: yes please. In case we can always change the target project later on\\n<jibel> didrocks, nothing is blocking it\\'s repeating the same sequence over and over again\\n<jibel> didrocks, something like http://paste.ubuntu.com/25777697/\\n<didrocks> jbicha: I\\'m removing your restore dep commit in gnome-shell, it doesn\\'t reference any bug, so not suitable for a SRU\\n<jibel> minus the inotify call\\n<didrocks> jibel: hum, I guess it has some retry logic\\n<didrocks> jbicha: please restore it with the correct bug # for a later SRU (don\\'t want to block current SRU on this)\\n<didrocks> jibel: have you tried \"systemd-inhibit echo foo\", does it blocks as well?\\n']\n","layer 6\n","286 ['<|endoftext|> some news went around the Fine Arts Center. The Dalai Lama was going to be visiting the university and would be speaking at Popejoy Hall.\\n\\nI knew little about the man. The organization Friends of Tibet had occasionally visited the college, had brought around a group of touring monks to entertain and perplex the patrons of art and music who haunted the foyer. These followers of the lama performed traditional dances and chants and were magically entrancing to those who had the privilege of attending.\\n\\nCoincidentally, my roommate, a graduate student in art history, was a devout Buddhist. He filled me in on concepts and events related to Tibetan Buddhism and the preeminence of the fourteenth Dalai Lama.\\n\\nAnyway, it came to pass the Dalai Lama and his entourage needed a place to camp out before his speaking engagement. These were in the days before UNM renovated the Fine Arts Center. Much of it was an unkempt old joint–that included the Popejoy Hall green room, which was mostly a place the technical crew hung out to smoke and nap.\\n\\nOwing to the fact that Keller hall was a genteel venue where chamber music and avant-garde compositions were performed, its green room was chosen as a headquarters for the visitors. The Keller Hall Green Room was tastefully decorated, well furnished and looked out onto a small verdant garden.\\n\\nWhen the day arrived, the Dalai Lama was driven to the loading dock in back of the UNM art museum. Advisers, a meteorologist with magical abilities, members of Friends of Tibet and a small press corps accompanied him. Though he had recently won the Nobel Prize, he was not nearly as famous as he is now; the issues surrounding Tibet had just begun to creep into the public’s consciousness.\\n\\nHis Holiness Tenzin Gyatso was immediately whisked to the Keller Hall green room, where different dignitaries, including the President of the University, came and went, presenting him with fresh fruit and prayer shawls.\\n\\nLate in the afternoon, I noticed there was an empty space on the couch next to the lama, so I went over and sat down next to him.\\n\\nHe looked over and remarked, “You are brave!” He put his arm around me, said something in Tibetan to the monk sitting next to him and continued, “Don’t worry,” he whispered, “everything will be fine.” He laughed. It was a deep and happy laugh.\\n\\nThen motioned to one of his advisers and the two got up from their seats. The lama needed some time alone, to eat and meditate, the adviser told everyone in the room.\\n\\nThe Dalai Lama waved at me, then retired to the downstairs lounge in Keller Hall. Later I was asked by one of his aides to join his procession over to Popejoy Hall. I didn’t have another opportunity to speak to him, though. He and his followers left soon after the event was over.\\n\\nThe rest of that spring and then the summer seemed to zip right on by. I finished a decent painting, figured out a tune by Bartok and then welded together a sculpture that held a bit of Ken’s ashes inside of it. When someone stole it from in front of the Art Building at the end of May, I felt the same pleasure Duchamp must have felt when workmen dropped and shattered Le Grand Verre.\\n\\nIn June, I got the only tattoo I would ever sport–from the legendary J.B. Jones, who decided to paint a picture of the Holy Spirit on my left shoulder. In August, my roommate and I decided to rent out a room in the old, rambling house we shared.\\n\\nThe ad we placed in the Daily Lobo was answered by a group of exchange students from Britain. They were young and brave and full of life. Two of them would end up living in the house and loudly introducing us to a thing called EDM.\\n\\nThe third was a long-haired wandering anthropologist from Wales. In the year that followed, she took me abroad. We traveled through Amazonia, basked on the beaches of lower Antilles, squatted in a shack in Middlesex and finally took a journey to the place where Nepal borders Tibet. In September 1996, we trekked up a river that followed a long, steep valley–into the kingdom of Mustang.\\n\\nThis was the place where lamas dwelt, walking amidst fields of buckwheat and dusty trails. They were in search of light, I remember thinking to myself as the straps from Ken’s old backpack dug into my shoulders and the mountains beckoned us.\\n\\nOn Tuesday, Feb. 3, Jack White and his five-piece band played a full house at Popejoy, and the performance was refreshingly classic. It was apparent that White is intent on bringing back something', '<|endoftext|> always knew why he was showering the McDonnell family with gifts.\\n\\nThey backed up his story by using other evidence to weave a strong circumstantial case that an agreement had been reached between the businessman and the first couple based on the close timing of Williams’s gifts and loans and efforts by the McDonnells to assist Williams and his company.\\n\\nIn one instance, McDonnell directed a subordinate to meet with Williams on the same night he returned from a free vacation at his lake house. In another, six minutes after e-mailing Williams about a loan, McDonnell e-mailed an aide about studies Williams wanted conducted on his product at public universities.\\n\\nDefense attorneys emphasized that even Williams did not describe an explicit, corrupt bargain with the governor. And they noted that Williams was testifying with generous immunity agreements, which they said motivated him to lie about his relationship with the McDonnells.\\n\\nThroughout the trial, jurors were attentive but expressionless. Their verdict made clear that they considered each defendant’s role in each charge.\\n\\nThey acquitted Maureen McDonnell, for example, on two public-corruption counts connected to a $20,000 loan in May 2012 that her husband texted Williams directly about.\\n\\nThey also found her not guilty of one charge connected to a January 2012 golf outing Williams funded for her husband and two sons at the exclusive Kinloch Golf Club, near Richmond, but guilty of another connected to a May 2011 golf outing her husband went on with their sons and future son-in-law.\\n\\nThe investigation into the couple’s relationship with Williams consumed much of Robert McDonnell’s last year in office. It halted what had been a steady rise through the ranks of Republican politics for the former state attorney general, which seemed likely to culminate in a run for president in 2016.\\n\\nMcDonnell had just concluded the final legislative session of his four-year term, which included the passage of his signature bipartisan transportation plan, when The Washington Post reported in March 2013 that Williams had paid $15,000 for wedding catering for one of the McDonnells’ daughters.\\n\\nThe wedding came three days after Maureen McDonnell flew to Florida and praised Williams’s product at an investor meeting and two months before the first couple attended an event at the governor’s mansion for Williams’s company.\\n\\nAs the governor’s time in office came to a close, he struggled in private with the growing criminal investigation, while publicly, more and more details of his relationship with Williams emerged. Among the embarrassing revelations: Williams had purchased a $6,500 Rolex for the governor, lent the governor his Ferrari for use on an expensive vacation and taken the first lady on a $20,000 New York shopping spree.\\n\\nMcDonnell finally apologized in July 2013, after The Post reported that Williams’s largesse had included $120,000 in low-interest loans to the first lady and to a small real estate company the governor and his sister owned.\\n\\nThe former first couple were indicted in January, 10 days after McDonnell concluded his term in office. Even as he repeatedly apologized for poor judgment, he maintained that he and his wife had broken no law.\\n\\nTina Griego, Steve Hendrix, Jenna Portnoy, Laura Vozzella and Rachel Weiner contributed to this report.<|endoftext|>Atheists, here is your proof of God\\'s existence, \"Tisha B\\'Av\", the 9th of Av\\n\\nThere are a very wide variety of ways to prove out the existence of God.\\n\\nFor example, are you aware that both original Holy Temples, were destroyed on the same day of the year?\\n\\nThe 9th of Av, in the Jewish calendar.\\n\\nAnd not only that, every major Jewish tragedy, has also occurred, on that day?\\n\\nEven in modern times?\\n\\nAll the 12 major tragedies, that the Jews have ever experienced, have occurred on the 9th of Av.\\n\\nWhy did God pick the obscure day, the 9th of Av?\\n\\nWell, that was the day that the Jews balked, the day when Moses said \"We are here, now we take the promised land\".\\n\\nAnd they said \"no\".\\n\\nWe don\\'t want it.\\n\\nThen God became enraged, and changed his mind, about the Jews, on that day, the 9th of Av.\\n\\nYou could easily say that God\\'s relationship with the Jews, ended on that day.\\n\\nAfter that, all the myriad of horror and tragedy, that God continually has sent to the Jews, for some 3,300 years now, has also started on that day, the 9th of Av. (about August 11th, it varies each year):\\n\\n\\n\\n1. The Jews balk, and reject the promised land. 9th of Av, 1313 BC (', \"<|endoftext|># which needs to be processed by an external indexer. Doxygen will invoke an\\n# external search engine pointed to by the SEARCHENGINE_URL option to obtain\\n# the search results. Doxygen ships with an example indexer (doxyindexer) and\\n# search engine (doxysearch.cgi) which are based on the open source search engine\\n# library Xapian. See the manual for configuration details.\\n\\nEXTERNAL_SEARCH        = NO\\n\\n# The SEARCHENGINE_URL should point to a search engine hosted by a web server\\n# which will returned the search results when EXTERNAL_SEARCH is enabled.\\n# Doxygen ships with an example search engine (doxysearch) which is based on\\n# the open source search engine library Xapian. See the manual for configuration\\n# details.\\n\\nSEARCHENGINE_URL       =\\n\\n# When SERVER_BASED_SEARCH and EXTERNAL_SEARCH are both enabled the unindexed\\n# search data is written to a file for indexing by an external tool. With the\\n# SEARCHDATA_FILE tag the name of this file can be specified.\\n\\nSEARCHDATA_FILE        = searchdata.xml\\n\\n# The EXTRA_SEARCH_MAPPINGS tag can be used to enable searching through other\\n# doxygen projects that are not otherwise connected via tags files, but are\\n# all added to the same search index. Each project needs to have a tag file set\\n# via GENERATE_TAGFILE. The search mapping then maps the name of the tag file\\n# to a relative location where the documentation can be found,\\n# similar to the\\n# TAGFILES option but without actually processing the tag file.\\n# The format is: EXTRA_SEARCH_MAPPINGS = tagname1=loc1 tagname2=loc2 ...\\n\\nEXTRA_SEARCH_MAPPINGS  =\\n\\n#---------------------------------------------------------------------------\\n# configuration options related to the LaTeX output\\n#---------------------------------------------------------------------------\\n\\n# If the GENERATE_LATEX tag is set to YES (the default) Doxygen will\\n# generate Latex output.\\n\\nGENERATE_LATEX         = NO\\n\\n# The LATEX_OUTPUT tag is used to specify where the LaTeX docs will be put.\\n# If a relative path is entered the value of OUTPUT_DIRECTORY will be\\n# put in front of it. If left blank `latex' will be used as the default path.\\n\\nLATEX_OUTPUT           =\\n\\n# The LATEX_CMD_NAME tag can be used to specify the LaTeX command name to be\\n# invoked. If left blank `latex' will be used as the default command name.\\n# Note that when enabling USE_PDFLATEX this option is only used for\\n# generating bitmaps for formulas in the HTML output, but not in the\\n# Makefile that is written to the output directory.\\n\\nLATEX_CMD_NAME         = latex\\n\\n# The MAKEINDEX_CMD_NAME tag can be used to specify the command name to\\n# generate index for LaTeX. If left blank `makeindex' will be used as the\\n# default command name.\\n\\nMAKEINDEX_CMD_NAME     = makeindex\\n\\n# If the COMPACT_LATEX tag is set to YES Doxygen generates more compact\\n# LaTeX documents. This may be useful for small projects and may help to\\n# save some trees in general.\\n\\nCOMPACT_LATEX          = NO\\n\\n# The PAPER_TYPE tag can be used to set the paper type that is used\\n# by the printer. Possible values are: a4, letter, legal and\\n# executive. If left blank a4wide will be used.\\n\\nPAPER_TYPE             = a4wide\\n\\n# The EXTRA_PACKAGES tag can be to specify one or more names of LaTeX\\n# packages that should be included in the LaTeX output.\\n\\nEXTRA_PACKAGES         =\\n\\n# The LATEX_HEADER tag can be used to specify a personal LaTeX header for\\n# the generated latex document. The header should contain everything until\\n# the first chapter. If it is left blank doxygen will generate a\\n# standard header. Notice: only use this tag if you know what you are doing!\\n\\nLATEX_HEADER           =\\n\\n# The LATEX_FOOTER tag can be used to specify a personal LaTeX footer for\\n# the generated latex document. The footer should contain everything after\\n# the last chapter. If it is left blank doxygen will generate a\\n# standard footer. Notice: only use this tag if you know what you are doing!\\n\\nL\", '<|endoftext|> Montgomery had any commission to do so, since he possessed no influence, \"except with some few of the most bigoted fanatics\". He was chosen as member for the county of Ayr in the Convention of the Estates of Scotland which met on 14 March 1689, when he distinguished himself by his eloquent advocacy of the resolution proposed by Sir John Dalrymple, that King James had forfeited his throne and kingdom. The resolution being carried, Montgomery was named one of three commissioners for the shires to offer the Scottish crown to William III and Mary II.\\n\\nAfter the convention had been formally converted into a parliament, he continued to sit for Ayrshire until he was obliged to stand down in 1693 for not having signed the Assurance (pledge of allegiance to King William III). His ambition had already selected the office of secretary of state for Scotland, as that alone commensurate with his services and abilities; and when George Melville, 1st Earl of Melville, chiefly on account of his moderate opinions, was preferred, Montgomery, although offered the office of lord justice clerk, so deeply resented the supposed slight that he determined at all hazards to have revenge, and immediately set himself to organise a political society called The Club, the main purpose of which was to concert measures against the government.\\n\\nMontgomery Plot\\nIn parliament he led with great ability and eloquence the opposition against Sir John Dalrymple, the two, according to Balcarres, frequently scolding each other \"like watermen\". Towards the close of the session he went to London with his closest confederates, the Earl of Annandale and Lord Ross, to present a declaration of Scottish grievances to the king, but the king declined to listen to their complaints.\\n\\nThereupon Montgomery entered into communication with the Jacobite agent, Neville Payne, and they concerted together a plot for the restoration of King James, known as the Montgomery Plot, each being, according to Balcarres, more or less the dupe of the other. Montgomery\\'s coalition with the Jacobites proved to him rather a hindrance than a help in parliament, and as soon as his influence began to wane the Jacobites revolted against him. A quarrel ensued, and soon afterwards Lord Ross made confession of his connection with the plot to a presbyterian minister, who informed Melville. On learning this Montgomery went to Melville, and on promise of an indemnity confessed all he knew, making it, however, a condition that he should not be obliged to be \"an evidence or legal witness\". Melville sent him, with a recommendation in his favour, to Queen Mary, to whom he pleaded for \"some place which might enable him to subsist with decency\". She wrote on his behalf to King William, but the king had conceived such an antipathy to him that he declined to utilise his services on any consideration. According to Gilbert Burnet, Montgomery\\'s \"art in managing such a design, and his firmness in not discovering his accomplices raised his character as much as it ruined his fortunes\". After lying for some time in concealment in London, he passed over to Paris, where he was well received by the Jacobites. Some time afterwards he returned to London, and on 11 January 1694 was taken into custody, on the accusation of being the author of several virulent papers against the government; but on the 18th he made his escape from the house of the messenger where he was confined, the two sentinels who guarded the door leaving their arms and going with him. He escaped to the continent, reaching Paris by 15 February, and he died at St. Germains before 6 October 1694. By Lady Margaret Johnstone, second daughter of James Johnstone, 1st Earl of Annandale, he had two sons: Robert (1680-1731) and William.\\n\\nWorks\\nMontgomery was the author of \"The People of England\\'s Grievances to be enquired into and redressed by their Representatives in Parliament\", reprinted in Somers Tracts, x. 542-6. The authorship of other political pamphlets attributed to him has been claimed by Robert Ferguson the Plotter, and in some instances there may have been a joint authorship. A portrait of Montgomerie in armour has been engraved.\\n\\nReferences\\n\\nAttribution\\n; Endnotes:\\nColin Lindsay, 3rd Earl of Balcarres, Memoirs touching the revolution in Scotland (Bannatyne Club)\\nJohn Lauder, Lord Fountainhall Historical Notices of Scottish Affairs (Bannatyne Club)\\nLeven and Melville Papers (Bannatyne Club)\\nGilbert Burnet: History of my Own Time\\nNarcissus Luttrell, A brief historical relation of state affairs: from September 1678 to April 1714\\nWilliam Carstares, State Papers\\nCatharine Macaulay, Hist. of England\\n,', \"<|endoftext|> by that function will be listed.\\n\\nREFERENCES_RELATION    = YES\\n\\n# If the REFERENCES_LINK_SOURCE tag is set to YES (the default)\\n# and SOURCE_BROWSER tag is set to YES, then the hyperlinks from\\n# functions in REFERENCES_RELATION and REFERENCED_BY_RELATION lists will\\n# link to the source code.\\n# Otherwise they will link to the documentation.\\n\\nREFERENCES_LINK_SOURCE = YES\\n\\n# If the USE_HTAGS tag is set to YES then the references to source code\\n# will point to the HTML generated by the htags(1) tool instead of doxygen\\n# built-in source browser. The htags tool is part of GNU's global source\\n# tagging system (see http://www.gnu.org/software/global/global.html). You\\n# will need version 4.8.6 or higher.\\n\\nUSE_HTAGS              = NO\\n\\n# If the VERBATIM_HEADERS tag is set to YES (the default) then Doxygen\\n# will generate a verbatim copy of the header file for each class for\\n# which an include is specified. Set to NO to disable this.\\n\\nVERBATIM_HEADERS       = YES\\n\\n#---------------------------------------------------------------------------\\n# configuration options related to the alphabetical class index\\n#---------------------------------------------------------------------------\\n\\n# If the ALPHABETICAL_INDEX tag is set to YES, an alphabetical index\\n# of all compounds will be generated. Enable this if the project\\n# contains a lot of classes, structs, unions or interfaces.\\n\\nALPHABETICAL_INDEX     = YES\\n\\n# If the alphabetical index is enabled (see ALPHABETICAL_INDEX) then\\n# the COLS_IN_ALPHA_INDEX tag can be used to specify the number of columns\\n# in which this list will be split (can be a number in the range [1..20])\\n\\nCOLS_IN_ALPHA_INDEX    = 3\\n\\n# In case all classes in a project start with a common prefix, all\\n# classes will be put under the same header in the alphabetical index.\\n# The IGNORE_PREFIX tag can be used to specify one or more prefixes that\\n# should be ignored while generating the index headers.\\n\\nIGNORE_PREFIX          =\\n\\n#---------------------------------------------------------------------------\\n# configuration options related to the HTML output\\n#---------------------------------------------------------------------------\\n\\n# If the GENERATE_HTML tag is set to YES (the default) Doxygen will\\n# generate HTML output.\\n\\nGENERATE_HTML          = YES\\n\\n# The HTML_OUTPUT tag is used to specify where the HTML docs will be put.\\n# If a relative path is entered the value of OUTPUT_DIRECTORY will be\\n# put in front of it. If left blank `html' will be used as the default path.\\n\\nHTML_OUTPUT            =\\n\\n# The HTML_FILE_EXTENSION tag can be used to specify the file extension for\\n# each generated HTML page (for example: .htm,.php,.asp). If it is left blank\\n# doxygen will generate files with .html extension.\\n\\nHTML_FILE_EXTENSION    = .html\\n\\n# The HTML_HEADER tag can be used to specify a personal HTML header for\\n# each generated HTML page. If it is left blank doxygen will generate a\\n# standard header.\\n\\nHTML_HEADER            =\\n\\n# The HTML_FOOTER tag can be used to specify a personal HTML footer for\\n# each generated HTML page. If it is left blank doxygen will generate a\\n# standard footer.\\n\\nHTML_FOOTER            =\\n\\n# The HTML_STYLESHEET tag can be used to specify a user-defined cascading\\n# style sheet that is used by each HTML page. It can be used to\\n# fine-tune the look of the HTML output. If the tag is left blank doxygen\\n# will generate a default style sheet. Note that doxygen will try to copy\\n# the style sheet file to the HTML output directory, so don't put your own\\n# stylesheet in the HTML output directory as well, or it will be erased!\\n\\nHTML_STYLESHEET        =\\n\\n# The HTML_COLORSTYLE_HUE tag controls the color of the HTML output.\\n# Doxygen will adjust the colors in the stylesheet and background images\\n# according to this color. Hue is specified as an angle on a colorwheel,\\n# see http://en.wikipedia.org/wiki/Hue for more information.\\n# For instance the value 0 represents red, 60 is yellow, 120 is\", \"<|endoftext|> range [1..20])\\n\\nCOLS_IN_ALPHA_INDEX    = 5\\n\\n# In case all classes in a project start with a common prefix, all \\n# classes will be put under the same header in the alphabetical index. \\n# The IGNORE_PREFIX tag can be used to specify one or more prefixes that \\n# should be ignored while generating the index headers.\\n\\nIGNORE_PREFIX          = \\n\\n#---------------------------------------------------------------------------\\n# configuration options related to the HTML output\\n#---------------------------------------------------------------------------\\n\\n# If the GENERATE_HTML tag is set to YES (the default) Doxygen will \\n# generate HTML output.\\n\\nGENERATE_HTML          = YES\\n\\n# The HTML_OUTPUT tag is used to specify where the HTML docs will be put. \\n# If a relative path is entered the value of OUTPUT_DIRECTORY will be \\n# put in front of it. If left blank `html' will be used as the default path.\\n\\nHTML_OUTPUT            = html\\n\\n# The HTML_FILE_EXTENSION tag can be used to specify the file extension for \\n# each generated HTML page (for example: .htm,.php,.asp). If it is left blank \\n# doxygen will generate files with .html extension.\\n\\nHTML_FILE_EXTENSION    = .html\\n\\n# The HTML_HEADER tag can be used to specify a personal HTML header for \\n# each generated HTML page. If it is left blank doxygen will generate a \\n# standard header.\\n\\nHTML_HEADER            = html/header.html\\n\\n# The HTML_FOOTER tag can be used to specify a personal HTML footer for \\n# each generated HTML page. If it is left blank doxygen will generate a \\n# standard footer.\\n\\nHTML_FOOTER            = html/footer.html\\n\\n# The HTML_STYLESHEET tag can be used to specify a user-defined cascading \\n# style sheet that is used by each HTML page. It can be used to \\n# fine-tune the look of the HTML output. If the tag is left blank doxygen \\n# will generate a default style sheet. Note that doxygen will try to copy \\n# the style sheet file to the HTML output directory, so don't put your own \\n# stylesheet in the HTML output directory as well, or it will be erased!\\n\\nHTML_STYLESHEET        = html/stylesheet.css\\n\\n# The HTML_COLORSTYLE_HUE tag controls the color of the HTML output. \\n# Doxygen will adjust the colors in the stylesheet and background images \\n# according to this color. Hue is specified as an angle on a colorwheel, \\n# see http://en.wikipedia.org/wiki/Hue for more information. \\n# For instance the value 0 represents red, 60 is yellow, 120 is green, \\n# 180 is cyan, 240 is blue, 300 purple, and 360 is red again. \\n# The allowed range is 0 to 359.\\n\\nHTML_COLORSTYLE_HUE    = 220\\n\\n# The HTML_COLORSTYLE_SAT tag controls the purity (or saturation) of \\n# the colors in the HTML output. For a value of 0 the output will use \\n# grayscales only. A value of 255 will produce the most vivid colors.\\n\\nHTML_COLORSTYLE_SAT    = 100\\n\\n# The HTML_COLORSTYLE_GAMMA tag controls the gamma correction applied to \\n# the luminance component of the colors in the HTML output. Values below \\n# 100 gradually make the output lighter, whereas values above 100 make \\n# the output darker. The value divided by 100 is the actual gamma applied, \\n# so 80 represents a gamma of 0.8, The value 220 represents a gamma of 2.2, \\n# and 100 does not change the gamma.\\n\\nHTML_COLORSTYLE_GAMMA  = 80\\n\\n# If the HTML_TIMESTAMP tag is set to YES then the footer of each generated HTML \\n# page will contain the date and time when the page was generated. Setting \\n# this to NO can help when comparing the output of multiple runs.\\n\\nHTML_TIMESTAMP         = NO\\n\\n# If the HTML_ALIGN_MEMBERS tag is set to YES, the members of classes, \\n# files or namespaces will be aligned in HTML using tables. If set to \\n# NO a bullet list will be used.\\n\\nHTML_ALIGN_MEMBERS     = YES\\n\\n# If the HTML_DYNAMIC_SECTIONS tag is set to YES then the generated HTML \\n\", '<|endoftext|> is written. Doxygen will use this\\n# information to generate all constant output in the proper language.\\n# The default language is English, other supported languages are:\\n# Afrikaans, Arabic, Brazilian, Catalan, Chinese, Chinese-Traditional,\\n# Croatian, Czech, Danish, Dutch, Esperanto, Farsi, Finnish, French, German,\\n# Greek, Hungarian, Italian, Japanese, Japanese-en (Japanese with English\\n# messages), Korean, Korean-en, Lithuanian, Norwegian, Macedonian, Persian,\\n# Polish, Portuguese, Romanian, Russian, Serbian, Serbian-Cyrilic, Slovak,\\n# Slovene, Spanish, Swedish, Ukrainian, and Vietnamese.\\n\\nOUTPUT_LANGUAGE        = English\\n\\n# If the BRIEF_MEMBER_DESC tag is set to YES (the default) Doxygen will\\n# include brief member descriptions after the members that are listed in\\n# the file and class documentation (similar to JavaDoc).\\n# Set to NO to disable this.\\n\\nBRIEF_MEMBER_DESC      = YES\\n\\n# If the REPEAT_BRIEF tag is set to YES (the default) Doxygen will prepend\\n# the brief description of a member or function before the detailed description.\\n# Note: if both HIDE_UNDOC_MEMBERS and BRIEF_MEMBER_DESC are set to NO, the\\n# brief descriptions will be completely suppressed.\\n\\nREPEAT_BRIEF           = YES\\n\\n# This tag implements a quasi-intelligent brief description abbreviator\\n# that is used to form the text in various listings. Each string\\n# in this list, if found as the leading text of the brief description, will be\\n# stripped from the text and the result after processing the whole list, is\\n# used as the annotated text. Otherwise, the brief description is used as-is.\\n# If left blank, the following values are used (\"$name\" is automatically\\n# replaced with the name of the entity): \"The $name class\" \"The $name widget\"\\n# \"The $name file\" \"is\" \"provides\" \"specifies\" \"contains\"\\n# \"represents\" \"a\" \"an\" \"the\"\\n\\nABBREVIATE_BRIEF       =\\n\\n# If the ALWAYS_DETAILED_SEC and REPEAT_BRIEF tags are both set to YES then\\n# Doxygen will generate a detailed section even if there is only a brief\\n# description.\\n\\nALWAYS_DETAILED_SEC    = NO\\n\\n# If the INLINE_INHERITED_MEMB tag is set to YES, doxygen will show all\\n# inherited members of a class in the documentation of that class as if those\\n# members were ordinary class members. Constructors, destructors and assignment\\n# operators of the base classes will not be shown.\\n\\nINLINE_INHERITED_MEMB  = NO\\n\\n# If the FULL_PATH_NAMES tag is set to YES then Doxygen will prepend the full\\n# path before files name in the file list and in the header files. If set\\n# to NO the shortest path that makes the file name unique will be used.\\n\\nFULL_PATH_NAMES        = YES\\n\\n# If the FULL_PATH_NAMES tag is set to YES then the STRIP_FROM_PATH tag\\n# can be used to strip a user-defined part of the path. Stripping is\\n# only done if one of the specified strings matches the left-hand part of\\n# the path. The tag can be used to show relative paths in the file list.\\n# If left blank the directory from which doxygen is run is used as the\\n# path to strip.\\n\\nSTRIP_FROM_PATH        =\\n\\n# The STRIP_FROM_INC_PATH tag can be used to strip a user-defined part of\\n# the path mentioned in the documentation of a class, which tells\\n# the reader which header file to include in order to use a class.\\n# If left blank only the name of the header file containing the class\\n# definition is used. Otherwise one should specify the include paths that\\n# are normally passed to the compiler using the -I flag.\\n\\nSTRIP_FROM_INC_PATH    =\\n\\n# If the SHORT_NAMES tag is set to YES, doxygen will generate much shorter\\n# (but less readable) file names. This can be useful is your file systems\\n# doesn\\'t support long names like on DOS, Mac, or CD-ROM.\\n\\nSHORT_NAMES            = NO\\n\\n# If the JAVADOC_AUTOBRIEF tag is set to YES then D', '<|endoftext|> station\\'s unoccupied. So now they don\\'t have one arm tied behind their backs.\"\\n\\nAventine swooped past the Klingon cruiser, cutting off its path and forcing it to angle away. \"I don\\'t suppose we could tell them we\\'ve got people inside?\"\\n\\n\"They wouldn\\'t believe us—or they wouldn\\'t want to. They\\'re all aching to act in ways their programming won\\'t let them.\"\\n\\n\"It helps that they\\'re not coordinating,\" Dax called out, straining to be heard over the din on the bridge.\\n\\n\"They are. There\\'s subspace messaging going back and forth. They keep forming alliances—and breaking them and forming new ones in mid-battle. That\\'s our advantage. We\\'re not changing our minds.\"\\n\\nWhile Riker was talking with her, another portion of the admiral\\'s mind was focused on the battle and their next steps, and operating his holographic doppelganger on the Far Embassy. For the first time, Dax realized the full scope of what the Cytherians had given—or foisted on—him. Just how busy could a living mind be, if it had both the capacity and the means to effect action?\\n\\nIt took her breath away. Glad he\\'s on our side—now.\\n\\n\"I\\'ve got Meuse hailing,\" Mirren said.\\n\\nBowers called over the communications systems. \"No way we can get back aboard with the shuttle, Captain. You\\'re moving too fast.\"\\n\\n\"Abandon it. Engineering, beam them to the bridge.\"\\n\\nThe two spacesuited officers materialized in front of the command chairs—and several seconds later, Dax saw the shuttle explode in a hail of disruptor fire from several of the renegade vessels.\\n\\nBowers looked back at the viewscreen, unnerved and astonished. \"They weren\\'t shooting at us at all before we left!\"\\n\\n\"That\\'s just it. You left,\" Dax said. Riker was right, she thought. A target with life signs could be harassed, but not destroyed. Meuse had been taken out the second it was empty.\\n\\n\"We\\'ve made contact with something,\" Riker said. \"We\\'ve got to keep the defense going.\"\\n\\nLike we have a choice, Dax wanted to say. But there was no point in carping now. \"Look alive, Aventine. Another wave incoming!\"\\n\\nFAR EMBASSY\\n\\nWe\\'re getting nowhere with Proctor, Picard thought. And she seemed to agree.\\n\\n\"Conversation futile,\" she had said. \"Queries irrelevant.\" And now the latest, \"Pointless exercise.\"\\n\\n\"Exercise?\" Riker snapped his holographic fingers. \"There\\'s something.\"\\n\\nPicard\\'s hands clapped over the back of a chair to steady himself against the shaking of the station. \"What have you got?\"\\n\\n\"Something I was thinking before I came here the first time,\" holo-Riker said. \"People exercise because a mind needs a body to be effective. But when I sat in the interlink chair, Aventine became my body—and I could suddenly do a whole lot more.\"\\n\\n\"Right.\"\\n\\n\"We\\'ve been thinking all along the Cytherians were far away—that this station was a trap to create drones for them, to give them a way to affect events here.\"\\n\\nPicard figured out where he was going. \"But if Cytherian power could make your mind merge with a starship—\"\\n\\n\"—then this station isn\\'t a trap. It isn\\'t even a station. It\\'s a starship, with a captain on board. And like Aventine, its captain\\'s lost control!\"\\n\\nDisregarding the shaking of the deck, Riker climbed up on a chair and looked accusingly at Proctor. \"Caster is here, isn\\'t he? I mean, really here. He\\'s aboard this ship!\"\\n\\nProctor glowered at Riker for a moment. \"Impertinence intolerable,\" she finally said. \"Mission vacated.\" Proctor turned, and her eyes fell on Picard. \"Federation.\"\\n\\nHer stare was so intense the captain actually took a step backward. \"Yes,\" he said, not understanding. He put his hand to his chest. \"I am Picard, of the Federation—\"\\n\\n\"Existing vested intelligence inadequate. Federation agent required.\" And with that, a low hum emanated from the table.\\n\\nRiker\\'s eyes widened. \"Wait a minute. This is where I came in!\" He hopped down and pushed Picard back out of the way of Proctor\\'s direct gaze. \" \\'Federation agent required?\\' I remember now. She\\'s going to transform you, as she did me!\"\\n\\n\"Federation', '<|endoftext|>6 or higher.\\n\\nUSE_HTAGS              = NO\\n\\n# If the VERBATIM_HEADERS tag is set to YES (the default) then Doxygen\\n# will generate a verbatim copy of the header file for each class for\\n# which an include is specified. Set to NO to disable this.\\n\\nVERBATIM_HEADERS       = YES\\n\\n#---------------------------------------------------------------------------\\n# configuration options related to the alphabetical class index\\n#---------------------------------------------------------------------------\\n\\n# If the ALPHABETICAL_INDEX tag is set to YES, an alphabetical index\\n# of all compounds will be generated. Enable this if the project\\n# contains a lot of classes, structs, unions or interfaces.\\n\\nALPHABETICAL_INDEX     = YES\\n\\n# If the alphabetical index is enabled (see ALPHABETICAL_INDEX) then\\n# the COLS_IN_ALPHA_INDEX tag can be used to specify the number of columns\\n# in which this list will be split (can be a number in the range [1..20])\\n\\nCOLS_IN_ALPHA_INDEX    = 5\\n\\n# In case all classes in a project start with a common prefix, all\\n# classes will be put under the same header in the alphabetical index.\\n# The IGNORE_PREFIX tag can be used to specify one or more prefixes that\\n# should be ignored while generating the index headers.\\n\\nIGNORE_PREFIX          =\\n\\n#---------------------------------------------------------------------------\\n# configuration options related to the HTML output\\n#---------------------------------------------------------------------------\\n\\n# If the GENERATE_HTML tag is set to YES (the default) Doxygen will\\n# generate HTML output.\\n\\nGENERATE_HTML          = YES\\n\\n# The HTML_OUTPUT tag is used to specify where the HTML docs will be put.\\n# If a relative path is entered the value of OUTPUT_DIRECTORY will be\\n# put in front of it. If left blank `html\\' will be used as the default path.\\n\\nHTML_OUTPUT            = html\\n\\n# The HTML_FILE_EXTENSION tag can be used to specify the file extension for\\n# each generated HTML page (for example: .htm,.php,.asp). If it is left blank\\n# doxygen will generate files with .html extension.\\n\\nHTML_FILE_EXTENSION    = .html\\n\\n# The HTML_HEADER tag can be used to specify a personal HTML header for\\n# each generated HTML page. If it is left blank doxygen will generate a\\n# standard header. Note that when using a custom header you are responsible\\n#  for the proper inclusion of any scripts and style sheets that doxygen\\n# needs, which is dependent on the configuration options used.\\n# It is advised to generate a default header using \"doxygen -w html\\n# header.html footer.html stylesheet.css YourConfigFile\" and then modify\\n# that header. Note that the header is subject to change so you typically\\n# have to redo this when upgrading to a newer version of doxygen or when\\n# changing the value of configuration settings such as GENERATE_TREEVIEW!\\n\\nHTML_HEADER            =\\n\\n# The HTML_FOOTER tag can be used to specify a personal HTML footer for\\n# each generated HTML page. If it is left blank doxygen will generate a\\n# standard footer.\\n\\nHTML_FOOTER            =\\n\\n# The HTML_STYLESHEET tag can be used to specify a user-defined cascading\\n# style sheet that is used by each HTML page. It can be used to\\n# fine-tune the look of the HTML output. If the tag is left blank doxygen\\n# will generate a default style sheet. Note that doxygen will try to copy\\n# the style sheet file to the HTML output directory, so don\\'t put your own\\n# style sheet in the HTML output directory as well, or it will be erased!\\n\\nHTML_STYLESHEET        =\\n\\n# The HTML_EXTRA_FILES tag can be used to specify one or more extra images or\\n# other source files which should be copied to the HTML output directory. Note\\n# that these files will be copied to the base HTML output directory. Use the\\n# $relpath$ marker in the HTML_HEADER and/or HTML_FOOTER files to load these\\n# files. In the HTML_STYLESHEET file, use the file name only. Also note that\\n# the files will be copied as-is; there are no commands or markers available.\\n\\nHTML_EXTRA_FILES       =\\n\\n# The HTML_COLORSTYLE_HUE tag controls the color of the HTML output.\\n# Doxygen will adjust the colors in the style sheet and background images', \"<|endoftext|> to realloc?\\n\\nI can't understand why valgrind (version 3.14) doesn't detect a possible memory leak in this program:\\n#include <stdlib.h>\\n\\nint main() {\\n  int *p = malloc(sizeof(int));\\n  p = realloc(p, 2 * sizeof(int));\\n\\n  free(p);\\n\\n  return 0;\\n}\\n\\nThe C99 standard (ISO/IEC 9899:1999, page 314) says this about realloc:\\n\\nIf memory for the new object cannot be allocated, the old object is not deallocated and its value is unchanged. [...]\\n  The realloc function returns a pointer to the new object (which may have the same\\n  value as a pointer to the old object), or a null pointer if the new object could not be\\n  allocated.\\n\\nSo it may occur that p is NULL but the memory cell previously allocated with malloc is still there, shouldn't this be a possible memory leak?\\nIf I compile the program with gcc -std=c99 and I execute valgrind with --tool=memcheck --leak-check=full --track-origins=yes it gives the following message:\\n==313618== Memcheck, a memory error detector\\n==313618== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al.\\n==313618== Using Valgrind-3.14.0 and LibVEX; rerun with -h for copyright info\\n==313618== Command: ./a.out\\n==313618== \\n==313618== \\n==313618== HEAP SUMMARY:\\n==313618==     in use at exit: 0 bytes in 0 blocks\\n==313618==   total heap usage: 2 allocs, 2 frees, 12 bytes allocated\\n==313618== \\n==313618== All heap blocks were freed -- no leaks are possible\\n==313618== \\n==313618== For counts of detected and suppressed errors, rerun with: -v\\n==313618== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)\\n\\nA:\\n\\nValgrind does not analyze your code; it analyzes the actions taken by your code.\\nIn this particular run realloc did not fail, so there was no memory leak, so valgrind had nothing to report:\\n\\nAll heap blocks were freed\\n\\nAnd that's all valgrind knows.\\nTo detect the problem in your code you need a static code analysis tool.\\n\\n<|endoftext|>Chin Augmentation\\n\\nChin augmentation or chin surgery is a prominent method to remove or add fats to the facial area to make chin perfect and symmetrical with the body. If you are planning to undergo chin augmentation in Pakistan, our clinic is the best choice already. The chin augmentation is necessary if your chin-nose isn’t in symmetry, the distance between chin and nose is balanced by the surgery.\\n\\nThe chin augmentation surgery gives a shining and brilliant look to the face and provided symmetry to the face and neck. Sometimes, chin augmentation is performed along with the cheek augmentation for the successful reshaping of the body. The procedure is also called Mentoplasty or chin implant surgery. The patient is required to take medications and prevent smoking or taking aspirin for at least a week before the surgery. When the surgery is done, the patients feel instant results and a great look and shape afterward. It increases self-confidence and boosts the communication skills in the patient after surgery.\\n\\nBefore the Surgery\\n\\nThe patient needs to attend a session with the specialized surgeon before undergoing surgery; the chin implants are different for various patients. Doctors will discuss the possible outcomes and things needed to be avoided before and after the surgery. Our top-notch surgeons will provide a realistic map of what the patient will look like after undergoing the operation. The whole process is quite safe and quick, the healing process is brisk and reshapes skin and bone structure of the patient.\\n\\nGood Candidate for Chin Augmentation\\n\\nA good candidate for chin augmentation surgery is the one having:\\n\\nAppropriate age required for any cosmetic surgery,i.e., between 20-50 years.\\n\\nClean medical history with no allergies or prone to infections\\n\\nRealistic approach towards the surgery\\n\\nDuring the Surgery\\n\\nThe surgeon injects general anesthesia into the patient, the operated area is numb, and the patient is not in full of its senses during the operation. Afterwards, incisions are made to the marked area of patients to perform the surgery. Cuts are made inside the lower lip region and chins. Now, the cuts are made inside the mouth,and the surgeon uses sutures for sewing up the incision cuts inside the mouth. After the chin is reshaped, the area is\", '<|endoftext|> shipping it too then\\n<desertc> geser: Do you have any recollection of the OnScripter package?  Wondering if it is worth updating.\\n<geser> desertc: no, from looking at the debdiff I guess it was a fix for a build-failure.\\n * blueyed also cheers persia :)\\n<desertc> geser: I talked with the developers who release graphic novels with OnScripter, and they said they typically package whatever versions with each release, so it\\'s probably not imperative to have Ubuntu\\'s OnScripter up-to-date, even though our version is 3 years old.\\n<desertc> gaser: Just wanted to get your opinion on it, since your name was associated with the package.\\n<blueyed> What\\'s the best method to get *.ogg from a http path in the current directory?\\n<geser> desertc: if you think it should be updated that go on, I\\'ve no opinion on it\\n<desertc> Back to the Mumble topic again, I just learned *wave* that slicer is the lead developer and is perma-idled here in #ubuntu-motu .  He\\'s very eager to resolve any remaining issues.\\n<ScottK2> desertc: Reading the description ... Why do we need a package for yet another proprietary VOIP protocol in the archives?\\n<leonel> the patches fixed in ubuntu  get back to  debian  ??\\n<desertc> ScottK2: Mumble is similar in function to Teamspeak and Ventrilio, where multiple users join a channels on a server.  It is often used for online games.  To my knowledge, there is nothing available for Linux like Mumble.\\n<ScottK2> leonel: Sometimes\\n<leonel> ok\\n<ScottK2> desertc: Fair enough.\\n<ScottK2> leonel: Did you have something specific in mind?\\n<leonel> just to clear  a discussion overhere ..\\n<leonel> not a real patch to send to debian\\n<frafu> Somebody knows a package using debhelpers and dh_gconf, so that I can look how to set it up?\\n<ScottK2> Where there is an ubuntu change, it shows up on the Debian Package Tracking System.\\n<ScottK2> So Debian maintainers know about it.\\n<desertc> ScottK2: Also, worth mentioning quickly, Mumble is open source software, unlike Teamspeak or Ventrilio, which may support or plan to support Linux versions.\\n<ScottK2> leonel: Good Ubuntu developers will file bugs with patches in Debian.\\n<ScottK2> desertc: OK.  I\\'m convinced.  I\\'ll go back to looking.\\n<leonel> ScottK2:  thanks\\n<ScottK2> desertc: Since we already have speex in the archive, can the package use that instead of it\\'s own copy?  Code duplication is hell for maintenance.\\n<geser> and for security updates\\n<ScottK2> Absolutely.\\n<desertc> ScottK2: This is the information I gathered through my discussion with the Mumble developer: http://pastebin.ca/888059\\n<desertc> It is his opinion that this issue has already been resolved through discussions he had in this channel (user name: slicer ), however, he does not have logs on with whom he discussed this topic.\\n<ScottK2> desertc: It wasn\\'t resolved with me, so I ask.\\n<desertc> Anyway, any resolution we can come to on the topic of Mumble / Speex should be documented on the launchpad page, imho.\\n<desertc> Since, right now it looks like an open issue.\\n<desertc> Even if there can be a decision made that this is not acceptable.  At least the specific roadblock would be documented.\\n<ScottK2> Would it make sense to update the current speex version in the archive to the one Mumble is using?  Would that cause problems with other packcages?\\n<desertc> Yes, I asked about this too, which generated the response that I pastebin\\'d: \"The problem really is that there is no modern and stable version of Speex;\"\\n<ScottK2> Right, so let\\'s pick one\\n<desertc> Sounds good to me, at least.  \" slicer \" told me he had to go afk for company who visited his house.\\n<desertc> Sounds like we could choose the version he is presently using in his latest stable, and see what conflicts would arise from using it.\\n<ScottK2> Nevermind.  I', \"<|endoftext|> there's data there that could be retrieved.\\n     It should, however, set up any internal metadata required such that\\n     the write_page() method can write to the cache.\\n\\n     If there's no backing block available, then -ENOBUFS should be returned\\n     (or -ENOMEM if there were other problems).  If a block is successfully\\n     allocated, then the netfs page should be marked and 0 returned.\\n\\n\\n (*) Request pages be allocated in the cache [mandatory]:\\n\\n\\tint (*allocate_pages)(struct fscache_retrieval *op,\\n\\t\\t\\t      struct list_head *pages,\\n\\t\\t\\t      unsigned *nr_pages,\\n\\t\\t\\t      gfp_t gfp)\\n\\n     This is an multiple page version of the allocate_page() method.  pages and\\n     nr_pages should be treated as for the read_or_alloc_pages() method.\\n\\n\\n (*) Request page be written to cache [mandatory]:\\n\\n\\tint (*write_page)(struct fscache_storage *op,\\n\\t\\t\\t  struct page *page);\\n\\n     This is called to write from a page on which there was a previously\\n     successful read_or_alloc_page() call or similar.  FS-Cache filters out\\n     pages that don't have mappings.\\n\\n     This method is called asynchronously from the FS-Cache thread pool.  It is\\n     not required to actually store anything, provided -ENODATA is then\\n     returned to the next read of this page.\\n\\n     If an error occurred, then a negative error code should be returned,\\n     otherwise zero should be returned.  FS-Cache will take appropriate action\\n     in response to an error, such as withdrawing this object.\\n\\n     If this method returns success then FS-Cache will inform the netfs\\n     appropriately.\\n\\n\\n (*) Discard retained per-page metadata [mandatory]:\\n\\n\\tvoid (*uncache_page)(struct fscache_object *object, struct page *page)\\n\\n     This is called when a netfs page is being evicted from the pagecache.  The\\n     cache backend should tear down any internal representation or tracking it\\n     maintains for this page.\\n\\n\\n==================\\nFS-CACHE UTILITIES\\n==================\\n\\nFS-Cache provides some utilities that a cache backend may make use of:\\n\\n (*) Note occurrence of an I/O error in a cache:\\n\\n\\tvoid fscache_io_error(struct fscache_cache *cache)\\n\\n     This tells FS-Cache that an I/O error occurred in the cache.  After this\\n     has been called, only resource dissociation operations (object and page\\n     release) will be passed from the netfs to the cache backend for the\\n     specified cache.\\n\\n     This does not actually withdraw the cache.  That must be done separately.\\n\\n\\n (*) Invoke the retrieval I/O completion function:\\n\\n\\tvoid fscache_end_io(struct fscache_retrieval *op, struct page *page,\\n\\t\\t\\t    int error);\\n\\n     This is called to note the end of an attempt to retrieve a page.  The\\n     error value should be 0 if successful and an error otherwise.\\n\\n\\n (*) Record that one or more pages being retrieved or allocated have been dealt\\n     with:\\n\\n\\tvoid fscache_retrieval_complete(struct fscache_retrieval *op,\\n\\t\\t\\t\\t\\tint n_pages);\\n\\n     This is called to record the fact that one or more pages have been dealt\\n     with and are no longer the concern of this operation.  When the number of\\n     pages remaining in the operation reaches 0, the operation will be\\n     completed.\\n\\n\\n (*) Record operation completion:\\n\\n\\tvoid fscache_op_complete(struct fscache_operation *op);\\n\\n     This is called to record the completion of an operation.  This deducts\\n     this operation from the parent object's run state, potentially permitting\\n     one or more pending operations to start running.\\n\\n\\n (*) Set highest store limit:\\n\\n\\tvoid fscache_set_store_limit(struct fscache_object *object,\\n\\t\\t\\t\\t     loff_t i_size);\\n\\n     This sets the limit FS-Cache imposes on the highest byte it's willing to\\n     try and store for a netfs.  Any page over this limit is automatically\\n     rejected by fscache_read_alloc_page() and co with -ENOBUFS.\\n\\n\\n (*) Mark pages as being cached:\\n\\n\\tvoid fscache_mark_pages_cached(struct fscache_retrieval *op,\\n\\t\\t\\t\\t       struct pagevec *pagevec);\\n\\n     This marks a set of pages as being cached.  After this has been called,\\n     the netfs\", '<|endoftext|> it and asking when it will be put in. She called me to tell me that when the stone gets wet, the etching kind of disappears. And it really does. Mike thinks it\\'s pretty neat...like a secret message or something. She also told me the stone would be placed the next afternoon. I politely asked her to let me know if something came up and it didn\\'t get placed.\\n\\nWe went on Friday and the stone wasn\\'t set. I text, I called. Nothing. I had never heard from her to know that it wasn\\'t going to be done. I called again Saturday, nothing. Finally Saturday afternoon when I called again, the husband answered the phone. I let him know how I upset I was about everything. He tried to be apologetic, but in my opinion was very unprofessional. He kept saying how everything was last minute, and things come up they can\\'t foresee. I repeated over and over again that wasn\\'t the biggest issue. The biggest issue is that things were promised to me that couldn\\'t be followed through on. If they couldn\\'t be guaranteed they never should have told me. I also mentioned how I was told I would be called if the headstone wasn\\'t going to be set on Friday afternoon. Apparently part of the problem is the communication between the husband and wife team. The wife told me the stone would be set that Friday afternoon and when I talked to the husband on Saturday he told me he knew the stone wouldn\\'t be set on Friday. If he knew that...why did she tell me that?\\n\\nHe then complained about the groundskeeper at the cemetery, saying he needs things to be too specific. You should never complain to a customer about someone you need to work with to deliver what they need. He also told me about how they don\\'t make much money on these stones and it\\'s just a part time business for them. And how they\\'re making even less money on Marcellus\\'s stone because he had to pay someone extra to get it done in time for our prayer service. Unprofessional. Very unprofessional.\\n\\nI think part of the problem also is that the lady sincerely wanted to make these things happen for us. She really did want them to come true. But that is not good customer service. Good customer service is following through on what you say you can do. I never asked for the stone to be put in by Memorial Day. She came up with that date. If she would have said let\\'s push it back to July to make sure everything is done and done right, I would have had no problem with that. We would have planned our trip in July.\\n\\nThe experience was completely miserable and incredibly stressful. More so than it needed to be. If you work in any business with the bereaved you must be compassionate and sensitive, but also direct. I feel like I never knew what was going on with his headstone, that I was just being give the run around.\\n\\nI am so thankful that the stone was done on time for us to see and share with family and friends while we were in MN. But it was supposed to be set and I am angry, upset, and very frustrated about that. Our trip was planned for us to be there to make everything with our son\\'s headstone is okay. To see it as it should be, properly placed in the ground. For us to be able to set everything up how we wanted it to be. Instead we had to leave hoping it will be okay just sitting out there (we could have had them pick it up, but Mike was more worried about it being moved multiple times). Instead I had to ask my mom to go out and pick up his new toy cars and some other things that were intended to sit on the cement up, so that they don\\'t get lost or aren\\'t in the way for mowing. Instead I have to wait over another week yet for it to maybe be put in. I was still never given a date (oh another thing I was told...\"this is a part-time business and we don\\'t want to be working every weekend\"). Once it\\'s put in my mom will go out there, set everything up and send me a picture.\\n\\nAnd we really do love the stone, which I will share in my next post. But the thing is, this business had nothing to do with how the stone itself turned out. Their job is to be the middle man, to facilitate everything. But I wish I would have just had to contact everyone on my own. It would have been less stressful. The stone is beautiful, but someone else cuts the stone. We like the carving, but that was the carver\\'s job. The etching turned out well, but that was done by the etcher.\\n\\nOkay, my rant is over. It\\'s longer than I thought it would be, but I needed to complain. To get that out before sharing the beauty and meaning behind Marcellus\\'s headstone. Thanks for \"listening\".', \"<|endoftext|> duration it is initialized to this value before the main function is called\\nif the newVariable has an automatic storage duration it is initialized to this value when the function is called.\\n\\nA:\\n\\nThe compiler will source the value 100 wherever the macro is used.  It is most likely found in various machine code instructions, using immediate mode addressing, e.g. when used within expression statements, like a = a + 100, or f(100).\\nThe compiler will most likely embed small constants like this on demand within instructions involved in computing expressions like the above, so if we do a = a + thisInteger; and f(thisInteger), there will probably be two different machine code instructions that embed the constant 100 as an immediate, one for each such use.\\xa0 Global data takes work to address, more so than embedding small immediates, so the compiler will not attempt to share the 100 between the two uses as global or static data.\\nSo, yes, you can see the 100 in objdump, but for many usages you probably need to look at the code (.text) section to find instructions that use #100 as an immediate operand (or #64h if printed in hex).\\xa0 In disassembly, you're looking for instructions like add [rbp+24], #100, or move rdi, #100.\\nYou're right that if you declare a mutable global variable int x = thisInteger; you could find the 100 in the data (.data) section with objdump.\\xa0 But local variable of the same declaration would be initialized at runtime using machine code instructions, so something like mov ??, #100.\\n\\n<|endoftext|>         IN THE COURT OF CRIMINAL APPEALS OF TENNESSEE\\n\\n                               AT JACKSON\\n\\n                           AUGUST SESSION, 1997                FILED\\n                                                         December 4, 1998\\nMICHAEL ANGELO COLEMAN, )          C.C.A. NO. 02C01-9611-CR-00395\\n                        )                                Cecil Crowson, Jr.\\n                                                               Appellate C ourt Clerk\\n     Appe llant,        )\\n                        )\\n                        )          SHELBY COUNTY\\nVS.                     )\\n                        )          HON. JOE B. BROWN, JR.\\nSTATE OF TENNESSEE,     )          JUDGE\\n                        )\\n     Appellee.          )          (Post-Conviction - First Degree\\n                        )          Felony Murde r)\\n\\n\\n\\n\\nFOR THE APPELLANT:                 FOR THE APPELLEE:\\n\\nMICHAEL J. PASSINO                 JOHN KNOX WALKUP\\n213 Fifth Avenu e, North           Attorney General and Reporter\\nNashville, TN 37219\\n                                   JOHN P. CAULEY\\nAPRIL FERGUSON                     Assistant Attorney General\\nAssistant Federal Defender         425 Fifth Avenu e, North\\n100 North Main Bldg.               Nashville, TN. 37243\\nSuite 410\\nMemphis, TN 38103                  WILLIAM L. GIBBONS\\n                                   District Attorney General\\n\\n                                   JOHN W . CAMPBELL\\n                                   District Attorney General\\n                                   201 Poplar Street\\n                                   Memphis, TN 38103\\n\\n\\nOPINION FILED ________________________\\n\\nAFFIRMED\\n\\nJERRY L. SMITH, JUDGE\\n\\x0c                                     OPINION\\n\\n\\n\\n       The appellant, Micha el Angelo C oleman, a ppeals the S helby County\\n\\nCriminal Cour t’s order de nying his s econd petition for p ost-con viction relief. In\\n\\n1980, Appellant received a death sentence after he was convicted of first degree\\n\\nfelony murd er. On appe al, he c laims that he is entitled to a new sentencing\\n\\nhearing due to th e jury’s erroneous reliance on the felony murder aggravating\\n\\ncircumstance to support the imposition of the death pe nalty.              See State v.\\n\\nMiddlebro oks, 840 S.W .2d 317 (Tenn . 1992). A fter a thoro ugh revie w of the\\n\\nrecord, w e find no re versible err or and a ffirm the jud gmen t of the trial cou rt.\\n\\n\\n\\n                                   BACKGROUND\\n\\n\\n\\n\\n       The proof at trial, as set out by our Supreme Court on direct appeal, was\\n\\nas follows:\\n\\n             Appellant and his codefendant were convicted of the killing of\\n       Leon Watson during a robbery, which occurred in Memphis,\\n       Tennessee, on May 2, 19 79. Th at mo rning, M r. W atson left his\\n       home to go to a nearby grocery store. He did not return. At about\\n       10:00 p. m. Mrs. Watson\", \"<|endoftext|> = YES\\n\\n# If the USE_HTAGS tag is set to YES then the references to source code\\n# will point to the HTML generated by the htags(1) tool instead of doxygen\\n# built-in source browser. The htags tool is part of GNU's global source\\n# tagging system (see http://www.gnu.org/software/global/global.html). You\\n# will need version 4.8.6 or higher.\\n\\nUSE_HTAGS              = NO\\n\\n# If the VERBATIM_HEADERS tag is set to YES (the default) then Doxygen\\n# will generate a verbatim copy of the header file for each class for\\n# which an include is specified. Set to NO to disable this.\\n\\nVERBATIM_HEADERS       = YES\\n\\n#---------------------------------------------------------------------------\\n# configuration options related to the alphabetical class index\\n#---------------------------------------------------------------------------\\n\\n# If the ALPHABETICAL_INDEX tag is set to YES, an alphabetical index\\n# of all compounds will be generated. Enable this if the project\\n# contains a lot of classes, structs, unions or interfaces.\\n\\nALPHABETICAL_INDEX     = YES\\n\\n# If the alphabetical index is enabled (see ALPHABETICAL_INDEX) then\\n# the COLS_IN_ALPHA_INDEX tag can be used to specify the number of columns\\n# in which this list will be split (can be a number in the range [1..20])\\n\\nCOLS_IN_ALPHA_INDEX    = 5\\n\\n# In case all classes in a project start with a common prefix, all\\n# classes will be put under the same header in the alphabetical index.\\n# The IGNORE_PREFIX tag can be used to specify one or more prefixes that\\n# should be ignored while generating the index headers.\\n\\nIGNORE_PREFIX          =\\n\\n#---------------------------------------------------------------------------\\n# configuration options related to the HTML output\\n#---------------------------------------------------------------------------\\n\\n# If the GENERATE_HTML tag is set to YES (the default) Doxygen will\\n# generate HTML output.\\n\\nGENERATE_HTML          = YES\\n\\n# The HTML_OUTPUT tag is used to specify where the HTML docs will be put.\\n# If a relative path is entered the value of OUTPUT_DIRECTORY will be\\n# put in front of it. If left blank `html' will be used as the default path.\\n\\nHTML_OUTPUT            = html\\n\\n# The HTML_FILE_EXTENSION tag can be used to specify the file extension for\\n# each generated HTML page (for example: .htm,.php,.asp). If it is left blank\\n# doxygen will generate files with .html extension.\\n\\nHTML_FILE_EXTENSION    = .html\\n\\n# The HTML_HEADER tag can be used to specify a personal HTML header for\\n# each generated HTML page. If it is left blank doxygen will generate a\\n# standard header.\\n\\nHTML_HEADER            =\\n\\n# The HTML_FOOTER tag can be used to specify a personal HTML footer for\\n# each generated HTML page. If it is left blank doxygen will generate a\\n# standard footer.\\n\\nHTML_FOOTER            =\\n\\n# The HTML_STYLESHEET tag can be used to specify a user-defined cascading\\n# style sheet that is used by each HTML page. It can be used to\\n# fine-tune the look of the HTML output. If the tag is left blank doxygen\\n# will generate a default style sheet. Note that doxygen will try to copy\\n# the style sheet file to the HTML output directory, so don't put your own\\n# stylesheet in the HTML output directory as well, or it will be erased!\\n\\nHTML_STYLESHEET        =\\n\\n# The HTML_COLORSTYLE_HUE tag controls the color of the HTML output.\\n# Doxygen will adjust the colors in the stylesheet and background images\\n# according to this color. Hue is specified as an angle on a colorwheel,\\n# see http://en.wikipedia.org/wiki/Hue for more information.\\n# For instance the value 0 represents red, 60 is yellow, 120 is green,\\n# 180 is cyan, 240 is blue, 300 purple, and 360 is red again.\\n# The allowed range is 0 to 359.\\n\\nHTML_COLORSTYLE_HUE    = 220\\n\\n# The HTML_COLORSTYLE_SAT tag controls the purity (or saturation) of\\n# the colors in the HTML output. For a value of 0 the output will use\\n# grayscales only. A value of 255 will produce the most vivid colors.\\n\\nHTML_COLORSTYLE_S\", \"<|endoftext|> tag can be used to specify a program that doxygen should \\n# invoke to filter for each input file. Doxygen will invoke the filter program \\n# by executing (via popen()) the command <filter> <input-file>, where <filter> \\n# is the value of the INPUT_FILTER tag, and <input-file> is the name of an \\n# input file. Doxygen will then use the output that the filter program writes \\n# to standard output.\\n\\nINPUT_FILTER           = \\n\\n# If the FILTER_SOURCE_FILES tag is set to YES, the input filter (if set using \\n# INPUT_FILTER) will be used to filter the input files when producing source \\n# files to browse (i.e. when SOURCE_BROWSER is set to YES).\\n\\nFILTER_SOURCE_FILES    = NO\\n\\n#---------------------------------------------------------------------------\\n# configuration options related to source browsing\\n#---------------------------------------------------------------------------\\n\\n# If the SOURCE_BROWSER tag is set to YES then a list of source files will \\n# be generated. Documented entities will be cross-referenced with these sources. \\n# Note: To get rid of all source code in the generated output, make sure also \\n# VERBATIM_HEADERS is set to NO.\\n\\nSOURCE_BROWSER         = NO\\n\\n# Setting the INLINE_SOURCES tag to YES will include the body \\n# of functions and classes directly in the documentation.\\n\\nINLINE_SOURCES         = NO\\n\\n# Setting the STRIP_CODE_COMMENTS tag to YES (the default) will instruct \\n# doxygen to hide any special comment blocks from generated source code \\n# fragments. Normal C and C++ comments will always remain visible.\\n\\nSTRIP_CODE_COMMENTS    = NO\\n\\n# If the REFERENCED_BY_RELATION tag is set to YES (the default) \\n# then for each documented function all documented \\n# functions referencing it will be listed.\\n\\nREFERENCED_BY_RELATION = YES\\n\\n# If the REFERENCES_RELATION tag is set to YES (the default) \\n# then for each documented function all documented entities \\n# called/used by that function will be listed.\\n\\nREFERENCES_RELATION    = YES\\n\\n# If the VERBATIM_HEADERS tag is set to YES (the default) then Doxygen \\n# will generate a verbatim copy of the header file for each class for \\n# which an include is specified. Set to NO to disable this.\\n\\nVERBATIM_HEADERS       = YES\\n\\n#---------------------------------------------------------------------------\\n# configuration options related to the alphabetical class index\\n#---------------------------------------------------------------------------\\n\\n# If the ALPHABETICAL_INDEX tag is set to YES, an alphabetical index \\n# of all compounds will be generated. Enable this if the project \\n# contains a lot of classes, structs, unions or interfaces.\\n\\nALPHABETICAL_INDEX     = NO\\n\\n# If the alphabetical index is enabled (see ALPHABETICAL_INDEX) then \\n# the COLS_IN_ALPHA_INDEX tag can be used to specify the number of columns \\n# in which this list will be split (can be a number in the range [1..20])\\n\\nCOLS_IN_ALPHA_INDEX    = 5\\n\\n# In case all classes in a project start with a common prefix, all \\n# classes will be put under the same header in the alphabetical index. \\n# The IGNORE_PREFIX tag can be used to specify one or more prefixes that \\n# should be ignored while generating the index headers.\\n\\nIGNORE_PREFIX          = \\n\\n#---------------------------------------------------------------------------\\n# configuration options related to the HTML output\\n#---------------------------------------------------------------------------\\n\\n# If the GENERATE_HTML tag is set to YES (the default) Doxygen will \\n# generate HTML output.\\n\\nGENERATE_HTML          = YES\\n\\n# The HTML_OUTPUT tag is used to specify where the HTML docs will be put. \\n# If a relative path is entered the value of OUTPUT_DIRECTORY will be \\n# put in front of it. If left blank `html' will be used as the default path.\\n\\nHTML_OUTPUT            = html\\n\\n# The HTML_FILE_EXTENSION tag can be used to specify the file extension for \\n# each generated HTML page (for example: .htm,.php,.asp). If it is left blank \\n# doxygen will generate files with .html extension.\\n\\nHTML_FILE_EXTENSION    = .html\\n\\n# The HTML_HEADER tag can be used to\", '<|endoftext|> touch him. \"The best possible ponies would have to be thirty-odd miles away. Not a single pony in all of Kent, or at the auctions in Town, would do.\"\\n\\nBased on Noah\\'s disgruntled expression, he would have preferred to go pony shopping in darkest Peru rather than endure Thea\\'s displeasure in public.\\n\\n\"I wasn\\'t looking for ponies when I dragged your brother to buy a mount for Lady Antoinette,\" Noah replied, slapping his riding gloves against his thigh. \"My wife had yet to inform me I\\'d been remiss in the matter of ponies.\"\\n\\n\"Oh, her.\" Thea groused. She wanted badly to smile, which was ridiculous, because Noah was haring off again, but this time he was dragging Harlan with him—or perhaps Harlan was doing the dragging. In any case, they were away to Surrey, though promising to be back the next day, or the day after, \"at the latest.\"\\n\\n\"You disparage my wife at your peril, Duchess,\" Noah said, looking stern despite the glint in his blue eyes. \"She is an estimable lady.\"\\n\\n\"And very determined,\" Thea reminded him. \"If you do not reappear as scheduled, Husband, I will hire the crankiest governess I can find for our daughters, and you will have to pension the old besom off at considerable cost upon your return.\"\\n\\nNoah pulled on his gloves, though Thea had seen something—humor, bashfulness, what?—in his gaze before he\\'d looked away.\\n\\n\"What did I say?\" Thea straightened the lapel of his faultlessly tailored riding jacket. \"I wouldn\\'t hire them anybody terrible, Husband. You know this.\"\\n\\nNoah stepped closer and planted a smacking kiss on her mouth, while Harlan made a production of cinching up his horse\\'s girth. Thea might have wiggled away for form\\'s sake—both grooms were grinning now—but Noah held her close long enough to murmur in her ear.\\n\\n\"See that you look after our daughters in my absence, Wife. My womenfolk matter to me.\"\\n\\nThea stepped back, her fingers going to her lips to mask her pleasure. Harlan winked at her, swung up, and began castigating Noah for how slowly old married men moved when there were horses to be bought, and perhaps his brother wasn\\'t getting enough rest, or perhaps the heat was disturbing his slumbers—\\n\\nNoah gently tapped Harlan\\'s mount on the quarters with a crop, which had the animal trotting off more in indignation than surprise, and Harlan laughing out loud.\\n\\n\"You have my direction,\" Noah said as he settled into the saddle. \"Mind you don\\'t let the girls explode with anticipation. They\\'re merely ponies.\"\\n\\n\"Be safe, Husband.\" Thea petted True\\'s sturdy neck. \"They\\'ll miss you.\"\\n\\n\"Right.\" He leaned down and kissed Thea again, and that kiss held a promise. A very marital promise she wasn\\'t at all reluctant to fulfill.\\n\\nWhen Noah cantered off to catch up with Harlan, Thea was still standing in the stable yard, the taste of her husband\\'s kiss lingering on her lips. What did it mean, that Noah\\'s womenfolk mattered to him, and why had he been surprised Thea had referred to Nini and Evvie as their daughters?\\n\\nThe girls were family, and little and dear. How else was she to refer to them, except as our daughters?\\n\\nKnowing the children were likely watching from the nursery windows, Thea marched herself back into the house. The day would be hot enough to do a little gardening, and then perhaps go wading, to maybe teach the girls the rudiments of fishing... No, not fishing. Anything involving worms on hooks was paternal territory.\\n\\nThe nursery maids reported that the girls were paying a call on Erikson, so Thea doubled back to the conservatory.\\n\\n\"We are dissecting,\" Erikson said, looking up from his worktable. \"It is very scientific work.\"\\n\\n\"What hapless creature are you dissecting?\" Thea knew to close the door behind her, lest the botanical beauties get cold. Erikson\\'s little assistants were ranged on either side of him, sitting on stools the better to view the procedure.\\n\\n\"A chocolate éclair.\" Erikson\\'s fair skin colored. \"Or half of one.\"\\n\\n\"Very scientific, indeed.\" Thea pulled up a stool across the table from the specimen. \"But here we have a discarded sample.\" She lifted the remaining half of the éclair, and took up a butter knife from the tea service. \"I abhor waste', '<|endoftext|>As the chart and tables indicate, a C-130J can, with maximum payload, depart from and arrive at a smaller airstrip than a C-17ER with maximum payload. Keep in mind though, that the 130J carries about one-quarter the payload of a C-17ER (roughly 36,000lbs max normal payload for a 130J whereas the 17ER carries 160,000 max normal). Both aircraft can exceed max normal weights for specific mission profiles.\\n\\nBoeing’s specs say the 17’s minimum landing distance with a 160,000lb payload is 3,000ft — assuming the field is at sea level with normal sea-level air pressure and temperature — these factors will affect the length of takeoff/landing rolls for any aircraft. A C-130J’s landing distance with max normal payload is also around 3,000ft, but it can be shaved down in exceptional circumstances (usually wartime) to about 1600ft if using “max effort” — reverse thrust, spoilers, maximum braking and delaying nosewheel touchdown (keeping more of the airframe in the airflow for longer periods of time helps brake the aircraft faster). The 17 can similarly perform a max effort landing but because it is a much bigger bird, and carries much greater mass and volume, it is still limited to around 2,800ft. So at the end of the day the 130J-30 can, if pressed, hit a smaller airstrip.\\n\\nOf course if you limited the C-17 to the C-130’s max cargo weight, it would be able to arrive and depart in similar takeoff/landing distances, but it would also cost more to get it there. When hefting large volumes, the C-17 wins hands down because it can deliver a much larger payload across longer distances for less cost. But when the payloads and airstrips get smaller, at a certain point the 130J becomes the more cost-efficient delivery system. There are metrics the transport planners use such as cost-per-payload-pound. This figure varies per aircraft type, depending on their resource and maintenance requirements. One must factor in not just getting the payload to the destination, but the extra expenses of ground maintenance, fuel costs, aircrew costs, etc. To use a somewhat down-to-earth example, consider truck rentals. If you had to move the contents of your house to a new house on the other side of town, then going to Budget and renting a 26ft truck is not a bad idea. Long distance, high capacity, eliminates multiple trips to the same destination — makes sense. If on the other hand you are just moving say a computer, chair and desk across town, then perhaps an ordinary van is better. You can still carry the computer, chair and desk in the 26ft truck, but it would cost you a lot more than just renting a van.\\n\\nAnother problem has to do with the nature of the airfields themselves. While the C-17 can deliver payloads to dirt airstrips like a C-130, it can not do so continuously. C-17s can deliver cargo to concrete runways continuously, but can deliver to a dirt runway once or possibly twice because of the inherent properties of dirt. Because of its great mass, the wheels of the aircraft cut into the surface of the airstrip and leave a rut. The more arrivals and departures the C-17 makes, the more ruts and general wear and tear it produces on the dirt airfield — until it finally becomes unusable. C-130s on the other hand are much lighter even at maximum landing weight, and can usually provide continuous service to unprepared dirt airstrips.\\n\\nThen there’s unit cost. A C-17ER quite a bit more expensive than the C-130J (on the order of about 250% more expensive) so we’d be buying fewer C-17s; we couldn’t replace the aging 130E/Hs on a one-for-one basis. Now you might think that this is not a bad thing, as the 17ER can carry four times the cargo. This is only a benefit, however, if all of the cargo has to go to the same place; then the C-17 is exactly what the doctor ordered. If you routinely have a variety of missions that requires cargo to go to geographically disparate locations on the same day, then having fewer but higher-capacity birds is not so great; you’d rather have more aircraft, even lower-capacity ones, to hit those multiple destinations within your allotted time window. To use the truck analogy once more, if you have to move multiple computers, chairs and desks across town to multiple destinations all with an arrival time of 9am, then a single 26ft truck is out of the question. You need a fleet of vans to accomplish the mission.\\n\\nThe final limiting factor is training. If we were', '<|endoftext|>.\\n\\nLouay Safi, a spokesman for Coalition, said the elections made clear that Assad has no intention of reaching a political resolution that would end the war.\\n\\n\"The political elite in Damascus is willing to sacrifice our country for one person — Bashar Assad — to stay in power,\" Safi said. \"This is bad for the Syrian people, because it means that this will be a protracted conflict, and more people will die.\"\\n\\nThe Coalition took part in two rounds of peace talks with Syrian officials earlier this year. The two sides parted in February without making any progress on ending the conflict. A third round of talks is not currently planned.\\n\\nFor some in the anti-Assad camp, even the president\\'s bowing out wouldn\\'t be enough at this point.\\n\\nAn activist who uses the name Abu Akram al-Shami said he would ignore the vote, and that the war now wasn\\'t just against Assad, but \"the whole regime.\"\\n\\n\"Even if, let\\'s say, he (Assad) left office, as things now stand his regime would continue,\" al-Shami said by Skype from Damascus.\\n\\nFrance, a strong supporter of the opposition, described Assad\\'s candidacy and the election as \"a tragic absurdity and parody.\"\\n\\n\"No legitimacy could come out of this phantom-election in a devastated country,\" said Foreign Ministry spokesman Romain Nadal.\\n\\nA spokesman for the German Foreign Ministry, Martin Schaefer, said that given the war, \"it\\'s completely impossible to ask the Syrian people about their political wishes.\"\\n\\nSyrian officials have shrugged off doubts about how the government intends to hold a credible vote in the middle of the conflict.\\n\\nA Syrian lawmaker told The Associated Press last week that there would not be voting centers in areas controlled by the opposition.\\n\\nThe elections\\' timing suggests that Assad, who has been supported diplomatically by Iran and Russia, wants to give himself electoral credibility while he is militarily strong. An ongoing government offensive aimed at recapturing key urban areas has made headway, and Assad appears to be aiming to try to have them under state control before the vote is held.\\n\\nThe Syrian president draws some of his support from the country\\'s Christian and Muslim minority groups that have huddled behind him, fearing for their future should hard-line Sunni Muslim rebels come to power.\\n\\nAlthough Syria enjoyed liberal, albeit tumultuous, parliamentary democracy in the fifties, most of the country\\'s citizens were born under the rule of the Assad family. Bashar took over from his late father, Hafez, who ruled the country for nearly 30 years.\\n\\nBoth Assads were elected by referendums in which they were the only candidates and voters cast yes-or-no ballots.<|endoftext|>Cyclic nucleotides in nervous tissue.\\nA review of the literature emphasizes that cyclic nucleotides play a key role in regulation of cell growth, differentiation and metabolism in diverse tissues and, in addition, are closely involved in neural tissue function. The role of cAMP as a second messenger is discussed.<|endoftext|>Listen up, readers, right off the bat we need to issue a disclaimer: We don’t know the full answer to the question posed in the headline. But we’re hopeful that, by putting out what we do know, perhaps more will come in from the community about the mysterious local resident whose notes inspire, entertain and have been known on many occasions to brighten people’s days.\\n\\nEarlier this year, we had a question from reader Karen Stevenson asking if we could find out who was responsible for hanging “Post-it’s with sweet and thought-provoking little messages on street crossing buttons in Berkeley. I’m told they are all over the 49 bus route and on the bus itself.”\\n\\nStevenson continued: “I first noticed them some months ago outside Star Market on Claremont. One I particularly liked read ‘Look for me — Beauty.’ I thought someone at Star made them, but I was told they don’t know who does it.”\\n\\nAs we are wont to do, we posted a question on our Facebook page asking if anyone knew the story behind the Post-its.\\n\\nOne reader said she had seen them along Dwight Way in Berkeley attached to poles and elsewhere.\\n\\nChimed in Suzanne Yada: “I saw one that said ‘Embrace me.’ —Change.”\\n\\nAnother reader, Jessica Kuo, said she thought it might be the work of Ariel Bierbaum, a Cal PhD student in the Department of City and Regional Planning.\\n\\nBierbaum has a blog on Tumblr called Bus Stop Angel where she has, in the past, often posted photographs of the Post-its at bus stops around town.\\n\\nWe reached out to determine if she was responsible for the notes.\\n\\nSubscribe to the Daily Briefing Don’t miss a story. Get Berkeleys', \"<|endoftext|>\\n\\nRTF_STYLESHEET_FILE    =\\n\\n# Set optional variables used in the generation of an rtf document.\\n# Syntax is similar to doxygen's config file.\\n\\nRTF_EXTENSIONS_FILE    =\\n\\n#---------------------------------------------------------------------------\\n# configuration options related to the man page output\\n#---------------------------------------------------------------------------\\n\\n# If the GENERATE_MAN tag is set to YES (the default) Doxygen will\\n# generate man pages\\n\\nGENERATE_MAN           = NO\\n\\n# The MAN_OUTPUT tag is used to specify where the man pages will be put.\\n# If a relative path is entered the value of OUTPUT_DIRECTORY will be\\n# put in front of it. If left blank `man' will be used as the default path.\\n\\nMAN_OUTPUT             = man\\n\\n# The MAN_EXTENSION tag determines the extension that is added to\\n# the generated man pages (default is the subroutine's section .3)\\n\\nMAN_EXTENSION          = .3\\n\\n# If the MAN_LINKS tag is set to YES and Doxygen generates man output,\\n# then it will generate one additional man file for each entity\\n# documented in the real man page(s). These additional files\\n# only source the real man page, but without them the man command\\n# would be unable to find the correct page. The default is NO.\\n\\nMAN_LINKS              = NO\\n\\n#---------------------------------------------------------------------------\\n# configuration options related to the XML output\\n#---------------------------------------------------------------------------\\n\\n# If the GENERATE_XML tag is set to YES Doxygen will\\n# generate an XML file that captures the structure of\\n# the code including all documentation.\\n\\nGENERATE_XML           = NO\\n\\n# The XML_OUTPUT tag is used to specify where the XML pages will be put.\\n# If a relative path is entered the value of OUTPUT_DIRECTORY will be\\n# put in front of it. If left blank `xml' will be used as the default path.\\n\\nXML_OUTPUT             = xml\\n\\n# The XML_SCHEMA tag can be used to specify an XML schema,\\n# which can be used by a validating XML parser to check the\\n# syntax of the XML files.\\n\\nXML_SCHEMA             =\\n\\n# The XML_DTD tag can be used to specify an XML DTD,\\n# which can be used by a validating XML parser to check the\\n# syntax of the XML files.\\n\\nXML_DTD                =\\n\\n# If the XML_PROGRAMLISTING tag is set to YES Doxygen will\\n# dump the program listings (including syntax highlighting\\n# and cross-referencing information) to the XML output. Note that\\n# enabling this will significantly increase the size of the XML output.\\n\\nXML_PROGRAMLISTING     = YES\\n\\n#---------------------------------------------------------------------------\\n# configuration options for the AutoGen Definitions output\\n#---------------------------------------------------------------------------\\n\\n# If the GENERATE_AUTOGEN_DEF tag is set to YES Doxygen will\\n# generate an AutoGen Definitions (see autogen.sf.net) file\\n# that captures the structure of the code including all\\n# documentation. Note that this feature is still experimental\\n# and incomplete at the moment.\\n\\nGENERATE_AUTOGEN_DEF   = NO\\n\\n#---------------------------------------------------------------------------\\n# configuration options related to the Perl module output\\n#---------------------------------------------------------------------------\\n\\n# If the GENERATE_PERLMOD tag is set to YES Doxygen will\\n# generate a Perl module file that captures the structure of\\n# the code including all documentation. Note that this\\n# feature is still experimental and incomplete at the\\n# moment.\\n\\nGENERATE_PERLMOD       = NO\\n\\n# If the PERLMOD_LATEX tag is set to YES Doxygen will generate\\n# the necessary Makefile rules, Perl scripts and LaTeX code to be able\\n# to generate PDF and DVI output from the Perl module output.\\n\\nPERLMOD_LATEX          = NO\\n\\n# If the PERLMOD_PRETTY tag is set to YES the Perl module output will be\\n# nicely formatted so it can be parsed by a human reader.\\n# This is useful\\n# if you want to understand what is going on.\\n# On the other hand, if this\\n# tag is set to NO the size of the Perl module output will be much smaller\\n# and Perl will parse it just the same.\\n\\nPERLMOD_PRETTY         = YES\\n\\n# The names of the make variables in the generated doxyrules.make file\\n# are prefixed with the string contained in PERLMOD_MAKEVAR_PREFIX.\\n# This is useful so different doxyrules.make files included by the same\\n\"]\n","194 ['<|endoftext|>LEN                     = 0x4\\n\\tETHER_CRC_POLY_BE                 = 0x4c11db6\\n\\tETHER_CRC_POLY_LE                 = 0xedb88320\\n\\tETHER_HDR_LEN                     = 0xe\\n\\tETHER_MAX_DIX_LEN                 = 0x600\\n\\tETHER_MAX_LEN                     = 0x5ee\\n\\tETHER_MIN_LEN                     = 0x40\\n\\tETHER_TYPE_LEN                    = 0x2\\n\\tETHER_VLAN_ENCAP_LEN              = 0x4\\n\\tEVFILT_AIO                        = -0x3\\n\\tEVFILT_PROC                       = -0x5\\n\\tEVFILT_READ                       = -0x1\\n\\tEVFILT_SIGNAL                     = -0x6\\n\\tEVFILT_SYSCOUNT                   = 0x7\\n\\tEVFILT_TIMER                      = -0x7\\n\\tEVFILT_VNODE                      = -0x4\\n\\tEVFILT_WRITE                      = -0x2\\n\\tEV_ADD                            = 0x1\\n\\tEV_CLEAR                          = 0x20\\n\\tEV_DELETE                         = 0x2\\n\\tEV_DISABLE                        = 0x8\\n\\tEV_ENABLE                         = 0x4\\n\\tEV_EOF                            = 0x8000\\n\\tEV_ERROR                          = 0x4000\\n\\tEV_FLAG1                          = 0x2000\\n\\tEV_ONESHOT                        = 0x10\\n\\tEV_SYSFLAGS                       = 0xf000\\n\\tEXTA                              = 0x4b00\\n\\tEXTB                              = 0x9600\\n\\tEXTPROC                           = 0x800\\n\\tFD_CLOEXEC                        = 0x1\\n\\tFD_SETSIZE                        = 0x400\\n\\tFLUSHO                            = 0x800000\\n\\tF_DUPFD                           = 0x0\\n\\tF_DUPFD_CLOEXEC                   = 0xa\\n\\tF_GETFD                           = 0x1\\n\\tF_GETFL                           = 0x3\\n\\tF_GETLK                           = 0x7\\n\\tF_GETOWN                          = 0x5\\n\\tF_OK                              = 0x0\\n\\tF_RDLCK                           = 0x1\\n\\tF_SETFD                           = 0x2\\n\\tF_SETFL                           = 0x4\\n\\tF_SETLK                           = 0x8\\n\\tF_SETLKW                          = 0x9\\n\\tF_SETOWN                          = 0x6\\n\\tF_UNLCK                           = 0x2\\n\\tF_WRLCK                           = 0x3\\n\\tHUPCL                             = 0x4000\\n\\tICANON                            = 0x100\\n\\tICMP6_FILTER                      = 0x12\\n\\tICRNL                             = 0x100\\n\\tIEXTEN                            = 0x400\\n\\tIFAN_ARRIVAL                      = 0x0\\n\\tIFAN_DEPARTURE                    = 0x1\\n\\tIFA_ROUTE                         = 0x1\\n\\tIFF_ALLMULTI                      = 0x200\\n\\tIFF_BROADCAST                     = 0x2\\n\\tIFF_CANTCHANGE                    = 0x8e52\\n\\tIFF_DEBUG                         = 0x4\\n\\tIFF_LINK0                         = 0x1000\\n\\tIFF_LINK1                         = 0x2000\\n\\tIFF_LINK2                         = 0x4000\\n\\tIFF_LOOPBACK                      = 0x8\\n\\tIFF_MULTICAST                     = 0x8000\\n\\tIFF_NOARP                         = 0x80\\n\\tIFF_NOTRAILERS                    = 0x20\\n\\tIFF_OACTIVE                       = 0x400\\n\\tIFF_POINTOPOINT                   = 0x10\\n\\tIFF_PROMISC                       = 0x100\\n\\tIFF_RUNNING                       = 0x40\\n\\tIFF_SIMPLEX                       = 0x800\\n\\tIFF_UP                            = 0x1\\n\\tIFNAMSIZ                          = 0x10\\n\\tIFT_1822                          = 0x2\\n\\tIFT_A12MPPSWITCH                  = 0x82\\n\\tIFT_AAL2                          = 0xbb\\n\\tIFT_AAL5                          = 0x31\\n\\tIFT_ADSL                          = 0x5e\\n\\tIFT_AFLANE8023                    = 0x3b\\n\\tIFT_AFLANE8025                    = 0x3c\\n\\tIFT_ARAP                          = 0', '<|endoftext|>= 0x4\\n\\tETHER_CRC_POLY_BE                 = 0x4c11db6\\n\\tETHER_CRC_POLY_LE                 = 0xedb88320\\n\\tETHER_HDR_LEN                     = 0xe\\n\\tETHER_MAX_DIX_LEN                 = 0x600\\n\\tETHER_MAX_LEN                     = 0x5ee\\n\\tETHER_MIN_LEN                     = 0x40\\n\\tETHER_TYPE_LEN                    = 0x2\\n\\tETHER_VLAN_ENCAP_LEN              = 0x4\\n\\tEVFILT_AIO                        = -0x3\\n\\tEVFILT_PROC                       = -0x5\\n\\tEVFILT_READ                       = -0x1\\n\\tEVFILT_SIGNAL                     = -0x6\\n\\tEVFILT_SYSCOUNT                   = 0x7\\n\\tEVFILT_TIMER                      = -0x7\\n\\tEVFILT_VNODE                      = -0x4\\n\\tEVFILT_WRITE                      = -0x2\\n\\tEV_ADD                            = 0x1\\n\\tEV_CLEAR                          = 0x20\\n\\tEV_DELETE                         = 0x2\\n\\tEV_DISABLE                        = 0x8\\n\\tEV_ENABLE                         = 0x4\\n\\tEV_EOF                            = 0x8000\\n\\tEV_ERROR                          = 0x4000\\n\\tEV_FLAG1                          = 0x2000\\n\\tEV_ONESHOT                        = 0x10\\n\\tEV_SYSFLAGS                       = 0xf000\\n\\tEXTA                              = 0x4b00\\n\\tEXTB                              = 0x9600\\n\\tEXTPROC                           = 0x800\\n\\tFD_CLOEXEC                        = 0x1\\n\\tFD_SETSIZE                        = 0x400\\n\\tFLUSHO                            = 0x800000\\n\\tF_DUPFD                           = 0x0\\n\\tF_DUPFD_CLOEXEC                   = 0xa\\n\\tF_GETFD                           = 0x1\\n\\tF_GETFL                           = 0x3\\n\\tF_GETLK                           = 0x7\\n\\tF_GETOWN                          = 0x5\\n\\tF_RDLCK                           = 0x1\\n\\tF_SETFD                           = 0x2\\n\\tF_SETFL                           = 0x4\\n\\tF_SETLK                           = 0x8\\n\\tF_SETLKW                          = 0x9\\n\\tF_SETOWN                          = 0x6\\n\\tF_UNLCK                           = 0x2\\n\\tF_WRLCK                           = 0x3\\n\\tHUPCL                             = 0x4000\\n\\tHW_MACHINE                        = 0x1\\n\\tICANON                            = 0x100\\n\\tICMP6_FILTER                      = 0x12\\n\\tICRNL                             = 0x100\\n\\tIEXTEN                            = 0x400\\n\\tIFAN_ARRIVAL                      = 0x0\\n\\tIFAN_DEPARTURE                    = 0x1\\n\\tIFA_ROUTE                         = 0x1\\n\\tIFF_ALLMULTI                      = 0x200\\n\\tIFF_BROADCAST                     = 0x2\\n\\tIFF_CANTCHANGE                    = 0x8e52\\n\\tIFF_DEBUG                         = 0x4\\n\\tIFF_LINK0                         = 0x1000\\n\\tIFF_LINK1                         = 0x2000\\n\\tIFF_LINK2                         = 0x4000\\n\\tIFF_LOOPBACK                      = 0x8\\n\\tIFF_MULTICAST                     = 0x8000\\n\\tIFF_NOARP                         = 0x80\\n\\tIFF_NOTRAILERS                    = 0x20\\n\\tIFF_OACTIVE                       = 0x400\\n\\tIFF_POINTOPOINT                   = 0x10\\n\\tIFF_PROMISC                       = 0x100\\n\\tIFF_RUNNING                       = 0x40\\n\\tIFF_SIMPLEX                       = 0x800\\n\\tIFF_UP                            = 0x1\\n\\tIFNAMSIZ                          = 0x10\\n\\tIFT_1822                          = 0x2\\n\\tIFT_A12MPPSWITCH                  = 0x82\\n\\tIFT_AAL2                          = 0xbb\\n\\tIFT_AAL5                          = 0x31\\n\\tIFT_ADSL                          = 0x5e\\n\\tIFT_AFLANE8023                    = 0x3b\\n\\tIFT_AFLANE8025                    = 0x3c\\n\\tIFT_ARAP                          = 0x', '<|endoftext|>ETHERTYPE_X25                     = 0x805\\n\\tETHERTYPE_X75                     = 0x801\\n\\tETHERTYPE_XNSSM                   = 0x9001\\n\\tETHERTYPE_XTP                     = 0x817d\\n\\tETHER_ADDR_LEN                    = 0x6\\n\\tETHER_CRC_LEN                     = 0x4\\n\\tETHER_CRC_POLY_BE                 = 0x4c11db6\\n\\tETHER_CRC_POLY_LE                 = 0xedb88320\\n\\tETHER_HDR_LEN                     = 0xe\\n\\tETHER_MAX_LEN                     = 0x5ee\\n\\tETHER_MAX_LEN_JUMBO               = 0x233a\\n\\tETHER_MIN_LEN                     = 0x40\\n\\tETHER_PPPOE_ENCAP_LEN             = 0x8\\n\\tETHER_TYPE_LEN                    = 0x2\\n\\tETHER_VLAN_ENCAP_LEN              = 0x4\\n\\tEVFILT_AIO                        = 0x2\\n\\tEVFILT_PROC                       = 0x4\\n\\tEVFILT_READ                       = 0x0\\n\\tEVFILT_SIGNAL                     = 0x5\\n\\tEVFILT_SYSCOUNT                   = 0x7\\n\\tEVFILT_TIMER                      = 0x6\\n\\tEVFILT_VNODE                      = 0x3\\n\\tEVFILT_WRITE                      = 0x1\\n\\tEV_ADD                            = 0x1\\n\\tEV_CLEAR                          = 0x20\\n\\tEV_DELETE                         = 0x2\\n\\tEV_DISABLE                        = 0x8\\n\\tEV_ENABLE                         = 0x4\\n\\tEV_EOF                            = 0x8000\\n\\tEV_ERROR                          = 0x4000\\n\\tEV_FLAG1                          = 0x2000\\n\\tEV_ONESHOT                        = 0x10\\n\\tEV_SYSFLAGS                       = 0xf000\\n\\tEXTA                              = 0x4b00\\n\\tEXTATTR_CMD_START                 = 0x1\\n\\tEXTATTR_CMD_STOP                  = 0x2\\n\\tEXTATTR_NAMESPACE_SYSTEM          = 0x2\\n\\tEXTATTR_NAMESPACE_USER            = 0x1\\n\\tEXTB                              = 0x9600\\n\\tEXTPROC                           = 0x800\\n\\tFD_CLOEXEC                        = 0x1\\n\\tFD_SETSIZE                        = 0x100\\n\\tFLUSHO                            = 0x800000\\n\\tF_CLOSEM                          = 0xa\\n\\tF_DUPFD                           = 0x0\\n\\tF_DUPFD_CLOEXEC                   = 0xc\\n\\tF_FSCTL                           = -0x80000000\\n\\tF_FSDIRMASK                       = 0x70000000\\n\\tF_FSIN                            = 0x10000000\\n\\tF_FSINOUT                         = 0x30000000\\n\\tF_FSOUT                           = 0x20000000\\n\\tF_FSPRIV                          = 0x8000\\n\\tF_FSVOID                          = 0x40000000\\n\\tF_GETFD                           = 0x1\\n\\tF_GETFL                           = 0x3\\n\\tF_GETLK                           = 0x7\\n\\tF_GETNOSIGPIPE                    = 0xd\\n\\tF_GETOWN                          = 0x5\\n\\tF_MAXFD                           = 0xb\\n\\tF_OK                              = 0x0\\n\\tF_PARAM_MASK                      = 0xfff\\n\\tF_PARAM_MAX                       = 0xfff\\n\\tF_RDLCK                           = 0x1\\n\\tF_SETFD                           = 0x2\\n\\tF_SETFL                           = 0x4\\n\\tF_SETLK                           = 0x8\\n\\tF_SETLKW                          = 0x9\\n\\tF_SETNOSIGPIPE                    = 0xe\\n\\tF_SETOWN                          = 0x6\\n\\tF_UNLCK                           = 0x2\\n\\tF_WRLCK                           = 0x3\\n\\tHUPCL                             = 0x4000\\n\\tHW_MACHINE                        = 0x1\\n\\tICANON                            = 0x100\\n\\tICMP6_FILTER                      = 0x12\\n\\tICRNL                             = 0x100\\n\\tIEXTEN                            = 0x400\\n\\tIFAN_ARRIVAL                      = 0x0\\n\\tIFAN_DEPARTURE                    = 0x1\\n\\tIFA_ROUTE                         = 0x1\\n\\tIFF_ALLMULT', '<|endoftext|>\\tETHER_MAX_LEN                     = 0x5ee\\n\\tETHER_MAX_LEN_JUMBO               = 0x233a\\n\\tETHER_MIN_LEN                     = 0x40\\n\\tETHER_PPPOE_ENCAP_LEN             = 0x8\\n\\tETHER_TYPE_LEN                    = 0x2\\n\\tETHER_VLAN_ENCAP_LEN              = 0x4\\n\\tEVFILT_AIO                        = 0x2\\n\\tEVFILT_PROC                       = 0x4\\n\\tEVFILT_READ                       = 0x0\\n\\tEVFILT_SIGNAL                     = 0x5\\n\\tEVFILT_SYSCOUNT                   = 0x7\\n\\tEVFILT_TIMER                      = 0x6\\n\\tEVFILT_VNODE                      = 0x3\\n\\tEVFILT_WRITE                      = 0x1\\n\\tEV_ADD                            = 0x1\\n\\tEV_CLEAR                          = 0x20\\n\\tEV_DELETE                         = 0x2\\n\\tEV_DISABLE                        = 0x8\\n\\tEV_ENABLE                         = 0x4\\n\\tEV_EOF                            = 0x8000\\n\\tEV_ERROR                          = 0x4000\\n\\tEV_FLAG1                          = 0x2000\\n\\tEV_ONESHOT                        = 0x10\\n\\tEV_SYSFLAGS                       = 0xf000\\n\\tEXTA                              = 0x4b00\\n\\tEXTATTR_CMD_START                 = 0x1\\n\\tEXTATTR_CMD_STOP                  = 0x2\\n\\tEXTATTR_NAMESPACE_SYSTEM          = 0x2\\n\\tEXTATTR_NAMESPACE_USER            = 0x1\\n\\tEXTB                              = 0x9600\\n\\tEXTPROC                           = 0x800\\n\\tFD_CLOEXEC                        = 0x1\\n\\tFD_SETSIZE                        = 0x100\\n\\tFLUSHO                            = 0x800000\\n\\tF_CLOSEM                          = 0xa\\n\\tF_DUPFD                           = 0x0\\n\\tF_DUPFD_CLOEXEC                   = 0xc\\n\\tF_FSCTL                           = -0x80000000\\n\\tF_FSDIRMASK                       = 0x70000000\\n\\tF_FSIN                            = 0x10000000\\n\\tF_FSINOUT                         = 0x30000000\\n\\tF_FSOUT                           = 0x20000000\\n\\tF_FSPRIV                          = 0x8000\\n\\tF_FSVOID                          = 0x40000000\\n\\tF_GETFD                           = 0x1\\n\\tF_GETFL                           = 0x3\\n\\tF_GETLK                           = 0x7\\n\\tF_GETNOSIGPIPE                    = 0xd\\n\\tF_GETOWN                          = 0x5\\n\\tF_MAXFD                           = 0xb\\n\\tF_OK                              = 0x0\\n\\tF_PARAM_MASK                      = 0xfff\\n\\tF_PARAM_MAX                       = 0xfff\\n\\tF_RDLCK                           = 0x1\\n\\tF_SETFD                           = 0x2\\n\\tF_SETFL                           = 0x4\\n\\tF_SETLK                           = 0x8\\n\\tF_SETLKW                          = 0x9\\n\\tF_SETNOSIGPIPE                    = 0xe\\n\\tF_SETOWN                          = 0x6\\n\\tF_UNLCK                           = 0x2\\n\\tF_WRLCK                           = 0x3\\n\\tHUPCL                             = 0x4000\\n\\tHW_MACHINE                        = 0x1\\n\\tICANON                            = 0x100\\n\\tICMP6_FILTER                      = 0x12\\n\\tICRNL                             = 0x100\\n\\tIEXTEN                            = 0x400\\n\\tIFAN_ARRIVAL                      = 0x0\\n\\tIFAN_DEPARTURE                    = 0x1\\n\\tIFA_ROUTE                         = 0x1\\n\\tIFF_ALLMULTI                      = 0x200\\n\\tIFF_BROADCAST                     = 0x2\\n\\tIFF_CANTCHANGE                    = 0x8f52\\n\\tIFF_DEBUG                         = 0x4\\n\\tIFF_LINK0                         = 0x1000\\n\\tIFF_LINK1                         = 0x2000\\n\\tIFF_LINK2                         = 0x4000\\n\\tIFF_LOOPBACK                      = 0x8\\n\\tIFF_MULTICAST                     = 0x8000\\n\\tIFF_NOARP                         = 0x80\\n\\tIFF_NOTRAILERS                    = 0x20', '<|endoftext|>= 0xbad\\n\\tETHERTYPE_VINESECHO               = 0xbaf\\n\\tETHERTYPE_VINESLOOP               = 0xbae\\n\\tETHERTYPE_VITAL                   = 0xff00\\n\\tETHERTYPE_VLAN                    = 0x8100\\n\\tETHERTYPE_VLTLMAN                 = 0x8080\\n\\tETHERTYPE_VPROD                   = 0x805c\\n\\tETHERTYPE_VURESERVED              = 0x8147\\n\\tETHERTYPE_WATERLOO                = 0x8130\\n\\tETHERTYPE_WELLFLEET               = 0x8103\\n\\tETHERTYPE_X25                     = 0x805\\n\\tETHERTYPE_X75                     = 0x801\\n\\tETHERTYPE_XNSSM                   = 0x9001\\n\\tETHERTYPE_XTP                     = 0x817d\\n\\tETHER_ADDR_LEN                    = 0x6\\n\\tETHER_ALIGN                       = 0x2\\n\\tETHER_CRC_LEN                     = 0x4\\n\\tETHER_CRC_POLY_BE                 = 0x4c11db6\\n\\tETHER_CRC_POLY_LE                 = 0xedb88320\\n\\tETHER_HDR_LEN                     = 0xe\\n\\tETHER_MAX_DIX_LEN                 = 0x600\\n\\tETHER_MAX_HARDMTU_LEN             = 0xff9b\\n\\tETHER_MAX_LEN                     = 0x5ee\\n\\tETHER_MIN_LEN                     = 0x40\\n\\tETHER_TYPE_LEN                    = 0x2\\n\\tETHER_VLAN_ENCAP_LEN              = 0x4\\n\\tEVFILT_AIO                        = -0x3\\n\\tEVFILT_DEVICE                     = -0x8\\n\\tEVFILT_PROC                       = -0x5\\n\\tEVFILT_READ                       = -0x1\\n\\tEVFILT_SIGNAL                     = -0x6\\n\\tEVFILT_SYSCOUNT                   = 0x8\\n\\tEVFILT_TIMER                      = -0x7\\n\\tEVFILT_VNODE                      = -0x4\\n\\tEVFILT_WRITE                      = -0x2\\n\\tEVL_ENCAPLEN                      = 0x4\\n\\tEVL_PRIO_BITS                     = 0xd\\n\\tEVL_PRIO_MAX                      = 0x7\\n\\tEVL_VLID_MASK                     = 0xfff\\n\\tEVL_VLID_MAX                      = 0xffe\\n\\tEVL_VLID_MIN                      = 0x1\\n\\tEVL_VLID_NULL                     = 0x0\\n\\tEV_ADD                            = 0x1\\n\\tEV_CLEAR                          = 0x20\\n\\tEV_DELETE                         = 0x2\\n\\tEV_DISABLE                        = 0x8\\n\\tEV_DISPATCH                       = 0x80\\n\\tEV_ENABLE                         = 0x4\\n\\tEV_EOF                            = 0x8000\\n\\tEV_ERROR                          = 0x4000\\n\\tEV_FLAG1                          = 0x2000\\n\\tEV_ONESHOT                        = 0x10\\n\\tEV_RECEIPT                        = 0x40\\n\\tEV_SYSFLAGS                       = 0xf000\\n\\tEXTA                              = 0x4b00\\n\\tEXTB                              = 0x9600\\n\\tEXTPROC                           = 0x800\\n\\tFD_CLOEXEC                        = 0x1\\n\\tFD_SETSIZE                        = 0x400\\n\\tFLUSHO                            = 0x800000\\n\\tF_DUPFD                           = 0x0\\n\\tF_DUPFD_CLOEXEC                   = 0xa\\n\\tF_GETFD                           = 0x1\\n\\tF_GETFL                           = 0x3\\n\\tF_GETLK                           = 0x7\\n\\tF_GETOWN                          = 0x5\\n\\tF_ISATTY                          = 0xb\\n\\tF_OK                              = 0x0\\n\\tF_RDLCK                           = 0x1\\n\\tF_SETFD                           = 0x2\\n\\tF_SETFL                           = 0x4\\n\\tF_SETLK                           = 0x8\\n\\tF_SETLKW                          = 0x9\\n\\tF_SETOWN                          = 0x6\\n\\tF_UNLCK                           = 0x2\\n\\tF_WRLCK                           = 0x3\\n\\tHUPCL                             = 0x4000\\n\\tHW_MACHINE                        = 0x1\\n\\tICANON                            = 0x100\\n\\tICMP6_FILTER                      = 0x12\\n\\tI', '<|endoftext|>812b\\n\\tETHERTYPE_TALARISMC               = 0x852b\\n\\tETHERTYPE_TCPCOMP                 = 0x876b\\n\\tETHERTYPE_TCPSM                   = 0x9002\\n\\tETHERTYPE_TEC                     = 0x814f\\n\\tETHERTYPE_TIGAN                   = 0x802f\\n\\tETHERTYPE_TRAIL                   = 0x1000\\n\\tETHERTYPE_TRANSETHER              = 0x6558\\n\\tETHERTYPE_TYMSHARE                = 0x802e\\n\\tETHERTYPE_UBBST                   = 0x7005\\n\\tETHERTYPE_UBDEBUG                 = 0x900\\n\\tETHERTYPE_UBDIAGLOOP              = 0x7002\\n\\tETHERTYPE_UBDL                    = 0x7000\\n\\tETHERTYPE_UBNIU                   = 0x7001\\n\\tETHERTYPE_UBNMC                   = 0x7003\\n\\tETHERTYPE_VALID                   = 0x1600\\n\\tETHERTYPE_VARIAN                  = 0x80dd\\n\\tETHERTYPE_VAXELN                  = 0x803b\\n\\tETHERTYPE_VEECO                   = 0x8067\\n\\tETHERTYPE_VEXP                    = 0x805b\\n\\tETHERTYPE_VGLAB                   = 0x8131\\n\\tETHERTYPE_VINES                   = 0xbad\\n\\tETHERTYPE_VINESECHO               = 0xbaf\\n\\tETHERTYPE_VINESLOOP               = 0xbae\\n\\tETHERTYPE_VITAL                   = 0xff00\\n\\tETHERTYPE_VLAN                    = 0x8100\\n\\tETHERTYPE_VLTLMAN                 = 0x8080\\n\\tETHERTYPE_VPROD                   = 0x805c\\n\\tETHERTYPE_VURESERVED              = 0x8147\\n\\tETHERTYPE_WATERLOO                = 0x8130\\n\\tETHERTYPE_WELLFLEET               = 0x8103\\n\\tETHERTYPE_X25                     = 0x805\\n\\tETHERTYPE_X75                     = 0x801\\n\\tETHERTYPE_XNSSM                   = 0x9001\\n\\tETHERTYPE_XTP                     = 0x817d\\n\\tETHER_ADDR_LEN                    = 0x6\\n\\tETHER_CRC_LEN                     = 0x4\\n\\tETHER_CRC_POLY_BE                 = 0x4c11db6\\n\\tETHER_CRC_POLY_LE                 = 0xedb88320\\n\\tETHER_HDR_LEN                     = 0xe\\n\\tETHER_MAX_LEN                     = 0x5ee\\n\\tETHER_MAX_LEN_JUMBO               = 0x233a\\n\\tETHER_MIN_LEN                     = 0x40\\n\\tETHER_PPPOE_ENCAP_LEN             = 0x8\\n\\tETHER_TYPE_LEN                    = 0x2\\n\\tETHER_VLAN_ENCAP_LEN              = 0x4\\n\\tEVFILT_AIO                        = 0x2\\n\\tEVFILT_PROC                       = 0x4\\n\\tEVFILT_READ                       = 0x0\\n\\tEVFILT_SIGNAL                     = 0x5\\n\\tEVFILT_SYSCOUNT                   = 0x7\\n\\tEVFILT_TIMER                      = 0x6\\n\\tEVFILT_VNODE                      = 0x3\\n\\tEVFILT_WRITE                      = 0x1\\n\\tEV_ADD                            = 0x1\\n\\tEV_CLEAR                          = 0x20\\n\\tEV_DELETE                         = 0x2\\n\\tEV_DISABLE                        = 0x8\\n\\tEV_ENABLE                         = 0x4\\n\\tEV_EOF                            = 0x8000\\n\\tEV_ERROR                          = 0x4000\\n\\tEV_FLAG1                          = 0x2000\\n\\tEV_ONESHOT                        = 0x10\\n\\tEV_SYSFLAGS                       = 0xf000\\n\\tEXTA                              = 0x4b00\\n\\tEXTATTR_CMD_START                 = 0x1\\n\\tEXTATTR_CMD_STOP                  = 0x2\\n\\tEXTATTR_NAMESPACE_SYSTEM          = 0x2\\n\\tEXTATTR_NAMESPACE_USER            = 0x1\\n\\tEXTB                              = 0x9600\\n\\tEXTPROC                           = 0x800\\n\\tFD_CLOEXEC                        = 0x1\\n\\tFD_SETSIZE                        = 0x100\\n\\tFLUSHO                            = 0x800000\\n\\tF_CLOSEM                          = 0xa\\n\\tF_DUPFD                           = 0x0\\n\\tF_DUPFD_CLOEXEC                   = 0xc\\n\\tF_FSCTL                           = -0x80000000\\n\\tF_FSDIRMASK                       = 0x70000000\\n\\tF_FSIN                            = 0', \"<|endoftext|> Commissione, che sembravano stupiti del fatto che i deputati non disponessero di tale corrispondenza. Ebbene, sulla rete abbiamo in effetti potuto trovare la lettera del Presidente Bush al Presidente Prodi, inviata due mesi fa, ma non abbiamo ancora copia della risposta del Presidente Prodi inviata a fine novembre.\\nD'altra parte pareva esserci un accordo con la commissione per le libertà per ricevere tale lettera. Le chiedo quindi se è possibile prenderne conoscenza.\\n\\nPresidente\\nDevo informarla che la Presidente non ha affermato che avrebbe reso disponibile il testo della lettera, perché tale lettera non è ancora pervenuta al Parlamento. Questo è il problema. Pertanto, temo non sia possibile esaudire la sua richiesta.\\n\\nSpazio di libertà, sicurezza e giustizia\\nPresidente\\nL'ordine del giorno reca, in discussione congiunta, le seguenti interrogazioni orali:\\nB5-0534/2001, presentata dalla onorevole Boumediene-Thiery a nome della commissione per le libertà e i diritti dei cittadini, la giustizia e gli affari interni, al Consiglio, sul dibattito annuale 2001 sullo spazio di libertà, di sicurezza e di giustizia (articoli 2 e 39 TUE),\\nB5-0535/2001, presentata dalla onorevole Boumediene-Thiery a nome della commissione per le libertà e i diritti dei cittadini, la giustizia e gli affari interni, alla Commissione, sul dibattito annuale 2001 sullo spazio di libertà, di sicurezza e di giustizia (articoli 2 e 39 TUE).\\n\\nBoumediene-Thiery\\nOnorevoli colleghi, con le conclusioni del Vertice di Tampere si è impresso un nuovo impulso alla realizzazione di uno spazio di libertà, di sicurezza e di giustizia. Per raggiungere gli obiettivi fissati è stato elaborato un piano d'azione che prevede scadenze da due a cinque anni dall'entrata in vigore del Trattato di Amsterdam. A metà percorso occorre verificare lo stato di avanzamento dell'agenda di Tampere, tenendo conto della tabella di marcia della Commissione.\\nLo spazio di libertà, di sicurezza e di giustizia comprende tre grandi dimensioni: la politica comunitaria in materia di asilo e d'immigrazione, il rafforzamento della cooperazione giudiziaria e la cooperazione di polizia. Quale bilancio possiamo tracciare per ciascuno di questi tre aspetti?\\nPer quanto riguarda la politica di asilo e d'immigrazione e, più in particolare, la gestione dei flussi migratori, le misure adottate concepiscono l'immigrazione come un palliativo per il problema della manodopera e un mezzo per compensare gli squilibri demografici degli Stati, senza prendere in considerazione la dimensione umana e sociale del fenomeno o le conseguenze della fuga di cervelli. Tuttavia, nel quadro di tale politica comunitaria d'immigrazione non viene forse messa in discussione l'universalità dei diritti fondamentali?\\nLa politica di riammissione è conforme agli impegni internazionali in materia di protezione dei profughi e di diritto di asilo? Consentitemi poi di esprimere una riserva in merito all'Osservatorio europeo delle migrazioni. Va riconosciuta la necessità di una riflessione preliminare sulla sua missione, sulla sua utilità e sul posto delle ONG di emigrati in questa nuova struttura.\\nNon è stata adottata alcuna misura significativa volta ad assicurare un trattamento equo dei cittadini dei paesi terzi. La questione della loro partecipazione polit\", '<|endoftext|>ap coil and an in-line drier arrived Wed 1/19. The third - a new fan shroud arrived Fri 1/21.\\n\\nThis morning the tech arrived and confirmed that there was a leak in the coil. He said that he\\'s only serviced 10 or so of these units so far and every one has needed the coil replaced. He discharged the system, unsoldered the old coil, soldered the new one in and re-charged it. I asked about the drier and he said he doesn\\'t usually replace them - not worth the trouble in his opinion. He also didn\\'t swap out the fan shroud, but I didn\\'t see any difference there anyway.\\n\\nI installed the GE GeoSpring GEH50DNSRSA on 11/29/10, and I just got the same F-C failure code today, 7/25/11. I called the number, and they said I should expect 2-3 packages, and have scheduled a tech visit for 7/29/11. For reference the manufacturing date is 11/2009.\\n\\nUpdate: The parts came on 7/27/11, two days after calling GE. The parts were \"FILTER DRYER\" (WS86X10001), \"KIT FAN SHROUD, GASKET\" (WS35X10061), and \"EVAPORATOR ASM\" (WS85X10002). You can see pictures of the water heater label and these three parts here: http://preview.tinyurl.com/3maoy72. GE gave a reminder call on 7/28/11, and the tech showed up around 10:30AM on 7/29/11. He finished after 1.5 hours. He said that he\\'s done this fix several times, and he\\'s getting better/faster with every one, so it seems this is a common problem. Hopefully it\\'s just a design problem with the original evaporators and there\\'s a new design they\\'re using for repairs.\\n\\nGood luck on your fix. I\\'ll post an update on mine now that 6 months have passed...\\n\\nMy unit must have been leaking from the factory. Between the time it was installed and the time I got the code and had the evap coil replaced, the cooling fans almost always ran on high. The compressor would kick on, then you would hear the fan speed step up a few times over the next 30 seconds or so. Even though the unit is in an enclosed, insulated room in the basement, the fan noise was loud enough to hear upstairs if the house was quiet and definitely loud enough to be noticable as soon as you opened the basement door. I always attributed it to the fact that I\\'m a bit under the minimum recommended limit size for an enclosed closet.\\n\\nSince the coil was replaced and the unit recharged, the fan has never stepped above the first or second speed. You can barely hear it running even if you are just outside the closed door. I never hear it in the rest of the basement or upstairs. It\\'s really no louder than a refrigerator, which is what I was expecting/hoping for when I originally purchased it. 6 months later I\\'m glad my coil went out as quick as it did so I could get it serviced and running right.\\n\\nThe parts came on 7/27/11, two days after calling GE. The parts were \"FILTER DRYER\" (WS86X10001), \"KIT FAN SHROUD, GASKET\" (WS35X10061), and \"EVAPORATOR ASM\" (WS85X10002). You can see pictures of the water heater label and these three parts here: http://preview.tinyurl.com/3maoy72. GE gave a reminder call on 7/28/11, and the tech showed up around 10:30AM on 7/29/11. He finished after 1.5 hours. He said that he\\'s done this fix several times, and he\\'s getting better/faster with every one, so it seems this is a common problem. Hopefully it\\'s just a design problem with the original evaporators and there\\'s a new design they\\'re using for repairs.\\n\\nI read a lengthy post on JustAnswer.com and found the installer code you need for FULL ACCESS to the GEH50DNSRSA menu options, including Diagnostic and Fault History. The code is \"FILTER\", \"LOCK\", \"VACATION\".\\n\\nI installed the GE GeoSpring GEH50DNSRSA on 11/29/10, and I just got the same F-C failure code today, 7/25/11. I called the number, and they said I should expect 2-3 packages, and have scheduled a tech visit for 7/29/11. For reference the manufacturing date is 11/2009.\\n\\nUpdate: The parts came on 7/27/11, two days after calling GE.', '<|endoftext|>\\tETHERTYPE_VLTLMAN                 = 0x8080\\n\\tETHERTYPE_VPROD                   = 0x805c\\n\\tETHERTYPE_VURESERVED              = 0x8147\\n\\tETHERTYPE_WATERLOO                = 0x8130\\n\\tETHERTYPE_WELLFLEET               = 0x8103\\n\\tETHERTYPE_X25                     = 0x805\\n\\tETHERTYPE_X75                     = 0x801\\n\\tETHERTYPE_XNSSM                   = 0x9001\\n\\tETHERTYPE_XTP                     = 0x817d\\n\\tETHER_ADDR_LEN                    = 0x6\\n\\tETHER_ALIGN                       = 0x2\\n\\tETHER_CRC_LEN                     = 0x4\\n\\tETHER_CRC_POLY_BE                 = 0x4c11db6\\n\\tETHER_CRC_POLY_LE                 = 0xedb88320\\n\\tETHER_HDR_LEN                     = 0xe\\n\\tETHER_MAX_DIX_LEN                 = 0x600\\n\\tETHER_MAX_LEN                     = 0x5ee\\n\\tETHER_MIN_LEN                     = 0x40\\n\\tETHER_TYPE_LEN                    = 0x2\\n\\tETHER_VLAN_ENCAP_LEN              = 0x4\\n\\tEVFILT_AIO                        = -0x3\\n\\tEVFILT_PROC                       = -0x5\\n\\tEVFILT_READ                       = -0x1\\n\\tEVFILT_SIGNAL                     = -0x6\\n\\tEVFILT_SYSCOUNT                   = 0x7\\n\\tEVFILT_TIMER                      = -0x7\\n\\tEVFILT_VNODE                      = -0x4\\n\\tEVFILT_WRITE                      = -0x2\\n\\tEV_ADD                            = 0x1\\n\\tEV_CLEAR                          = 0x20\\n\\tEV_DELETE                         = 0x2\\n\\tEV_DISABLE                        = 0x8\\n\\tEV_ENABLE                         = 0x4\\n\\tEV_EOF                            = 0x8000\\n\\tEV_ERROR                          = 0x4000\\n\\tEV_FLAG1                          = 0x2000\\n\\tEV_ONESHOT                        = 0x10\\n\\tEV_SYSFLAGS                       = 0xf000\\n\\tEXTA                              = 0x4b00\\n\\tEXTB                              = 0x9600\\n\\tEXTPROC                           = 0x800\\n\\tFD_CLOEXEC                        = 0x1\\n\\tFD_SETSIZE                        = 0x400\\n\\tFLUSHO                            = 0x800000\\n\\tF_DUPFD                           = 0x0\\n\\tF_DUPFD_CLOEXEC                   = 0xa\\n\\tF_GETFD                           = 0x1\\n\\tF_GETFL                           = 0x3\\n\\tF_GETLK                           = 0x7\\n\\tF_GETOWN                          = 0x5\\n\\tF_RDLCK                           = 0x1\\n\\tF_SETFD                           = 0x2\\n\\tF_SETFL                           = 0x4\\n\\tF_SETLK                           = 0x8\\n\\tF_SETLKW                          = 0x9\\n\\tF_SETOWN                          = 0x6\\n\\tF_UNLCK                           = 0x2\\n\\tF_WRLCK                           = 0x3\\n\\tHUPCL                             = 0x4000\\n\\tHW_MACHINE                        = 0x1\\n\\tICANON                            = 0x100\\n\\tICMP6_FILTER                      = 0x12\\n\\tICRNL                             = 0x100\\n\\tIEXTEN                            = 0x400\\n\\tIFAN_ARRIVAL                      = 0x0\\n\\tIFAN_DEPARTURE                    = 0x1\\n\\tIFA_ROUTE                         = 0x1\\n\\tIFF_ALLMULTI                      = 0x200\\n\\tIFF_BROADCAST                     = 0x2\\n\\tIFF_CANTCHANGE                    = 0x8e52\\n\\tIFF_DEBUG                         = 0x4\\n\\tIFF_LINK0                         = 0x1000\\n\\tIFF_LINK1                         = 0x2000\\n\\tIFF_LINK2                         = 0x4000\\n\\tIFF_LOOPBACK                      = 0x8\\n\\tIFF_MULTICAST                     = 0x8000\\n\\tIFF_NOARP                         = 0x80\\n\\tIFF_NOTRAILERS                    = 0x20\\n\\tIFF_OACTIVE                       = 0x400\\n\\tIFF_POINTOPOINT                   = 0x10\\n\\tIFF_PROMISC                       = 0x100\\n\\tIFF_RUN', '<|endoftext|>ETHERTYPE_UBDEBUG                 = 0x900\\n\\tETHERTYPE_UBDIAGLOOP              = 0x7002\\n\\tETHERTYPE_UBDL                    = 0x7000\\n\\tETHERTYPE_UBNIU                   = 0x7001\\n\\tETHERTYPE_UBNMC                   = 0x7003\\n\\tETHERTYPE_VALID                   = 0x1600\\n\\tETHERTYPE_VARIAN                  = 0x80dd\\n\\tETHERTYPE_VAXELN                  = 0x803b\\n\\tETHERTYPE_VEECO                   = 0x8067\\n\\tETHERTYPE_VEXP                    = 0x805b\\n\\tETHERTYPE_VGLAB                   = 0x8131\\n\\tETHERTYPE_VINES                   = 0xbad\\n\\tETHERTYPE_VINESECHO               = 0xbaf\\n\\tETHERTYPE_VINESLOOP               = 0xbae\\n\\tETHERTYPE_VITAL                   = 0xff00\\n\\tETHERTYPE_VLAN                    = 0x8100\\n\\tETHERTYPE_VLTLMAN                 = 0x8080\\n\\tETHERTYPE_VPROD                   = 0x805c\\n\\tETHERTYPE_VURESERVED              = 0x8147\\n\\tETHERTYPE_WATERLOO                = 0x8130\\n\\tETHERTYPE_WELLFLEET               = 0x8103\\n\\tETHERTYPE_X25                     = 0x805\\n\\tETHERTYPE_X75                     = 0x801\\n\\tETHERTYPE_XNSSM                   = 0x9001\\n\\tETHERTYPE_XTP                     = 0x817d\\n\\tETHER_ADDR_LEN                    = 0x6\\n\\tETHER_ALIGN                       = 0x2\\n\\tETHER_CRC_LEN                     = 0x4\\n\\tETHER_CRC_POLY_BE                 = 0x4c11db6\\n\\tETHER_CRC_POLY_LE                 = 0xedb88320\\n\\tETHER_HDR_LEN                     = 0xe\\n\\tETHER_MAX_DIX_LEN                 = 0x600\\n\\tETHER_MAX_LEN                     = 0x5ee\\n\\tETHER_MIN_LEN                     = 0x40\\n\\tETHER_TYPE_LEN                    = 0x2\\n\\tETHER_VLAN_ENCAP_LEN              = 0x4\\n\\tEVFILT_AIO                        = -0x3\\n\\tEVFILT_PROC                       = -0x5\\n\\tEVFILT_READ                       = -0x1\\n\\tEVFILT_SIGNAL                     = -0x6\\n\\tEVFILT_SYSCOUNT                   = 0x7\\n\\tEVFILT_TIMER                      = -0x7\\n\\tEVFILT_VNODE                      = -0x4\\n\\tEVFILT_WRITE                      = -0x2\\n\\tEV_ADD                            = 0x1\\n\\tEV_CLEAR                          = 0x20\\n\\tEV_DELETE                         = 0x2\\n\\tEV_DISABLE                        = 0x8\\n\\tEV_ENABLE                         = 0x4\\n\\tEV_EOF                            = 0x8000\\n\\tEV_ERROR                          = 0x4000\\n\\tEV_FLAG1                          = 0x2000\\n\\tEV_ONESHOT                        = 0x10\\n\\tEV_SYSFLAGS                       = 0xf000\\n\\tEXTA                              = 0x4b00\\n\\tEXTB                              = 0x9600\\n\\tEXTPROC                           = 0x800\\n\\tFD_CLOEXEC                        = 0x1\\n\\tFD_SETSIZE                        = 0x400\\n\\tFLUSHO                            = 0x800000\\n\\tF_DUPFD                           = 0x0\\n\\tF_DUPFD_CLOEXEC                   = 0xa\\n\\tF_GETFD                           = 0x1\\n\\tF_GETFL                           = 0x3\\n\\tF_GETLK                           = 0x7\\n\\tF_GETOWN                          = 0x5\\n\\tF_OK                              = 0x0\\n\\tF_RDLCK                           = 0x1\\n\\tF_SETFD                           = 0x2\\n\\tF_SETFL                           = 0x4\\n\\tF_SETLK                           = 0x8\\n\\tF_SETLKW                          = 0x9\\n\\tF_SETOWN                          = 0x6\\n\\tF_UNLCK                           = 0x2\\n\\tF_WRLCK                           = 0x3\\n\\tHUPCL                             = 0x4000\\n\\tHW_MACHINE                        = 0x1\\n\\tICANON                            = 0x100\\n\\tICMP6_FILTER                      = 0x12\\n\\tICRNL                             = 0x100\\n\\tIEXTEN                            = 0x400', '<|endoftext|> require that LTD\\n\\nitself perform such \"personal services\" in order to be engaged in\\n\\n\"trade or business within the United States.\"\\n\\n     We first look to the \"real business\" of the taxpayers, the\\n\\n\"doing of what * * * [the taxpayers] were principally organized\\n\\nto do in order to profit\".     Scottish Am. Inv. Co., v.\\n\\nCommissioner, supra at 59.     LTD is a corporation organized\\n\\npursuant to the laws of the Cayman Islands.    Based on the record,\\n\\nwe believe that the \"real business\" of LTD, the doing of what LTD\\n\\x0c                                - 102 -\\n\\nwas \"principally organized to do in order to realize profit\", was\\n\\nto enable Mexican nationals to invest their capital in non-\\n\\nMexican financial markets.     LTD’s \"real business\" was not merely\\n\\nto render investment advice to clients in Mexico, as petitioners\\n\\ncontend.    During each of the years in issue, LTD’s income\\n\\nconsisted of four major categories:       Management fees, interest\\n\\nincome, currency transactions fees, and other fees and\\n\\ncommissions.    LTD’s income, therefore, was derived from\\n\\neffecting, primarily in the United States, transactions in\\n\\nfinancial markets.     Accordingly, we conclude that LTD’s \"real\\n\\nbusiness\" was providing Mexican nationals with access to non-\\n\\nMexican financial markets and that such business was conducted\\n\\nprimarily in the United States.\\n\\n     In Scottish Am. Inv. Co. v. Commissioner, supra at 59, the\\n\\nCourt made \"a quantitative and a qualitative analysis of the\\n\\nservices performed\".    Quantitatively, LTD performed a substantial\\n\\nnumber of services in the United States.      LTD maintained a client\\n\\nclearing account at Frost Bank in San Antonio in which it\\n\\ncollected deposits from clients.    During the years in issue, LTD\\n\\nhad approximately the following number of client accounts:      257\\n\\nduring 1985, 434 during 1986, 557 during 1987, 870 during 1988,\\n\\nand 1,131 during 1989.    Not all client accounts were actively\\n\\ntraded.    Nonetheless, we conclude that the number of LTD’s client\\n\\naccounts, and, as a corollary, the number of services performed\\n\\x0c                               - 103 -\\n\\nin the United States for such accounts, during each of the years\\n\\nin issue, can be characterized as quantitatively substantial.\\n\\n     Qualitatively, LTD performed substantial services in the\\n\\nUnited States.    Directly and through its agent INC, LTD provided\\n\\ninvestment management services and marketed investment products.\\n\\nThe purpose for which LTD was established was to provide access\\n\\nto non-Mexican financial markets, and LTD conducted such business\\n\\nprimarily in the United States.    We therefore conclude that LTD’s\\n\\nactivities in the United States during each of the years in issue\\n\\ncan be characterized as qualitatively substantial.\\n\\n     In sum, we conclude that LTD \"engaged in * * * substantial,\\n\\nregular, or continuous ordinary business activity in the United\\n\\nStates.\"   Spermacet Whaling & Shipping Co. S/A v. Commissioner,\\n\\nsupra at 634.    We find that LTD’s activities in the United\\n\\nStates, conducted directly or through agents, included:\\n\\nReceiving client funds, monitoring interest rates, effecting\\n\\ntrades, collecting and disbursing dividends and interest,\\n\\nmaintaining customer account information, and valuing portfolios.\\n\\nAccordingly, we conclude that, during the years in issue, LTD was\\n\\n\"engaged in business in the United States\" within the meaning of\\n\\nsection 1.864-4(c)(5)(i), Income Tax Regs.    Consequently, we hold\\n\\nthat LTD was \"engaged in the active conduct of a banking,\\n\\nfinancing, or similar business in the United States\" pursuant to\\n\\nsection 1.864-4(c)(5)(i), Income Tax Regs.    A fortiori, we hold\\n\\nthat LTD was engaged in \"trade or business within the United\\n\\x0c                              - 104 -\\n\\nStates\" pursuant to section 864(b) for its taxable years June 30,\\n\\n1985 through 1989.\\n\\nB.   Whether Each Item of LTD\\'s Income\\n     Was Effectively Connected\\n\\n           1.   Character and Source Rules\\n\\n     Before deciding whether an item of income is \"effectively\\n\\nconnected with the conduct of trade or business within the United\\n\\nStates\" pursuant to section 882(a)(1), we must first decide the\\n\\ncharacter', '<|endoftext|> F.3d at 654. In accord with that statement, Ramadan\\n\\x0c6904                       HUSYEV v. MUKASEY\\nexamined whether the question of “changed circumstances,”\\nwhich it had determined to present a question of law, was\\ncommitted to the discretion of the Attorney General. See id.\\nat 655-56. Thus Ramadan points in a different direction from\\nthe text of the REAL ID Act and Afridi, and suggests that we\\nmust address whether the determination of “extraordinary cir-\\ncumstances” is a discretionary question even though we have\\ndetermined that it presents a question of law.2\\n\\n   We need not resolve this question, however, to reach a\\nresult in our case. It makes no difference whether or not we\\nare required to satisfy ourselves that a determination of “ex-\\ntraordinary circumstances” is not a discretionary decision. If\\nwe are not required to do so, then we have jurisdiction to\\ndecide “extraordinary circumstances” as a question of law. If\\nwe are required to satisfy ourselves that the issue is not a dis-\\ncretionary one, Ramadan itself supplies the authority for rul-\\ning that the issue is not discretionary. In its examination of the\\nparallel issue of “changed circumstances,” Ramadan firmly\\nrejects the contention that the issue is a discretionary question.\\nSee id. at 654-56. This reasoning of Ramadan is equally appli-\\ncable to the determination of “extraordinary circumstances” in\\nour case. The asylum statute provides that an alien seeking to\\nfile an asylum application more than one year after arrival\\nmust demonstrate either “changed circumstances” (as in Ram-\\nadan) or “extraordinary circumstances” (is in our case) “to the\\nsatisfaction of the Attorney General.” 8 U.S.C.\\n§ 1158(a)(2)(D). Ramadan made clear that the latter phrase\\n“is a specification of who is to make the decision, rather than\\na characterization of that decision itself.” Ramadan, 479 F.3d\\n  2\\n    We are aware of decisions from other circuits holding that discretion-\\nary decisions in general were not intended by Congress to be made\\nreviewable under the REAL ID Act. See, e.g., Chen v. U.S. Dept. of Jus-\\ntice, 434 F.3d 144, 151-55 (2d Cir. 2006); Grass v. Gonzales, 418 F.3d\\n876, 878-79 (8th Cir. 2005). These decisions support the view of Rama-\\ndan, but are in conflict with Afridi and seem to accord no effect to that part\\nof the REAL ID Act that provides for jurisdiction over questions of law\\nnotwithstanding the prohibition on review of discretionary determinations.\\n\\x0c                     HUSYEV v. MUKASEY                    6905\\nat 655. Because Congress ordinarily is very explicit when it\\nprovides for decisions “in the discretion” of the Attorney\\nGeneral, Ramadan concluded that no commitment to discre-\\ntion had been made in § 1158(a)(2)(D). See id. This reasoning\\nof Ramadan necessarily applies to both “changed circum-\\nstances” and “extraordinary circumstances.” In addition, we\\ncan find no difference in the nature of the two issues that\\nwould require or permit different results in Ramadan and our\\ncase.\\n\\n   The government argues, however, that the nature of the\\ndetermination of “extraordinary circumstances” is inherently\\nso lacking in measurable standards that it presents one of the\\n“rare instances where ‘statutes are drawn in such broad terms\\nthat in a given case there is no law to apply.’ ” Heckler v.\\nChaney, 470 U.S. 821, 830 (1985) (quoting Citizens to Pre-\\nserve Overton Park v. Volpe, 401 U.S. 402, 410 (1971), over-\\nruled on other grounds by Califano v. Sanders, 430 U.S. 99,\\n105 (1977)). If there is no law to apply, the issue presumably\\nwould not present a “question of law” within the meaning of\\nthe REAL ID Act. The government relies on cases holding\\nunreviewable determinations such as “exceptional and\\nextremely unusual hardship,” Romero-Torres v. Ashcroft, 327\\nF.3d 887, 891 (9th Cir. 2003), and “extreme cruelty,” Perales-\\nCumpean v. Gonzales, 429 F.3d 977, 981-84 (10th Cir. 2005).\\n\\n   We reject the government’s contention. The term “extraor-\\ndinary circumstances” is not rendered standardless by the fact\\nthat Congress left the Attorney General and other agencies the\\nauthority to refine', '<|endoftext|>ous par endroits avec mise en évidence d\\\\\\'une extravasation du produit de contraste à ce niveau se présentant comme une flaque spontanément hyperdense. Il est situé à 9 cm de l\\\\\\'origine de l\\\\\\'artère splénique et à 4.5 cm du hile splénique ([Figure 2](#f0002){ref-type=\"fig\"}). Il s\\\\\\'y associe un deuxième anévrysme sacciforme contigu situé en aval à celui précédemment décrit mesurant 18 mm de grand axe et 4 mm au niveau de son collet ([Figure 2](#f0002){ref-type=\"fig\"}). Multiples foyers d\\\\\\'infarctus splénique ([Figure 2](#f0002){ref-type=\"fig\"}); mort fœtal in utéro objectivé par l\\\\\\'absence de rehaussement du fœtus ni du versant fœtal du placenta ([Figure 3](#f0003){ref-type=\"fig\"}).\\n\\n![Épanchement liquidien intra péritonéal de grande abondance](PAMJ-34-63-g001){#f0001}\\n\\n![Anévrysme sacciforme de l´artère splénique proximale mesurant 3 cm de grand axe et 4 mm au niveau de son collet, avec mise en évidence d´une extravasation du produit de contraste à ce niveau se présentant comme une flaque spontanément hyperdense](PAMJ-34-63-g002){#f0002}\\n\\n![Mort fœtal in utéro objectivée par l´absence de rehaussement du fœtus ni du versant fœtal du placenta](PAMJ-34-63-g003){#f0003}\\n\\nUne heure après l\\\\\\'examen, la patiente a eu un état de choc hémorragique (tension artérielle 8/5 mmHg, fréquence cardiaque à 120 bpm) avec hémoglobine de contrôle à 6 g/dl. Elle a bénéficié d\\\\\\'un remplissage vasculaire 1000 ml de Voluven et d\\\\\\'une transfusion sanguine et après une brève réanimation la patiente a eu une laparotomie médiane objectivant un hémo péritoine de grande abondance évalué à 1200 ml provenant d\\\\\\'un anévrysme rompu de l\\\\\\'artère splénique. La patiente a bénéficiée d\\\\\\'une splénectomie avec pancréatectomie caudale emportant les deux anévrysmes associés à une césarienne. Bonne évolution par la suite avec stabilisation hémodynamique et la sortie a été autorisée après 10 jours de l\\\\\\'opération. �� noter que la patiente a été proposée pour embolisation artérielle qui n\\\\\\'était pas faite par défaut de matériel (coil).\\n\\nDiscussion {#sec3}\\n==========\\n\\nLa rupture d\\\\\\'anévrysme de l\\\\\\'artère splénique en cours de grossesse est une affection rare mais de pronostic redoutable. En 1993, Angelakis *et al.* \\\\[[@cit0001], [@cit0002]\\\\] rapportait une mortalité maternelle à 75%, une mortalité fœtale à 90%. L\\\\\\'incidence de l\\\\\\'anévrysme de l\\\\\\'artère splénique dans la population générale est estimée à moins de 1% \\\\[[@cit0001], [@cit0002]\\\\] mais s\\\\\\'élève avec l\\\\\\'âge pour dépasser les 10% après 60 ans. La grossesse contribue à l\\\\\\'apparition et/ou à la rupture de l\\\\\\'anévrysme par 2 mécanismes: la fragilisation des parois vasculaires liée à un processus dégénératif gravidique (dysplasie des fibres de la média, dédoublement et rupture de la lame élastique interne, fragmentation des fibres élastiques) \\\\[[@cit0001]-[@cit0003]\\\\]; l\\\\\\'hypertension portale induite par l\\\\\\'augmentation du volume utérin. Cette association \"hypertension-fragilisation vasculaire\" peut être aggravée par une anomalie congénitale du tissu conjonctif et par l\\\\\\'augmentation du débit vasculaire splénique au cours de la grossesse. D\\\\\\'autres localisations vasculaires sont affectées de la même manière comme le montrent l\\\\\\'augmentation du risque de dissection aortique (', '<|endoftext|>= 0x8013\\n\\tETHERTYPE_SG_NETGAMES             = 0x8014\\n\\tETHERTYPE_SG_RESV                 = 0x8015\\n\\tETHERTYPE_SIMNET                  = 0x5208\\n\\tETHERTYPE_SLOWPROTOCOLS           = 0x8809\\n\\tETHERTYPE_SNA                     = 0x80d5\\n\\tETHERTYPE_SNMP                    = 0x814c\\n\\tETHERTYPE_SONIX                   = 0xfaf5\\n\\tETHERTYPE_SPIDER                  = 0x809f\\n\\tETHERTYPE_SPRITE                  = 0x500\\n\\tETHERTYPE_STP                     = 0x8181\\n\\tETHERTYPE_TALARIS                 = 0x812b\\n\\tETHERTYPE_TALARISMC               = 0x852b\\n\\tETHERTYPE_TCPCOMP                 = 0x876b\\n\\tETHERTYPE_TCPSM                   = 0x9002\\n\\tETHERTYPE_TEC                     = 0x814f\\n\\tETHERTYPE_TIGAN                   = 0x802f\\n\\tETHERTYPE_TRAIL                   = 0x1000\\n\\tETHERTYPE_TRANSETHER              = 0x6558\\n\\tETHERTYPE_TYMSHARE                = 0x802e\\n\\tETHERTYPE_UBBST                   = 0x7005\\n\\tETHERTYPE_UBDEBUG                 = 0x900\\n\\tETHERTYPE_UBDIAGLOOP              = 0x7002\\n\\tETHERTYPE_UBDL                    = 0x7000\\n\\tETHERTYPE_UBNIU                   = 0x7001\\n\\tETHERTYPE_UBNMC                   = 0x7003\\n\\tETHERTYPE_VALID                   = 0x1600\\n\\tETHERTYPE_VARIAN                  = 0x80dd\\n\\tETHERTYPE_VAXELN                  = 0x803b\\n\\tETHERTYPE_VEECO                   = 0x8067\\n\\tETHERTYPE_VEXP                    = 0x805b\\n\\tETHERTYPE_VGLAB                   = 0x8131\\n\\tETHERTYPE_VINES                   = 0xbad\\n\\tETHERTYPE_VINESECHO               = 0xbaf\\n\\tETHERTYPE_VINESLOOP               = 0xbae\\n\\tETHERTYPE_VITAL                   = 0xff00\\n\\tETHERTYPE_VLAN                    = 0x8100\\n\\tETHERTYPE_VLTLMAN                 = 0x8080\\n\\tETHERTYPE_VPROD                   = 0x805c\\n\\tETHERTYPE_VURESERVED              = 0x8147\\n\\tETHERTYPE_WATERLOO                = 0x8130\\n\\tETHERTYPE_WELLFLEET               = 0x8103\\n\\tETHERTYPE_X25                     = 0x805\\n\\tETHERTYPE_X75                     = 0x801\\n\\tETHERTYPE_XNSSM                   = 0x9001\\n\\tETHERTYPE_XTP                     = 0x817d\\n\\tETHER_ADDR_LEN                    = 0x6\\n\\tETHER_CRC_LEN                     = 0x4\\n\\tETHER_CRC_POLY_BE                 = 0x4c11db6\\n\\tETHER_CRC_POLY_LE                 = 0xedb88320\\n\\tETHER_HDR_LEN                     = 0xe\\n\\tETHER_MAX_LEN                     = 0x5ee\\n\\tETHER_MAX_LEN_JUMBO               = 0x233a\\n\\tETHER_MIN_LEN                     = 0x40\\n\\tETHER_PPPOE_ENCAP_LEN             = 0x8\\n\\tETHER_TYPE_LEN                    = 0x2\\n\\tETHER_VLAN_ENCAP_LEN              = 0x4\\n\\tEVFILT_AIO                        = 0x2\\n\\tEVFILT_PROC                       = 0x4\\n\\tEVFILT_READ                       = 0x0\\n\\tEVFILT_SIGNAL                     = 0x5\\n\\tEVFILT_SYSCOUNT                   = 0x7\\n\\tEVFILT_TIMER                      = 0x6\\n\\tEVFILT_VNODE                      = 0x3\\n\\tEVFILT_WRITE                      = 0x1\\n\\tEV_ADD                            = 0x1\\n\\tEV_CLEAR                          = 0x20\\n\\tEV_DELETE                         = 0x2\\n\\tEV_DISABLE                        = 0x8\\n\\tEV_ENABLE                         = 0x4\\n\\tEV_EOF                            = 0x8000\\n\\tEV_ERROR                          = 0x4000\\n\\tEV_FLAG1                          = 0x2000\\n\\tEV_ONESHOT                        = 0x10\\n\\tEV_SYSFLAGS                       = 0xf000\\n\\tEXTA                              = 0x4b00\\n\\tEXTATTR_CMD_START                 = 0x1\\n\\tEXTATTR_CMD_STOP                  = 0x2\\n\\tEXTATTR_NAMESPACE_SYSTEM          = 0x2\\n', '<|endoftext|>\\tEVFILT_PROC                       = -0x5\\n\\tEVFILT_READ                       = -0x1\\n\\tEVFILT_SIGNAL                     = -0x6\\n\\tEVFILT_SYSCOUNT                   = 0xf\\n\\tEVFILT_THREADMARKER               = 0xf\\n\\tEVFILT_TIMER                      = -0x7\\n\\tEVFILT_USER                       = -0xa\\n\\tEVFILT_VM                         = -0xc\\n\\tEVFILT_VNODE                      = -0x4\\n\\tEVFILT_WRITE                      = -0x2\\n\\tEV_ADD                            = 0x1\\n\\tEV_CLEAR                          = 0x20\\n\\tEV_DELETE                         = 0x2\\n\\tEV_DISABLE                        = 0x8\\n\\tEV_DISPATCH                       = 0x80\\n\\tEV_DISPATCH2                      = 0x180\\n\\tEV_ENABLE                         = 0x4\\n\\tEV_EOF                            = 0x8000\\n\\tEV_ERROR                          = 0x4000\\n\\tEV_FLAG0                          = 0x1000\\n\\tEV_FLAG1                          = 0x2000\\n\\tEV_ONESHOT                        = 0x10\\n\\tEV_OOBAND                         = 0x2000\\n\\tEV_POLL                           = 0x1000\\n\\tEV_RECEIPT                        = 0x40\\n\\tEV_SYSFLAGS                       = 0xf000\\n\\tEV_UDATA_SPECIFIC                 = 0x100\\n\\tEV_VANISHED                       = 0x200\\n\\tEXTA                              = 0x4b00\\n\\tEXTB                              = 0x9600\\n\\tEXTPROC                           = 0x800\\n\\tFD_CLOEXEC                        = 0x1\\n\\tFD_SETSIZE                        = 0x400\\n\\tFF0                               = 0x0\\n\\tFF1                               = 0x4000\\n\\tFFDLY                             = 0x4000\\n\\tFLUSHO                            = 0x800000\\n\\tFSOPT_ATTR_CMN_EXTENDED           = 0x20\\n\\tFSOPT_NOFOLLOW                    = 0x1\\n\\tFSOPT_NOINMEMUPDATE               = 0x2\\n\\tFSOPT_PACK_INVAL_ATTRS            = 0x8\\n\\tFSOPT_REPORT_FULLSIZE             = 0x4\\n\\tF_ADDFILESIGS                     = 0x3d\\n\\tF_ADDFILESIGS_FOR_DYLD_SIM        = 0x53\\n\\tF_ADDFILESIGS_RETURN              = 0x61\\n\\tF_ADDSIGS                         = 0x3b\\n\\tF_ALLOCATEALL                     = 0x4\\n\\tF_ALLOCATECONTIG                  = 0x2\\n\\tF_BARRIERFSYNC                    = 0x55\\n\\tF_CHECK_LV                        = 0x62\\n\\tF_CHKCLEAN                        = 0x29\\n\\tF_DUPFD                           = 0x0\\n\\tF_DUPFD_CLOEXEC                   = 0x43\\n\\tF_FINDSIGS                        = 0x4e\\n\\tF_FLUSH_DATA                      = 0x28\\n\\tF_FREEZE_FS                       = 0x35\\n\\tF_FULLFSYNC                       = 0x33\\n\\tF_GETCODEDIR                      = 0x48\\n\\tF_GETFD                           = 0x1\\n\\tF_GETFL                           = 0x3\\n\\tF_GETLK                           = 0x7\\n\\tF_GETLKPID                        = 0x42\\n\\tF_GETNOSIGPIPE                    = 0x4a\\n\\tF_GETOWN                          = 0x5\\n\\tF_GETPATH                         = 0x32\\n\\tF_GETPATH_MTMINFO                 = 0x47\\n\\tF_GETPROTECTIONCLASS              = 0x3f\\n\\tF_GETPROTECTIONLEVEL              = 0x4d\\n\\tF_GLOBAL_NOCACHE                  = 0x37\\n\\tF_LOG2PHYS                        = 0x31\\n\\tF_LOG2PHYS_EXT                    = 0x41\\n\\tF_NOCACHE                         = 0x30\\n\\tF_NODIRECT                        = 0x3e\\n\\tF_OK                              = 0x0\\n\\tF_PATHPKG_CHECK                   = 0x34\\n\\tF_PEOFPOSMODE                     = 0x3\\n\\tF_PREALLOCATE                     = 0x2a\\n\\tF_PUNCHHOLE                       = 0x63\\n\\tF_RDADV', '<|endoftext|> mes de demanda tanto de pesos como de dólares, por lo que veremos cómo se comporta la tasa\", analizó el director de MB Inversiones.\"El tipo de cambio podría dar alguna sorpresa hacia fin de año cuando haya más pesos en la calle por cuestiones estacionales. Por eso, la sugerencia es diversificar monedas, preferentemente con bonos cortos en dólares\", remató el director de inversiones de GMA Capital.<|endoftext|>(Recasts 1st paragraph, adds Richard Li\\'s stake in HKT Trust in the 6th paragraph, reasons for the weak response in the 7th paragraph, use of net proceeds of the IPO in the 8th paragraph.)\\n\\nHONG KONG (MarketWatch) -- The initial public offering of HKT Trust & HKT Ltd. (6823.HK), the telecommunications trust spun off from PCCW Ltd. (0008.HK), drew a lukewarm response from retail investors, who subscribed to just over a tenth of the shares on offer in the deal\\'s retail portion, according to allotment results released Monday.\\n\\nThe trust, which is scheduled to begin trading on the Hong Kong stock exchange Tuesday after raising US$1.2 billion in its IPO, said in a statement that 1.2% of the 2.05 billion units on offer were allocated to retail investors. The trust had originally set aside 10% of the available units for the retail tranche.\\n\\nHKT Trust said the unsubscribed units of the retail tranche have been re-allocated to the institutional tranche, which amounted to 98.8% of the shares on offer following the re-allocation. It added that the institutional tranche was moderately oversubscribed, but didn\\'t elaborate.\\n\\nThe offering was likely hurt by the volatility in global market conditions. Hong Kong\\'s benchmark Hang Seng Index is down more than 9% so far this month. The Dow Jones Industrial Average has lost 7.6% over the last two weeks.\\n\\nThat the deal is going ahead at all, despite the jittery markets, counts as a victory for PCCW Chairman Richard Li, the younger son of Hong Kong\\'s richest man, Li Ka-shing.\\n\\nHowever, in an apparent indication of the headwinds the deal faced, he ended up subscribing to as much as 12.5% of the units on offer through various vehicles, far more than the less-than 3% to which he was automatically entitled as a result of his shareholding in PCCW.\\n\\nThe weak sentiment toward the deal was partly due to concerns about the limited growth prospects of the trust\\'s underlying businesses--mainly local fixed-line and broadband services--given Hong Kong\\'s saturated market. Such concerns, coupled with the weak markets, led PCCW, the city\\'s dominant fixed-line operator, to price the trust\\'s units at the bottom of its indicative price range at HK$4.53 each last week.\\n\\nHKT Trust estimated the net proceeds of the IPO were HK$8.84 billion (US$1.13 billion), of which HK$7.8 billion would be used to repay the debts of its telecommunications businesses.\\n\\nIntraday Data provided by SIX Financial Information and subject to terms of use.\\nHistorical and current end-of-day data provided by SIX Financial Information. Intraday data\\ndelayed per exchange requirements. S&P/Dow Jones Indices (SM) from Dow Jones & Company, Inc.\\nAll quotes are in local exchange time. Real time last sale data provided by NASDAQ. More\\ninformation on NASDAQ traded symbols and their current financial status. Intraday\\ndata delayed 15 minutes for Nasdaq, and 20 minutes for other exchanges. S&P/Dow Jones Indices (SM)\\nfrom Dow Jones & Company, Inc. SEHK intraday data is provided by SIX Financial Information and is\\nat least 60-minutes delayed. All quotes are in local exchange time.<|endoftext|>The US military will formally end its ban on women serving in front-line combat roles, officials said on Wednesday, in a move that could open thousands of fighting jobs to female service members.\\n\\nThe move knocks down another societal barrier, after the Pentagon scrapped its \"Don\\'t Ask, Don\\'t Tell\" ban in 2011 on gays and lesbians serving openly in the military.\\n\\nThe decision by outgoing Defense Secretary Leon Panetta is expected to be formally announced on Thursday and comes after 11 years of non-stop war that has seen dozens of women killed in Iraq and Afghanistan.\\n\\nThey have represented around 2 percent of the casualties of those unpopular, costly wars, and some 12 percent of those deployed for the war effort, in which there were often no clearly defined front', \"<|endoftext|> month, the sharp rally in the U.S. dollar following the jobs number reflects a rush to adjust expectations and positioning,” said Kathy. Lien, director of currency research for GFT.\\n\\nOthers note the Fed is still concerned about the moribund housing market, which could derive support from the more central-bank purchases of mortgage-related debt if it lowers borrowing costs.\\n\\n“We do not see this report as a game-changer for the Fed as we suspect that further evidence that this performance is being sustained will be required for the Fed to be assured of a transition to a self-sustaining recovery,” Millan Mulraine, senior macro strategist at TD Securities, wrote in emailed comments.\\n\\nFor the week, the euro remains down 0.6% against the dollar.\\n\\nThe dollar index has advanced 0.1% from last Friday.\\n\\nJapan, U.K., Australia\\n\\nAmong other major currencies, the Japanese yen weakened much more, after being under pressure since Asian hours. Finance Minister Jun Azumi said Friday trade in the currency appeared to be “one-sided” and could prompt “decisive steps.” See report on Azumi’s latest intervention warning.\\n\\nJapan last intervened in the forex market in October when its currency was last near current levels, selling yen to push the unit lower, as the strong currency has hurt the nation’s important export sector. Japanese officials have warned recently of fresh moves to push down the yen but have yet to act.\\n\\n“The Bank of Japan and the Ministry of Finance will be rejoicing because the Japanese are the single biggest beneficiaries of today’s strong jobs number,” GFT’s Lien said. “If nonfarm payrolls were abysmally weak, dollar-yen would have probably broken below ¥76, forcing the MoF to intervene in the yen but now, the pressure to intervene has been instantly lifted.”\\n\\nThe dollar\\nUSDJPY, +1.01%\\ntraded at ¥76.62, up from ¥76.18 late Thursday. The move erased most of the dollar’s weekly drop to 0.1% from last Friday.\\n\\nAfter being supported earlier by positive U.K. economic data, the British pound\\nGBPUSD, -0.1430%\\nlately turned up to $1.5817, compared to $1.5799.\\n\\nSterling gained 0.5% on the week, and is up 1.7% already this year even though many expect the Bank of England next week to expand its own easing policies.\\n\\nThe Australian dollar\\nAUDUSD, -0.0938%\\nsometimes seen as a gauge of investors’ appetite for riskier assets, turned up to $1.0777, from $1.0708 Thursday.\\n\\nIntraday Data provided by SIX Financial Information and subject to terms of use.\\nHistorical and current end-of-day data provided by SIX Financial Information. Intraday data\\ndelayed per exchange requirements. S&P/Dow Jones Indices (SM) from Dow Jones & Company, Inc.\\nAll quotes are in local exchange time. Real time last sale data provided by NASDAQ. More\\ninformation on NASDAQ traded symbols and their current financial status. Intraday\\ndata delayed 15 minutes for Nasdaq, and 20 minutes for other exchanges. S&P/Dow Jones Indices (SM)\\nfrom Dow Jones & Company, Inc. SEHK intraday data is provided by SIX Financial Information and is\\nat least 60-minutes delayed. All quotes are in local exchange time.<|endoftext|>Q:\\n\\nIf $x^m + y^m = z^m$ has no solutions and $m \\\\mid n$, then $x^n + y^n = z^n$ has no solutions\\n\\nWe know from Fermat's Last Theorem that $x^n + y^n = z^n$ has no solutions for $n\\\\geq 3$, but if we assume we did not know FLT, how could you prove that \\n                          $x^n + y^n = z^n$\\nhas no solutions if we know \\n                          $x^m$ + $y^m$ $\\\\neq$ $z^m$ \\nand $m \\\\mid n$? It seems obvious from just looking at the statement along with the information given, however I am unsure how it could be shown? \\n\\nA:\\n\\nWrite $n=mk$ and suppose that $x^n+y^n=z^n$. Then $(x^k)^m + (y^k)^m = (z^k)^m$, so $(x^k,y^k,z^k)$ is a solution to $x^m+y^m=z^m$.\", \"<|endoftext|> state, has publicly stated that she supported the coup that has created the conditions for the criminalization of protest and the murder of human rights activists in Honduras and around the world.” At the event, women spoke of fair wages, environmental rights, and state violence at home and abroad — rarely of women directly. “There’s been a kind of institutional feminism that’s been promoted by women like Hillary Clinton,” Ana Martina, a community organizer originally from Mexico, said while breastfeeding her 10-month-old daughter. “Feminism is more holistic. For a woman to think that they’re being represented by a feminist in Hillary is totally wrong. She’s a right-wing candidate, no better or worse than Trump.” Trump’s sexism But the specter of a possible Trump presidency — and the ways in which the Republican nominee has spoken to and about women — also served for many observers as a reminder of the progress women have yet to make.\\n\\nPhoto: Alice Speri<|endoftext|>Stock futures up after jobless claims, ECB\\n\\nCentral banks in Europe keep rates unchanged\\n\\nKateGibson\\n\\nNEW YORK (MarketWatch) — Stock-market futures pointed to another day of gains for Wall Street Thursday as jobless claims illustrated ongoing economic improvement in the U.S. and signals from Europe and China were also supportive.\\n\\nNew applications for jobless benefits rose slightly last week, but the level of claims revealed little change over the past few months and were consistent with a modestly improving U.S. labor market.Jobless claims rise by 4,000 to 371,000.\\n\\n“We see decent if unspectacular jobs growth. In Europe the recession is not worsening, Chinese growth is accelerating and in the U.S., the worst of the fiscal cliff is behind us, and the impact of tax cuts is less than what the CBO [Congressional Budget Office] initially scored, so there is the potential to lift confidence and as a result business spending,” said Mark Luschini, chief investment strategist at Janney Montgomery Scott.\\n\\nBlowing out analysts’ expectations, China’s exports surged 14.1% in December from a year earlier, compared with a 2.9% gain in November. The trade surplus shot up to $31.6 billion from $19.6 billion the prior month. Read: China's exports surge, boosting trade surplus\\n\\nData points and speeches\\n\\nU.S. November job openings and wholesale inventories are due for release at 10 a.m. Eastern.\\n\\nA handful of Fed speeches are scheduled for Thursday as well. Among those, Kansas City Fed President Esther George will present her economic outlook to the Central Exchange in Kansas City at 1:10 p.m. Eastern and St. Louis Fed President James Bullard speaks at the Wisconsin Economic Forecast Luncheon at 2 p.m. Eastern.\\n\\nReuters\\n\\nEmployees work at a Nestle factory in Shanghai in this October 18, 2012 file photo.\\n\\n“The speeches will be followed closely for signals on how hawkish they are. We assess both to be soft hawks,” said analysts at Danske Bank. Both are voting members of the policy-making FOMC.\\n\\nIn Europe, the Bank of England and European Central Bank concluded policy meetings with no change in key rates.\\n\\nEurope, Asia, commodities\\n\\nIn overseas markets, European stocks struggled for direction on central-bank-meetings day, while Asia stocks gained after that trade data out of China. A weaker yen boosted exporters in Japan, helping the Nikkei Stock Average\\nNIK, +0.30%\\nto extend gains. Read: Asia stocks get a lift from China trade data\\n\\nCrude-oil prices moved higher, with the February contract\\nUS:CLG3\\nup $1, or 1% to $94.08 a barrel, also inspired by the China data.\\n\\nGold prices also moved higher, with February gold\\nUS:GCG3\\nup $5.30, or 0.3%, to $1,660.80 an ounce.\\n\\nIntraday Data provided by SIX Financial Information and subject to terms of use.\\nHistorical and current end-of-day data provided by SIX Financial Information. Intraday data\\ndelayed per exchange requirements. S&P/Dow Jones Indices (SM) from Dow Jones & Company, Inc.\\nAll quotes are in local exchange time. Real time last sale data provided by NASDAQ. More\\ninformation on NASDAQ traded symbols and their current financial status. Intraday\\ndata delayed 15 minutes for Nasdaq, and 20 minutes for other exchanges. S&P/Dow Jones Indices (SM)\\nfrom Dow Jones & Company, Inc. SEHK intraday data is provided by SIX Financial Information and is\\nat least 60-minutes delayed. All quotes are in local exchange\", '<|endoftext|>NFLOG                         = 0xef\\n\\tDLT_NG40                          = 0xf4\\n\\tDLT_NULL                          = 0x0\\n\\tDLT_PCI_EXP                       = 0x7d\\n\\tDLT_PFLOG                         = 0x75\\n\\tDLT_PFSYNC                        = 0x12\\n\\tDLT_PPI                           = 0xc0\\n\\tDLT_PPP                           = 0x9\\n\\tDLT_PPP_BSDOS                     = 0x10\\n\\tDLT_PPP_ETHER                     = 0x33\\n\\tDLT_PPP_PPPD                      = 0xa6\\n\\tDLT_PPP_SERIAL                    = 0x32\\n\\tDLT_PPP_WITH_DIR                  = 0xcc\\n\\tDLT_PPP_WITH_DIRECTION            = 0xa6\\n\\tDLT_PRISM_HEADER                  = 0x77\\n\\tDLT_PRONET                        = 0x4\\n\\tDLT_RAIF1                         = 0xc6\\n\\tDLT_RAW                           = 0xc\\n\\tDLT_RIO                           = 0x7c\\n\\tDLT_SCCP                          = 0x8e\\n\\tDLT_SITA                          = 0xc4\\n\\tDLT_SLIP                          = 0x8\\n\\tDLT_SLIP_BSDOS                    = 0xf\\n\\tDLT_STANAG_5066_D_PDU             = 0xed\\n\\tDLT_SUNATM                        = 0x7b\\n\\tDLT_SYMANTEC_FIREWALL             = 0x63\\n\\tDLT_TZSP                          = 0x80\\n\\tDLT_USB                           = 0xba\\n\\tDLT_USB_LINUX                     = 0xbd\\n\\tDLT_USB_LINUX_MMAPPED             = 0xdc\\n\\tDLT_USER0                         = 0x93\\n\\tDLT_USER1                         = 0x94\\n\\tDLT_USER10                        = 0x9d\\n\\tDLT_USER11                        = 0x9e\\n\\tDLT_USER12                        = 0x9f\\n\\tDLT_USER13                        = 0xa0\\n\\tDLT_USER14                        = 0xa1\\n\\tDLT_USER15                        = 0xa2\\n\\tDLT_USER2                         = 0x95\\n\\tDLT_USER3                         = 0x96\\n\\tDLT_USER4                         = 0x97\\n\\tDLT_USER5                         = 0x98\\n\\tDLT_USER6                         = 0x99\\n\\tDLT_USER7                         = 0x9a\\n\\tDLT_USER8                         = 0x9b\\n\\tDLT_USER9                         = 0x9c\\n\\tDLT_WIHART                        = 0xdf\\n\\tDLT_X2E_SERIAL                    = 0xd5\\n\\tDLT_X2E_XORAYA                    = 0xd6\\n\\tDT_BLK                            = 0x6\\n\\tDT_CHR                            = 0x2\\n\\tDT_DIR                            = 0x4\\n\\tDT_FIFO                           = 0x1\\n\\tDT_LNK                            = 0xa\\n\\tDT_REG                            = 0x8\\n\\tDT_SOCK                           = 0xc\\n\\tDT_UNKNOWN                        = 0x0\\n\\tDT_WHT                            = 0xe\\n\\tECHO                              = 0x8\\n\\tECHOCTL                           = 0x40\\n\\tECHOE                             = 0x2\\n\\tECHOK                             = 0x4\\n\\tECHOKE                            = 0x1\\n\\tECHONL                            = 0x10\\n\\tECHOPRT                           = 0x20\\n\\tEVFILT_AIO                        = -0x3\\n\\tEVFILT_EXCEPT                     = -0xf\\n\\tEVFILT_FS                         = -0x9\\n\\tEVFILT_MACHPORT                   = -0x8\\n\\tEVFILT_PROC                       = -0x5\\n\\tEVFILT_READ                       = -0x1\\n\\tEVFILT_SIGNAL                     = -0x6\\n\\tEVFILT_SYSCOUNT                   = 0xf\\n\\tEVFILT_THREADMARKER               = 0xf\\n\\tEVFILT_TIMER                      = -0x7\\n\\tEVFILT_USER                       = -0xa\\n\\tEVFILT_VM                         = -0xc\\n\\tEVFILT_VNODE                      = -0x4\\n\\tEVFILT_WRITE                      = -0x2\\n\\tEV_ADD                            = 0x1\\n\\tEV_CLEAR                          = 0x20\\n\\tEV_DELETE                         = 0x2\\n\\tEV', '<|endoftext|>57 Ab urbe condita). The denomination \"AD 4\" for this year has been used since the early medieval period, when the Anno Domini calendar era became the prevalent method in Europe for naming years.\\n\\nEvents\\n\\nBy place\\n\\nRoman Empire \\n Emperor Augustus summons Tiberius to Rome, and names him his heir and future emperor.  At the same time, Agrippa Postumus, the last son of Marcus Vipsanius Agrippa, is also adopted and named as Augustus\\' heir.\\n Tiberius also adopts Germanicus as his own heir.\\n The Lex Aelia Sentia regulates the manumission of slaves.\\n A pact of non-aggression and friendship is signed between the Roman Empire, represented by Tiberius, and the German tribe the Cherusci, represented by their King Segimer. Arminius and Flavus, sons of Segimer, are brought into the Roman army as leaders of the auxiliary troops.\\n Julia the Elder returns from exile to live in Rhegium in disgrace.\\n Augustus pardons Gnaeus Cornelius Cinna Magnus, along with Aemilia Lepida, the granddaughter of Marcus Aemilius Lepidus, for alleged involvement in a conspiracy against the emperor.\\n\\nMiddle East \\n King Phraataces and Queen Musa of Parthia are overthrown and killed, the crown being offered to Orodes III of Parthia—the beginning of the interregnum.\\n\\nKorea \\n Namhae Chachaung succeeds Bak Hyeokgeose as king of the Korean kingdom of Silla (traditional date).\\n\\nChina \\n Emperor Ping of Han marries Empress Wang (Ping), daughter of Wang Mang, cementing his influence.\\n Wang Mang is given the title \"superior duke\".\\n\\nBy topic\\n\\nArts and sciences \\n Nicolaus of Damascus writes the 15-volume History of the World.\\n\\nBirths \\n Columella, Roman Latin writer (d. AD 70)\\n Daemusin, Korean king of Goguryeo (d. AD 44)\\n Publius Quinctilius Varus (the Younger), Roman nobleman (d. AD 27)\\n Some believe that Jesus of Nazareth was actually born this year\\n\\nDeaths \\n February 21 – Gaius Caesar, son of Marcus Vipsanius Agrippa and Julia the Elder (b. 20 BC)\\n June 26 – Ariobarzanes II, Roman client king of Armenia (b. 40 BC)\\n Gaius Asinius Pollio, Roman orator, poet and historian (b. 65 BC)\\n Hyeokgeose, Korean king of Silla (b. 75 BC)\\n Lucius Cornelius Lentulus, Roman consul\\n\\nNotes\\n\\nSee also \\nAb urbe condita\\n\\nReferences\\n\\nSources \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nals:0er#Johr 4<|endoftext|>Q:\\n\\nCheck for keyword in first and last line\\n\\ni have the following string\\n-----BEGIN CERTIFICATE REQUEST-----\\nMIICtzCCAZ8CAQAwcjELMAkGA1UEBhMCQVUxETAPBgNVBAgMCFZpY3RvcmlhMRIw\\nEAYDVQQHDAlNZWxib3VybmUxDzANBgNVBAoMBk1LVEVTVDELMAkGA1UECwwCSVQx\\nHjAcBgNVBAMMFWRuc3Rlc3Q0LnNzbHRlY2hzLmNvbTCCASIwDQYJKoZIhvcNAQEB\\nBQADggEPADCCAQoCggEBANRhwPJLWYTFS19kgWLs49wR1BR+qaeET26BHT4ZdmQi\\niDKOFn1VzuBhv6bIWJpGrkBqM5oKkB6ckAjUlMKUNeCTiA0NAqvrAgM19GptzgIq\\n-----END CERTIFICATE REQUEST-----\\n\\nI would like to be able to check the first and last line for the word \"NEW\" if its missing, then it should be added in.\\nThe result should be like this:\\n-----BEGIN NEW CERTIFICATE REQUEST-----\\nMIICtzCCAZ8CAQAwcjELMAkGA1UEBhMCQVUxETAPBgNVBAgMCFZpY3RvcmlhMRIw\\nEAYDVQQHDAlNZWxib3VybmUxDzANBgNVBAoMBk1LVEVTVDELMAkGA1UECwwCSVQx']\n","layer 7\n","513 [\"<|endoftext|>\\nPower\\nA vacuum cleaner with powerful suction can depend on many things but the wattage of the motor is a very good indicator of its power. The more Watts a vacuum has, the more powerful it is. A good figure for a cylinder cleaner is around 1400 Watts, and 1300 for an upright.\\n\\nBag or Bagless\\nThis seems to be the latest, and most confusing, feature on many vacuum cleaners. Until recently, all vacuum cleaners collected dirt in a bag. However, this changed when Dyson vacuum cleaners came on to the market. The main disadvantage with vacuums that use bags is loss of suction as the bag fills up. A bagless vacuum like the Dyson DC07 upright vacuum cleaner does not use dust bags but induces suction by means of centrifugal force. Vacuums that don’t use bags don’t loose suction power. Bagless vacuum cleaners tend to be more expensive that ones that use bags. Another disadvantage of bagless vacuum cleaners is empty the dust cup. Bagged models can be more hygienic because the dirt and dust is collected in a sealed bag. If you or anyone in your house is asthmatic then it is better to go for a bagged cleaner.\\n\\nFiltration\\nWhen a vacuum sucks up dirt some particles are expelled out the exhaust of the vacuum. The type of filter determines the size and number of particles that are expelled. There are now three types of filters on offer. Standard filtration is now usually found in only low cost vacuum cleaners. If you buy a vacuum cleaner with standard filtration, make sure you look for one with more than one filtration level. S-class and HEPA filters greatly reduce the number and size of particles that are emitted back into the air. These types of filter retain up to 99.97% of dust, down to 0.3 microns (microscopic in size). Allergy sufferers should only consider using HEPA filters. There are now many top rated HEPA vacuum cleaners, the Eureka 3684D canister vacuum being one of the best.\\n\\nOther Types of Vacuum Cleaners\\nThere are many other types of vacuum cleaners offering specialized cleaning capabilities. Stick vacuum cleaner are light weight and meant for small cleaning jobs and are great for high area such as the tops of curtains. Handheld vacuum cleaners are also meant for clearing up spills and typically come with a wall mounting and charging unit.\\n\\nSteam vacuum cleaners use steam to lift out dirt from carpets. These are very effective in getting out ground in dirt. They are not that difficult to use and a good quality steam vacuum like the Hoover SteamVac should leave the carpet dry to the touch after use. Finally, Wet and Dry vacuum cleaners are versatile units. They can be used in dry mode exactly like their more common counterparts. But they can also be used to clean your carpet with water and carpet shampoo, leaving your carpet clean and sweet smelling. The Eureka InstaRinse Cleaning System is an excellent wet to dry vacuum.\\n\\nThere are many good vacuum cleaner products on the market but all of them are different and meet the needs of different customers.You may choose a top of the line Kirby Vacuum Cleaner, a mid priced Oreck, a Hoover, or any of the lower priced vacuums on the market. Establish your priority list and set a budget before buying your vacuum cleaner. A good vacuum cleaner is an investment in your home and your health. Make the right choice for your family and lifestyle!<|endoftext|>2017 Empire Slovak Open – Singles\\n\\nKateřina Siniaková was the defending champion, but chose to participate at the 2017 Internazionali BNL d'Italia instead.\\n\\nMarkéta Vondroušová won the title, defeating Verónica Cepede Royg in the final, 7–5, 7–6(7–3).\\n\\nSeeds\\n\\nDraw\\n\\nFinals\\n\\nTop half\\n\\nBottom half\\n\\nReferences\\nMain Draw\\n\\nEmpire Slovak Open - Singles<|endoftext|>Police say the woman smiled and waved at the man, who then screamed and asked what she was looking at.\\n\\nPolice say he tackled her from behind and began punching her, leaving lacerations on her neck, chest and right ear. The man fled and dropped several items from a grocery bag, including a water bottle, spoon and food containers.\\n\\nPolice last year responded to several violent assaults on the Greenway; most of the victims were women.<|endoftext|>Choanograptis argyrocyma\\n\\nChoanograptis argyrocyma is a species of moth of the family Tortricidae. It is found in New Guinea.\\n\\nReferences\\n\\nCategory:Moths described in 1953\\nCategory:Archipini<|endoftext|>Malik Sikandar Khan\\n\\nMalik Sikandar Khan is a\", '<|endoftext|>.](e-69-0o285-fig1){#Fap1}\\n\\n![Partial crystal packing of the title compound. The C14---H···O2 and C13---H···π connected pairs of molecules are linked into a chain by C4---H4···π interactions.](e-69-0o285-fig2){#Fap2}\\n\\nCrystal data {#tablewrapcrystaldatalong}\\n============\\n\\n  ------------------------ ---------------------------------------\\n  C~21~H~18~O~2~S          *Z* = 2\\n  *M~r~* = 334.41          *F*(000) = 352\\n  Triclinic, *P*1          *D*~x~ = 1.291 Mg m^−3^\\n  Hall symbol: -P 1        Cu *K*α radiation, λ = 1.54180 Å\\n  *a* = 5.6957 (3) Å       Cell parameters from 2123 reflections\\n  *b* = 12.1117 (11) Å     θ = 3.5--72.3°\\n  *c* = 13.0813 (11) Å     µ = 1.74 mm^−1^\\n  α = 72.748 (8)°          *T* = 293 K\\n  β = 86.477 (6)°          Prism, colourless\\n  γ = 89.941 (6)°          0.11 × 0.10 × 0.05 mm\\n  *V* = 860.04 (12) Å^3^   \\n  ------------------------ ---------------------------------------\\n\\nData collection {#tablewrapdatacollectionlong}\\n===============\\n\\n  ------------------------------------------------------------------------------ --------------------------------------\\n  Oxford Diffraction Xcalibur Gemini Sapphire3 diffractometer                    3299 independent reflections\\n  Radiation source: Enhance (Cu) X-ray Source                                    2554 reflections with *I* \\\\> 2σ(*I*)\\n  Graphite monochromator                                                         *R*~int~ = 0.018\\n  Detector resolution: 16.3280 pixels mm^-1^                                     θ~max~ = 72.4°, θ~min~ = 3.6°\\n  ω scans                                                                        *h* = −5→7\\n  Absorption correction: multi-scan (*CrysAlis PRO*; Oxford Diffraction, 2012)   *k* = −14→14\\n  *T*~min~ = 0.944, *T*~max~ = 1.000                                             *l* = −16→15\\n  5368 measured reflections                                                      \\n  ------------------------------------------------------------------------------ --------------------------------------\\n\\nRefinement {#tablewraprefinementdatalong}\\n==========\\n\\n  ------------------------------------- -------------------------------------------------------------------------------------------------\\n  Refinement on *F*^2^                  Primary atom site location: structure-invariant direct methods\\n  Least-squares matrix: full            Secondary atom site location: difference Fourier map\\n  *R*\\\\[*F*^2^ \\\\> 2σ(*F*^2^)\\\\] = 0.040   Hydrogen site location: inferred from neighbouring sites\\n  *wR*(*F*^2^) = 0.113                  H-atom parameters constrained\\n  *S* = 1.04                            *w* = 1/\\\\[σ^2^(*F*~o~^2^) + (0.0493*P*)^2^ + 0.0651*P*\\\\] where *P* = (*F*~o~^2^ + 2*F*~c~^2^)/3\\n  3299 reflections                      (Δ/σ)~max~ \\\\< 0.001\\n  217 parameters                        Δρ~max~ = 0.21 e Å^−3^\\n  0 restraints                          Δρ~min~ = −0.21 e Å^−3^\\n  ------------------------------------- -------------------------------------------------------------------------------------------------\\n\\nSpecial details {#specialdetails}\\n===============\\n\\n  --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n  Experimental. IR (KBr, cm^-1^): 3414, 3061, 2920, 2648, 2559, 1674, 1584, 1562, 1463, 1412, 1317, 1272, 1255, 1154, 1062, 1046, 897, 743, 711, 652, 551. ^1^H NMR (200 MHz, CDCl~3~, δ p.p.m.): 4.11 (s, 2H, C^15^H2), 5.45 (s, 2H, C^8^H~2~), 7.00--7.93 (m, 17H, Ar and bz). ^13^C NMR (50 MHz, DMSO-d6, δ p.p.m.): 38.5 (C^15^H2), 68.3 (C^8^H2) 125.0;', '<|endoftext|> all cases, what\\n\\nconstitutes a “miscarriage of justice” in one case is not the same as what\\n\\nconstitutes a “miscarriage of justice” in another. It is up to the judiciary to develop\\n\\na framework for assessing and analyzing this determination in individual cases. If\\n\\nthe statute clearly and unambiguously set forth the specific test for courts to apply\\n\\nto determine whether an error is harmless in an individual case, courts would not\\n\\nhave struggled for more than a century to interpret the statute, and this Court would\\n\\nnot now be called upon to provide a framework for analyzing what constitutes a\\n\\n“miscarriage of justice” in civil cases.\\n\\n      Instead of adopting the identical test for the sake of consistency between\\n\\ncases that arise in contexts that are completely different, I would adopt the well-\\n\\nreasoned opinion of the Fourth District as to the appropriate standard for harmless\\n\\nerror in civil cases. Sitting en banc, the Fourth District cogently articulated why\\n\\n\\n                                           - 35 -\\n\\x0cthe proper test should require the beneficiary of the error to prove “more likely\\n\\nthan not that the error did not influence the trier of fact and thereby contribute to\\n\\nthe verdict.” Special, 79 So. 3d at 771.\\n\\n      In my view, the Fourth District persuasively explained why a different\\n\\nstandard for reversal is well-suited to civil cases:\\n\\n             In formulating a harmless error test in civil cases, it is important\\n      to recognize that DiGuilio derived its formulation from the elevated\\n      burden of proof in criminal cases:\\n             The harmless error test . . . places the burden on the state,\\n             as the beneficiary of the error, to prove beyond a\\n             reasonable doubt that the error complained of did not\\n             contribute to the verdict or, alternatively stated, that there\\n             is no reasonable possibility that the error contributed to\\n             the conviction.\\n      DiGuilio, 491 So. 2d at 1135 (emphasis added) (citation omitted).\\n      This elevated test acknowledges (1) the higher burden of proof in\\n      criminal cases, which amplifies the potential effect of an evidentiary\\n      error on the trier of fact, and (2) the special concern for the legitimacy\\n      of criminal convictions expressed in the constitutional and statutory\\n      protections accorded to criminal defendants. A harmless error test for\\n      civil cases should acknowledge the particular attributes of those cases.\\nId. at 770. In other words, as DiGuilio makes clear, the “no reasonable possibility”\\n\\nlanguage in the criminal harmless error test cannot be divorced from the “beyond a\\n\\nreasonable doubt” language, since the two phrases are simply alternative\\n\\nformulations of the same test, which is rooted in the “particular attributes” of\\n\\ncriminal prosecutions. See Chapman v. California, 386 U.S. 18, 24 (1967) (“There\\n\\nis little, if any, difference between our statement in [a prior case] about ‘whether\\n\\n\\n                                         - 36 -\\n\\x0cthere is a reasonable possibility that the evidence complained of might have\\n\\ncontributed to the conviction’ and requiring the beneficiary of a constitutional error\\n\\nto prove beyond a reasonable doubt that the error complained of did not contribute\\n\\nto the verdict obtained.”); see also Black’s Law Dictionary 1457 (10th ed. 2009)\\n\\n(defining “reasonable doubt” as “the belief that there is a real possibility that a\\n\\ndefendant is not guilty”).\\n\\n      When the Court is required to address harmless error in criminal cases, it is\\n\\nalways the State that has obtained a conviction against a defendant based in some\\n\\nmeasure on an erroneous legal ruling at trial. Therefore, the strictest formulation\\n\\nof the harmless error test, as set forth in DiGuilio, is consistent with the State’s\\n\\nresponsibility to ensure that convictions are secured without the assistance of\\n\\nharmful errors, which is an important public policy concern. See DiGuilio, 491 So.\\n\\n2d at 1138-39.\\n\\n      By contrast, an error in a civil case could result in potential harm to either a\\n\\nplaintiff or a defendant. Thus, the use of the same standard for harmless error as\\n\\napplies to the burden of proof in civil cases—that a particular occurrence was\\n\\n“more likely than not”—vindicates the concerns that the majority refers to as\\n\\n“conserv[ing] judicial resources while protecting the integrity of the process.”\\n\\nMajority op. at 10. It also “strikes the proper balance between the parties.” Id. In\\n\\nfact, a harmless error test based on the “preponderance of the evidence” standard\\n\\n\\n                                         - 37 -\\n\\x0cactually strikes a better and more appropriate balance because it takes into account\\n\\nhow each of the', '<|endoftext|>/O1/O2) and five membered ring B (C9---C12/S1) of 2-amino-4,5,6,7- tetrahydro-1-benzothiophene-3-carbonitrile group are planar with r. m. s. deviations of 0.010 and 0.007 Å, respectively. The dihedral angle between A/B is 3.76 (5)°. In the second molecule, the ring system of 1,3-benzodioxole-5-carbaldehyde moiety C (C18---C24/O3/O4) and five membered ring D (C26---C29/S2) of 2-amino-4,5,6,7-tetrahydro-1-benzothiophene-3- carbonitrile group are also almost planar with r. m. s. deviation of 0.003 and 0.003 Å, respectively. The dihedral angle between C/D is 5.33 (12)°. There exist intra-molecular H-bonding of C---H···S type completing S(5) ring (Table 1, Fig. 1) motifs (Bernstein *et al.*, 1995) in each molecule. The inter-molecular H-bondings of C---H···N type links the molecules in pair.\\n\\nExperimental {#experimental}\\n============\\n\\nA mixture of 1,3-benzodioxole-5-carbaldehyde (0.50 g, 3.3 mmol) and 2-amino-4,5,6,7-tetrahydro-1-benzothiophene-3-carbonitrile (0.58 g, 3.3 mmol) in ethanol (15 ml) was heated for 3 h. The progress of the reaction was monitored by TLC. The solid that separated from the cooled mixture was collected and recrystallized from a methanol-chloroform mixture (9:1) to give yellow prisms of the title compound (I).\\n\\nYield: 80%; m.p. 452--453 K.\\n\\nRefinement {#refinement}\\n==========\\n\\nThe H-atoms were positioned geometrically (C--H = 0.93--0.97 Å) and refined as riding with *U*~iso~(H) = x*U*~eq~(C), where x = 1.2 for all H-atoms.\\n\\nFigures\\n=======\\n\\n![View of the title compound with displacement ellipsoids drawn at the 50% probability level. The dotted lines represent the C---H···S short contacts.](e-67-o2162-fig1){#Fap1}\\n\\n![The partial packing of (I0, which shows that molecules are linked into pairs.](e-67-o2162-fig2){#Fap2}\\n\\nCrystal data {#tablewrapcrystaldatalong}\\n============\\n\\n  ------------------------ ---------------------------------------\\n  C~17~H~14~N~2~O~2~S      *Z* = 4\\n  *M~r~* = 310.36          *F*(000) = 648\\n  Triclinic, *P*1          *D*~x~ = 1.368 Mg m^−3^\\n  Hall symbol: -P 1        Mo *K*α radiation, λ = 0.71073 Å\\n  *a* = 10.9450 (3) Å      Cell parameters from 3812 reflections\\n  *b* = 10.9895 (3) Å      θ = 3.0--25.3°\\n  *c* = 13.5749 (3) Å      µ = 0.22 mm^−1^\\n  α = 99.409 (1)°          *T* = 296 K\\n  β = 109.707 (1)°         Prism, yellow\\n  γ = 92.854 (1)°          0.32 × 0.23 × 0.20 mm\\n  *V* = 1506.77 (7) Å^3^   \\n  ------------------------ ---------------------------------------\\n\\nData collection {#tablewrapdatacollectionlong}\\n===============\\n\\n  ------------------------------------------------------------ --------------------------------------\\n  Bruker Kappa APEXII CCD diffractometer                       5331 independent reflections\\n  Radiation source: fine-focus sealed tube                     3812 reflections with *I* \\\\> 2σ(*I*)\\n  graphite                                                     *R*~int~ = 0.030\\n  Detector resolution: 8.20 pixels mm^-1^                      θ~max~ = 25.1°, θ~min~ = 3.0°\\n  ω scans                                                      *h* = −13→13\\n  Absorption correction: multi-scan (*SADABS*; Bruker, 2005)   *k* = −13→13\\n  *T*~min~ = 0.', '<|endoftext|>2019008){ref-type=\"table\"} while in [Table 6](#t6-eaht-34-3-e2019008){ref-type=\"table\"}, the sum of HQs for L~2~ exceeded 1, implying the potentials of the pool at L~2~ to causing Hg poisoning. Also, oral intake levels of As attained a close level to the reference dose, thus requiring very imminent measures that can effectively curtail the deposition of As in these pools. By dermal exposure, none of the deposited heavy metals exceeded their respective reference doses hence may not portend any toxic risk. Hg toxicities could manifest as desquamation \\\\[[@b34-eaht-34-3-e2019008]\\\\], central nerve system and autoimmune diseases \\\\[[@b35-eaht-34-3-e2019008]\\\\] and Young\\'s syndrome \\\\[[@b34-eaht-34-3-e2019008]\\\\], while for As poisoning, cardiovascular and skin diseases, abdominal pain and cancer could result \\\\[[@b37-eaht-34-3-e2019008]\\\\]. Also, as shown in [Table 6](#t6-eaht-34-3-e2019008){ref-type=\"table\"}, only L~2~ among six swimming pools portends the potentials of eliciting metal toxicities having shown HQ value greater than 1. In addition, the toxic risk of the cumulative contents of all the heavy metals in each of the swimming pools indicates two of the swimming pools are unsafe.\\n\\nConclusion\\n==========\\n\\nThis study has shown that the aesthetic quality of the swimming pools was compromised, and contained elevated levels of Hg, As, and Cu, which were significant enough to threaten the health safety of users of these swimming pools users. Thus, imminent strategies are required by the regulatory bodies to checkmate the safety processes applied by the management of these commercial swimming pools to prevent the heavy metal contamination, and enforce compliance to standard approaches. Also, this result raises serious concerns over the heavy metal pollution status of the metropolis at large, as well as the rationale behind situating commercial swimming pools in the heart of population dense cities without adequate protections put in place.\\n\\nNo conflict of interest declared.\\n\\n![Temperatures of swimming pools\\\\\\n\\\\* NSDWQ=Nigeria Standard for Drinking Water Quality](eaht-34-3-e2019008f1){#f1-eaht-34-3-e2019008}\\n\\n![pH of swimming pools\\\\\\n\\\\* NSDWQ=Nigeria Standard for Drinking Water Quality](eaht-34-3-e2019008f2){#f2-eaht-34-3-e2019008}\\n\\n![Turbidity of swimming pools\\\\\\n\\\\* NSDWQ=Nigeria Standard for Drinking Water Quality](eaht-34-3-e2019008f3){#f3-eaht-34-3-e2019008}\\n\\n![Alkalinity of swimming pools\\\\\\n\\\\* WHO=World Health Organization](eaht-34-3-e2019008f4){#f4-eaht-34-3-e2019008}\\n\\n![Total dissolved solute (TDS) of swimming pools\\\\\\n\\\\* NSDWQ=Nigeria Standard for Drinking Water Quality](eaht-34-3-e2019008f5){#f5-eaht-34-3-e2019008}\\n\\n![Conductivity of swimming pools\\\\\\n\\\\* NSDWQ=Nigeria Standard for Drinking Water Quality](eaht-34-3-e2019008f6){#f6-eaht-34-3-e2019008}\\n\\n![Dissolved oxygen of swimming pools\\\\\\n\\\\* MK= Manoj and Avinash \\\\[[@b17-eaht-34-3-e2019008]\\\\]](eaht-34-3-e2019008f7){#f7-eaht-34-3-e2019008}\\n\\n###### \\n\\nIron (Fe), cadmium (Cd), mercury (Hg), arsenic (As), and nickel (Ni) contents (mg/L) of swimming pools\\n\\n  Swimming pool   Fe             Cd             Hg             As             Ni\\n  --------------- -------------- -------------- -------------- -------------- --------------\\n  L~1~                                                                        \\n  Test            3.86±0.9^a^    0.03±0.0^a^    0.02±0.0^a^    0.08±0.01^a^   0.13±0.01^a^\\n  Control         1.06±0.3^b^    BDL            BDL            0.02±0.0^b^    0.06±0.0^b^\\n  Standard        0.20±0.1^c^    0.003±0.0^b^   0', '<|endoftext|> the mixture was washed with saturated sodium bicarbonate solution and the organic layer was separated, dried over magnesium sulfate, filtered and concentrated at reduced pressure. The residue was purified by column chromatography (hexane--ethyl acetate, 2:1 v/v) to afford the title compound as a colorless solid \\\\[yield 78%, m.p. 428--429 K; *R*~f~ = 0.49 (hexane--ethyl acetate, 2:1 v/v)\\\\]. Single crystals suitable for X-ray diffraction were prepared by slow evaporation of a solution of the title compound in ethyl acetate at room temperature.\\n\\nRefinement {#refinement}\\n==========\\n\\nAll H atoms were positioned geometrically and refined using a riding model, with C---H = 0.95 Å for aryl and 0.98 Å for methyl H atoms. *U*~iso~(H) =1.2*U*~eq~(C) for aryl and 1.5*U*~eq~(C)for methyl H atoms.\\n\\nFigures\\n=======\\n\\n![The molecular structure of the title compound. Displacement ellipsoids are drawn at the 50% probability level.](e-68-0o943-fig1){#Fap1}\\n\\n![A view of the C---H···O, C---H···π, C---S···π and π--π interactions (dotted lines)in the crystal structure of the title compound. H atoms non-participating in hydrogen-bonding were omitted for clarity. \\\\[ Symmetry codes: (i) - x + 2, - y + 1, - z + 2 (ii) - x + 1, - y + 1, - z + 1 (iii) - x + 1, - y + 1 , - z + 2](e-68-0o943-fig2){#Fap2}\\n\\nCrystal data {#tablewrapcrystaldatalong}\\n============\\n\\n  ----------------------- ---------------------------------------\\n  C~17~H~15~ClO~2~S       *Z* = 2\\n  *M~r~* = 318.80         *F*(000) = 332\\n  Triclinic, *P*1         *D*~x~ = 1.414 Mg m^−3^\\n  Hall symbol: -P 1       Mo *K*α radiation, λ = 0.71073 Å\\n  *a* = 6.1701 (1) Å      Cell parameters from 7460 reflections\\n  *b* = 11.6670 (2) Å     θ = 3.3--27.6°\\n  *c* = 12.1123 (3) Å     µ = 0.40 mm^−1^\\n  α = 112.965 (1)°        *T* = 173 K\\n  β = 99.114 (1)°         Block, colourless\\n  γ = 103.698 (1)°        0.20 × 0.19 × 0.18 mm\\n  *V* = 748.70 (3) Å^3^   \\n  ----------------------- ---------------------------------------\\n\\nData collection {#tablewrapdatacollectionlong}\\n===============\\n\\n  ------------------------------------------------------------ --------------------------------------\\n  Bruker SMART APEXII CCD diffractometer                       3463 independent reflections\\n  Radiation source: rotating anode                             3136 reflections with *I* \\\\> 2σ(*I*)\\n  Graphite multilayer monochromator                            *R*~int~ = 0.023\\n  Detector resolution: 10.0 pixels mm^-1^                      θ~max~ = 27.6°, θ~min~ = 1.9°\\n  φ and ω scans                                                *h* = −7→8\\n  Absorption correction: multi-scan (*SADABS*; Bruker, 2009)   *k* = −15→15\\n  *T*~min~ = 0.926, *T*~max~ = 0.934                           *l* = −14→15\\n  13458 measured reflections                                   \\n  ------------------------------------------------------------ --------------------------------------\\n\\nRefinement {#tablewraprefinementdatalong}\\n==========\\n\\n  ------------------------------------- -------------------------------------------------------------------------------------------------\\n  Refinement on *F*^2^                  Primary atom site location: structure-invariant direct methods\\n  Least-squares matrix: full            Secondary atom site location: difference Fourier map\\n  *R*\\\\[*F*^2^ \\\\> 2σ(*F*^2^)\\\\] = 0.034   Hydrogen site location: difference Fourier map\\n  *wR*(*F*^2^) = 0.096                  H-atom parameters constrained\\n  *S* = 1.07                            *w* = 1/\\\\[σ^2^(*F*~o~^2^) + (0.0531*P*)^2^ + 0.2623*P*\\\\] where *P', '<|endoftext|> sociodemographic profile of participants and Young\\'s Internet Addiction Test. The final analysis included 842 subjects. Overall, 38.7 and 10.5 % of respondents scored in the mild and moderate categories. Only a small fraction (0.5 %) of students scored in the severe category. Being male and spending more time on the internet were correlated with problematic internet use. Moreover, a significantly higher proportion of participants who scored above the cutoff used the Internet for browsing, social networking, chatting, gaming, shopping, and viewing pornography. However, there was no difference between the two groups with regard to using the internet for e-mailing or academic activities. It is important to address problematic internet use among medical students. The correlates can help identify those at increased risk.<|endoftext|>A 10-year analysis of venous thromboembolism on the surgical service: the effect of practice guidelines for prophylaxis.\\nThere is a national effort to decrease the incidence of venous thromboembolism (VTE) in surgical patients by encouraging compliance with established guidelines for prophylaxis. Reported compliance with these guidelines has been poor. The outcome of noncompliance in terms of morbidity and mortality in surgical patients is unknown. We sought to determine if there has been a decrease in the incidence of symptomatic VTE since implementation of the guidelines and whether there has been compliance with the guidelines in individual patients; we also analyzed the outcome of a cohort with VTE. We reviewed the records of all patients with symptomatic VTE on 3 surgery services over the 10-year period since initial publication of the guidelines. We determined in each patient whether there was compliance with the guidelines. We weighted the morbidity of each episode of VTE based on the likelihood of short-term mortality and long-term morbidity to determine the disease burden. Of 37,615 patients, 172 developed a VTE (0.46%), and the incidence increased gradually over the years of the study. There was partial or complete compliance with the guidelines in 84% of the patients, but 37% of the VTEs were considered to be preventable. The disease burden was greatest in the higher-risk patients-there were 20 deaths (6%), 4 of which were caused by a pulmonary embolus. Despite one of the highest published rates of compliance with the guidelines for prophylaxis, the rate of symptomatic VTE is increasing.<|endoftext|>Chinchipena elettaria\\n\\nChinchipena elettaria is a species of moth of the family Tortricidae. It is found in Zamora-Chinchipe Province, Ecuador.\\n\\nReferences\\n\\nCategory:Moths described in 1999\\nCategory:Euliini\\nCategory:Moths of South America\\nCategory:Taxa named by Józef Razowski<|endoftext|>In recent years, when a tire mounted to a vehicle is punctured, puncture repair liquid is injected into the tire via the tire valve to temporarily repair the puncture, and the tire is filled with air. Installing a puncture repair device of this sort in a vehicle eliminates the need for carrying a spare tire in the vehicle, thereby conserving resources and reducing vehicle weight. This arrangement also yields the advantage that a space provided in the vehicle for carrying the spare tire can be used for other purposes.\\nOne example of a device for injecting puncture repair liquid is a hand-squeezable tire repair kit constituted by puncture repair liquid contained in a flexible container, the container being manually squeezed to inject the puncture repair liquid into a tire (see, for example, Japanese Unexamined Patent Application Publication No. 2009-248982A).\\nIt is desirable that the puncture repair liquid-holding container used in a hand-squeezable tire repair kit of this sort easily deform when squeezed (i.e., exhibit superior squeezability) so that a user can easily repair the tire. Meanwhile, because it must be repeatedly squeezed in order to dispense all of the puncture repair liquid, the container must also exhibit superior shape retention. The outer wall of the puncture repair liquid-holding container must also be of suitable thickness in order to prevent degradation of the puncture repair liquid during storage. This results in the difficult problem of improving the squeezability of the container while maintaining the shape retention and puncture repair liquid degradation preventing capability thereof. In particular, because the squeezability of a puncture repair liquid-holding container at low temperatures decreases as the thickness of the outer wall thereof increases, there is demand for a high balance between preventing puncture repair liquid degradation and improving squeezability.<|endoftext|>The Plagiarist\\n\\n\"Every so often, you stumble on a story in the slush pile that seems to have every duck in place. When I read “The Plagiarist,” I knew immediately that we had something special here. I loved the interplay of mortality and poetry--not poetry in the sappy sense, but poetry in the practical daily sense of an English professor who lives and breathes it, and also grades papers on it. The juxtaposition of the student\\'s desire for words and the professor\\'s desire for reass', '<|endoftext|>BrNOS2 at the 70% probability level; hydrogen atoms are drawn as spheres of arbitrary radius.](e-65-0o598-fig1){#Fap1}\\n\\nCrystal data {#tablewrapcrystaldatalong}\\n============\\n\\n  ------------------------ ---------------------------------------\\n  C~22~H~22~BrNOS~2~       *Z* = 4\\n  *M~r~* = 460.44          *F*(000) = 944\\n  Triclinic, *P*1          *D*~x~ = 1.468 Mg m^−3^\\n  Hall symbol: -P 1        Mo *K*α radiation, λ = 0.71073 Å\\n  *a* = 11.8210 (2) Å      Cell parameters from 5387 reflections\\n  *b* = 12.8904 (2) Å      θ = 2.3--28.2°\\n  *c* = 15.8833 (3) Å      µ = 2.19 mm^−1^\\n  α = 67.670 (1)°          *T* = 100 K\\n  β = 71.434 (1)°          Prism, orange\\n  γ = 73.283 (1)°          0.40 × 0.15 × 0.05 mm\\n  *V* = 2083.56 (6) Å^3^   \\n  ------------------------ ---------------------------------------\\n\\nData collection {#tablewrapdatacollectionlong}\\n===============\\n\\n  --------------------------------------------------------------- --------------------------------------\\n  Bruker SMART APEX diffractometer                                9548 independent reflections\\n  Radiation source: fine-focus sealed tube                        7113 reflections with *I* \\\\> 2σ(*I*)\\n  graphite                                                        *R*~int~ = 0.029\\n  ω scans                                                         θ~max~ = 27.5°, θ~min~ = 1.7°\\n  Absorption correction: multi-scan (*SADABS*; Sheldrick, 1996)   *h* = −15→15\\n  *T*~min~ = 0.667, *T*~max~ = 0.899                              *k* = −16→16\\n  19892 measured reflections                                      *l* = −20→20\\n  --------------------------------------------------------------- --------------------------------------\\n\\nRefinement {#tablewraprefinementdatalong}\\n==========\\n\\n  ------------------------------------- -------------------------------------------------------------------------------------------------\\n  Refinement on *F*^2^                  Primary atom site location: structure-invariant direct methods\\n  Least-squares matrix: full            Secondary atom site location: difference Fourier map\\n  *R*\\\\[*F*^2^ \\\\> 2σ(*F*^2^)\\\\] = 0.034   Hydrogen site location: inferred from neighbouring sites\\n  *wR*(*F*^2^) = 0.091                  H atoms treated by a mixture of independent and constrained refinement\\n  *S* = 1.00                            *w* = 1/\\\\[σ^2^(*F*~o~^2^) + (0.0461*P*)^2^ + 0.3098*P*\\\\] where *P* = (*F*~o~^2^ + 2*F*~c~^2^)/3\\n  9548 reflections                      (Δ/σ)~max~ = 0.001\\n  499 parameters                        Δρ~max~ = 0.64 e Å^−3^\\n  2 restraints                          Δρ~min~ = −0.80 e Å^−3^\\n  ------------------------------------- -------------------------------------------------------------------------------------------------\\n\\nFractional atomic coordinates and isotropic or equivalent isotropic displacement parameters (Å^2^) {#tablewrapcoords}\\n==================================================================================================\\n\\n  ------ -------------- --------------- --------------- -------------------- --\\n         *x*            *y*             *z*             *U*~iso~\\\\*/*U*~eq~   \\n  Br1    0.82709 (3)    0.56564 (2)     0.965667 (18)   0.03058 (8)          \\n  Br2    0.99128 (3)    0.68807 (2)     0.63996 (2)     0.03598 (9)          \\n  S1     0.39347 (5)    1.31023 (5)     0.49538 (4)     0.02024 (14)         \\n  S2     0.37604 (6)    1.16479 (6)     0.69198 (4)     0.02758 (16)         \\n  S3     1.27628 (5)    −0.14493 (5)    1.10260 (4)     0.01872 (13)         \\n  S4     1.34366 (5)    0.04070 (5)     0.92901 (4)     0.', '<|endoftext|>tetracarboxylic acid reacts with hydrazine to form bis(hydrazinium) 4-hydroxy-1-oxo-*2H*-phthalazine-6,7-dicarboxylate, whose anion represents a ligand possesses a recognition site for metals as well as a rich hydrogen-bonding motif (Benniston *et al.*, 1999). The neutral acid itself would be more useful for the synthesis of metal derivatives; the neutral acid has been unexpectedly obtained when the reaction was carried out in the presence of a cobaltous salt. The acid crystallizes as a dihydrate (Scheme I, Fig. 1). The --OH and --NH groups each serves as hydrogen-bond donor to one acceptor site whereas the water molecules each serves as hydrogen bond donor to two acceptor sites. The hydrogen bonding scheme gives rise to a three-dimensional network.\\n\\nExperimental {#experimental}\\n============\\n\\nHydrazine hydrate (0.01 g, 0.2 mmol), pyromellitic acid (0.05 g, 0.2 mmol), cobaltous chloride hexahydrate (0.02 g, 0.1 mmol) and water (10 ml) were heated in a 25 ml, Teflon-lined Parr bomb at 433 K for 96 h. The bomb was cooled to room temperature at 10 K per hour.\\n\\nRefinement {#refinement}\\n==========\\n\\nAll hydrogen atoms were located in a difference Fouier map, and were refined with distance restraints (C--H 0.95±0.01, N--H 0.88±0.01 and O--H 0.84±0.01 Å). Temperature factors were freely refined.\\n\\nFigures\\n=======\\n\\n![Molecular structure of (I) showing atomic labelling scheme and displacement ellipsoids at the 70% probability level.](e-64-o1225-fig1){#Fap1}\\n\\nCrystal data {#tablewrapcrystaldatalong}\\n============\\n\\n  -------------------------- ---------------------------------------\\n  C~10~H~6~N~2~O~6~·2H~2~O   *Z* = 2\\n  *M~r~* = 286.20            *F*~000~ = 296\\n  Triclinic, *P*1            *D*~x~ = 1.708 Mg m^−3^\\n  Hall symbol: -P 1          Mo *K*α radiation λ = 0.71073 Å\\n  *a* = 6.4069 (1) Å         Cell parameters from 2234 reflections\\n  *b* = 9.4254 (2) Å         θ = 2.9--28.2º\\n  *c* = 9.6922 (2) Å         µ = 0.15 mm^−1^\\n  α = 82.843 (2)º            *T* = 100 (2) K\\n  β = 87.496 (1)º            Prism, colorless\\n  γ = 73.451 (2)º            0.33 × 0.31 × 0.09 mm\\n  *V* = 556.65 (2) Å^3^      \\n  -------------------------- ---------------------------------------\\n\\nData collection {#tablewrapdatacollectionlong}\\n===============\\n\\n  ------------------------------------------ --------------------------------------\\n  Bruker SMART APEX diffractometer           2160 reflections with *I* \\\\> 2σ(*I*)\\n  Radiation source: fine-focus sealed tube   *R*~int~ = 0.017\\n  Monochromator: graphite                    θ~max~ = 27.5º\\n  *T* = 100(2) K                             θ~min~ = 2.1º\\n  ω scans                                    *h* = −8→8\\n  Absorption correction: None                *k* = −12→11\\n  4702 measured reflections                  *l* = −12→11\\n  2530 independent reflections               \\n  ------------------------------------------ --------------------------------------\\n\\nRefinement {#tablewraprefinementdatalong}\\n==========\\n\\n  ---------------------------------------------------------------- ---------------------------------------------------------------------------------------------------\\n  Refinement on *F*^2^                                             Secondary atom site location: difference Fourier map\\n  Least-squares matrix: full                                       Hydrogen site location: inferred from neighbouring sites\\n  *R*\\\\[*F*^2^ \\\\> 2σ(*F*^2^)\\\\] = 0.035                              All H-atom parameters refined\\n  *wR*(*F*^2^) = 0.105                                             \\xa0 *w* = 1/\\\\[σ^2^(*F*~o~^2^) + (0.0657*P*)^2^ + 0.0694*P*\\\\] where *P* = (*F*~o~^2^ + 2*F*~c~^2^)/3\\n  *S* = 1.06                                                       (Δ/σ)~max~ = 0.', '<|endoftext|>\\xa0(3)Å for N1). The dihedral angles between the four essentially planar atoms of the pyrazole ring and fluoro-substituted benzene rings are 2.6\\xa0(2) and 82.2\\xa0(2)°, respectively. The dihedral angle between the two benzene rings is 83.7\\xa0(2)°. The crystal packing is stabilized by weak intermolecular C---H···O hydrogen bonds (Fig .2).\\n\\nExperimental {#experimental}\\n============\\n\\nA mixture of (2*E*)-1,3-bis(4-fluorophenyl)prop-2-en-1-one (2.44 g, 0.01 mol) and hydrazine hydrate (0.5 ml, 0.01 mol) in 20 ml formic acid was refluxed for 8 h. The reaction mixture was cooled and poured into 50 ml ice-cold water. The precipitate was collected by filtration and purified by recrystallization from ethanol. The single-crystal was grown from DMF by slow evaporation method and yield of the compound was 86%. (m. p.: 408 K).\\n\\nRefinement {#refinement}\\n==========\\n\\nAll H atoms were positioned geometrically \\\\[C---H = 0.93 and 0.97 Å\\\\] and allowed to ride on their parent C atoms, with *U*~iso~(H) = 1.2*U*~eq~(C). Owing to the large number of weak high-angle reflections, the ratio of observed to unique reflections is low (37%).\\n\\nFigures\\n=======\\n\\n![The title molecule with displacement ellipsoids for non-H atoms are drawn at the 30% probability level.](e-67-o1292-fig1){#Fap1}\\n\\n![Hydrogen bonding of the title compound viewed along the a axis. Hydrogen bonds are shown as dotted lines (symmetry code: (a) x-2, y-1, z).](e-67-o1292-fig2){#Fap2}\\n\\nCrystal data {#tablewrapcrystaldatalong}\\n============\\n\\n  ------------------------ ---------------------------------------\\n  C~16~H~12~F~2~N~2~O      *Z* = 2\\n  *M~r~* = 286.28          *F*(000) = 296\\n  Triclinic, *P*1          *D*~x~ = 1.418 Mg m^−3^\\n  Hall symbol: -P 1        Mo *K*α radiation, λ = 0.71073 Å\\n  *a* = 6.2141 (9) Å       Cell parameters from 1748 reflections\\n  *b* = 6.7802 (8) Å       θ = 2.3--26.3°\\n  *c* = 17.9857 (9) Å      µ = 0.11 mm^−1^\\n  α = 96.727 (4)°          *T* = 294 K\\n  β = 90.254 (4)°          Prism, pale yellow\\n  γ = 116.791 (5)°         0.30 × 0.20 × 0.10 mm\\n  *V* = 670.39 (13) Å^3^   \\n  ------------------------ ---------------------------------------\\n\\nData collection {#tablewrapdatacollectionlong}\\n===============\\n\\n  ---------------------------------------------------- --------------------------------------\\n  Rigaku R-AXIS RAPID-S diffractometer                 2736 independent reflections\\n  Radiation source: Sealed Tube                        1011 reflections with *I* \\\\> 2σ(*I*)\\n  Graphite Monochromator                               *R*~int~ = 0.095\\n  Detector resolution: 10.0000 pixels mm^-1^           θ~max~ = 26.5°, θ~min~ = 3.4°\\n  dtprofit.ref scans                                   *h* = −7→7\\n  Absorption correction: multi-scan (Blessing, 1995)   *k* = −8→8\\n  *T*~min~ = 0.968, *T*~max~ = 0.989                   *l* = −22→22\\n  14070 measured reflections                           \\n  ---------------------------------------------------- --------------------------------------\\n\\nRefinement {#tablewraprefinementdatalong}\\n==========\\n\\n  ------------------------------------- -------------------------------------------------------------------------------------\\n  Refinement on *F*^2^                  Primary atom site location: structure-invariant direct methods\\n  Least-squares matrix: full            Secondary atom site location: difference Fourier map\\n  *R*\\\\[*F*^2^ \\\\> 2σ(*F*^2^)\\\\] = 0.062   Hydrogen site location: inferred from neighbouring sites\\n  *wR*(*F*^2^) = 0.206                  H-atom parameters constrained\\n  *S* = 0.94                            *w* = 1', '<|endoftext|> case, the adhesiveness to the glass substrate is not improved, and sufficient oxidation resistance may not be acquired to withstand liquid crystal manufacturing process.\\nJapanese Unexamined Patent Application Publication No. 2005-158887 proposes a copper alloy in which at least one element of titanium (Ti), molybdenum (Mo), nickel (Ni), aluminum (Al) and silver (Ag) is added by 0.5 to weight percent to the copper (Cu). However, the additional element increases electric resistance of the interconnections.\\nJapanese Unexamined Patent Application Publication No. 2004-91907 discloses the addition of molybdenum (Mo) by 0.1 to 3.0 weight percent to the copper (Cu) and segregation of molybdenum (Mo) to a grain boundary suppresses oxidation by grain boundary diffusion. Although this technique can improve oxidation resistance of the copper (Cu), there is a problem in that the interconnection resistance increases.\\nInternational Unexamined Patent Application Publication No. WO2006-025347 discloses that an oxide protective layer formed by an additional element will suppress the oxidation of Cu in the copper alloy layer in which the appropriate additional element is added. The protective layer is formed at an interface of an adjacent insulating layer that suppresses the mutual diffusion. This technique provides a copper interconnection that has high conductivity and good adhesiveness with the substrate. Further, this technique provides liquid crystal display (LCD) devices utilizing this copper interconnections. In addition, this publication suggests that manganese (Mn) is preferable as one of the additional elements. However, this technique is insufficient to realize features of interconnection structures used in the liquid crystal display (LCD) devices and TFT electrode structures.\\nJapanese patent No. 3302894 proposes a TFT structure used in TFT-LCD devices and explicitly discloses the gate electrode of TFT structure is covered by an oxide layer when a Cu alloy is applied to the gate electrode. This patent discloses that when a first metal is Cu, a second metal is at least one element selected from titanium (Ti), zirconium (Zr), hafnium (Hf), tantalum (Ta), niobium (Nb), silicon (Si), boron (B), lanthanum (La), neodymium (Nd), samarium (Sm), europium (Eu), gadolinium (Gd), dysprosium (Dy), yttrium (Y), ytterbium (Yb), cerium (Ce), magnesium (Mg), thorium (Th), and chromium (Cr). However, the second element is different from an additional element of the present invention.\\nNone of the above-mentioned documents refers to a structure of source or drain electrodes in a TFT structure. However, high adhesiveness to a semiconductor layer or a pixel electrode, tolerability to a circumstance in which the TFT electrode is used, and stability of electric contacts with source or drain electrodes portion are required for the structure of the source or drain electrode. Therefore, the structure of the source or drain electrode is an important element of liquid crystal display (LCD) device.\\nAs mentioned above, according to these conventional techniques, although adhesiveness to the semiconductor layer or the pixel electrode and the oxidation-resistance layer are tried to be secured by adding an additional alloyed element to the copper (Cu), a sufficient result is not yet obtained in all techniques. Further, sufficient results are not obtained with regard to the high adhesiveness to the semiconductor layer or the pixel electrode and tolerability of circumstances in which the TFT electrode is used. In the same way, the requirement of having stable electric contacts with the source or drain electrodes portion are not yet met.\\nEspecially, although the International Unexamined Patent Application Publication No. WO2006-025347 suggests the liquid crystal display (LCD) device using copper interconnections, a sufficient structure for realizing the gate interconnection structure utilized in the liquid crystal display (LCD) device is not yet achieved by the suggested technique. Further, the Japanese patent No. 3302894 clearly specifies that an oxide layer covering a gate electrode is an oxide layer mainly composed of a second metal element, which is formed by applying a heat treatment in an oxygen atmosphere. However, it is not described at all nor even suggested that the adhesiveness between the semiconductor layer and the source electrode or drain electrode is secured by forming an oxide layer on the source or drain electrodes as a result of reaction between Cu alloy and a Si oxide layer contacting to the Cu alloy by heat treatment, as mentioned in the present invention. Further, an electrically stable contact between the source electrode or drain electrode and the semiconductor layer is not described nor suggested.\\nIn other words, there is a need to provide a solution for all the above-mentioned problems such as, for example, depositing the Cu alloy layer with fewer process steps, decreasing effective resistance of interconnections, and forming a stable electric contact with improving the adhesiveness between the semiconductor layer and the source or drain electrodes', \"<|endoftext|> = 0.96 Å and *U*~iso~(H) = 1.5*U*~eq~(C) for methyl.\\n\\nFigures\\n=======\\n\\n![The asymmetric of title compound, with the atom numbering. Displacement ellipsoids of non-H atoms are drawn at the 30% probalility level.](e-65-o2627-fig1){#Fap1}\\n\\nCrystal data {#tablewrapcrystaldatalong}\\n============\\n\\n  ------------------------ ---------------------------------------\\n  C~16~H~25~NO~3~          *Z* = 4\\n  *M~r~* = 279.37          *F*(000) = 608\\n  Triclinic, *P*1          *D*~x~ = 1.140 Mg m^−3^\\n  Hall symbol: -P 1        Mo *K*α radiation, λ = 0.71073 Å\\n  *a* = 5.642 (3) Å        Cell parameters from 9752 reflections\\n  *b* = 16.065 (8) Å       θ = 3.2--27.5°\\n  *c* = 19.135 (7) Å       µ = 0.08 mm^−1^\\n  α = 107.410 (16)°        *T* = 291 K\\n  β = 90.610 (16)°         Block, colorless\\n  γ = 99.780 (18)°         0.20 × 0.19 × 0.17 mm\\n  *V* = 1627.4 (13) Å^3^   \\n  ------------------------ ---------------------------------------\\n\\nData collection {#tablewrapdatacollectionlong}\\n===============\\n\\n  ------------------------------------------------------------- --------------------------------------\\n  Rigaku R-AXIS RAPID diffractometer                            7274 independent reflections\\n  Radiation source: fine-focus sealed tube                      3970 reflections with *I* \\\\> 2σ(*I*)\\n  graphite                                                      *R*~int~ = 0.030\\n  ω scans                                                       θ~max~ = 27.5°, θ~min~ = 3.2°\\n  Absorption correction: multi-scan (*ABSCOR*; Higashi, 1995)   *h* = −7→7\\n  *T*~min~ = 0.984, *T*~max~ = 0.987                            *k* = −20→20\\n  15990 measured reflections                                    *l* = −23→24\\n  ------------------------------------------------------------- --------------------------------------\\n\\nRefinement {#tablewraprefinementdatalong}\\n==========\\n\\n  ------------------------------------- ----------------------------------------------------------------------------------\\n  Refinement on *F*^2^                  Primary atom site location: structure-invariant direct methods\\n  Least-squares matrix: full            Secondary atom site location: difference Fourier map\\n  *R*\\\\[*F*^2^ \\\\> 2σ(*F*^2^)\\\\] = 0.052   Hydrogen site location: inferred from neighbouring sites\\n  *wR*(*F*^2^) = 0.176                  H-atom parameters constrained\\n  *S* = 0.97                            *w* = 1/\\\\[σ^2^(*F*~o~^2^) + (0.1*P*)^2^\\\\] where *P* = (*F*~o~^2^ + 2*F*~c~^2^)/3\\n  7274 reflections                      (Δ/σ)~max~ \\\\< 0.001\\n  363 parameters                        Δρ~max~ = 0.18 e Å^−3^\\n  0 restraints                          Δρ~min~ = −0.17 e Å^−3^\\n  ------------------------------------- ----------------------------------------------------------------------------------\\n\\nSpecial details {#specialdetails}\\n===============\\n\\n  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n  Geometry. All e.s.d.\\\\'s (except the e.s.d. in the dihedral angle between two l.s. planes) are estimated using the full covariance matrix. The cell e.s.d.\\\\'s are taken into account individually in the estimation of e.s.d.\\\\'s in distances, angles and torsion angles; correlations between e.s.d.\\\\'s in cell parameters are only used when they are defined by crystal symmetry. An approximate (isotropic) treatment of cell e.s.d.\\\\'s is used for estimating e.s.d.\\\\'s involving l.s. planes.\\n  Refinement. Refinement of *F*^2^ against ALL reflections. The weighted *R*-factor *wR* and goodness of fit *S* are based on *F*^2^, conventional *R*-factors *R* are based on *F*, with *F* set to zero for negative *F*^2^. The threshold expression of *F*^2^ \\\\> σ(*F*^2^) is used only for calculating *R*-factors(gt) *etc\", \"<|endoftext|> and methylsulfanyl substituted benzene ring, respectively. In the crystal, molecules are connected *via* intermolecular C---H···O hydrogen bonds (Fig.2) to form layers. The crystal structure is further stabilized by π-π interactions between the benzene ring (C10---C15) of the molecule at (*x*, *y*, *z*) and the same benzene ring of inversion related molecules at (2 - *x*, -1 - *y*, -*z*) \\\\[centroid separation = 3.681\\xa0(1) Å, interplanar spacing = 3.512 Å and centroid shift = 1.102 Å\\\\] and (1 - *x*, -1 - *y*, -*z*) \\\\[centroid separation = 3.818\\xa0(1) Å, interplanar spacing = 3.379 Å and centroid shift = 1.777 Å\\\\].\\n\\nExperimental {#experimental}\\n============\\n\\nTo a mixture of 1-(4,4\\\\'\\\\'-difluoro-5\\\\'-methoxy-1,1\\\\':3\\\\',1\\\\'\\\\'-terphenyl-4\\\\'-yl)ethanone (0.338 g, 001 mol) and 4-(methylsulfanyl)benzaldehyde (0.152 g, 0.001 mol) in 30 ml ethanol, 0.5 ml of 10% sodium hydroxide solution was added and the reaction mixture was stirred at 5--10°C for 3 hrs. The precipitate formed was collected by filtration and purified by recrystallization from ethanol ( yield 72%; m.p. 407 K). Single-crystal was grown from DMF by slow evaporation method.\\n\\nRefinement {#refinement}\\n==========\\n\\nAll H atoms were positioned geometrically and were treated as riding on their parent C atoms, with C---H distances of 0.93--0.96 Å and with *U*~iso~(H) = 1.2*U*~eq~(C) or 1.5*U*~eq~(methyl C).\\n\\nFigures\\n=======\\n\\n![ORTEP view of the molecule with the atom-labeling scheme. The displacement ellipsoids are drawn at the 40% probability level. H atoms are shown as small spheres of arbitrary radii.](e-68-o2378-fig1){#Fap1}\\n\\n![The packing arrangement of molecules viewed down the a axis.](e-68-o2378-fig2){#Fap2}\\n\\nCrystal data {#tablewrapcrystaldatalong}\\n============\\n\\n  ------------------------ ---------------------------------------\\n  C~29~H~22~F~2~O~2~S      *Z* = 2\\n  *M~r~* = 472.53          *F*(000) = 492\\n  Triclinic, *P*1          *D*~x~ = 1.329 Mg m^−3^\\n  Hall symbol: -P 1        Mo *K*α radiation, λ = 0.71073 Å\\n  *a* = 6.9341 (3) Å       Cell parameters from 6989 reflections\\n  *b* = 11.4440 (4) Å      θ = 3.4--29.0°\\n  *c* = 15.4719 (5) Å      µ = 0.18 mm^−1^\\n  α = 89.611 (3)°          *T* = 293 K\\n  β = 84.738 (3)°          Block, colourless\\n  γ = 74.981 (3)°          0.3 × 0.2 × 0.1 mm\\n  *V* = 1180.63 (8) Å^3^   \\n  ------------------------ ---------------------------------------\\n\\nData collection {#tablewrapdatacollectionlong}\\n===============\\n\\n  ------------------------------------------------------------------------------ --------------------------------------\\n  Oxford Diffraction Xcalibur Sapphire3 diffractometer                           4637 independent reflections\\n  Radiation source: fine-focus sealed tube                                       2891 reflections with *I* \\\\> 2σ(*I*)\\n  Graphite monochromator                                                         *R*~int~ = 0.044\\n  Detector resolution: 16.1049 pixels mm^-1^                                     θ~max~ = 26.0°, θ~min~ = 3.4°\\n  ω scans                                                                        *h* = −8→8\\n  Absorption correction: multi-scan (*CrysAlis PRO*; Oxford Diffraction, 2010)   *k* = −14→14\\n  *T*~min~ = 0.743, *T*~max~ = 1.000                                             *l* = −19→18\\n  17866 measured reflections                                                     \\n  ------------------------------------------------------------------------------ --------------------------------------\\n\\nRefinement {#tablewraprefinementdatalong}\\n==========\\n\\n  ------------------------------------- ------------------------------------------------------------------------------------------------\\n  Refinement on *F*^\", '<|endoftext|>···π (Egli & Sarkhel, 2007) interactions form between one terminal S atom of the anion and the other terminal π system of adjacent anion \\\\[S1···Cg1^i^ = 3.378\\xa0(2) and S10^i^···Cg2 = 3.537\\xa0(2) Å. Cg1 and Cg2 are the centroids of C4--C6, S8, S9 ring and C1--C3, S2, S3 ring, respectively. Symmetry code: (i) x, -1+y, 1+z\\\\]. The anion and the neighbouring cation are also associated together through lp···π interactions between two terminal S atoms of the anion and the pyridine rings of two different cations \\\\[S1···Cg3^ii^ = 3.360\\xa0(3) and S10···Cg3^iii^ = 3.681\\xa0(3) Å. Cg3 is the centroid of C14--C18, N1 ring. Symmetry codes: (ii) 1+x, -1+y, z; (iii) x, 1+y, -1+z\\\\]. The weak S···S and S(lp)···π interactions lead to a three-dimensional supramolecular structure. In addition, the cations adopt a parallel arrangement, and the shortest distance between H14 from the pyridine ring of a cation and F1 atom from the neighbouring cation is 2.60 Å, indicating the existence of a C---H···F hydrogen bond (Table 2), which stabilizes the three-dimensional structure (Fig. 2).\\n\\nExperimental {#experimental}\\n============\\n\\n4,5-Bis(thiobenzoyl)-1,3-dithiole-2-thione (812 mg, 2.0 mmol) (Wang *et al.*, 1998) was suspended in dry methanol (20 ml) and sodium (92 mg, 4.0 mmol) was added under a nitrogen atmosphere at room temperature to give a bright-red solution. NiCl~2~.6H~2~O (238 mg, 1 mmol) was then added, followed successively by addition of I~2~ (127 mg, 0.5 mmol) and a solution of *N*-(2-fluoro-4-bromobenzyl)pyridinium bromide (346 mg, 1 mmol) in methanol at an interval of approximately 20 min. The solution was stirred for a further 30 min and the resulting solid was collected by filtration. Single crystals of the title compound were obtained by evaporation of a dilute acetone solution over 1--2 weeks at room temperature.\\n\\nRefinement {#refinement}\\n==========\\n\\nH atoms were positioned geometrically and refined using a riding model, with C---H = 0.93(aromatic) and 0.97(CH~2~) Å and *U*~iso~(H) = 1.2*U*~eq~(C).\\n\\nFigures\\n=======\\n\\n![The structures of the cation and anion in the title compound, with displacement ellipsoids drawn at the 50% probability level.](e-66-m1367-fig1){#Fap1}\\n\\n![Three-dimensional supramolecular structure of the title compound. H atoms have been omitted for clarity. Dashed lines indicate weak S···S, S···π and C---H···F interactions.](e-66-m1367-fig2){#Fap2}\\n\\nCrystal data {#tablewrapcrystaldatalong}\\n============\\n\\n  ------------------------------------- --------------------------------------\\n  (C~12~H~10~BrFN)\\\\[Ni(C~3~S~5~)~2~\\\\]   *Z* = 1\\n  *M~r~* = 718.56                       *F*(000) = 357\\n  Triclinic, *P*1                       *D*~x~ = 1.909 Mg m^−3^\\n  Hall symbol: P 1                      Mo *K*α radiation, λ = 0.71073 Å\\n  *a* = 6.2952 (15) Å                   Cell parameters from 617 reflections\\n  *b* = 9.716 (2) Å                     θ = 3.5--25.2°\\n  *c* = 11.482 (3) Å                    µ = 3.23 mm^−1^\\n  α = 65.953 (4)°                       *T* = 296 K\\n  β = 77.592 (4)°                       Block, black\\n  γ = 88.498 (4)°                       0.19 × 0.16 × 0.15 mm\\n  *V* = 624.9 (3) Å^3^                  \\n  ------------------------------------- --------------------------------------\\n\\nData collection {#tablewrapdatacollectionlong}\\n===============\\n\\n  ------------------------------------------------------------ --------------------------------------\\n  Bruker APEXII CCD diffract', '<|endoftext|>\\nAll H atoms were placed at geometrically calculated positions and included in the refinement in the riding model approximation, with C---H lengths of 0.93 (CH), 0.96 (CH~3~) and 0.97 (CH~2~) Å. *U*~iso~ of the H atoms was set at 1.5*U*~eq~ of the parent C atom for the methyl group and at 1.2*U*~eq~ otherwise.\\n\\nFigures\\n=======\\n\\n![The molecular structure of the title compound, with atom labels and 40% probability displacement ellipsoids for non-H atoms.](e-69-o1625-fig1){#Fap1}\\n\\n![Intermolecular interactions in the title compound: (a) C---H···O interactions (dashed lines) connecting centrosymmetrically related molecules into dimers; (b) C---H···π (dotted lines) and C---H···S interactions (dashed lines) connecting the molecules along a axis. H-atoms not involved in hydrogen interactions are omitted.](e-69-o1625-fig2){#Fap2}\\n\\nCrystal data {#tablewrapcrystaldatalong}\\n============\\n\\n  ------------------------ ---------------------------------------\\n  C~11~H~14~OS             *Z* = 2\\n  *M~r~* = 194.28          *F*(000) = 208\\n  Triclinic, *P*1          *D*~x~ = 1.198 Mg m^−3^\\n  Hall symbol: -P 1        Cu *K*α radiation, λ = 1.54180 Å\\n  *a* = 7.2703 (11) Å      Cell parameters from 1309 reflections\\n  *b* = 7.3226 (7) Å       θ = 7.0--72.1°\\n  *c* = 11.7615 (11) Å     µ = 2.33 mm^−1^\\n  α = 88.232 (8)°          *T* = 293 K\\n  β = 79.343 (10)°         Prismatic, colourless\\n  γ = 61.350 (13)°         0.50 × 0.26 × 0.14 mm\\n  *V* = 538.80 (13) Å^3^   \\n  ------------------------ ---------------------------------------\\n\\nData collection {#tablewrapdatacollectionlong}\\n===============\\n\\n  ------------------------------------------------------------------- --------------------------------------\\n  Agilent Gemini S diffractometer                                     2052 independent reflections\\n  Radiation source: Enhance (Cu) X-ray Source                         1731 reflections with *I* \\\\> 2σ(*I*)\\n  Graphite monochromator                                              *R*~int~ = 0.027\\n  Detector resolution: 16.3280 pixels mm^-1^                          θ~max~ = 72.9°, θ~min~ = 3.8°\\n  ω scans                                                             *h* = −8→8\\n  Absorption correction: multi-scan (*CrysAlis PRO*; Agilent, 2013)   *k* = −9→5\\n  *T*~min~ = 0.444, *T*~max~ = 1.000                                  *l* = −14→14\\n  3254 measured reflections                                           \\n  ------------------------------------------------------------------- --------------------------------------\\n\\nRefinement {#tablewraprefinementdatalong}\\n==========\\n\\n  ------------------------------------- ------------------------------------------------------------------------------------------------\\n  Refinement on *F*^2^                  Primary atom site location: structure-invariant direct methods\\n  Least-squares matrix: full            Secondary atom site location: difference Fourier map\\n  *R*\\\\[*F*^2^ \\\\> 2σ(*F*^2^)\\\\] = 0.055   Hydrogen site location: inferred from neighbouring sites\\n  *wR*(*F*^2^) = 0.170                  H-atom parameters constrained\\n  *S* = 1.07                            *w* = 1/\\\\[σ^2^(*F*~o~^2^) + (0.1046*P*)^2^ + 0.083*P*\\\\] where *P* = (*F*~o~^2^ + 2*F*~c~^2^)/3\\n  2052 reflections                      (Δ/σ)~max~ \\\\< 0.001\\n  120 parameters                        Δρ~max~ = 0.34 e Å^−3^\\n  0 restraints                          Δρ~min~ = −0.33 e Å^−3^\\n  ------------------------------------- ------------------------------------------------------------------------------------------------\\n\\nFractional atomic coordinates and isotropic or equivalent isotropic displacement parameters (Å^2^) {#tablewrapcoords}\\n==================================================================================================\\n\\n  ------ -------------- -------------- --------------- -------------------- --\\n         *x*            *y*            *z*             *U*~iso~\\\\*/*U*~eq~   \\n  S1     0.31244 (10', '<|endoftext|>acrylate (1 mmol), isatin (1 mmol) and sarcosine (1 mmol) was refluxed in methanol until completion of the reaction was evidenced by TLC analysis. After completion of the reaction the solvent was evaporated under reduced pressure. The reaction mixture was dissolved in ethyl acetate and washed with water followed by brine solution. The organic layer was separated and evaporated under reduced pressure. The crude mixture was purified by column chromatography using ethyl acetate and hexane as eluent (4: 6). The product was dissolved in chloroform and heated for two minutes. The resulting solution was subjected to crystallization by slow evaporation of the solvent for 48 h resulting in the formation of single crystals.\\n\\nRefinement {#refinement}\\n==========\\n\\nThe H atoms were positioned geometrically with N---H = 0.86 Å and C---H = 0.93, 0.96, 0.97 and 0.98 Å for aryl, methyl, methylene and methyne H atoms, respectively, and constrained to ride on their parent atoms, with *U*~iso~(H) = 1.5*U*~eq~(methyl C) or 1.2*U*~eq~(non-methyl C/N).\\n\\nFigures\\n=======\\n\\n![A perspective view of the molecule showing the thermal ellipsoids drawn at the 30% probability level.](e-68-o2202-fig1){#Fap1}\\n\\n![N---H···O and C---H···O interactions (dotted lines) in the crystal structure of the title compound. The crystal packing of the molecules is viewed down the a axis.](e-68-o2202-fig2){#Fap2}\\n\\nCrystal data {#tablewrapcrystaldatalong}\\n============\\n\\n  ------------------------ ---------------------------------------\\n  C~30~H~27~N~3~O~6~       *Z* = 2\\n  *M~r~* = 525.55          *F*(000) = 552\\n  Triclinic, *P*1          *D*~x~ = 1.328 Mg m^−3^\\n  Hall symbol: -P 1        Mo *K*α radiation, λ = 0.71073 Å\\n  *a* = 10.8510 (4) Å      Cell parameters from 1025 reflections\\n  *b* = 11.1669 (4) Å      θ = 1.9--28.4°\\n  *c* = 11.2736 (4) Å      µ = 0.09 mm^−1^\\n  α = 103.087 (2)°         *T* = 293 K\\n  β = 97.367 (2)°          Block, colourless\\n  γ = 93.402 (2)°          0.25 × 0.23 × 0.2 mm\\n  *V* = 1314.05 (8) Å^3^   \\n  ------------------------ ---------------------------------------\\n\\nData collection {#tablewrapdatacollectionlong}\\n===============\\n\\n  ------------------------------------------------------------ --------------------------------------\\n  Bruker SMART APEXII area-detector diffractometer             6513 independent reflections\\n  Radiation source: fine-focus sealed tube                     4678 reflections with *I* \\\\> 2σ(*I*)\\n  Graphite monochromator                                       *R*~int~ = 0.027\\n  ω and φ scans                                                θ~max~ = 28.4°, θ~min~ = 1.9°\\n  Absorption correction: multi-scan (*SADABS*; Bruker, 2008)   *h* = −14→14\\n  *T*~min~ = 0.977, *T*~max~ = 0.981                           *k* = −14→14\\n  24049 measured reflections                                   *l* = −14→14\\n  ------------------------------------------------------------ --------------------------------------\\n\\nRefinement {#tablewraprefinementdatalong}\\n==========\\n\\n  ------------------------------------- -------------------------------------------------------------------------------------------------\\n  Refinement on *F*^2^                  Primary atom site location: structure-invariant direct methods\\n  Least-squares matrix: full            Secondary atom site location: difference Fourier map\\n  *R*\\\\[*F*^2^ \\\\> 2σ(*F*^2^)\\\\] = 0.042   Hydrogen site location: inferred from neighbouring sites\\n  *wR*(*F*^2^) = 0.114                  H-atom parameters constrained\\n  *S* = 1.03                            *w* = 1/\\\\[σ^2^(*F*~o~^2^) + (0.0516*P*)^2^ + 0.1891*P*\\\\] where *P* = (*F*~o~^2^ + 2*F*~c~^2^)/3\\n  6513 reflections                      (Δ/σ)~max~ \\\\< 0.001\\n  354 parameters                        Δρ~max~ = 0.20 e', \"<|endoftext|>N). The hydroxyl and C-bound H atoms were included in calculated positions and treated as riding atoms: O-H = 0.85 Å, N-H = 0.89 Å, and C-H = 0.93 Å, with *U*~iso~(H) = k × *U*~eq~ (O,N,C), where k = 1.5 for OH and NH~2~ H atoms, and k = 1.2 for C-bound H-atoms.\\n\\nFigures\\n=======\\n\\n![Molecular structure of the title compound showing the numbering scheme, and displacement ellipsoids drawn at the 50% probability level \\\\[H-atoms have been omitted for clarity\\\\].](e-67-m1344-fig1){#Fap1}\\n\\n![A view along the c-axis of the two-dimensional network in the crystal of the title compound, formed via N--H···O and O--H···O hydrogen bonds (red dashed lines; see Table 1 for details).](e-67-m1344-fig2){#Fap2}\\n\\nCrystal data {#tablewrapcrystaldatalong}\\n============\\n\\n  ------------------------------------------------------- ---------------------------------------\\n  \\\\[Co(C~12~H~10~N~6~)~2~(H~2~O)~2~\\\\](C~8~H~4~NO~6~)~2~   *Z* = 2\\n  *M~r~* = 991.73                                         *F*(000) = 1018\\n  Triclinic, *P*1                                         *D*~x~ = 1.533 Mg m^−3^\\n  Hall symbol: -P 1                                       Mo *K*α radiation, λ = 0.71073 Å\\n  *a* = 7.589 (3) Å                                       Cell parameters from 2949 reflections\\n  *b* = 16.104 (6) Å                                      θ = 2.3--27.8°\\n  *c* = 18.256 (6) Å                                      µ = 0.49 mm^−1^\\n  α = 74.739 (6)°                                         *T* = 296 K\\n  β = 86.435 (6)°                                         Block, red\\n  γ = 88.619 (6)°                                         0.28 × 0.20 × 0.10 mm\\n  *V* = 2148.4 (13) Å^3^                                  \\n  ------------------------------------------------------- ---------------------------------------\\n\\nData collection {#tablewrapdatacollectionlong}\\n===============\\n\\n  --------------------------------------------------------------- --------------------------------------\\n  Bruker SMART CCD area-detector diffractometer                   7532 independent reflections\\n  Radiation source: fine-focus sealed tube                        5560 reflections with *I* \\\\> 2σ(*I*)\\n  graphite                                                        *R*~int~ = 0.020\\n  φ and ω scans                                                   θ~max~ = 25.0°, θ~min~ = 1.5°\\n  Absorption correction: multi-scan (*SADABS*; Sheldrick, 1996)   *h* = −9→9\\n  *T*~min~ = 0.876, *T*~max~ = 0.953                              *k* = −19→14\\n  11079 measured reflections                                      *l* = −21→16\\n  --------------------------------------------------------------- --------------------------------------\\n\\nRefinement {#tablewraprefinementdatalong}\\n==========\\n\\n  ------------------------------------- -------------------------------------------------------------------------------------------------\\n  Refinement on *F*^2^                  Primary atom site location: structure-invariant direct methods\\n  Least-squares matrix: full            Secondary atom site location: difference Fourier map\\n  *R*\\\\[*F*^2^ \\\\> 2σ(*F*^2^)\\\\] = 0.039   Hydrogen site location: inferred from neighbouring sites\\n  *wR*(*F*^2^) = 0.098                  H-atom parameters constrained\\n  *S* = 1.03                            *w* = 1/\\\\[σ^2^(*F*~o~^2^) + (0.0395*P*)^2^ + 0.4823*P*\\\\] where *P* = (*F*~o~^2^ + 2*F*~c~^2^)/3\\n  7532 reflections                      (Δ/σ)~max~ = 0.001\\n  624 parameters                        Δρ~max~ = 0.19 e Å^−3^\\n  0 restraints                          Δρ~min~ = −0.28 e Å^−3^\\n  ------------------------------------- -------------------------------------------------------------------------------------------------\\n\\nSpecial details {#specialdetails}\\n===============\\n\\n  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n  Geometry. All e.s.d.\\\\'s (except the e.s.d. in the dihedral angle between two l.s. planes) are estimated using the full covariance\", '<|endoftext|>-face π-π stacking interactions \\\\[centroid--centroid^ii^ distance between the pyran rings of the 4*H*-chromene units = 3.854 (4) Å, ii: *x*, *y* + 1, *z*\\\\], as shown in Fig. 3. Shorter contacts than the sum of van der Waals radii are observed between the bromine atoms at 8-position and the formyl O atoms \\\\[Br1···O3^iii^ = 3.046 (4) Å, C7--Br1···O3^iii^ = 175.23 (18)°, Br1···O3^iii^--C10^iii^ = 132.6 (3)°, iii: --*x* + 2, *y* -- 1, --*z* + 3/2, Fig. 1*c*\\\\], features that indicate halogen bonding.\\n\\nS2. Experimental {#experimental}\\n================\\n\\nTo a solution of 3-bromo-2-hydroxyacetophenone (11.3 mmol) in *N*,*N*-dimethylformamide (20 ml) was added dropwise POCl~3~ (28.3 mmol) at 0 °C. After the mixture was stirred for 15 h at room temperature, water (50 ml) was added. The precipitates were collected, washed with water and dried *in vacuo* (yield: 55%). ^1^H NMR (400 MHz, CDCl~3~): *δ* = 7.40 (t, 1H, *J* = 7.8 Hz), 7.99 (dd, 1H, *J* = 1.4 and 7.8 Hz), 8.26 (dd, 1H, *J* = 1.4 and 8.3 Hz), 8.62 (s, 1H), 10.38 (s, 1H). Single crystals suitable for X-ray diffraction were obtained from a 1,2-dimethoxyethane solution of the title compound at room temperature.\\n\\nS3. Refinement {#refinement}\\n==============\\n\\nThe C(*sp*^2^)-bound hydrogen atoms were placed in geometrical positions \\\\[C--H 0.95 Å, *U*~iso~(H) = 1.2*U*~eq~(C)\\\\], and refined using a riding model.\\n\\nFigures\\n=======\\n\\n![Sphere models of the crystal structures of (a) 6-bromo-4-oxo-4H-chromene-3-carbaldehyde (Ishikawa, 2014a), (b) 7-bromo-4-oxo-4H-chromene-3-carbaldehyde (Ishikawa, 2014b) and (c) the title compound (this work).](e-71-0o572-fig1){#Fap1}\\n\\n![The molecular structure of the title compound with displacement ellipsoids drawn at the 50% probability level. Hydrogen atoms are shown as small spheres of arbitrary radius.](e-71-0o572-fig2){#Fap2}\\n\\n![A packing view of the title compound. C---H···O hydrogen bonds and Br···O halogen bonds are represented by dashed lines.](e-71-0o572-fig3){#Fap3}\\n\\nCrystal data {#tablewrapcrystaldatalong}\\n============\\n\\n  ------------------------ -------------------------------------\\n  C~10~H~5~BrO~3~          *F*(000) = 992.00\\n  *M~r~* = 253.05          *D*~x~ = 1.963 Mg m^−3^\\n  Monoclinic, *C*2/*c*     Mo *K*α radiation, λ = 0.71069 Å\\n  Hall symbol: -C 2yc      Cell parameters from 25 reflections\\n  *a* = 27.908 (14) Å      θ = 15.0--17.3°\\n  *b* = 3.854 (3) Å        µ = 4.79 mm^−1^\\n  *c* = 19.145 (10) Å      *T* = 100 K\\n  β = 123.75 (4)°          Plate, yellow\\n  *V* = 1712.1 (18) Å^3^   0.37 × 0.10 × 0.07 mm\\n  *Z* = 8                  \\n  ------------------------ -------------------------------------\\n\\nData collection {#tablewrapdatacollectionlong}\\n===============\\n\\n  ------------------------------------------------------ ----------------------------------------------\\n  Rigaku AFC-7R diffractometer                           *R*~int~ = 0.020\\n  ω scans                                                θ~max~ = 27.5°\\n  Absorption correction: ψ scan (North *et al.*, 1968)   *h* = −20→36\\n  *T*~', '<|endoftext|> - C1 are 2.9\\xa0(3), -177.4\\xa0(2), 0.2\\xa0(3) and -180.0\\xa0(2)°, respectively.\\n\\nThe packing of molecules into layered row like chains along *c*-axis is shown in Fig.2.\\n\\nExperimental {#experimental}\\n============\\n\\nThe solution of succinic anhydride (0.025 mole) in toluene (25 ml) was treated dropwise with the solution of 2,3-dimethylaniline (0.025 mole) also in toluene (25 ml) with constant stirring. The resulting mixture was stirred for one h and set aside for an additional hour at room temperature for the completion of reaction. The mixture was then treated with dilute hydrochloric acid to remove the unreacted 2,3-dimethylaniline. The resultant solid *N*-(2,3-dimethylphenyl)succinamic acid was filtered under suction and washed thoroughly with water to remove the unreacted succinic anhydride and succinic acid. It was recrystallized to constant melting point from ethanol.\\n\\n*N*-(2,3-Dimethylphenyl)succinamic acid was heated for 2 h and then allowed to cool slowly to room temperature to get the compound, *N*-(2,3-dimethylphenyl)succinimide. The purity of the compound was checked and characterized by its infrared spectra.\\n\\nPrism like colourless single crystals of the compound used in X-ray diffraction studies were grown in ethanolic solution by a slow evaporation at room temperature.\\n\\nRefinement {#refinement}\\n==========\\n\\nThe H atoms were positioned with idealized geometry using a riding model with C---H = 0.93--0.97 Å. Isotropic displacement parameters for the H atoms were set equal to 1.2 U~eq~ (parent atom).\\n\\nIn the absence of significant anomalous dispersion effects, Friedel pairs were merged and the Δf\\\\\"term set to zero.\\n\\nFigures\\n=======\\n\\n![Molecular structure of the title compound, showing the atom labelling scheme. The displacement ellipsoids are drawn at the 50% probability level. The H atoms are represented as small spheres of arbitrary radii.](e-66-0o919-fig1){#Fap1}\\n\\n![Molecular packing of the title compound.](e-66-0o919-fig2){#Fap2}\\n\\nCrystal data {#tablewrapcrystaldatalong}\\n============\\n\\n  ------------------------- -------------------------------------\\n  C~12~H~13~NO~2~           *F*(000) = 432\\n  *M~r~* = 203.23           *D*~x~ = 1.281 Mg m^−3^\\n  Monoclinic, *P*2~1~/*c*   Cu *K*α radiation, λ = 1.54180 Å\\n  Hall symbol: -P 2ybc      Cell parameters from 25 reflections\\n  *a* = 6.0600 (5) Å        θ = 5.4--18.0°\\n  *b* = 16.429 (2) Å        µ = 0.71 mm^−1^\\n  *c* = 10.593 (1) Å        *T* = 299 K\\n  β = 91.992 (8)°           Prism, colourless\\n  *V* = 1054.00 (18) Å^3^   0.40 × 0.20 × 0.15 mm\\n  *Z* = 4                   \\n  ------------------------- -------------------------------------\\n\\nData collection {#tablewrapdatacollectionlong}\\n===============\\n\\n  ------------------------------------------ --------------------------------------\\n  Enraf--Nonius CAD-4 diffractometer         *R*~int~ = 0.016\\n  Radiation source: fine-focus sealed tube   θ~max~ = 66.9°, θ~min~ = 5.0°\\n  graphite                                   *h* = −7→1\\n  ω/2θ scans                                 *k* = −19→0\\n  2096 measured reflections                  *l* = −12→12\\n  1883 independent reflections               3 standard reflections every 120 min\\n  1472 reflections with *I* \\\\> 2σ(*I*)       intensity decay: 1.0%\\n  ------------------------------------------ --------------------------------------\\n\\nRefinement {#tablewraprefinementdatalong}\\n==========\\n\\n  ---------------------------------------------------------------- ----------------------------------------------------------------------------------------------------\\n  Refinement on *F*^2^                                             Secondary atom site location: difference Fourier map\\n  Least-squares matrix: full                                       Hydrogen site location: inferred from neighbouring sites\\n  *R*\\\\[*F*^2^ \\\\> 2σ(*F*^2^)\\\\] = 0.041                              H-atom parameters constrained\\n  *wR*(*F*^2^) = 0.122                                             *w* = 1', \"<|endoftext|>-ethyl acetate mixture (7:3 *v*/*v*), which afforded the pure compound. Melting point 282°C, yield: 67%.\\n\\nS3. Refinement {#refinement}\\n==============\\n\\nH atoms were placed at calculated positions and allowed to ride on their carrier atoms with C---H = 0.93--0.98 Å and with *U*~iso~ = 1.2*U*~eq~(C, N) for N, CH~2~ and CH atoms and *U*~iso~ = 1.5*U*~eq~(C) for CH~3~ atoms.\\n\\nFigures\\n=======\\n\\n![The molecular structure of compound showing 30% probability displacement ellipsoids.](e-70-0o968-fig1){#Fap1}\\n\\n![Partial packing view of the compound showing molecules interconnected through a C---H···π stacking interaction (dotted lines; symmetry code: (i) 1/2 - x, 1/2 + y, 1/2 - z)](e-70-0o968-fig2){#Fap2}\\n\\nCrystal data {#tablewrapcrystaldatalong}\\n============\\n\\n  ------------------------- ---------------------------------------\\n  C~24~H~14~BrN~3~S         *F*(000) = 920\\n  *M~r~* = 456.35           *D*~x~ = 1.532 Mg m^−3^\\n  Monoclinic, *P*2~1~/*c*   Mo *K*α radiation, λ = 0.71073 Å\\n  Hall symbol: -P 2ybc      Cell parameters from 2000 reflections\\n  *a* = 10.470 (5) Å        θ = 2--27°\\n  *b* = 21.353 (5) Å        µ = 2.20 mm^−1^\\n  *c* = 9.292 (5) Å         *T* = 293 K\\n  β = 107.710 (5)°          Block, colourless\\n  *V* = 1978.9 (15) Å^3^    0.52 × 0.23 × 0.17 mm\\n  *Z* = 4                   \\n  ------------------------- ---------------------------------------\\n\\nData collection {#tablewrapdatacollectionlong}\\n===============\\n\\n  --------------------------------------------------------------- --------------------------------------\\n  Bruker Kappa APEXII diffractometer                              4305 independent reflections\\n  Radiation source: fine-focus sealed tube                        2837 reflections with *I* \\\\> 2σ(*I*)\\n  Graphite monochromator                                          *R*~int~ = 0.041\\n  Detector resolution: 0 pixels mm^-1^                            θ~max~ = 27.0°, θ~min~ = 1.9°\\n  ω and φ scans                                                   *h* = −12→13\\n  Absorption correction: multi-scan (*SADABS*; Sheldrick, 1996)   *k* = −27→27\\n  *T*~min~ = 0.958, *T*~max~ = 0.986                              *l* = −11→11\\n  17079 measured reflections                                      \\n  --------------------------------------------------------------- --------------------------------------\\n\\nRefinement {#tablewraprefinementdatalong}\\n==========\\n\\n  ------------------------------------- -------------------------------------------------------------------------------------------------\\n  Refinement on *F*^2^                  Primary atom site location: structure-invariant direct methods\\n  Least-squares matrix: full            Secondary atom site location: difference Fourier map\\n  *R*\\\\[*F*^2^ \\\\> 2σ(*F*^2^)\\\\] = 0.046   Hydrogen site location: inferred from neighbouring sites\\n  *wR*(*F*^2^) = 0.121                  H-atom parameters constrained\\n  *S* = 1.02                            *w* = 1/\\\\[σ^2^(*F*~o~^2^) + (0.0618*P*)^2^ + 0.4334*P*\\\\] where *P* = (*F*~o~^2^ + 2*F*~c~^2^)/3\\n  4305 reflections                      (Δ/σ)~max~ \\\\< 0.001\\n  262 parameters                        Δρ~max~ = 0.48 e Å^−3^\\n  0 restraints                          Δρ~min~ = −0.35 e Å^−3^\\n  ------------------------------------- -------------------------------------------------------------------------------------------------\\n\\nSpecial details {#specialdetails}\\n===============\\n\\n  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n  Geometry. All e.s.d.\\\\'s (except the e.s.d. in the dihedral angle between two l.s. planes) are estimated using the full covariance matrix. The cell e.s.d.\\\\'s are taken into account individually in the estimation of e.s.d.\\\\'s in distances, angles and torsion angles; correlations between\"]\n","300 ['<|endoftext|>acrylate (1 mmol), isatin (1 mmol) and sarcosine (1 mmol) was refluxed in methanol until completion of the reaction was evidenced by TLC analysis. After completion of the reaction the solvent was evaporated under reduced pressure. The reaction mixture was dissolved in ethyl acetate and washed with water followed by brine solution. The organic layer was separated and evaporated under reduced pressure. The crude mixture was purified by column chromatography using ethyl acetate and hexane as eluent (4: 6). The product was dissolved in chloroform and heated for two minutes. The resulting solution was subjected to crystallization by slow evaporation of the solvent for 48 h resulting in the formation of single crystals.\\n\\nRefinement {#refinement}\\n==========\\n\\nThe H atoms were positioned geometrically with N---H = 0.86 Å and C---H = 0.93, 0.96, 0.97 and 0.98 Å for aryl, methyl, methylene and methyne H atoms, respectively, and constrained to ride on their parent atoms, with *U*~iso~(H) = 1.5*U*~eq~(methyl C) or 1.2*U*~eq~(non-methyl C/N).\\n\\nFigures\\n=======\\n\\n![A perspective view of the molecule showing the thermal ellipsoids drawn at the 30% probability level.](e-68-o2202-fig1){#Fap1}\\n\\n![N---H···O and C---H···O interactions (dotted lines) in the crystal structure of the title compound. The crystal packing of the molecules is viewed down the a axis.](e-68-o2202-fig2){#Fap2}\\n\\nCrystal data {#tablewrapcrystaldatalong}\\n============\\n\\n  ------------------------ ---------------------------------------\\n  C~30~H~27~N~3~O~6~       *Z* = 2\\n  *M~r~* = 525.55          *F*(000) = 552\\n  Triclinic, *P*1          *D*~x~ = 1.328 Mg m^−3^\\n  Hall symbol: -P 1        Mo *K*α radiation, λ = 0.71073 Å\\n  *a* = 10.8510 (4) Å      Cell parameters from 1025 reflections\\n  *b* = 11.1669 (4) Å      θ = 1.9--28.4°\\n  *c* = 11.2736 (4) Å      µ = 0.09 mm^−1^\\n  α = 103.087 (2)°         *T* = 293 K\\n  β = 97.367 (2)°          Block, colourless\\n  γ = 93.402 (2)°          0.25 × 0.23 × 0.2 mm\\n  *V* = 1314.05 (8) Å^3^   \\n  ------------------------ ---------------------------------------\\n\\nData collection {#tablewrapdatacollectionlong}\\n===============\\n\\n  ------------------------------------------------------------ --------------------------------------\\n  Bruker SMART APEXII area-detector diffractometer             6513 independent reflections\\n  Radiation source: fine-focus sealed tube                     4678 reflections with *I* \\\\> 2σ(*I*)\\n  Graphite monochromator                                       *R*~int~ = 0.027\\n  ω and φ scans                                                θ~max~ = 28.4°, θ~min~ = 1.9°\\n  Absorption correction: multi-scan (*SADABS*; Bruker, 2008)   *h* = −14→14\\n  *T*~min~ = 0.977, *T*~max~ = 0.981                           *k* = −14→14\\n  24049 measured reflections                                   *l* = −14→14\\n  ------------------------------------------------------------ --------------------------------------\\n\\nRefinement {#tablewraprefinementdatalong}\\n==========\\n\\n  ------------------------------------- -------------------------------------------------------------------------------------------------\\n  Refinement on *F*^2^                  Primary atom site location: structure-invariant direct methods\\n  Least-squares matrix: full            Secondary atom site location: difference Fourier map\\n  *R*\\\\[*F*^2^ \\\\> 2σ(*F*^2^)\\\\] = 0.042   Hydrogen site location: inferred from neighbouring sites\\n  *wR*(*F*^2^) = 0.114                  H-atom parameters constrained\\n  *S* = 1.03                            *w* = 1/\\\\[σ^2^(*F*~o~^2^) + (0.0516*P*)^2^ + 0.1891*P*\\\\] where *P* = (*F*~o~^2^ + 2*F*~c~^2^)/3\\n  6513 reflections                      (Δ/σ)~max~ \\\\< 0.001\\n  354 parameters                        Δρ~max~ = 0.20 e', \"<|endoftext|>.94; H, 4.31; N, 3.18.\\n\\nRefinement {#refinement}\\n==========\\n\\nH atoms were positioned geometrically and refined using a riding model, with C---H = 0.95Å and with *U*~iso~(H) = 1.2 times *U*~eq~(C).\\n\\nFigures\\n=======\\n\\n![The molecular structure of (I), with 50% probability displacement ellipsoids.](e-67-m1820-fig1){#Fap1}\\n\\nCrystal data {#tablewrapcrystaldatalong}\\n============\\n\\n  ---------------------------------------- ---------------------------------------\\n  \\\\[PdBr(C~4~H~3~N~2~)(C~18~H~15~P)~2~\\\\]   *F*(000) = 1592\\n  *M~r~* = 789.93                          *D*~x~ = 1.549 Mg m^−3^\\n  Monoclinic, *P*2~1~/*c*                  Mo *K*α radiation, λ = 0.71073 Å\\n  Hall symbol: -P 2ybc                     Cell parameters from 1845 reflections\\n  *a* = 15.0953 (10) Å                     θ = 2.7--21.4°\\n  *b* = 12.0379 (8) Å                      µ = 1.85 mm^−1^\\n  *c* = 19.8066 (13) Å                     *T* = 150 K\\n  β = 109.7481 (13)°                       Block, colourless\\n  *V* = 3387.5 (4) Å^3^                    0.35 × 0.20 × 0.12 mm\\n  *Z* = 4                                  \\n  ---------------------------------------- ---------------------------------------\\n\\nData collection {#tablewrapdatacollectionlong}\\n===============\\n\\n  ------------------------------------------------------------ --------------------------------------\\n  Bruker SMART APEX CCD area-detector diffractometer           7764 independent reflections\\n  Radiation source: fine-focus sealed tube                     5553 reflections with *I* \\\\> 2σ(*I*)\\n  graphite                                                     *R*~int~ = 0.079\\n  ω scans                                                      θ~max~ = 27.5°, θ~min~ = 1.4°\\n  Absorption correction: multi-scan (*SADABS*; Bruker, 2001)   *h* = −19→19\\n  *T*~min~ = 0.563, *T*~max~ = 0.808                           *k* = −15→11\\n  19582 measured reflections                                   *l* = −25→25\\n  ------------------------------------------------------------ --------------------------------------\\n\\nRefinement {#tablewraprefinementdatalong}\\n==========\\n\\n  ------------------------------------- -------------------------------------------------------------------------------------\\n  Refinement on *F*^2^                  Primary atom site location: structure-invariant direct methods\\n  Least-squares matrix: full            Secondary atom site location: difference Fourier map\\n  *R*\\\\[*F*^2^ \\\\> 2σ(*F*^2^)\\\\] = 0.052   Hydrogen site location: inferred from neighbouring sites\\n  *wR*(*F*^2^) = 0.132                  H-atom parameters constrained\\n  *S* = 1.01                            *w* = 1/\\\\[σ^2^(*F*~o~^2^) + (0.0532*P*)^2^\\\\] where *P* = (*F*~o~^2^ + 2*F*~c~^2^)/3\\n  7764 reflections                      (Δ/σ)~max~ \\\\< 0.001\\n  415 parameters                        Δρ~max~ = 0.87 e Å^−3^\\n  0 restraints                          Δρ~min~ = −0.98 e Å^−3^\\n  ------------------------------------- -------------------------------------------------------------------------------------\\n\\nSpecial details {#specialdetails}\\n===============\\n\\n  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n  Geometry. All e.s.d.\\\\'s (except the e.s.d. in the dihedral angle between two l.s. planes) are estimated using the full covariance matrix. The cell e.s.d.\\\\'s are taken into account individually in the estimation of e.s.d.\\\\'s in distances, angles and torsion angles; correlations between e.s.d.\\\\'s in cell parameters are only used when they are defined by crystal symmetry. An approximate (isotropic) treatment of cell e.s.d.\\\\'s is used for estimating e.s.d.\\\\'s involving l.s. planes.\\n  Refinement. Refinement of *F*^2^ against ALL reflections. The weighted *R*-factor *wR* and goodness of fit *S* are based on *F*^2^, conventional *R*-factors *R* are based on *F*, with *F\", \"<|endoftext|>N). The hydroxyl and C-bound H atoms were included in calculated positions and treated as riding atoms: O-H = 0.85 Å, N-H = 0.89 Å, and C-H = 0.93 Å, with *U*~iso~(H) = k × *U*~eq~ (O,N,C), where k = 1.5 for OH and NH~2~ H atoms, and k = 1.2 for C-bound H-atoms.\\n\\nFigures\\n=======\\n\\n![Molecular structure of the title compound showing the numbering scheme, and displacement ellipsoids drawn at the 50% probability level \\\\[H-atoms have been omitted for clarity\\\\].](e-67-m1344-fig1){#Fap1}\\n\\n![A view along the c-axis of the two-dimensional network in the crystal of the title compound, formed via N--H···O and O--H···O hydrogen bonds (red dashed lines; see Table 1 for details).](e-67-m1344-fig2){#Fap2}\\n\\nCrystal data {#tablewrapcrystaldatalong}\\n============\\n\\n  ------------------------------------------------------- ---------------------------------------\\n  \\\\[Co(C~12~H~10~N~6~)~2~(H~2~O)~2~\\\\](C~8~H~4~NO~6~)~2~   *Z* = 2\\n  *M~r~* = 991.73                                         *F*(000) = 1018\\n  Triclinic, *P*1                                         *D*~x~ = 1.533 Mg m^−3^\\n  Hall symbol: -P 1                                       Mo *K*α radiation, λ = 0.71073 Å\\n  *a* = 7.589 (3) Å                                       Cell parameters from 2949 reflections\\n  *b* = 16.104 (6) Å                                      θ = 2.3--27.8°\\n  *c* = 18.256 (6) Å                                      µ = 0.49 mm^−1^\\n  α = 74.739 (6)°                                         *T* = 296 K\\n  β = 86.435 (6)°                                         Block, red\\n  γ = 88.619 (6)°                                         0.28 × 0.20 × 0.10 mm\\n  *V* = 2148.4 (13) Å^3^                                  \\n  ------------------------------------------------------- ---------------------------------------\\n\\nData collection {#tablewrapdatacollectionlong}\\n===============\\n\\n  --------------------------------------------------------------- --------------------------------------\\n  Bruker SMART CCD area-detector diffractometer                   7532 independent reflections\\n  Radiation source: fine-focus sealed tube                        5560 reflections with *I* \\\\> 2σ(*I*)\\n  graphite                                                        *R*~int~ = 0.020\\n  φ and ω scans                                                   θ~max~ = 25.0°, θ~min~ = 1.5°\\n  Absorption correction: multi-scan (*SADABS*; Sheldrick, 1996)   *h* = −9→9\\n  *T*~min~ = 0.876, *T*~max~ = 0.953                              *k* = −19→14\\n  11079 measured reflections                                      *l* = −21→16\\n  --------------------------------------------------------------- --------------------------------------\\n\\nRefinement {#tablewraprefinementdatalong}\\n==========\\n\\n  ------------------------------------- -------------------------------------------------------------------------------------------------\\n  Refinement on *F*^2^                  Primary atom site location: structure-invariant direct methods\\n  Least-squares matrix: full            Secondary atom site location: difference Fourier map\\n  *R*\\\\[*F*^2^ \\\\> 2σ(*F*^2^)\\\\] = 0.039   Hydrogen site location: inferred from neighbouring sites\\n  *wR*(*F*^2^) = 0.098                  H-atom parameters constrained\\n  *S* = 1.03                            *w* = 1/\\\\[σ^2^(*F*~o~^2^) + (0.0395*P*)^2^ + 0.4823*P*\\\\] where *P* = (*F*~o~^2^ + 2*F*~c~^2^)/3\\n  7532 reflections                      (Δ/σ)~max~ = 0.001\\n  624 parameters                        Δρ~max~ = 0.19 e Å^−3^\\n  0 restraints                          Δρ~min~ = −0.28 e Å^−3^\\n  ------------------------------------- -------------------------------------------------------------------------------------------------\\n\\nSpecial details {#specialdetails}\\n===============\\n\\n  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n  Geometry. All e.s.d.\\\\'s (except the e.s.d. in the dihedral angle between two l.s. planes) are estimated using the full covariance\", '<|endoftext|>BrNOS2 at the 70% probability level; hydrogen atoms are drawn as spheres of arbitrary radius.](e-65-0o598-fig1){#Fap1}\\n\\nCrystal data {#tablewrapcrystaldatalong}\\n============\\n\\n  ------------------------ ---------------------------------------\\n  C~22~H~22~BrNOS~2~       *Z* = 4\\n  *M~r~* = 460.44          *F*(000) = 944\\n  Triclinic, *P*1          *D*~x~ = 1.468 Mg m^−3^\\n  Hall symbol: -P 1        Mo *K*α radiation, λ = 0.71073 Å\\n  *a* = 11.8210 (2) Å      Cell parameters from 5387 reflections\\n  *b* = 12.8904 (2) Å      θ = 2.3--28.2°\\n  *c* = 15.8833 (3) Å      µ = 2.19 mm^−1^\\n  α = 67.670 (1)°          *T* = 100 K\\n  β = 71.434 (1)°          Prism, orange\\n  γ = 73.283 (1)°          0.40 × 0.15 × 0.05 mm\\n  *V* = 2083.56 (6) Å^3^   \\n  ------------------------ ---------------------------------------\\n\\nData collection {#tablewrapdatacollectionlong}\\n===============\\n\\n  --------------------------------------------------------------- --------------------------------------\\n  Bruker SMART APEX diffractometer                                9548 independent reflections\\n  Radiation source: fine-focus sealed tube                        7113 reflections with *I* \\\\> 2σ(*I*)\\n  graphite                                                        *R*~int~ = 0.029\\n  ω scans                                                         θ~max~ = 27.5°, θ~min~ = 1.7°\\n  Absorption correction: multi-scan (*SADABS*; Sheldrick, 1996)   *h* = −15→15\\n  *T*~min~ = 0.667, *T*~max~ = 0.899                              *k* = −16→16\\n  19892 measured reflections                                      *l* = −20→20\\n  --------------------------------------------------------------- --------------------------------------\\n\\nRefinement {#tablewraprefinementdatalong}\\n==========\\n\\n  ------------------------------------- -------------------------------------------------------------------------------------------------\\n  Refinement on *F*^2^                  Primary atom site location: structure-invariant direct methods\\n  Least-squares matrix: full            Secondary atom site location: difference Fourier map\\n  *R*\\\\[*F*^2^ \\\\> 2σ(*F*^2^)\\\\] = 0.034   Hydrogen site location: inferred from neighbouring sites\\n  *wR*(*F*^2^) = 0.091                  H atoms treated by a mixture of independent and constrained refinement\\n  *S* = 1.00                            *w* = 1/\\\\[σ^2^(*F*~o~^2^) + (0.0461*P*)^2^ + 0.3098*P*\\\\] where *P* = (*F*~o~^2^ + 2*F*~c~^2^)/3\\n  9548 reflections                      (Δ/σ)~max~ = 0.001\\n  499 parameters                        Δρ~max~ = 0.64 e Å^−3^\\n  2 restraints                          Δρ~min~ = −0.80 e Å^−3^\\n  ------------------------------------- -------------------------------------------------------------------------------------------------\\n\\nFractional atomic coordinates and isotropic or equivalent isotropic displacement parameters (Å^2^) {#tablewrapcoords}\\n==================================================================================================\\n\\n  ------ -------------- --------------- --------------- -------------------- --\\n         *x*            *y*             *z*             *U*~iso~\\\\*/*U*~eq~   \\n  Br1    0.82709 (3)    0.56564 (2)     0.965667 (18)   0.03058 (8)          \\n  Br2    0.99128 (3)    0.68807 (2)     0.63996 (2)     0.03598 (9)          \\n  S1     0.39347 (5)    1.31023 (5)     0.49538 (4)     0.02024 (14)         \\n  S2     0.37604 (6)    1.16479 (6)     0.69198 (4)     0.02758 (16)         \\n  S3     1.27628 (5)    −0.14493 (5)    1.10260 (4)     0.01872 (13)         \\n  S4     1.34366 (5)    0.04070 (5)     0.92901 (4)     0.', '<|endoftext|>) Å       *T* = 200 K\\n  β = 93.517 (2)°           Block, colorless\\n  *V* = 1669.29 (12) Å^3^   0.08 × 0.06 × 0.04 mm\\n  *Z* = 4                   \\n  ------------------------- ---------------------------------------\\n\\nData collection {#tablewrapdatacollectionlong}\\n===============\\n\\n  -------------------------------------------------------------- --------------------------------------\\n  Nonius KappaCCD diffractometer                                 3756 independent reflections\\n  Radiation source: fine-focus sealed tube                       3052 reflections with *I* \\\\> 2σ(*I*)\\n  graphite                                                       *R*~int~ = 0.033\\n  ω and φ scans                                                  θ~max~ = 27.4°, θ~min~ = 2.2°\\n  Absorption correction: multi-scan (*SORTAV*; Blessing, 1997)   *h* = −11→11\\n  *T*~min~ = 0.971, *T*~max~ = 0.986                             *k* = −23→18\\n  6489 measured reflections                                      *l* = −13→13\\n  -------------------------------------------------------------- --------------------------------------\\n\\nRefinement {#tablewraprefinementdatalong}\\n==========\\n\\n  ------------------------------------- -------------------------------------------------------------------------------------------------\\n  Refinement on *F*^2^                  Primary atom site location: structure-invariant direct methods\\n  Least-squares matrix: full            Secondary atom site location: difference Fourier map\\n  *R*\\\\[*F*^2^ \\\\> 2σ(*F*^2^)\\\\] = 0.049   Hydrogen site location: inferred from neighbouring sites\\n  *wR*(*F*^2^) = 0.112                  H-atom parameters constrained\\n  *S* = 1.09                            *w* = 1/\\\\[σ^2^(*F*~o~^2^) + (0.0212*P*)^2^ + 2.3993*P*\\\\] where *P* = (*F*~o~^2^ + 2*F*~c~^2^)/3\\n  3756 reflections                      (Δ/σ)~max~ \\\\< 0.001\\n  244 parameters                        Δρ~max~ = 0.30 e Å^−3^\\n  0 restraints                          Δρ~min~ = −0.42 e Å^−3^\\n  ------------------------------------- -------------------------------------------------------------------------------------------------\\n\\nSpecial details {#specialdetails}\\n===============\\n\\n  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n  Geometry. All esds (except the esd in the dihedral angle between two l.s. planes) are estimated using the full covariance matrix. The cell esds are taken into account individually in the estimation of esds in distances, angles and torsion angles; correlations between esds in cell parameters are only used when they are defined by crystal symmetry. An approximate (isotropic) treatment of cell esds is used for estimating esds involving l.s. planes.\\n  Refinement. Refinement of *F*^2^ against ALL reflections. The weighted *R*-factor wR and goodness of fit *S* are based on *F*^2^, conventional *R*-factors *R* are based on *F*, with *F* set to zero for negative *F*^2^. The threshold expression of *F*^2^ \\\\> σ(*F*^2^) is used only for calculating *R*-factors(gt) etc. and is not relevant to the choice of reflections for refinement. *R*-factors based on *F*^2^ are statistically about twice as large as those based on *F*, and *R*- factors based on ALL data will be even larger.\\n  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\nFractional atomic coordinates and isotropic or equivalent isotropic displacement parameters (Å^2^) {#tablewrapcoords}\\n==================================================================================================\\n\\n  ------ ------------- --------------- -------------- -------------------- --\\n         *x*           *y*             *z*            *U*~iso~\\\\*/*U*~eq~   \\n  S1     0.16733 (7)   0.13166 (4)     0.14038 (7)    0.03295 (17)         \\n  S2     0.38728 (7)   0.12529 (3)     0.66150 (6)    0.02728 (15)         \\n  O1     0.2772 (2)    0.12845 (12)    0.0444 (2)     0.0478 (5)           \\n  O2     0.1836 (2)    0.18787 (11)    0.2374 (2)     0.0429 (5)           \\n  O3     −0.0103 (2)   −0.04351 (11)   0.2382 (2)     0.0442 (5)           \\n  ', \"<|endoftext|>58                 *D*~x~ = 1.236 Mg m^−3^\\n  Orthorhombic, *P*2~1~2~1~2~1~   Mo *K*α radiation, λ = 0.71073 Å\\n  Hall symbol: P 2ac 2ab          Cell parameters from 7550 reflections\\n  *a* = 7.8695 (16) Å             θ = 1.4--26.0°\\n  *b* = 11.893 (2) Å              µ = 0.08 mm^−1^\\n  *c* = 28.346 (6) Å              *T* = 173 K\\n  *V* = 2652.9 (9) Å^3^           Block, colorless\\n  *Z* = 4                         0.35 × 0.26 × 0.12 mm\\n  ------------------------------- ---------------------------------------\\n\\nData collection {#tablewrapdatacollectionlong}\\n===============\\n\\n  ------------------------------------------------------------------ --------------------------------------\\n  Rigaku Saturn724+ diffractometer                                   2967 independent reflections\\n  Radiation source: Rotating Anode                                   2651 reflections with *I* \\\\> 2σ(*I*)\\n  Confocal                                                           *R*~int~ = 0.088\\n  Detector resolution: 28.5714 pixels mm^-1^                         θ~max~ = 26.0°, θ~min~ = 1.9°\\n  ω scans at fixed χ = 45°                                           *h* = −9→6\\n  Absorption correction: multi-scan (*CrystalClear*; Rigaku, 2008)   *k* = −14→14\\n  *T*~min~ = 0.525, *T*~max~ = 1.000                                 *l* = −18→34\\n  9151 measured reflections                                          \\n  ------------------------------------------------------------------ --------------------------------------\\n\\nRefinement {#tablewraprefinementdatalong}\\n==========\\n\\n  ------------------------------------- -------------------------------------------------------------------------------------------------\\n  Refinement on *F*^2^                  Primary atom site location: structure-invariant direct methods\\n  Least-squares matrix: full            Secondary atom site location: difference Fourier map\\n  *R*\\\\[*F*^2^ \\\\> 2σ(*F*^2^)\\\\] = 0.055   Hydrogen site location: inferred from neighbouring sites\\n  *wR*(*F*^2^) = 0.132                  H-atom parameters constrained\\n  *S* = 1.05                            *w* = 1/\\\\[σ^2^(*F*~o~^2^) + (0.0628*P*)^2^ + 0.4619*P*\\\\] where *P* = (*F*~o~^2^ + 2*F*~c~^2^)/3\\n  2967 reflections                      (Δ/σ)~max~ \\\\< 0.001\\n  334 parameters                        Δρ~max~ = 0.20 e Å^−3^\\n  0 restraints                          Δρ~min~ = −0.23 e Å^−3^\\n  ------------------------------------- -------------------------------------------------------------------------------------------------\\n\\nSpecial details {#specialdetails}\\n===============\\n\\n  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n  Geometry. All e.s.d.\\\\'s (except the e.s.d. in the dihedral angle between two l.s. planes) are estimated using the full covariance matrix. The cell e.s.d.\\\\'s are taken into account individually in the estimation of e.s.d.\\\\'s in distances, angles and torsion angles; correlations between e.s.d.\\\\'s in cell parameters are only used when they are defined by crystal symmetry. An approximate (isotropic) treatment of cell e.s.d.\\\\'s is used for estimating e.s.d.\\\\'s involving l.s. planes.\\n  Refinement. Refinement of *F*^2^ against ALL reflections. The weighted *R*-factor *wR* and goodness of fit *S* are based on *F*^2^, conventional *R*-factors *R* are based on *F*, with *F* set to zero for negative *F*^2^. The threshold expression of *F*^2^ \\\\> σ(*F*^2^) is used only for calculating *R*-factors(gt) *etc*. and is not relevant to the choice of reflections for refinement. *R*-factors based on *F*^2^ are statistically about twice as large as those based on *F*, and *R*- factors based on ALL data will be even larger.\\n  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\nFractional atomic coordinates and isotropic or equivalent isotropic displacement parameters (Å^2^) {#tablewrapcoords}\\n==================================================================================================\\n\\n  ------ ------------- -------------- -------------- -------------------- --\\n         *x*           *y*            *z*            *U*~iso~\\\\*/*U*~eq~   \\n  O1     0.1446 (\", \"<|endoftext|> and TFIP2/TFIP3. Supplementary Table A reports the main interactions of the structure. Figure 2 shows the crystal packing.\\n\\nExperimental {#experimental}\\n============\\n\\nThe synthesis of the compound was reported by Caronna *et al.*, (2004). Crystals for X-ray analysis were obtained *via* isothermal evaporation of a chloroform solution.\\n\\nRefinement {#refinement}\\n==========\\n\\nH atoms were obtained by difference map. They were refined independently with isotropic displacement parameters but restrained to have approximately the same C---H distances.\\n\\nFigures\\n=======\\n\\n![The molecular structure of the title compound with ellipsoids drawn at the 50% probability level.](e-69-0o579-fig1){#Fap1}\\n\\n![The crystal packing viewed along the a axis highlighting the π---π interactions between benzene rings.](e-69-0o579-fig2){#Fap2}\\n\\nCrystal data {#tablewrapcrystaldatalong}\\n============\\n\\n  ------------------------- ---------------------------------------\\n  C~29~H~8~F~16~I~4~O~4~    *F*(000) = 2280\\n  *M~r~* = 1231.95          *D*~x~ = 2.463 Mg m^−3^\\n  Monoclinic, *P*2~1~/*n*   Mo *K*α radiation, λ = 0.71073 Å\\n  *a* = 7.9716 (9) Å        Cell parameters from 8992 reflections\\n  *b* = 20.665 (3) Å        θ = 2.2--30.0°\\n  *c* = 20.194 (4) Å        µ = 3.88 mm^−1^\\n  β = 92.745 (12)°          *T* = 90 K\\n  *V* = 3322.8 (9) Å^3^     Neddle, colourless\\n  *Z* = 4                   0.34 × 0.06 × 0.04 mm\\n  ------------------------- ---------------------------------------\\n\\nData collection {#tablewrapdatacollectionlong}\\n===============\\n\\n  ------------------------------------------------------------ --------------------------------------\\n  Bruker APEX 2000 CCD area-detector diffractometer            9728 independent reflections\\n  Radiation source: fine-focus sealed tube                     7975 reflections with *I* \\\\> 2σ(*I*)\\n  Graphite monochromator                                       *R*~int~ = 0.042\\n  φ and ω scans                                                θ~max~ = 30.1°, θ~min~ = 1.4°\\n  Absorption correction: multi-scan (*SADABS*; Bruker, 1998)   *h* = −11→11\\n  *T*~min~ = 0.742, *T*~max~ = 1.000                           *k* = −29→25\\n  39668 measured reflections                                   *l* = −28→28\\n  ------------------------------------------------------------ --------------------------------------\\n\\nRefinement {#tablewraprefinementdatalong}\\n==========\\n\\n  ------------------------------------- -------------------------------------------------------------------------------------------------\\n  Refinement on *F*^2^                  Primary atom site location: structure-invariant direct methods\\n  Least-squares matrix: full            Secondary atom site location: difference Fourier map\\n  *R*\\\\[*F*^2^ \\\\> 2σ(*F*^2^)\\\\] = 0.038   Hydrogen site location: difference Fourier map\\n  *wR*(*F*^2^) = 0.093                  All H-atom parameters refined\\n  *S* = 1.04                            *w* = 1/\\\\[σ^2^(*F*~o~^2^) + (0.0456*P*)^2^ + 4.8626*P*\\\\] where *P* = (*F*~o~^2^ + 2*F*~c~^2^)/3\\n  9728 reflections                      (Δ/σ)~max~ = 0.004\\n  510 parameters                        Δρ~max~ = 2.08 e Å^−3^\\n  28 restraints                         Δρ~min~ = −0.54 e Å^−3^\\n  ------------------------------------- -------------------------------------------------------------------------------------------------\\n\\nSpecial details {#specialdetails}\\n===============\\n\\n  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n  Experimental. OXFORD low temperature device.\\n  Geometry. All e.s.d.\\\\'s (except the e.s.d. in the dihedral angle between two l.s. planes) are estimated using the full covariance matrix. The cell e.s.d.\\\\'s are taken into account individually in the estimation of e.s.d.\\\\'s in distances, angles and torsion angles; correlations between e.s.d.\\\\'s in cell parameters are only used when they are defined by crystal symmetry. An approximate (isotropic) treatment of cell\", '<|endoftext|> companies raising early stage equity during the week (For brevity’s sake, I’ll list the company along with its (sector), and (deal amount)) included MicroPower Global (Energy Efficiency), ($351,000); VCharge (Smart Grid), ($770,000); and Utilight (Solar), ($4.5 million).\\n\\nIn an interesting partnership for the Smart Grid sector, Silver Spring Networks and eMeter announced they would work together to integrate eMeter’s EnergyIP platform with Silver Spring’s UtilityIQ system for interoperability. The companies had initially partnered back in 2008, when Silver Spring joined eMeter’s ‘IntegratedMDM’ program.<|endoftext|>[Selective coronary angiography via flashing tomosynthesis].\\nTo assess the value and significance of short-term tomosynthesis in judging the pathological condition of coronary vessels, the authors examined 34 patients with coronary heart disease. In comparison with 35 mm cinecoronary angiography, all angiographically determined vascular occlusions and stenoses were identified via short-term tomosynthesis. Comparison of the degrees of stenoses yielded good correlation (r = 0.85). Short-term tomosynthesis offers the advantage of employing smaller amounts of contrast medium to be injected; furthermore, the examination period is shorter, and exposure to radiation is also significantly less.<|endoftext|>Related literature {#sec1}\\n==================\\n\\nFor our ongoing research investigating the reactions of various *O*,*O*′-and *N*,*O*-bidentate ligands with hafnium(IV) and zirconium(IV) to exploit possible separation techniques and for the crystal structures of hafnium(IV) and zirconium(IV) complexes, see: Viljoen *et al.* (2010[@bb8]); Steyn *et al.* (2011[@bb7]).\\n\\nExperimental {#sec2}\\n============\\n\\n {#sec2.1}\\n\\n### Crystal data {#sec2.1.1}\\n\\n\\\\[Hf~2~(C~10~H~6~F~3~O~2~)~6~(OH)~2~\\\\]·2C~3~H~7~NO*M* *~r~* = 1828.08Monoclinic,*a* = 12.4143 (3) Å*b* = 19.244 (5) Å*c* = 17.503 (5) Åβ = 122.937 (5)°*V* = 3509 (2) Å^3^*Z* = 2Mo *K*α radiationμ = 3.07 mm^−1^*T* = 100 K0.28 × 0.23 × 0.21 mm\\n\\n### Data collection {#sec2.1.2}\\n\\nBruker X8 APEXII 4K KappaCCD diffractometerAbsorption correction: multi-scan (*SADABS*; Bruker, 2004[@bb3]) *T* ~min~ = 0.431, *T* ~max~ = 0.52641903 measured reflections8726 independent reflections6864 reflections with *I* \\\\> 2σ(*I*)*R* ~int~ = 0.050\\n\\n### Refinement {#sec2.1.3}\\n\\n*R*\\\\[*F* ^2^ \\\\> 2σ(*F* ^2^)\\\\] = 0.030*wR*(*F* ^2^) = 0.072*S* = 1.038726 reflections475 parameters1 restraintH atoms treated by a mixture of independent and constrained refinementΔρ~max~ = 1.33 e Å^−3^Δρ~min~ = −0.97 e Å^−3^\\n\\n {#d5e474}\\n\\nData collection: *APEX2* (Bruker, 2005[@bb4]); cell refinement: *SAINT-Plus* (Bruker, 2004[@bb3]); data reduction: *SAINT-Plus*; program(s) used to solve structure: *SIR92* (Altomare *et al.*, 1999[@bb1]); program(s) used to refine structure: *SHELXL97* (Sheldrick, 2008[@bb6]); molecular graphics: *DIAMOND* (Brandenburg & Putz, 2005[@bb2]); software used to prepare material for publication: *WinGX* (Farrugia, 1999[@bb5]).\\n\\nSupplementary Material\\n======================\\n\\nCrystal structure: contains datablock(s) I, global. DOI: [10.1107/S1600536811049543/pv2484sup1.cif](http://dx.doi.org/10.1107/S1600536811049543/pv2484sup1.cif)\\n\\nStructure factors: contains datablock(s) I. DOI: [10.1107/S160053681', '<|endoftext|>*^2^)\\\\] = 0.043   H-atom parameters constrained\\n  *wR*(*F*^2^) = 0.097                  *w* = 1/\\\\[σ^2^(*F*~o~^2^) + (0.0336*P*)^2^ + 15.8643*P*\\\\] where *P* = (*F*~o~^2^ + 2*F*~c~^2^)/3\\n  *S* = 1.01                            (Δ/σ)~max~ = 0.003\\n  19875 reflections                     Δρ~max~ = 2.43 e Å^−3^\\n  851 parameters                        Δρ~min~ = −1.32 e Å^−3^\\n  ------------------------------------- --------------------------------------------------------------------------------------------------\\n\\nSpecial details {#d1e539}\\n===============\\n\\n  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n  Geometry. All esds (except the esd in the dihedral angle between two l.s. planes) are estimated using the full covariance matrix. The cell esds are taken into account individually in the estimation of esds in distances, angles and torsion angles; correlations between esds in cell parameters are only used when they are defined by crystal symmetry. An approximate (isotropic) treatment of cell esds is used for estimating esds involving l.s. planes.\\n  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\nFractional atomic coordinates and isotropic or equivalent isotropic displacement parameters (Å^2^) {#d1e558}\\n==================================================================================================\\n\\n  ------ -------------- -------------- -------------- -------------------- ------------\\n         *x*            *y*            *z*            *U*~iso~\\\\*/*U*~eq~   Occ. (\\\\<1)\\n  Ru1    1.00620 (2)    0.55309 (2)    0.32612 (2)    0.01502 (6)          \\n  Ru2    1.03733 (2)    0.43753 (2)    0.28780 (2)    0.01907 (6)          \\n  Ru3    1.02396 (2)    0.52319 (2)    0.18283 (2)    0.01861 (6)          \\n  Ru4    0.44772 (2)    0.73619 (2)    0.66392 (2)    0.01666 (6)          \\n  Ru5    0.43523 (2)    0.85302 (2)    0.70390 (2)    0.02018 (7)          \\n  Ru6    0.45413 (2)    0.76646 (2)    0.80837 (2)    0.02177 (7)          \\n  P1     0.95575 (6)    0.64831 (4)    0.33370 (4)    0.01513 (17)         \\n  P2     0.49391 (6)    0.64017 (4)    0.66137 (4)    0.01546 (17)         \\n  O1     1.19315 (19)   0.60410 (11)   0.29484 (15)   0.0285 (6)           \\n  O2     1.0800 (2)     0.52828 (12)   0.47441 (13)   0.0290 (6)           \\n  O3     0.8119 (2)     0.50828 (13)   0.35164 (16)   0.0366 (7)           \\n  O4     1.22972 (19)   0.47647 (12)   0.34408 (15)   0.0292 (6)           \\n  O5     0.9991 (2)     0.38167 (12)   0.42725 (15)   0.0364 (7)           \\n  O6     0.8389 (2)     0.41183 (14)   0.22927 (17)   0.0411 (8)           \\n  O7     1.1266 (3)     0.33838 (13)   0.21263 (18)   0.0459 (9)           \\n  O8     0.9924 (3)     0.43736 (14)   0.06391 (17)   0.0514 (9)           \\n  O9     1.0394 (2)     0.62774 (12)   0.08849 (14)   0.0345 (7)           \\n  O10    0.8182 (2)     0.54838 (13)   0.19471 (16)   0.0360 (7)           \\n  O11    1.2344', '<|endoftext|> 0.09 mm^−1^\\n  α = 113.030 (6)°         *T* = 100 K\\n  β = 101.231 (6)°         Prism, colorless\\n  γ = 102.378 (6)°         0.40 × 0.40 × 0.20 mm\\n  *V* = 761.45 (11) Å^3^   \\n  ------------------------ ---------------------------------------\\n\\nData collection {#tablewrapdatacollectionlong}\\n===============\\n\\n  ------------------------------------------------------------------- --------------------------------------\\n  Agilent SuperNova Dual diffractometer with an Atlas detector        3525 independent reflections\\n  Radiation source: SuperNova (Mo) X-ray Source                       2497 reflections with *I* \\\\> 2σ(*I*)\\n  Mirror monochromator                                                *R*~int~ = 0.027\\n  Detector resolution: 10.4041 pixels mm^-1^                          θ~max~ = 27.6°, θ~min~ = 3.4°\\n  ω scan                                                              *h* = −11→8\\n  Absorption correction: multi-scan (*CrysAlis PRO*; Agilent, 2013)   *k* = −11→12\\n  *T*~min~ = 0.964, *T*~max~ = 0.982                                  *l* = −13→13\\n  6267 measured reflections                                           \\n  ------------------------------------------------------------------- --------------------------------------\\n\\nRefinement {#tablewraprefinementdatalong}\\n==========\\n\\n  ------------------------------------- -------------------------------------------------------------------------------------------------\\n  Refinement on *F*^2^                  Primary atom site location: structure-invariant direct methods\\n  Least-squares matrix: full            Secondary atom site location: difference Fourier map\\n  *R*\\\\[*F*^2^ \\\\> 2σ(*F*^2^)\\\\] = 0.050   Hydrogen site location: inferred from neighbouring sites\\n  *wR*(*F*^2^) = 0.132                  H-atom parameters constrained\\n  *S* = 1.06                            *w* = 1/\\\\[σ^2^(*F*~o~^2^) + (0.0533*P*)^2^ + 0.0956*P*\\\\] where *P* = (*F*~o~^2^ + 2*F*~c~^2^)/3\\n  3525 reflections                      (Δ/σ)~max~ = 0.001\\n  199 parameters                        Δρ~max~ = 0.47 e Å^−3^\\n  0 restraints                          Δρ~min~ = −0.24 e Å^−3^\\n  ------------------------------------- -------------------------------------------------------------------------------------------------\\n\\nFractional atomic coordinates and isotropic or equivalent isotropic displacement parameters (Å^2^) {#tablewrapcoords}\\n==================================================================================================\\n\\n  ------ -------------- -------------- -------------- -------------------- --\\n         *x*            *y*            *z*            *U*~iso~\\\\*/*U*~eq~   \\n  O1     0.25854 (15)   0.56195 (13)   0.97044 (12)   0.0239 (3)           \\n  O2     0.17691 (14)   0.49329 (12)   0.68408 (12)   0.0201 (3)           \\n  O3     0.03197 (15)   0.26310 (13)   0.66616 (13)   0.0242 (3)           \\n  O4     0.54829 (15)   0.06265 (13)   0.33989 (13)   0.0245 (3)           \\n  C1     0.1367 (2)     0.61293 (18)   0.92258 (18)   0.0198 (4)           \\n  C2     0.0589 (2)     0.70167 (19)   1.01000 (18)   0.0212 (4)           \\n  H2     0.0890         0.7300         1.1126         0.025\\\\*              \\n  C3     −0.0628 (2)    0.75000 (19)   0.94958 (18)   0.0223 (4)           \\n  C4     −0.1092 (2)    0.70584 (19)   0.79870 (18)   0.0228 (4)           \\n  H4     −0.1929        0.7373         0.7565         0.027\\\\*              \\n  C5     −0.0329 (2)    0.61580 (19)   0.70993 (18)   0.0208 (4)           \\n  H5     −0.0646        0.5852         0.6069         ', \"<|endoftext|>e-69-o1794-fig1){#Fap1}\\n\\n![View of the hydrogen-bonding in (I). Dashed lines indicate O---H···Br and N---H···Br hydrogen bonds.](e-69-o1794-fig2){#Fap2}\\n\\n![Packing features in (I).](e-69-o1794-fig3){#Fap3}\\n\\nCrystal data {#tablewrapcrystaldatalong}\\n============\\n\\n  --------------------------- -------------------------------------\\n  C~18~H~21~FNO~2~^+^·Br^−^   *V* = 441.48 (3) Å^3^\\n  *M~r~* = 382.27             *Z* = 1\\n  Triclinic, *P*1             *F*(000) = 196\\n  *a* = 4.9248 (2) Å          *D*~x~ = 1.438 Mg m^−3^\\n  *b* = 5.5117 (2) Å          Mo *K*α~1~ radiation, λ = 0.71073 Å\\n  *c* = 16.3894 (7) Å         µ = 2.35 mm^−1^\\n  α = 83.721 (2)°             *T* = 115 K\\n  β = 89.038 (2)°             Prism, clear light colourless\\n  γ = 86.765 (2)°             0.25 × 0.2 × 0.2 mm\\n  --------------------------- -------------------------------------\\n\\nData collection {#tablewrapdatacollectionlong}\\n===============\\n\\n  ------------------------------------------------------------ --------------------------------------\\n  Nonius KappaCCD diffractometer with APEXII detector          3903 independent reflections\\n  Radiation source: X-ray tube, Siemens KFF Mo 2K-180          3886 reflections with *I* \\\\> 2σ(*I*)\\n  Graphite monochromator                                       *R*~int~ = 0.020\\n  Detector resolution: 9 pixels mm^-1^                         θ~max~ = 27.6°, θ~min~ = 3.7°\\n  CCD rotation images, thick slices scans                      *h* = −6→6\\n  Absorption correction: multi-scan (*SADABS*; Bruker, 2012)   *k* = −7→6\\n  *T*~min~ = 0.61, *T*~max~ = 0.74                             *l* = −21→21\\n  10328 measured reflections                                   \\n  ------------------------------------------------------------ --------------------------------------\\n\\nRefinement {#tablewraprefinementdatalong}\\n==========\\n\\n  ------------------------------------- -------------------------------------------------------------------------------------------------\\n  Refinement on *F*^2^                  Hydrogen site location: inferred from neighbouring sites\\n  Least-squares matrix: full            H-atom parameters constrained\\n  *R*\\\\[*F*^2^ \\\\> 2σ(*F*^2^)\\\\] = 0.021   *w* = 1/\\\\[σ^2^(*F*~o~^2^) + (0.0317*P*)^2^ + 0.0488*P*\\\\] where *P* = (*F*~o~^2^ + 2*F*~c~^2^)/3\\n  *wR*(*F*^2^) = 0.052                  (Δ/σ)~max~ \\\\< 0.001\\n  *S* = 1.11                            Δρ~max~ = 0.37 e Å^−3^\\n  3903 reflections                      Δρ~min~ = −0.18 e Å^−3^\\n  210 parameters                        Absolute structure: Flack (1983); refined as an inversion twin\\n  3 restraints                          Absolute structure parameter: 0.013 (7)\\n  0 constraints                         \\n  ------------------------------------- -------------------------------------------------------------------------------------------------\\n\\nSpecial details {#specialdetails}\\n===============\\n\\n  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n  Geometry. All e.s.d.\\\\'s (except the e.s.d. in the dihedral angle between two l.s. planes) are estimated using the full covariance matrix. The cell e.s.d.\\\\'s are taken into account individually in the estimation of e.s.d.\\\\'s in distances, angles and torsion angles; correlations between e.s.d.\\\\'s in cell parameters are only used when they are defined by crystal symmetry. An approximate (isotropic) treatment of cell e.s.d.\\\\'s is used for estimating e.s.d.\\\\'s involving l.s. planes.\\n  Refinement. Refined as a 2-component inversion twin.\\n  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\nFractional atomic coordinates and isotropic or equivalent isotropic displacement parameters (Å^2^) {#tablewrapcoords}\\n==================================================================================================\\n\\n  ------ ------------- ------------- --------------- -------------------- --\\n         *x\", \"<|endoftext|>x~ = 1.765 Mg m^−3^\\n  Hall symbol: -P 1                                 Mo *K*α radiation, λ = 0.71073 Å\\n  *a* = 7.1330 (14) Å                               Cell parameters from 2008 reflections\\n  *b* = 8.7013 (16) Å                               θ = 2.6--26.9°\\n  *c* = 11.979 (2) Å                                µ = 1.84 mm^−1^\\n  α = 103.969 (2)°                                  *T* = 298 K\\n  β = 101.052 (2)°                                  Block, colorless\\n  γ = 100.882 (3)°                                  0.28 × 0.22 × 0.20 mm\\n  *V* = 686.2 (2) Å^3^                              \\n  ------------------------------------------------- ---------------------------------------\\n\\nData collection {#tablewrapdatacollectionlong}\\n===============\\n\\n  ------------------------------------------------------------ --------------------------------------\\n  Bruker SMART APEX CCD diffractometer                         2384 independent reflections\\n  Radiation source: fine-focus sealed tube                     2080 reflections with *I* \\\\> 2σ(*I*)\\n  Graphite monochromator                                       *R*~int~ = 0.057\\n  ω scans                                                      θ~max~ = 25.0°, θ~min~ = 1.8°\\n  Absorption correction: multi-scan (*SADABS*; Bruker, 2000)   *h* = −7→8\\n  *T*~min~ = 0.627, *T*~max~ = 0.710                           *k* = −10→10\\n  3582 measured reflections                                    *l* = −14→9\\n  ------------------------------------------------------------ --------------------------------------\\n\\nRefinement {#tablewraprefinementdatalong}\\n==========\\n\\n  ------------------------------------- -------------------------------------------------------------------------------------\\n  Refinement on *F*^2^                  Primary atom site location: structure-invariant direct methods\\n  Least-squares matrix: full            Secondary atom site location: difference Fourier map\\n  *R*\\\\[*F*^2^ \\\\> 2σ(*F*^2^)\\\\] = 0.034   Hydrogen site location: inferred from neighbouring sites\\n  *wR*(*F*^2^) = 0.089                  H-atom parameters constrained\\n  *S* = 0.99                            *w* = 1/\\\\[σ^2^(*F*~o~^2^) + (0.0505*P*)^2^\\\\] where *P* = (*F*~o~^2^ + 2*F*~c~^2^)/3\\n  2384 reflections                      (Δ/σ)~max~ \\\\< 0.001\\n  190 parameters                        Δρ~max~ = 0.49 e Å^−3^\\n  0 restraints                          Δρ~min~ = −0.75 e Å^−3^\\n  ------------------------------------- -------------------------------------------------------------------------------------\\n\\nSpecial details {#specialdetails}\\n===============\\n\\n  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n  Geometry. All e.s.d.\\\\'s (except the e.s.d. in the dihedral angle between two l.s. planes) are estimated using the full covariance matrix. The cell e.s.d.\\\\'s are taken into account individually in the estimation of e.s.d.\\\\'s in distances, angles and torsion angles; correlations between e.s.d.\\\\'s in cell parameters are only used when they are defined by crystal symmetry. An approximate (isotropic) treatment of cell e.s.d.\\\\'s is used for estimating e.s.d.\\\\'s involving l.s. planes.\\n  Refinement. Refinement of *F*^2^ against all reflections. The weighted *R*-factor *wR* and goodness of fit *S* are based on *F*^2^, conventional *R*-factors *R* are based on *F*, with *F* set to zero for negative *F*^2^. The threshold expression of *F*^2^ \\\\> σ(*F*^2^) is used only for calculating *R*-factors(gt) *etc*. and is not relevant to the choice of reflections for refinement. *R*-factors based on *F*^2^ are statistically about twice as large as those based on *F*, and *R*- factors based on all data will be even larger.\\n  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\nFractional atomic coordinates and isotropic or equivalent isotropic displacement parameters (Å^2^) {#tablewrapcoords}\\n==================================================================================================\\n\\n  ----- ------------- ------------- -------------- -------------------- ------------\\n        *x*           *y*           *z*            *U*~iso~\\\\*/*U*~eq~   Occ. (\\\\<1)\\n  Zn1   0.27323 (5)   0.29051 (4)   0.29273\", \"<|endoftext|> give a colorless flaky crystalline product (2.94 g; m.p. 411 - 414 K).\\n\\nRefinement {#refinement}\\n==========\\n\\nAll H atoms were positioned geometrically (C---H = 0.96 Å for CH~3~ and 0.97 Å for CH~2~ groups, respectively) and constrained to ride on their parent atoms with *U*~iso~(H) values set to 1.5 times *U*~eq~ of the parent atoms.\\n\\nFigures\\n=======\\n\\n![Molecular structure of the title compound, showing the atom labeling scheme and displacement ellipsoids drawn at the 30% probability level.](e-67-o1669-fig1){#Fap1}\\n\\n![A view of the crystal packing of the title compound, showing the C--H···N and π-π interactions. Symmetry operators: i 1 - x, 1 - y, 1 - z; iix, 1 + y, z; iii 1 - x, 2 - y, x-z.](e-67-o1669-fig2){#Fap2}\\n\\nCrystal data {#tablewrapcrystaldatalong}\\n============\\n\\n  ---------------------- -------------------------------------------------------------------------------\\n  C~6~H~10~N~8~S~2~      *Z* = 2\\n  *M~r~* = 258.34        *F*(000) = 268\\n  Triclinic, *P*1        *D*~x~ = 1.515 Mg m^−3^*D*~m~ = 1.515 Mg m^−3^*D*~m~ measured by not measured\\n  Hall symbol: -P 1      Mo *K*α radiation, λ = 0.71073 Å\\n  *a* = 7.5905 (17) Å    Cell parameters from 816 reflections\\n  *b* = 7.9958 (17) Å    θ = 3.0--24.3°\\n  *c* = 10.398 (2) Å     µ = 0.46 mm^−1^\\n  α = 95.206 (3)°        *T* = 296 K\\n  β = 92.922 (3)°        Flake-like, colourless\\n  γ = 115.109 (2)°       0.31 × 0.27 × 0.04 mm\\n  *V* = 566.3 (2) Å^3^   \\n  ---------------------- -------------------------------------------------------------------------------\\n\\nData collection {#tablewrapdatacollectionlong}\\n===============\\n\\n  ------------------------------------------------------------ --------------------------------------\\n  Bruker APEXII CCD diffractometer                             1972 independent reflections\\n  Radiation source: fine-focus sealed tube                     1454 reflections with *I* \\\\> 2σ(*I*)\\n  graphite                                                     *R*~int~ = 0.017\\n  φ and ω scans                                                θ~max~ = 25.1°, θ~min~ = 2.0°\\n  Absorption correction: multi-scan (*SADABS*; Bruker, 2002)   *h* = −8→9\\n  *T*~min~ = 0.868, *T*~max~ = 0.982                           *k* = −9→9\\n  2874 measured reflections                                    *l* = −12→12\\n  ------------------------------------------------------------ --------------------------------------\\n\\nRefinement {#tablewraprefinementdatalong}\\n==========\\n\\n  ------------------------------------- ------------------------------------------------------------------------------------\\n  Refinement on *F*^2^                  Primary atom site location: structure-invariant direct methods\\n  Least-squares matrix: full            Secondary atom site location: difference Fourier map\\n  *R*\\\\[*F*^2^ \\\\> 2σ(*F*^2^)\\\\] = 0.047   Hydrogen site location: inferred from neighbouring sites\\n  *wR*(*F*^2^) = 0.135                  H-atom parameters constrained\\n  *S* = 1.39                            *w* = 1/\\\\[σ^2^(*F*~o~^2^) + (0.050*P*)^2^\\\\] where *P* = (*F*~o~^2^ + 2*F*~c~^2^)/3\\n  1972 reflections                      (Δ/σ)~max~ \\\\< 0.001\\n  147 parameters                        Δρ~max~ = 0.26 e Å^−3^\\n  0 restraints                          Δρ~min~ = −0.26 e Å^−3^\\n  ------------------------------------- ------------------------------------------------------------------------------------\\n\\nSpecial details {#specialdetails}\\n===============\\n\\n  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n  Geometry. All e.s.d.\\\\'s (except the e.s.d. in the dihedral angle between two l.s. planes) are estimated using the full covariance matrix. The cell e.s.d.\\\\'s are taken into account individually in the\", '<|endoftext|> *et al.* (2012[@bb3]); Ding *et al.* (2009[@bb6]); Sarojini *et al.* (2007*a* [@bb19],*b* [@bb18]). For standard bond lengths, see: Allen *et al.* (1987[@bb2]).\\n\\nExperimental \\xa0 {#sec2}\\n==============\\n\\n {#sec2.1}\\n\\n### Crystal data \\xa0 {#sec2.1.1}\\n\\nC~10~H~10~N~4~OS*M* *~r~* = 234.28Triclinic,*a* = 5.7677 (5) Å*b* = 7.7233 (8) Å*c* = 12.7269 (12) Åα = 84.104 (8)°β = 77.719 (8)°γ = 73.358 (9)°*V* = 530.23 (9) Å^3^*Z* = 2Cu *K*α radiationμ = 2.59 mm^−1^*T* = 173 K0.28 × 0.16 × 0.12 mm\\n\\n### Data collection \\xa0 {#sec2.1.2}\\n\\nAgilent Eos Gemini diffractometerAbsorption correction: multi-scan (*CrysAlis PRO* and *CrysAlis RED*; Agilent, 2012[@bb1]) *T* ~min~ = 0.723, *T* ~max~ = 1.0003082 measured reflections1987 independent reflections1658 reflections with *I* \\\\> 2σ(*I*)*R* ~int~ = 0.030\\n\\n### Refinement \\xa0 {#sec2.1.3}\\n\\n*R*\\\\[*F* ^2^ \\\\> 2σ(*F* ^2^)\\\\] = 0.054*wR*(*F* ^2^) = 0.151*S* = 1.051987 reflections147 parametersH-atom parameters constrainedΔρ~max~ = 0.62 e Å^−3^Δρ~min~ = −0.40 e Å^−3^\\n\\n {#d5e577}\\n\\nData collection: *CrysAlis PRO* (Agilent, 2012[@bb1]); cell refinement: *CrysAlis PRO*; data reduction: *CrysAlis RED* (Agilent, 2012[@bb1]); program(s) used to solve structure: *SUPERFLIP* (Palatinus *et al.*, 2012[@bb15]); program(s) used to refine structure: *SHELXL2012* (Sheldrick, 2008[@bb20]); molecular graphics: *OLEX2* (Dolomanov *et al.*, 2009[@bb7]); software used to prepare material for publication: *OLEX2*.\\n\\nSupplementary Material\\n======================\\n\\nCrystal structure: contains datablock(s) I. DOI: [10.1107/S1600536814012215/sj5405sup1.cif](http://dx.doi.org/10.1107/S1600536814012215/sj5405sup1.cif)\\n\\nStructure factors: contains datablock(s) I. DOI: [10.1107/S1600536814012215/sj5405Isup2.hkl](http://dx.doi.org/10.1107/S1600536814012215/sj5405Isup2.hkl)\\n\\n###### \\n\\nClick here for additional data file.\\n\\nSupporting information file. DOI: [10.1107/S1600536814012215/sj5405Isup3.cml](http://dx.doi.org/10.1107/S1600536814012215/sj5405Isup3.cml)\\n\\nCCDC reference: [1005409](http://scripts.iucr.org/cgi-bin/cr.cgi?rm=csd&csdid=1005409)\\n\\nAdditional supporting information: [crystallographic information](http://scripts.iucr.org/cgi-bin/sendsupfiles?sj5405&file=sj5405sup0.html&mime=text/html); [3D view](http://scripts.iucr.org/cgi-bin/sendcif?sj5405sup1&Qmime=cif); [checkCIF report](http://scripts.iucr.org/cgi-bin/paper?sj5405&checkcif=yes)\\n\\nSupporting information for this paper is available from the IUCr electronic archives (Reference: [SJ5405](http://scripts.iucr.org/cgi-bin/sendsup?sj5', \"<|endoftext|> is discharged the bullet leaves the barrel followed by a rush of hot propellant gases known as the muzzle blast. A suppressor slows down those gasses, reducing the sound of the gunshot.\\n\\nU.S. Marines with Bravo Company, 1st Battalion, 2nd Marine Regiment utilize suppressors while conducting company attacks on range 400 in Twentynine Palms, Calif., Oct. 23, 2016. Department of Defense photo.\\n\\nAdvanced Armament Company, a military contractor and maker of suppressors, says their suppressor reduces the noise of a gunshot from an M4-type rifle by 32-34 decibels . That drops the noise of an M4 down to about 130 decibels, or about that of a jackhammer . Civilian AR-15 owners with suppressors, weapons similar to M4s but without the ability to fire quick bursts of full auto fire, report they can fire their weapons comfortably without ear protection.\\n\\nThat may not be silence, but it's a big improvement for troops on the battlefield who need to communicate with one another. The article says that although Marine squads are often spread out over 100 yards, it's hard for the squad leader to control the fire of individual riflemen—particularly those farthest away. With suppressors, it's easier for everyone to hear one another on the battlefield, trade information, and give and receive orders.\\n\\nSuppressors do have some drawbacks. They have a tendency to gradually wear out, which is accelerated when firing fully automatic. They also add length to the firearm, a less desirable trait when fighting in cities and their enclosed spaces. Then again, enclosed spaces can magnify gunshot noises, so carrying a suppressor in such circumstances is a tradeoff that is probably worth it.\\n\\nEven with those drawbacks in mind, the benefits of equipping America's riflemen with suppressors are pretty impressive. Expect to hear more in the future about equipping the troops with suppressors.\\n\\nJust don't call them silencers.\\n\\nRead more at Military.com .\\n\\nThis content is created and maintained by a third party, and imported onto this page to help users provide their email addresses. You may be able to find more information about this and similar content at piano.io<|endoftext|>Related literature {#sec1}\\n==================\\n\\nFor uses of carboxylic acids in materials science, see: Church & Halvorson (1959[@bb3]). For uses in biological systems, see: Chung *et al.* (1971[@bb2]); Okabe & Oya (2000[@bb5]); Serre *et al.* (2005[@bb8]); Pocker & Fong (1980[@bb6]); Scapin *et al.* (1997[@bb7]); Kim *et al.* (2001[@bb4]).\\n\\nExperimental {#sec2}\\n============\\n\\n {#sec2.1}\\n\\n### Crystal data {#sec2.1.1}\\n\\n\\\\[Cu(C~2~H~3~O~2~)(C~12~H~11~N~2~O~4~)(H~2~O)\\\\]*M* *~r~* = 387.83Monoclinic,*a* = 8.106 (2) Å*b* = 23.918 (4) Å*c* = 8.946 (2) Åβ = 106.90 (3)°*V* = 1659.5 (6) Å^3^*Z* = 4Mo *K*α radiationμ = 1.35 mm^−1^*T* = 293 (2) K0.43 × 0.28 × 0.22 mm\\n\\n### Data collection {#sec2.1.2}\\n\\nBruker APEXII CCD diffractometerAbsorption correction: multi-scan (*SADABS*; Bruker, 2004[@bb1]) *T* ~min~ = 0.594, *T* ~max~ = 0.7558654 measured reflections4235 independent reflections2693 reflections with *I* \\\\> 2σ(*I*)*R* ~int~ = 0.034\\n\\n### Refinement {#sec2.1.3}\\n\\n*R*\\\\[*F* ^2^ \\\\> 2σ(*F* ^2^)\\\\] = 0.064*wR*(*F* ^2^) = 0.219*S* = 1.004235 reflections226 parameters3 restraintsH atoms treated by a mixture of independent and constrained refinementΔρ~max~ = 0.94 e Å^−3^Δρ~min~ = −1.73 e Å^−3^\\n\\n {#d5e521}\\n\\nData collection: *APEX2* (Bruker, 2004[@bb1]); cell refinement: *SAINT-Plus* (Bruker, 2004[@bb1]); data reduction: *SAINT-Plus*; program(s)\", \"<|endoftext|> 1.425 Mg m^−3^\\n  Monoclinic, *P*2~1~/*c*    Mo *K*α radiation, λ = 0.71073 Å\\n  Hall symbol: -P 2ybc       Cell parameters from 7657 reflections\\n  *a* = 7.9238 (4) Å         θ = 1.0--28.3°\\n  *b* = 21.1712 (11) Å       µ = 0.68 mm^−1^\\n  *c* = 12.6186 (7) Å        *T* = 298 K\\n  β = 99.238 (1)°            Block, white\\n  *V* = 2089.39 (19) Å^3^    0.25 × 0.22 × 0.20 mm\\n  *Z* = 4                    \\n  -------------------------- ---------------------------------------\\n\\nData collection {#tablewrapdatacollectionlong}\\n===============\\n\\n  --------------------------------------------------------------- --------------------------------------\\n  Bruker APEXII area-detector diffractometer                      4008 independent reflections\\n  Radiation source: fine-focus sealed tube                        3342 reflections with *I* \\\\> 2σ(*I*)\\n  graphite                                                        *R*~int~ = 0.018\\n  φ and ω scan                                                    θ~max~ = 26.0°, θ~min~ = 1.9°\\n  Absorption correction: multi-scan (*SADABS*; Sheldrick, 1996)   *h* = −9→9\\n  *T*~min~ = 0.849, *T*~max~ = 0.876                              *k* = −26→26\\n  13412 measured reflections                                      *l* = −15→15\\n  --------------------------------------------------------------- --------------------------------------\\n\\nRefinement {#tablewraprefinementdatalong}\\n==========\\n\\n  ------------------------------------- -------------------------------------------------------------------------------------------------\\n  Refinement on *F*^2^                  Primary atom site location: structure-invariant direct methods\\n  Least-squares matrix: full            Secondary atom site location: difference Fourier map\\n  *R*\\\\[*F*^2^ \\\\> 2σ(*F*^2^)\\\\] = 0.042   Hydrogen site location: inferred from neighbouring sites\\n  *wR*(*F*^2^) = 0.126                  H-atom parameters constrained\\n  *S* = 1.04                            *w* = 1/\\\\[σ^2^(*F*~o~^2^) + (0.0694*P*)^2^ + 1.0128*P*\\\\] where *P* = (*F*~o~^2^ + 2*F*~c~^2^)/3\\n  4008 reflections                      (Δ/σ)~max~ \\\\< 0.001\\n  228 parameters                        Δρ~max~ = 0.88 e Å^−3^\\n  0 restraints                          Δρ~min~ = −0.63 e Å^−3^\\n  ------------------------------------- -------------------------------------------------------------------------------------------------\\n\\nSpecial details {#specialdetails}\\n===============\\n\\n  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n  Geometry. All e.s.d.\\\\'s (except the e.s.d. in the dihedral angle between two l.s. planes) are estimated using the full covariance matrix. The cell e.s.d.\\\\'s are taken into account individually in the estimation of e.s.d.\\\\'s in distances, angles and torsion angles; correlations between e.s.d.\\\\'s in cell parameters are only used when they are defined by crystal symmetry. An approximate (isotropic) treatment of cell e.s.d.\\\\'s is used for estimating e.s.d.\\\\'s involving l.s. planes.\\n  Refinement. Refinement of *F*^2^ against ALL reflections. The weighted *R*-factor *wR* and goodness of fit *S* are based on *F*^2^, conventional *R*-factors *R* are based on *F*, with *F* set to zero for negative *F*^2^. The threshold expression of *F*^2^ \\\\> σ(*F*^2^) is used only for calculating *R*-factors(gt) *etc*. and is not relevant to the choice of reflections for refinement. *R*-factors based on *F*^2^ are statistically about twice as large as those based on *F*, and *R*- factors based on ALL data will be even larger.\\n  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\nFractional atomic coordinates and isotropic or equivalent isotropic displacement parameters (Å^2^) {#tablewrapcoords}\\n==================================================================================================\\n\\n  ------ --------------- -------------- -------------- -------------------- --\\n         *x*             *y*            *z*            *U*~iso~\\\\*/*U*~eq~   \\n  C1     0.6440 (3)      0.16192 (11)   0.566\", \"<|endoftext|> θ~min~ = 1.7°\\n  Absorption correction: multi-scan (*SADABS*; Sheldrick, 1996)   *h* = −10→10\\n  *T*~min~ = 0.887, *T*~max~ = 0.951                              *k* = −10→10\\n  12704 measured reflections                                      *l* = −16→16\\n  --------------------------------------------------------------- --------------------------------------\\n\\nRefinement {#tablewraprefinementdatalong}\\n==========\\n\\n  ------------------------------------- -------------------------------------------------------------------------------------------------\\n  Refinement on *F*^2^                  Primary atom site location: structure-invariant direct methods\\n  Least-squares matrix: full            Secondary atom site location: difference Fourier map\\n  *R*\\\\[*F*^2^ \\\\> 2σ(*F*^2^)\\\\] = 0.041   Hydrogen site location: inferred from neighbouring sites\\n  *wR*(*F*^2^) = 0.124                  H atoms treated by a mixture of independent and constrained refinement\\n  *S* = 1.04                            *w* = 1/\\\\[σ^2^(*F*~o~^2^) + (0.0681*P*)^2^ + 0.1946*P*\\\\] where *P* = (*F*~o~^2^ + 2*F*~c~^2^)/3\\n  3374 reflections                      (Δ/σ)~max~ = 0.001\\n  198 parameters                        Δρ~max~ = 0.34 e Å^−3^\\n  2 restraints                          Δρ~min~ = −0.34 e Å^−3^\\n  ------------------------------------- -------------------------------------------------------------------------------------------------\\n\\nSpecial details {#specialdetails}\\n===============\\n\\n  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n  Geometry. All s.u.\\\\'s (except the s.u. in the dihedral angle between two l.s. planes) are estimated using the full covariance matrix. The cell s.u.\\\\'s are taken into account individually in the estimation of s.u.\\\\'s in distances, angles and torsion angles; correlations between s.u.\\\\'s in cell parameters are only used when they are defined by crystal symmetry. An approximate (isotropic) treatment of cell s.u.\\\\'s is used for estimating s.u.\\\\'s involving l.s. planes.\\n  Refinement. Refinement of *F*^2^ against ALL reflections. The weighted *R*-factor *wR* and goodness of fit *S* are based on *F*^2^, conventional *R*-factors *R* are based on *F*, with *F* set to zero for negative *F*^2^. The threshold expression of *F*^2^ \\\\> 2σ(*F*^2^) is used only for calculating *R*-factors(gt) *etc*. and is not relevant to the choice of reflections for refinement. *R*-factors based on *F*^2^ are statistically about twice as large as those based on *F*, and *R*- factors based on ALL data will be even larger.\\n  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\nFractional atomic coordinates and isotropic or equivalent isotropic displacement parameters (Å^2^) {#tablewrapcoords}\\n==================================================================================================\\n\\n  ------ --------------- --------------- -------------- -------------------- --\\n         *x*             *y*             *z*            *U*~iso~\\\\*/*U*~eq~   \\n  S1     0.12002 (5)     0.25013 (5)     0.75637 (3)    0.04453 (15)         \\n  O1     −0.01522 (16)   0.24530 (17)    0.84756 (11)   0.0578 (3)           \\n  O2     0.09188 (18)    0.42467 (16)    0.67943 (11)   0.0581 (3)           \\n  O3     0.4166 (2)      −0.2526 (2)     0.37348 (12)   0.0728 (4)           \\n  N1     0.31999 (19)    0.17594 (19)    0.79741 (11)   0.0459 (3)           \\n  H1N    0.391 (2)       0.214 (3)       0.7440 (11)    0.055\\\\*              \\n  N2     0.21546 (19)    −0.29178 (19)   0.51939 (11)   0.0437 (3)           \\n  H2N    0.164 (2)       −0.365 (2)      0.5573 (13)    0.052\\\\*              \\n  C1     0.4103 (2)      −0.0054 (2)     0.86613 (\", '<|endoftext|> idea to parametrize the cone using polar parameters.\\n\\\\documentclass{article}\\n\\\\usepackage{pst-solides3d}\\n\\\\usepackage{pst-3dplot}\\n\\n\\\\begin{document}\\n\\n\\\\psset{Decran=20, linecolor=gray}\\n\\\\begin{pspicture}(-5,-5)(5,5)\\n\\\\defFunction[algebraic]{cone}(r,t)\\n{r*cos(t)}\\n{r*sin(t)}\\n{r}\\n\\\\psSolid[object=surfaceparametree,base=-3 3 0 360,\\nngrid=36 60,\\nfunction=cone,incolor=white]\\n\\\\axesIIID(4,4,5)\\n\\\\end{pspicture}\\n\\\\end{document}\\n\\n@jake: I realized that you are using polar parameters already.  A slightly simplified version is given below.\\n\\\\documentclass{article}\\n\\\\usepackage{pgfplots}\\n\\\\begin{document}\\n\\\\begin{tikzpicture}\\n\\\\begin{axis}[\\ndomain=-5:5,\\ny domain=0:2*pi,\\nxmin=-10,\\nxmax=10,\\nymin=-10,\\nymax=10,\\nsamples=20]\\n\\\\addplot3 [surf,z buffer=sort] \\n({x*cos(deg(y))},\\n{x*sin(deg(y))},\\n{x} );\\n\\\\end{axis}\\n\\\\end{tikzpicture}\\n\\\\end{document}\\n\\n<|endoftext|>Related literature {#sec1}\\n==================\\n\\nFor background information, see: Antonioli *et al.* (2006[@bb1]); Bourlier *et al.* (2007[@bb2]); Niu *et al.* (2007[@bb3]); Sumby & Hardie (2005[@bb9]).\\n\\nExperimental {#sec2}\\n============\\n\\n {#sec2.1}\\n\\n### Crystal data {#sec2.1.1}\\n\\n\\\\[Ag~2~(ClO~4~)~2~(C~10~H~7~N~3~)~2~\\\\]*M* *~r~* = 753.02Monoclinic,*a* = 7.8522 (13) Å*b* = 10.6086 (17) Å*c* = 15.322 (2) Åβ = 101.100 (2)°*V* = 1252.5 (3) Å^3^*Z* = 2Mo *K*α radiationμ = 1.83 mm^−1^*T* = 173 (2) K0.51 × 0.47 × 0.36 mm\\n\\n### Data collection {#sec2.1.2}\\n\\nSiemens SMART CCD diffractometerAbsorption correction: multi-scan (*SADABS*; Sheldrick, 1996[@bb4]) *T* ~min~ = 0.455, *T* ~max~ = 0.558 (expected range = 0.421--0.517)7721 measured reflections2833 independent reflections2180 reflections with *I* \\\\> 2σ(*I*)*R* ~int~ = 0.021\\n\\n### Refinement {#sec2.1.3}\\n\\n*R*\\\\[*F* ^2^ \\\\> 2σ(*F* ^2^)\\\\] = 0.042*wR*(*F* ^2^) = 0.114*S* = 0.962833 reflections209 parameters74 restraintsH-atom parameters constrainedΔρ~max~ = 0.75 e Å^−3^Δρ~min~ = −0.59 e Å^−3^\\n\\n {#d5e510}\\n\\nData collection: *SMART* (Siemens, 1996[@bb7]); cell refinement: *SAINT* (Siemens, 1994[@bb6]); data reduction: *SAINT*; program(s) used to solve structure: *SHELXS97* (Sheldrick, 2008[@bb5]); program(s) used to refine structure: *SHELXL97* (Sheldrick, 2008[@bb5]); molecular graphics: *SHELXTL* (Sheldrick, 2008[@bb5]) and *PLATON* (Spek, 2003[@bb8]); software used to prepare material for publication: *SHELXTL*.\\n\\nSupplementary Material\\n======================\\n\\nCrystal structure: contains datablocks I, global. DOI: [10.1107/S1600536808030602/lh2676sup1.cif](http://dx.doi.org/10.1107/S1600536808030602/lh2676sup1.cif)\\n\\nStructure factors: contains datablocks I. DOI:', '<|endoftext|> stand out from the competition and rank higher in SERPs. This plugin supports following Schemas types,\\n\\nReview\\n\\nEvent\\n\\nPeople\\n\\nProduct\\n\\nRecipe\\n\\nSoftware Application\\n\\nVideo\\n\\nArticles\\n\\nMobile searches and users are growing fast day by day. That’s why it’s important that your website is mobile-friendly. This plugin makes your WordPress website mobile-friendly and faster for mobile users. With this plugin, you can make your site mobile-friendly in just a few seconds.\\n\\nKey features\\n\\nMany Optimizations.\\n\\nAMP-first Experiences support.\\n\\nGutenberg Support.\\n\\nCore Theme Support.\\n\\nRankie is a premium ($25) rank checker plugin that tracks the Google rankings of your WordPress website. It updates keywords rank position daily and generates powerful reports.\\n\\nRankie is not only a rank tracker plugin. Also integrates a powerful keyword research tool that generates huge lists of valuable keywords that you can target.\\n\\nLinkPatrol helps you gain more control over links to your site. The links that can hurt your website’s search ranking, you can find and fix them with the help of LinkPatrol. What does LinkPatrol do?\\n\\nProtect your site from spammy links.\\n\\nDestroy spammy keywords.\\n\\nMonitor recently added links and keywords.\\n\\nUndo Changes Instantly (Made a mistake? Restore links in one click).\\n\\nAutoptimize is a speed booster plugin that makes your site super fast by reducing code on your website. If you want to increase your site’s performance and keep your website lightweight, then plugin can help you a lot.\\n\\nApart from this, the plugin removes query strings and Google font from your site.\\n\\nWhat did you think of today’s post? Let me know by leaving a comment below.\\n\\nLike listed WordPress SEO plugins? Do not forget to share it!\\n\\nYou may also like:<|endoftext|>Related literature {#sec1}\\n==================\\n\\nFor octacyanidometalates as mol\\xadecular building units for transition metal complex assemblies, see: Przychodzeń *et al.* (2006[@bb2]); Withers *et al.* (2005[@bb6]). For a related structure, see: Liu *et al.* (2008[@bb1]).\\n\\nExperimental {#sec2}\\n============\\n\\n {#sec2.1}\\n\\n### Crystal data {#sec2.1.1}\\n\\n\\\\[Ni(C~2~H~8~N~2~)~3~\\\\]~2~\\\\[Mo(CN)~8~\\\\]·5H~2~O*M* *~r~* = 872.18Monoclinic,*a* = 13.384 (3) Å*b* = 16.465 (3) Å*c* = 21.094 (6) Åβ = 124.45 (2)°*V* = 3833.2 (18) Å^3^*Z* = 4Mo *K*α radiationμ = 1.35 mm^−1^*T* = 153 K0.40 × 0.23 × 0.18 mm\\n\\n### Data collection {#sec2.1.2}\\n\\nRigaku Mercury CCD diffractometerAbsorption correction: multi-scan (*ABSCOR*; Higashi, 1995[@bb4]) *T* ~min~ = 0.770, *T* ~max~ = 1.00036947 measured reflections6993 independent reflections6541 reflections with *I* \\\\> 2σ(*I*)*R* ~int~ = 0.030\\n\\n### Refinement {#sec2.1.3}\\n\\n*R*\\\\[*F* ^2^ \\\\> 2σ(*F* ^2^)\\\\] = 0.028*wR*(*F* ^2^) = 0.059*S* = 1.166993 reflections469 parametersH atoms treated by a mixture of independent and constrained refinementΔρ~max~ = 0.50 e Å^−3^Δρ~min~ = −0.47 e Å^−3^\\n\\n {#d5e880}\\n\\nData collection: *CrystalClear* (Rigaku, 2008)[@bb3]; cell refinement: *CrystalClear*; data reduction: *CrystalClear*; program(s) used to solve structure: *SHELXS97* (Sheldrick, 2008[@bb5]); program(s) used to refine structure: *SHELXL97* (Sheldrick, 2008[@bb5]); molecular graphics: *SHELXTL* (Sheldrick, 2008[@bb5]); software used to prepare material for publication: *SHELXTL*.\\n\\nSupplementary Material\\n======================\\n\\nCrystal structure: contains datablocks I, global. DOI: [10.1107/S1600536', \"<|endoftext|> dashed lines.](e-64-0m453-fig3){#Fap3}\\n\\nCrystal data {#tablewrapcrystaldatalong}\\n============\\n\\n  ------------------------------------------------ ---------------------------------------\\n  \\\\[Mn(C~2~H~3~O~2~)~2~(C~18~H~20~N~4~)\\\\]·6H~2~O   *Z* = 2\\n  *M~r~* = 573.50                                  *F*(000) = 606\\n  Triclinic, *P*1                                  *D*~x~ = 1.355 Mg m^−3^\\n  Hall symbol: -P 1                                Mo *K*α radiation, λ = 0.71073 Å\\n  *a* = 8.5124 (5) Å                               Cell parameters from 5115 reflections\\n  *b* = 11.6768 (7) Å                              θ = 2.5--26.4°\\n  *c* = 15.1971 (10) Å                             µ = 0.53 mm^−1^\\n  α = 79.049 (1)°                                  *T* = 243 K\\n  β = 85.195 (1)°                                  Plate, yellow\\n  γ = 71.484 (1)°                                  0.25 × 0.25 × 0.20 mm\\n  *V* = 1405.83 (15) Å^3^                          \\n  ------------------------------------------------ ---------------------------------------\\n\\nData collection {#tablewrapdatacollectionlong}\\n===============\\n\\n  ------------------------------------------------------------ --------------------------------------\\n  Bruker SMART 1000 CCD diffractometer                         5710 independent reflections\\n  Radiation source: fine-focus sealed tube                     4641 reflections with *I* \\\\> 2σ(*I*)\\n  graphite                                                     *R*~int~ = 0.015\\n  φ and ω scans                                                θ~max~ = 26.4°, θ~min~ = 2.1°\\n  Absorption correction: multi-scan (*SADABS*; Bruker, 2000)   *h* = −10→10\\n  *T*~min~ = 0.824, *T*~max~ = 0.900                           *k* = −14→11\\n  11880 measured reflections                                   *l* = −19→15\\n  ------------------------------------------------------------ --------------------------------------\\n\\nRefinement {#tablewraprefinementdatalong}\\n==========\\n\\n  ------------------------------------- -------------------------------------------------------------------------------------\\n  Refinement on *F*^2^                  Primary atom site location: structure-invariant direct methods\\n  Least-squares matrix: full            Secondary atom site location: difference Fourier map\\n  *R*\\\\[*F*^2^ \\\\> 2σ(*F*^2^)\\\\] = 0.040   Hydrogen site location: inferred from neighbouring sites\\n  *wR*(*F*^2^) = 0.111                  H-atom parameters constrained\\n  *S* = 1.02                            *w* = 1/\\\\[σ^2^(*F*~o~^2^) + (0.0678*P*)^2^\\\\] where *P* = (*F*~o~^2^ + 2*F*~c~^2^)/3\\n  5710 reflections                      (Δ/σ)~max~ \\\\< 0.001\\n  348 parameters                        Δρ~max~ = 0.44 e Å^−3^\\n  0 restraints                          Δρ~min~ = −0.20 e Å^−3^\\n  ------------------------------------- -------------------------------------------------------------------------------------\\n\\nSpecial details {#specialdetails}\\n===============\\n\\n  -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n  Geometry. All e.s.d.\\\\'s (except the e.s.d. in the dihedral angle between two l.s. planes) are estimated using the full covariance matrix. The cell e.s.d.\\\\'s are taken into account individually in the estimation of e.s.d.\\\\'s in distances, angles and torsion angles; correlations between e.s.d.\\\\'s in cell parameters are only used when they are defined by crystal symmetry. An approximate (isotropic) treatment of cell e.s.d.\\\\'s is used for estimating e.s.d.\\\\'s involving l.s. planes.\\n  Refinement. Refinement of *F*^2^ against ALL reflections. The weighted *R*-factor *wR* and goodness of fit *S* are based on *F*^2^, conventional *R*-factors *R* are based on *F*, with *F* set to zero for negative *F*^2^. The threshold expression of *F*^2^ \\\\> σ(*F*^2^) is used only for calculating *R*-factors(gt) *etc*. and is not relevant to the choice of reflections for refinement. *R*-factors based on *F*^2^ are statistically about twice as\"]\n"]}]},{"cell_type":"markdown","source":["### Pruning"],"metadata":{"id":"Rfc0Ycm3eVWX"}},{"cell_type":"code","source":["with open(os.path.join(base_path, \"data/snippets.json\")) as ifh:\n","  snippet_dicts = json.load(ifh)"],"metadata":{"id":"LtnAW3SGeqXU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","\n","pruned_dicts = []\n","for layer, snippet_dict in enumerate(snippet_dicts):\n","  print(\"layer\", layer)\n","  pruned_dicts.append({})\n","  for j, (neuron, snippets) in enumerate(snippet_dict.items()):\n","    print(j)\n","    print(\"neuron\", neuron)\n","    neuron = int(neuron)\n","    pruned_dicts[layer][neuron] = []\n","    for k, snippet in enumerate(snippets):\n","      # if k >= 5:\n","      #   break\n","      pruned_prompt, max_index = prune(model, f\"blocks.{layer}.mlp.hook_mid\", neuron, snippet, proportion_threshold=-0.5)\n","      print(\"max_index\", max_index)      \n","      # if max_index > 50:\n","      #   print(\"\\n\")\n","      #   print([pruned_prompt])\n","      pruned_dicts[layer][neuron].append([pruned_prompt, max_index])\n","    # break\n","  # break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3I9jaDKiexwJ","executionInfo":{"status":"ok","timestamp":1673150023980,"user_tz":0,"elapsed":15057375,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"835e767a-bf97-40ef-a530-4e775dd262f1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","max_index 59\n","max_index 59\n","max_index 79\n","173\n","neuron 899\n","max_index 69\n","max_index 449\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 449\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 449\n","max_index 449\n","max_index 469\n","max_index 69\n","max_index 69\n","max_index 39\n","max_index 449\n","max_index 449\n","max_index 449\n","174\n","neuron 83\n","max_index 4\n","max_index 5\n","max_index 8\n","max_index 5\n","max_index 7\n","max_index 3\n","max_index 7\n","max_index 1\n","max_index 12\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 11\n","max_index 9\n","max_index 3\n","max_index 2\n","max_index 3\n","max_index 3\n","max_index 2\n","max_index 2\n","175\n","neuron 246\n","max_index 4\n","max_index 3\n","max_index 3\n","max_index 9\n","max_index 6\n","max_index 3\n","max_index 4\n","max_index 3\n","max_index 5\n","max_index 13\n","max_index 3\n","max_index 7\n","max_index 5\n","max_index 3\n","max_index 2\n","max_index 2\n","max_index 2\n","max_index 7\n","max_index 3\n","max_index 2\n","176\n","neuron 101\n","max_index 12\n","max_index 12\n","max_index 7\n","max_index 16\n","max_index 11\n","max_index 4\n","max_index 7\n","max_index 7\n","max_index 13\n","max_index 9\n","max_index 29\n","max_index 7\n","max_index 4\n","max_index 11\n","max_index 29\n","max_index 9\n","max_index 4\n","max_index 6\n","max_index 9\n","max_index 11\n","177\n","neuron 846\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 4\n","178\n","neuron 783\n","max_index 5\n","max_index 3\n","max_index 9\n","max_index 3\n","max_index 4\n","max_index 4\n","max_index 5\n","max_index 3\n","max_index 5\n","max_index 8\n","max_index 1\n","max_index 1\n","max_index 2\n","max_index 3\n","max_index 6\n","max_index 19\n","max_index 3\n","max_index 2\n","max_index 3\n","max_index 3\n","179\n","neuron 157\n","max_index 12\n","max_index 11\n","max_index 8\n","max_index 13\n","max_index 6\n","max_index 7\n","max_index 4\n","max_index 12\n","max_index 11\n","max_index 4\n","max_index 6\n","max_index 13\n","max_index 6\n","max_index 18\n","max_index 6\n","max_index 4\n","max_index 5\n","max_index 29\n","max_index 4\n","max_index 4\n","180\n","neuron 423\n","max_index 4\n","max_index 8\n","max_index 319\n","max_index 5\n","max_index 18\n","max_index 12\n","max_index 29\n","max_index 9\n","max_index 12\n","max_index 79\n","max_index 5\n","max_index 12\n","max_index 59\n","max_index 89\n","max_index 39\n","max_index 4\n","max_index 69\n","max_index 8\n","max_index 39\n","max_index 29\n","181\n","neuron 218\n","max_index 12\n","max_index 59\n","max_index 49\n","max_index 12\n","max_index 49\n","max_index 49\n","max_index 49\n","max_index 49\n","max_index 377\n","max_index 49\n","max_index 59\n","max_index 29\n","max_index 49\n","max_index 59\n","max_index 49\n","max_index 49\n","max_index 59\n","max_index 49\n","max_index 49\n","max_index 49\n","182\n","neuron 451\n","max_index 11\n","max_index 89\n","max_index 69\n","max_index 69\n","max_index 18\n","max_index 14\n","max_index 14\n","max_index 13\n","max_index 99\n","max_index 10\n","max_index 13\n","max_index 12\n","max_index 29\n","max_index 69\n","max_index 39\n","max_index 11\n","max_index 13\n","max_index 14\n","max_index 29\n","max_index 29\n","183\n","neuron 999\n","max_index 13\n","max_index 11\n","max_index 8\n","max_index 8\n","max_index 8\n","max_index 4\n","max_index 8\n","max_index 29\n","max_index 59\n","max_index 29\n","max_index 18\n","max_index 49\n","max_index 5\n","max_index 7\n","max_index 49\n","max_index 119\n","max_index 5\n","max_index 29\n","max_index 49\n","max_index 49\n","184\n","neuron 78\n","max_index 4\n","max_index 1\n","max_index 4\n","max_index 2\n","max_index 3\n","max_index 2\n","max_index 5\n","max_index 14\n","max_index 1\n","max_index 4\n","max_index 8\n","max_index 2\n","max_index 2\n","max_index 29\n","max_index 4\n","max_index 3\n","max_index 1\n","max_index 1\n","max_index 4\n","max_index 2\n","185\n","neuron 837\n","max_index 5\n","max_index 292\n","max_index 9\n","max_index 4\n","max_index 10\n","max_index 8\n","max_index 9\n","max_index 4\n","max_index 3\n","max_index 4\n","max_index 6\n","max_index 230\n","max_index 5\n","max_index 3\n","max_index 4\n","max_index 9\n","max_index 3\n","max_index 9\n","max_index 14\n","max_index 4\n","186\n","neuron 986\n","max_index 14\n","max_index 3\n","max_index 13\n","max_index 6\n","max_index 5\n","max_index 7\n","max_index 6\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 6\n","max_index 6\n","max_index 7\n","max_index 10\n","max_index 8\n","max_index 10\n","max_index 6\n","max_index 2\n","max_index 2\n","max_index 2\n","187\n","neuron 572\n","max_index 17\n","max_index 10\n","max_index 79\n","max_index 10\n","max_index 10\n","max_index 13\n","max_index 2\n","max_index 11\n","max_index 7\n","max_index 3\n","max_index 3\n","max_index 2\n","max_index 5\n","max_index 4\n","max_index 8\n","max_index 2\n","max_index 5\n","max_index 5\n","max_index 7\n","max_index 9\n","188\n","neuron 772\n","max_index 39\n","max_index 39\n","max_index 9\n","max_index 11\n","max_index 15\n","max_index 29\n","max_index 8\n","max_index 6\n","max_index 7\n","max_index 7\n","max_index 49\n","max_index 4\n","max_index 39\n","max_index 11\n","max_index 12\n","max_index 19\n","max_index 149\n","max_index 11\n","max_index 11\n","max_index 29\n","189\n","neuron 403\n","max_index 15\n","max_index 29\n","max_index 5\n","max_index 2\n","max_index 9\n","max_index 9\n","max_index 8\n","max_index 7\n","max_index 16\n","max_index 16\n","max_index 16\n","max_index 12\n","max_index 16\n","max_index 12\n","max_index 12\n","max_index 8\n","max_index 2\n","max_index 17\n","max_index 15\n","max_index 19\n","190\n","neuron 40\n","max_index 9\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 6\n","max_index 7\n","max_index 3\n","max_index 6\n","max_index 6\n","max_index 8\n","max_index 8\n","max_index 9\n","max_index 8\n","max_index 9\n","max_index 5\n","max_index 7\n","max_index 4\n","max_index 6\n","max_index 3\n","max_index 6\n","191\n","neuron 184\n","max_index 3\n","max_index 2\n","max_index 29\n","max_index 49\n","max_index 2\n","max_index 7\n","max_index 49\n","max_index 49\n","max_index 29\n","max_index 29\n","max_index 4\n","max_index 29\n","max_index 2\n","max_index 2\n","max_index 2\n","max_index 2\n","max_index 2\n","max_index 2\n","max_index 29\n","max_index 29\n","192\n","neuron 255\n","max_index 12\n","max_index 14\n","max_index 29\n","max_index 12\n","max_index 39\n","max_index 15\n","max_index 7\n","max_index 7\n","max_index 6\n","max_index 13\n","max_index 13\n","max_index 14\n","max_index 9\n","max_index 9\n","max_index 39\n","max_index 6\n","max_index 13\n","max_index 4\n","max_index 11\n","max_index 17\n","193\n","neuron 931\n","max_index 549\n","max_index 6\n","max_index 11\n","max_index 6\n","max_index 29\n","max_index 649\n","max_index 6\n","max_index 8\n","max_index 6\n","max_index 7\n","max_index 7\n","max_index 29\n","max_index 6\n","max_index 6\n","max_index 6\n","max_index 7\n","max_index 6\n","max_index 679\n","max_index 6\n","max_index 489\n","194\n","neuron 981\n","max_index 7\n","max_index 18\n","max_index 7\n","max_index 14\n","max_index 7\n","max_index 18\n","max_index 4\n","max_index 10\n","max_index 5\n","max_index 11\n","max_index 10\n","max_index 12\n","max_index 5\n","max_index 19\n","max_index 6\n","max_index 9\n","max_index 9\n","max_index 10\n","max_index 17\n","max_index 12\n","195\n","neuron 131\n","max_index 29\n","max_index 49\n","max_index 13\n","max_index 17\n","max_index 16\n","max_index 16\n","max_index 29\n","max_index 16\n","max_index 99\n","max_index 15\n","max_index 15\n","max_index 29\n","max_index 10\n","max_index 15\n","max_index 11\n","max_index 15\n","max_index 17\n","max_index 18\n","max_index 19\n","max_index 17\n","196\n","neuron 285\n","max_index 29\n","max_index 11\n","max_index 5\n","max_index 16\n","max_index 8\n","max_index 8\n","max_index 11\n","max_index 8\n","max_index 59\n","max_index 4\n","max_index 3\n","max_index 5\n","max_index 4\n","max_index 79\n","max_index 6\n","max_index 8\n","max_index 11\n","max_index 8\n","max_index 29\n","max_index 11\n","197\n","neuron 360\n","max_index 2\n","max_index 39\n","max_index 7\n","max_index 2\n","max_index 2\n","max_index 6\n","max_index 8\n","max_index 2\n","max_index 2\n","max_index 2\n","max_index 2\n","max_index 5\n","max_index 4\n","max_index 2\n","max_index 7\n","max_index 4\n","max_index 6\n","max_index 4\n","max_index 29\n","max_index 2\n","198\n","neuron 327\n","max_index 9\n","max_index 12\n","max_index 12\n","max_index 5\n","max_index 12\n","max_index 12\n","max_index 8\n","max_index 11\n","max_index 6\n","max_index 11\n","max_index 12\n","max_index 11\n","max_index 6\n","max_index 9\n","max_index 11\n","max_index 11\n","max_index 12\n","max_index 11\n","max_index 11\n","max_index 11\n","199\n","neuron 1002\n","max_index 3\n","max_index 4\n","max_index 2\n","max_index 3\n","max_index 3\n","max_index 4\n","max_index 2\n","max_index 2\n","max_index 3\n","max_index 2\n","max_index 2\n","max_index 3\n","max_index 2\n","max_index 3\n","max_index 2\n","max_index 2\n","max_index 3\n","max_index 2\n","max_index 2\n","max_index 2\n","layer 7\n","0\n","neuron 219\n","max_index 2\n","max_index 3\n","max_index 2\n","max_index 2\n","max_index 8\n","max_index 12\n","max_index 2\n","max_index 2\n","max_index 2\n","max_index 1\n","max_index 2\n","max_index 7\n","max_index 1\n","max_index 8\n","max_index 5\n","max_index 1\n","max_index 69\n","max_index 2\n","max_index 2\n","max_index 13\n","1\n","neuron 570\n","max_index 12\n","max_index 16\n","max_index 14\n","max_index 4\n","max_index 11\n","max_index 8\n","max_index 14\n","max_index 10\n","max_index 4\n","max_index 10\n","max_index 16\n","max_index 11\n","max_index 8\n","max_index 4\n","max_index 8\n","max_index 7\n","max_index 4\n","max_index 4\n","max_index 8\n","max_index 8\n","2\n","neuron 921\n","max_index 19\n","max_index 39\n","max_index 39\n","max_index 49\n","max_index 9\n","max_index 29\n","max_index 9\n","max_index 39\n","max_index 11\n","max_index 39\n","max_index 10\n","max_index 39\n","max_index 29\n","max_index 9\n","max_index 29\n","max_index 14\n","max_index 7\n","max_index 8\n","max_index 39\n","max_index 13\n","3\n","neuron 292\n","max_index 29\n","max_index 9\n","max_index 59\n","max_index 9\n","max_index 9\n","max_index 9\n","max_index 9\n","max_index 9\n","max_index 9\n","max_index 10\n","max_index 17\n","max_index 9\n","max_index 9\n","max_index 9\n","max_index 18\n","max_index 14\n","max_index 39\n","max_index 9\n","max_index 14\n","max_index 39\n","4\n","neuron 624\n","max_index 49\n","max_index 49\n","max_index 29\n","max_index 29\n","max_index 49\n","max_index 49\n","max_index 29\n","max_index 59\n","max_index 49\n","max_index 39\n","max_index 49\n","max_index 59\n","max_index 49\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 49\n","max_index 49\n","max_index 29\n","max_index 49\n","5\n","neuron 554\n","max_index 89\n","max_index 79\n","max_index 79\n","max_index 79\n","max_index 79\n","max_index 79\n","max_index 79\n","max_index 79\n","max_index 79\n","max_index 79\n","max_index 79\n","max_index 79\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 79\n","max_index 69\n","max_index 79\n","max_index 69\n","max_index 79\n","6\n","neuron 807\n","max_index 49\n","max_index 9\n","max_index 7\n","max_index 2\n","max_index 7\n","max_index 29\n","max_index 3\n","max_index 12\n","max_index 39\n","max_index 6\n","max_index 7\n","max_index 8\n","max_index 16\n","max_index 7\n","max_index 6\n","max_index 39\n","max_index 3\n","max_index 13\n","max_index 4\n","max_index 6\n","7\n","neuron 206\n","max_index 29\n","max_index 129\n","max_index 18\n","max_index 59\n","max_index 39\n","max_index 18\n","max_index 19\n","max_index 18\n","max_index 14\n","max_index 16\n","max_index 29\n","max_index 119\n","max_index 16\n","max_index 18\n","max_index 139\n","max_index 16\n","max_index 39\n","max_index 17\n","max_index 39\n","max_index 39\n","8\n","neuron 728\n","max_index 269\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 8\n","max_index 39\n","max_index 39\n","max_index 14\n","max_index 49\n","max_index 39\n","max_index 39\n","max_index 89\n","max_index 11\n","max_index 39\n","max_index 39\n","max_index 29\n","max_index 39\n","max_index 5\n","max_index 15\n","max_index 15\n","9\n","neuron 303\n","max_index 18\n","max_index 69\n","max_index 14\n","max_index 49\n","max_index 29\n","max_index 13\n","max_index 19\n","max_index 19\n","max_index 12\n","max_index 69\n","max_index 39\n","max_index 39\n","max_index 69\n","max_index 29\n","max_index 59\n","max_index 59\n","max_index 149\n","max_index 79\n","max_index 59\n","max_index 29\n","10\n","neuron 796\n","max_index 29\n","max_index 809\n","max_index 18\n","max_index 39\n","max_index 29\n","max_index 159\n","max_index 29\n","max_index 39\n","max_index 79\n","max_index 594\n","max_index 79\n","max_index 304\n","max_index 49\n","max_index 409\n","max_index 734\n","max_index 179\n","max_index 99\n","max_index 59\n","max_index 99\n","max_index 109\n","11\n","neuron 452\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 17\n","max_index 69\n","max_index 15\n","max_index 16\n","max_index 16\n","max_index 29\n","max_index 16\n","max_index 29\n","max_index 69\n","max_index 59\n","max_index 12\n","max_index 129\n","max_index 13\n","max_index 29\n","max_index 3\n","max_index 49\n","max_index 49\n","12\n","neuron 526\n","max_index 4\n","max_index 4\n","max_index 3\n","max_index 7\n","max_index 2\n","max_index 17\n","max_index 4\n","max_index 6\n","max_index 8\n","max_index 4\n","max_index 5\n","max_index 2\n","max_index 2\n","max_index 7\n","max_index 79\n","max_index 17\n","max_index 7\n","max_index 17\n","max_index 15\n","max_index 2\n","13\n","neuron 619\n","max_index 59\n","max_index 59\n","max_index 129\n","max_index 59\n","max_index 9\n","max_index 10\n","max_index 9\n","max_index 11\n","max_index 10\n","max_index 10\n","max_index 15\n","max_index 7\n","max_index 10\n","max_index 10\n","max_index 59\n","max_index 5\n","max_index 59\n","max_index 59\n","max_index 8\n","max_index 59\n","14\n","neuron 473\n","max_index 9\n","max_index 12\n","max_index 5\n","max_index 2\n","max_index 4\n","max_index 13\n","max_index 2\n","max_index 8\n","max_index 7\n","max_index 2\n","max_index 10\n","max_index 12\n","max_index 9\n","max_index 8\n","max_index 5\n","max_index 5\n","max_index 8\n","max_index 2\n","max_index 4\n","max_index 2\n","15\n","neuron 549\n","max_index 344\n","max_index 49\n","max_index 91\n","max_index 39\n","max_index 59\n","max_index 39\n","max_index 47\n","max_index 99\n","max_index 49\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 29\n","max_index 6\n","max_index 39\n","max_index 39\n","max_index 29\n","max_index 39\n","max_index 59\n","max_index 29\n","16\n","neuron 649\n","max_index 29\n","max_index 99\n","max_index 99\n","max_index 29\n","max_index 39\n","max_index 17\n","max_index 29\n","max_index 19\n","max_index 628\n","max_index 179\n","max_index 18\n","max_index 249\n","max_index 17\n","max_index 29\n","max_index 18\n","max_index 809\n","max_index 169\n","max_index 109\n","max_index 289\n","max_index 39\n","17\n","neuron 267\n","max_index 99\n","max_index 39\n","max_index 69\n","max_index 18\n","max_index 39\n","max_index 39\n","max_index 18\n","max_index 39\n","max_index 18\n","max_index 39\n","max_index 18\n","max_index 29\n","max_index 18\n","max_index 99\n","max_index 18\n","max_index 18\n","max_index 18\n","max_index 18\n","max_index 18\n","max_index 39\n","18\n","neuron 279\n","max_index 6\n","max_index 8\n","max_index 8\n","max_index 8\n","max_index 5\n","max_index 14\n","max_index 16\n","max_index 7\n","max_index 6\n","max_index 6\n","max_index 5\n","max_index 11\n","max_index 4\n","max_index 14\n","max_index 5\n","max_index 6\n","max_index 9\n","max_index 6\n","max_index 14\n","max_index 3\n","19\n","neuron 237\n","max_index 39\n","max_index 4\n","max_index 12\n","max_index 5\n","max_index 49\n","max_index 9\n","max_index 6\n","max_index 4\n","max_index 6\n","max_index 11\n","max_index 11\n","max_index 17\n","max_index 8\n","max_index 9\n","max_index 7\n","max_index 14\n","max_index 17\n","max_index 39\n","max_index 19\n","max_index 15\n","20\n","neuron 16\n","max_index 109\n","max_index 69\n","max_index 99\n","max_index 59\n","max_index 59\n","max_index 69\n","max_index 59\n","max_index 12\n","max_index 59\n","max_index 14\n","max_index 49\n","max_index 12\n","max_index 14\n","max_index 11\n","max_index 12\n","max_index 59\n","max_index 59\n","max_index 69\n","max_index 139\n","max_index 13\n","21\n","neuron 121\n","max_index 14\n","max_index 14\n","max_index 14\n","max_index 14\n","max_index 14\n","max_index 10\n","max_index 39\n","max_index 2\n","max_index 29\n","max_index 2\n","max_index 8\n","max_index 2\n","max_index 2\n","max_index 8\n","max_index 2\n","max_index 39\n","max_index 29\n","max_index 14\n","max_index 14\n","max_index 16\n","22\n","neuron 629\n","max_index 6\n","max_index 19\n","max_index 16\n","max_index 11\n","max_index 9\n","max_index 8\n","max_index 6\n","max_index 3\n","max_index 29\n","max_index 8\n","max_index 4\n","max_index 4\n","max_index 3\n","max_index 16\n","max_index 4\n","max_index 14\n","max_index 6\n","max_index 39\n","max_index 29\n","max_index 3\n","23\n","neuron 802\n","max_index 59\n","max_index 29\n","max_index 29\n","max_index 19\n","max_index 29\n","max_index 69\n","max_index 19\n","max_index 19\n","max_index 19\n","max_index 29\n","max_index 29\n","max_index 8\n","max_index 19\n","max_index 29\n","max_index 169\n","max_index 19\n","max_index 19\n","max_index 19\n","max_index 159\n","max_index 39\n","24\n","neuron 1015\n","max_index 119\n","max_index 109\n","max_index 79\n","max_index 99\n","max_index 129\n","max_index 109\n","max_index 109\n","max_index 99\n","max_index 149\n","max_index 129\n","max_index 109\n","max_index 109\n","max_index 109\n","max_index 109\n","max_index 99\n","max_index 139\n","max_index 79\n","max_index 69\n","max_index 89\n","max_index 59\n","25\n","neuron 101\n","max_index 1\n","max_index 3\n","max_index 1\n","max_index 1\n","max_index 1\n","max_index 109\n","max_index 1\n","max_index 2\n","max_index 1\n","max_index 1\n","max_index 19\n","max_index 1\n","max_index 1\n","max_index 1\n","max_index 1\n","max_index 17\n","max_index 1\n","max_index 1\n","max_index 1\n","max_index 1\n","26\n","neuron 176\n","max_index 6\n","max_index 29\n","max_index 13\n","max_index 13\n","max_index 6\n","max_index 39\n","max_index 5\n","max_index 39\n","max_index 7\n","max_index 17\n","max_index 17\n","max_index 219\n","max_index 4\n","max_index 109\n","max_index 29\n","max_index 4\n","max_index 29\n","max_index 29\n","max_index 16\n","max_index 5\n","27\n","neuron 750\n","max_index 29\n","max_index 69\n","max_index 18\n","max_index 29\n","max_index 18\n","max_index 17\n","max_index 29\n","max_index 29\n","max_index 18\n","max_index 18\n","max_index 104\n","max_index 19\n","max_index 18\n","max_index 19\n","max_index 29\n","max_index 19\n","max_index 29\n","max_index 19\n","max_index 29\n","max_index 29\n","28\n","neuron 424\n","max_index 5\n","max_index 4\n","max_index 11\n","max_index 4\n","max_index 4\n","max_index 129\n","max_index 10\n","max_index 6\n","max_index 4\n","max_index 19\n","max_index 9\n","max_index 9\n","max_index 3\n","max_index 6\n","max_index 5\n","max_index 13\n","max_index 13\n","max_index 7\n","max_index 3\n","max_index 3\n","29\n","neuron 254\n","max_index 79\n","max_index 159\n","max_index 79\n","max_index 79\n","max_index 79\n","max_index 59\n","max_index 99\n","max_index 129\n","max_index 129\n","max_index 69\n","max_index 69\n","max_index 159\n","max_index 69\n","max_index 129\n","max_index 89\n","max_index 79\n","max_index 109\n","max_index 79\n","max_index 59\n","max_index 59\n","30\n","neuron 223\n","max_index 5\n","max_index 4\n","max_index 4\n","max_index 12\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 2\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 2\n","max_index 189\n","max_index 4\n","max_index 2\n","max_index 2\n","max_index 189\n","max_index 4\n","max_index 4\n","31\n","neuron 291\n","max_index 11\n","max_index 17\n","max_index 7\n","max_index 5\n","max_index 6\n","max_index 6\n","max_index 7\n","max_index 15\n","max_index 5\n","max_index 5\n","max_index 2\n","max_index 5\n","max_index 49\n","max_index 11\n","max_index 5\n","max_index 8\n","max_index 2\n","max_index 7\n","max_index 49\n","max_index 4\n","32\n","neuron 900\n","max_index 59\n","max_index 19\n","max_index 6\n","max_index 16\n","max_index 29\n","max_index 29\n","max_index 18\n","max_index 39\n","max_index 18\n","max_index 79\n","max_index 18\n","max_index 16\n","max_index 29\n","max_index 19\n","max_index 16\n","max_index 169\n","max_index 12\n","max_index 29\n","max_index 29\n","max_index 12\n","33\n","neuron 753\n","max_index 18\n","max_index 9\n","max_index 29\n","max_index 13\n","max_index 14\n","max_index 5\n","max_index 18\n","max_index 49\n","max_index 6\n","max_index 9\n","max_index 3\n","max_index 8\n","max_index 6\n","max_index 29\n","max_index 4\n","max_index 9\n","max_index 14\n","max_index 4\n","max_index 6\n","max_index 18\n","34\n","neuron 675\n","max_index 5\n","max_index 11\n","max_index 9\n","max_index 4\n","max_index 6\n","max_index 11\n","max_index 12\n","max_index 4\n","max_index 6\n","max_index 39\n","max_index 3\n","max_index 7\n","max_index 7\n","max_index 2\n","max_index 2\n","max_index 10\n","max_index 8\n","max_index 3\n","max_index 5\n","max_index 2\n","35\n","neuron 6\n","max_index 49\n","max_index 16\n","max_index 13\n","max_index 16\n","max_index 59\n","max_index 16\n","max_index 16\n","max_index 16\n","max_index 16\n","max_index 59\n","max_index 12\n","max_index 499\n","max_index 17\n","max_index 17\n","max_index 16\n","max_index 16\n","max_index 16\n","max_index 119\n","max_index 17\n","max_index 19\n","36\n","neuron 759\n","max_index 3\n","max_index 43\n","max_index 1\n","max_index 0\n","max_index 79\n","max_index 0\n","max_index 580\n","max_index 59\n","max_index 444\n","max_index 3\n","max_index 1\n","max_index 0\n","max_index 2\n","max_index 0\n","max_index 2\n","max_index 0\n","max_index 1\n","max_index 6\n","max_index 1\n","max_index 1\n","37\n","neuron 548\n","max_index 9\n","max_index 29\n","max_index 11\n","max_index 49\n","max_index 6\n","max_index 2\n","max_index 17\n","max_index 12\n","max_index 39\n","max_index 5\n","max_index 4\n","max_index 2\n","max_index 10\n","max_index 5\n","max_index 10\n","max_index 5\n","max_index 29\n","max_index 15\n","max_index 16\n","max_index 18\n","38\n","neuron 527\n","max_index 799\n","max_index 89\n","max_index 49\n","max_index 699\n","max_index 39\n","max_index 89\n","max_index 699\n","max_index 779\n","max_index 99\n","max_index 89\n","max_index 9\n","max_index 49\n","max_index 39\n","max_index 59\n","max_index 89\n","max_index 69\n","max_index 29\n","max_index 89\n","max_index 89\n","max_index 49\n","39\n","neuron 438\n","max_index 59\n","max_index 59\n","max_index 59\n","max_index 59\n","max_index 99\n","max_index 149\n","max_index 59\n","max_index 99\n","max_index 11\n","max_index 59\n","max_index 119\n","max_index 2\n","max_index 129\n","max_index 2\n","max_index 4\n","max_index 59\n","max_index 3\n","max_index 3\n","max_index 59\n","max_index 49\n","40\n","neuron 879\n","max_index 5\n","max_index 129\n","max_index 49\n","max_index 149\n","max_index 39\n","max_index 29\n","max_index 29\n","max_index 59\n","max_index 29\n","max_index 119\n","max_index 59\n","max_index 29\n","max_index 139\n","max_index 129\n","max_index 19\n","max_index 499\n","max_index 39\n","max_index 14\n","max_index 69\n","max_index 29\n","41\n","neuron 50\n","max_index 69\n","max_index 69\n","max_index 49\n","max_index 49\n","max_index 29\n","max_index 39\n","max_index 39\n","max_index 49\n","max_index 49\n","max_index 49\n","max_index 49\n","max_index 49\n","max_index 49\n","max_index 39\n","max_index 5\n","max_index 7\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 29\n","42\n","neuron 124\n","max_index 60\n","max_index 790\n","max_index 860\n","max_index 651\n","max_index 520\n","max_index 488\n","max_index 930\n","max_index 550\n","max_index 959\n","max_index 56\n","max_index 697\n","max_index 589\n","max_index 838\n","max_index 610\n","max_index 498\n","max_index 210\n","max_index 518\n","max_index 679\n","max_index 50\n","max_index 760\n","43\n","neuron 393\n","max_index 69\n","max_index 69\n","max_index 6\n","max_index 5\n","max_index 13\n","max_index 29\n","max_index 6\n","max_index 5\n","max_index 13\n","max_index 69\n","max_index 49\n","max_index 6\n","max_index 49\n","max_index 13\n","max_index 15\n","max_index 29\n","max_index 9\n","max_index 49\n","max_index 7\n","max_index 49\n","44\n","neuron 660\n","max_index 39\n","max_index 16\n","max_index 29\n","max_index 19\n","max_index 17\n","max_index 29\n","max_index 29\n","max_index 14\n","max_index 19\n","max_index 14\n","max_index 18\n","max_index 3\n","max_index 39\n","max_index 11\n","max_index 49\n","max_index 10\n","max_index 16\n","max_index 39\n","max_index 29\n","max_index 8\n","45\n","neuron 1005\n","max_index 99\n","max_index 99\n","max_index 49\n","max_index 89\n","max_index 79\n","max_index 69\n","max_index 59\n","max_index 69\n","max_index 59\n","max_index 59\n","max_index 59\n","max_index 69\n","max_index 49\n","max_index 79\n","max_index 89\n","max_index 49\n","max_index 279\n","max_index 39\n","max_index 39\n","max_index 79\n","46\n","neuron 1002\n","max_index 79\n","max_index 13\n","max_index 9\n","max_index 29\n","max_index 9\n","max_index 14\n","max_index 11\n","max_index 9\n","max_index 59\n","max_index 79\n","max_index 11\n","max_index 49\n","max_index 29\n","max_index 89\n","max_index 39\n","max_index 69\n","max_index 8\n","max_index 99\n","max_index 29\n","max_index 29\n","47\n","neuron 754\n","max_index 12\n","max_index 5\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 3\n","max_index 5\n","max_index 3\n","max_index 3\n","max_index 4\n","max_index 5\n","max_index 4\n","max_index 4\n","max_index 10\n","max_index 4\n","max_index 3\n","max_index 6\n","max_index 4\n","max_index 3\n","48\n","neuron 578\n","max_index 29\n","max_index 6\n","max_index 6\n","max_index 3\n","max_index 6\n","max_index 8\n","max_index 9\n","max_index 9\n","max_index 10\n","max_index 9\n","max_index 6\n","max_index 7\n","max_index 5\n","max_index 7\n","max_index 29\n","max_index 2\n","max_index 5\n","max_index 9\n","max_index 4\n","max_index 4\n","49\n","neuron 367\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 49\n","max_index 39\n","max_index 49\n","max_index 39\n","max_index 49\n","max_index 39\n","max_index 29\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 49\n","max_index 39\n","max_index 39\n","max_index 49\n","max_index 39\n","max_index 39\n","50\n","neuron 235\n","max_index 6\n","max_index 2\n","max_index 8\n","max_index 6\n","max_index 6\n","max_index 2\n","max_index 39\n","max_index 2\n","max_index 12\n","max_index 7\n","max_index 6\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 2\n","max_index 5\n","max_index 7\n","max_index 10\n","max_index 9\n","51\n","neuron 691\n","max_index 4\n","max_index 29\n","max_index 6\n","max_index 4\n","max_index 6\n","max_index 4\n","max_index 6\n","max_index 4\n","max_index 19\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 17\n","max_index 4\n","max_index 14\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 17\n","52\n","neuron 733\n","max_index 8\n","max_index 7\n","max_index 6\n","max_index 11\n","max_index 6\n","max_index 6\n","max_index 7\n","max_index 8\n","max_index 6\n","max_index 7\n","max_index 6\n","max_index 7\n","max_index 11\n","max_index 12\n","max_index 6\n","max_index 10\n","max_index 10\n","max_index 8\n","max_index 10\n","max_index 6\n","53\n","neuron 720\n","max_index 169\n","max_index 89\n","max_index 129\n","max_index 119\n","max_index 189\n","max_index 8\n","max_index 229\n","max_index 59\n","max_index 139\n","max_index 8\n","max_index 249\n","max_index 59\n","max_index 119\n","max_index 119\n","max_index 39\n","max_index 129\n","max_index 89\n","max_index 189\n","max_index 129\n","max_index 219\n","54\n","neuron 559\n","max_index 149\n","max_index 139\n","max_index 149\n","max_index 139\n","max_index 129\n","max_index 129\n","max_index 149\n","max_index 149\n","max_index 139\n","max_index 149\n","max_index 139\n","max_index 149\n","max_index 139\n","max_index 139\n","max_index 149\n","max_index 129\n","max_index 109\n","max_index 139\n","max_index 129\n","max_index 149\n","55\n","neuron 676\n","max_index 29\n","max_index 409\n","max_index 59\n","max_index 739\n","max_index 49\n","max_index 59\n","max_index 49\n","max_index 159\n","max_index 49\n","max_index 49\n","max_index 389\n","max_index 49\n","max_index 17\n","max_index 49\n","max_index 809\n","max_index 49\n","max_index 49\n","max_index 419\n","max_index 13\n","max_index 439\n","56\n","neuron 288\n","max_index 18\n","max_index 7\n","max_index 4\n","max_index 6\n","max_index 6\n","max_index 3\n","max_index 5\n","max_index 7\n","max_index 3\n","max_index 7\n","max_index 11\n","max_index 13\n","max_index 6\n","max_index 4\n","max_index 11\n","max_index 6\n","max_index 3\n","max_index 5\n","max_index 7\n","max_index 1\n","57\n","neuron 226\n","max_index 189\n","max_index 169\n","max_index 159\n","max_index 89\n","max_index 349\n","max_index 89\n","max_index 149\n","max_index 79\n","max_index 539\n","max_index 159\n","max_index 49\n","max_index 149\n","max_index 229\n","max_index 49\n","max_index 219\n","max_index 189\n","max_index 49\n","max_index 329\n","max_index 49\n","max_index 649\n","58\n","neuron 757\n","max_index 9\n","max_index 59\n","max_index 11\n","max_index 29\n","max_index 5\n","max_index 10\n","max_index 13\n","max_index 4\n","max_index 7\n","max_index 29\n","max_index 3\n","max_index 16\n","max_index 369\n","max_index 13\n","max_index 10\n","max_index 3\n","max_index 18\n","max_index 5\n","max_index 11\n","max_index 10\n","59\n","neuron 851\n","max_index 159\n","max_index 149\n","max_index 149\n","max_index 99\n","max_index 809\n","max_index 29\n","max_index 149\n","max_index 179\n","max_index 159\n","max_index 89\n","max_index 149\n","max_index 349\n","max_index 149\n","max_index 59\n","max_index 329\n","max_index 509\n","max_index 59\n","max_index 59\n","max_index 59\n","max_index 17\n","60\n","neuron 923\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 3\n","max_index 29\n","max_index 4\n","max_index 29\n","61\n","neuron 245\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 69\n","max_index 16\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 16\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 49\n","max_index 39\n","max_index 169\n","max_index 16\n","62\n","neuron 66\n","max_index 9\n","max_index 49\n","max_index 29\n","max_index 89\n","max_index 39\n","max_index 8\n","max_index 4\n","max_index 39\n","max_index 39\n","max_index 6\n","max_index 11\n","max_index 3\n","max_index 13\n","max_index 39\n","max_index 9\n","max_index 39\n","max_index 6\n","max_index 4\n","max_index 39\n","max_index 29\n","63\n","neuron 530\n","max_index 5\n","max_index 9\n","max_index 12\n","max_index 13\n","max_index 5\n","max_index 18\n","max_index 8\n","max_index 8\n","max_index 17\n","max_index 39\n","max_index 10\n","max_index 5\n","max_index 29\n","max_index 10\n","max_index 3\n","max_index 29\n","max_index 13\n","max_index 29\n","max_index 4\n","max_index 10\n","64\n","neuron 314\n","max_index 11\n","max_index 8\n","max_index 19\n","max_index 8\n","max_index 5\n","max_index 11\n","max_index 16\n","max_index 8\n","max_index 8\n","max_index 11\n","max_index 13\n","max_index 8\n","max_index 18\n","max_index 10\n","max_index 11\n","max_index 7\n","max_index 3\n","max_index 10\n","max_index 4\n","max_index 5\n","65\n","neuron 690\n","max_index 89\n","max_index 89\n","max_index 99\n","max_index 89\n","max_index 89\n","max_index 89\n","max_index 89\n","max_index 89\n","max_index 89\n","max_index 89\n","max_index 89\n","max_index 89\n","max_index 89\n","max_index 89\n","max_index 89\n","max_index 89\n","max_index 89\n","max_index 89\n","max_index 79\n","max_index 89\n","66\n","neuron 335\n","max_index 4\n","max_index 11\n","max_index 6\n","max_index 11\n","max_index 13\n","max_index 9\n","max_index 6\n","max_index 12\n","max_index 8\n","max_index 5\n","max_index 10\n","max_index 5\n","max_index 5\n","max_index 6\n","max_index 13\n","max_index 8\n","max_index 7\n","max_index 5\n","max_index 18\n","max_index 5\n","67\n","neuron 239\n","max_index 16\n","max_index 10\n","max_index 8\n","max_index 2\n","max_index 4\n","max_index 9\n","max_index 5\n","max_index 7\n","max_index 5\n","max_index 11\n","max_index 1\n","max_index 6\n","max_index 2\n","max_index 5\n","max_index 1\n","max_index 10\n","max_index 3\n","max_index 12\n","max_index 2\n","max_index 5\n","68\n","neuron 382\n","max_index 6\n","max_index 9\n","max_index 7\n","max_index 8\n","max_index 7\n","max_index 7\n","max_index 9\n","max_index 7\n","max_index 7\n","max_index 6\n","max_index 7\n","max_index 9\n","max_index 6\n","max_index 6\n","max_index 7\n","max_index 7\n","max_index 6\n","max_index 7\n","max_index 6\n","max_index 6\n","69\n","neuron 643\n","max_index 17\n","max_index 109\n","max_index 69\n","max_index 39\n","max_index 79\n","max_index 139\n","max_index 5\n","max_index 29\n","max_index 49\n","max_index 129\n","max_index 16\n","max_index 5\n","max_index 15\n","max_index 29\n","max_index 3\n","max_index 18\n","max_index 29\n","max_index 13\n","max_index 349\n","max_index 16\n","70\n","neuron 491\n","max_index 18\n","max_index 3\n","max_index 13\n","max_index 59\n","max_index 3\n","max_index 10\n","max_index 3\n","max_index 5\n","max_index 4\n","max_index 6\n","max_index 9\n","max_index 49\n","max_index 59\n","max_index 3\n","max_index 15\n","max_index 11\n","max_index 4\n","max_index 17\n","max_index 29\n","max_index 4\n","71\n","neuron 293\n","max_index 6\n","max_index 2\n","max_index 13\n","max_index 2\n","max_index 29\n","max_index 2\n","max_index 2\n","max_index 9\n","max_index 2\n","max_index 29\n","max_index 7\n","max_index 11\n","max_index 49\n","max_index 39\n","max_index 6\n","max_index 8\n","max_index 10\n","max_index 4\n","max_index 2\n","max_index 12\n","72\n","neuron 596\n","max_index 15\n","max_index 59\n","max_index 6\n","max_index 9\n","max_index 5\n","max_index 11\n","max_index 16\n","max_index 8\n","max_index 5\n","max_index 12\n","max_index 4\n","max_index 29\n","max_index 5\n","max_index 10\n","max_index 3\n","max_index 8\n","max_index 4\n","max_index 7\n","max_index 4\n","max_index 11\n","73\n","neuron 175\n","max_index 10\n","max_index 14\n","max_index 14\n","max_index 12\n","max_index 49\n","max_index 5\n","max_index 12\n","max_index 11\n","max_index 5\n","max_index 7\n","max_index 69\n","max_index 9\n","max_index 39\n","max_index 11\n","max_index 7\n","max_index 6\n","max_index 6\n","max_index 12\n","max_index 7\n","max_index 6\n","74\n","neuron 140\n","max_index 39\n","max_index 15\n","max_index 89\n","max_index 69\n","max_index 89\n","max_index 69\n","max_index 89\n","max_index 79\n","max_index 79\n","max_index 89\n","max_index 39\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 39\n","max_index 69\n","max_index 13\n","max_index 79\n","max_index 79\n","75\n","neuron 829\n","max_index 39\n","max_index 12\n","max_index 14\n","max_index 14\n","max_index 14\n","max_index 12\n","max_index 14\n","max_index 12\n","max_index 12\n","max_index 14\n","max_index 12\n","max_index 12\n","max_index 14\n","max_index 14\n","max_index 14\n","max_index 12\n","max_index 10\n","max_index 12\n","max_index 14\n","max_index 10\n","76\n","neuron 15\n","max_index 39\n","max_index 49\n","max_index 17\n","max_index 39\n","max_index 29\n","max_index 9\n","max_index 89\n","max_index 39\n","max_index 18\n","max_index 29\n","max_index 18\n","max_index 319\n","max_index 39\n","max_index 9\n","max_index 10\n","max_index 49\n","max_index 29\n","max_index 29\n","max_index 10\n","max_index 39\n","77\n","neuron 566\n","max_index 49\n","max_index 49\n","max_index 49\n","max_index 59\n","max_index 49\n","max_index 39\n","max_index 39\n","max_index 389\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 389\n","max_index 49\n","max_index 389\n","max_index 49\n","max_index 49\n","max_index 49\n","max_index 49\n","max_index 49\n","max_index 39\n","78\n","neuron 516\n","max_index 49\n","max_index 99\n","max_index 429\n","max_index 59\n","max_index 369\n","max_index 11\n","max_index 209\n","max_index 109\n","max_index 29\n","max_index 29\n","max_index 11\n","max_index 259\n","max_index 17\n","max_index 12\n","max_index 59\n","max_index 169\n","max_index 10\n","max_index 18\n","max_index 309\n","max_index 29\n","79\n","neuron 957\n","max_index 9\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 3\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","80\n","neuron 375\n","max_index 9\n","max_index 1\n","max_index 8\n","max_index 1\n","max_index 1\n","max_index 4\n","max_index 1\n","max_index 7\n","max_index 1\n","max_index 9\n","max_index 29\n","max_index 4\n","max_index 4\n","max_index 7\n","max_index 99\n","max_index 49\n","max_index 5\n","max_index 5\n","max_index 4\n","max_index 6\n","81\n","neuron 599\n","max_index 4\n","max_index 7\n","max_index 7\n","max_index 4\n","max_index 2\n","max_index 2\n","max_index 2\n","max_index 6\n","max_index 2\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 6\n","max_index 6\n","max_index 4\n","max_index 15\n","max_index 4\n","max_index 6\n","82\n","neuron 650\n","max_index 11\n","max_index 18\n","max_index 11\n","max_index 11\n","max_index 11\n","max_index 29\n","max_index 18\n","max_index 9\n","max_index 9\n","max_index 9\n","max_index 7\n","max_index 11\n","max_index 11\n","max_index 9\n","max_index 17\n","max_index 11\n","max_index 11\n","max_index 9\n","max_index 8\n","max_index 5\n","83\n","neuron 25\n","max_index 4\n","max_index 3\n","max_index 3\n","max_index 2\n","max_index 29\n","max_index 7\n","max_index 29\n","max_index 29\n","max_index 12\n","max_index 3\n","max_index 19\n","max_index 3\n","max_index 8\n","max_index 3\n","max_index 5\n","max_index 3\n","max_index 3\n","max_index 29\n","max_index 4\n","max_index 2\n","84\n","neuron 831\n","max_index 99\n","max_index 59\n","max_index 69\n","max_index 79\n","max_index 79\n","max_index 59\n","max_index 69\n","max_index 89\n","max_index 69\n","max_index 69\n","max_index 79\n","max_index 79\n","max_index 49\n","max_index 69\n","max_index 59\n","max_index 59\n","max_index 69\n","max_index 99\n","max_index 89\n","max_index 99\n","85\n","neuron 132\n","max_index 10\n","max_index 12\n","max_index 6\n","max_index 9\n","max_index 19\n","max_index 6\n","max_index 9\n","max_index 12\n","max_index 39\n","max_index 5\n","max_index 39\n","max_index 5\n","max_index 7\n","max_index 12\n","max_index 17\n","max_index 16\n","max_index 6\n","max_index 19\n","max_index 10\n","max_index 13\n","86\n","neuron 897\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 59\n","max_index 69\n","max_index 4\n","max_index 29\n","max_index 29\n","max_index 9\n","max_index 607\n","max_index 14\n","max_index 14\n","max_index 29\n","max_index 289\n","max_index 14\n","max_index 4\n","max_index 14\n","max_index 29\n","max_index 2\n","87\n","neuron 405\n","max_index 3\n","max_index 3\n","max_index 4\n","max_index 3\n","max_index 3\n","max_index 5\n","max_index 3\n","max_index 12\n","max_index 3\n","max_index 9\n","max_index 7\n","max_index 9\n","max_index 4\n","max_index 3\n","max_index 3\n","max_index 3\n","max_index 3\n","max_index 4\n","max_index 3\n","max_index 3\n","88\n","neuron 158\n","max_index 159\n","max_index 149\n","max_index 99\n","max_index 149\n","max_index 179\n","max_index 149\n","max_index 149\n","max_index 29\n","max_index 159\n","max_index 149\n","max_index 149\n","max_index 889\n","max_index 49\n","max_index 349\n","max_index 209\n","max_index 49\n","max_index 49\n","max_index 49\n","max_index 17\n","max_index 49\n","89\n","neuron 181\n","max_index 9\n","max_index 12\n","max_index 15\n","max_index 11\n","max_index 14\n","max_index 8\n","max_index 49\n","max_index 13\n","max_index 49\n","max_index 39\n","max_index 8\n","max_index 14\n","max_index 39\n","max_index 99\n","max_index 39\n","max_index 12\n","max_index 29\n","max_index 11\n","max_index 39\n","max_index 39\n","90\n","neuron 522\n","max_index 7\n","max_index 10\n","max_index 29\n","max_index 11\n","max_index 8\n","max_index 8\n","max_index 8\n","max_index 18\n","max_index 7\n","max_index 7\n","max_index 8\n","max_index 9\n","max_index 8\n","max_index 9\n","max_index 8\n","max_index 8\n","max_index 6\n","max_index 13\n","max_index 7\n","max_index 8\n","91\n","neuron 78\n","max_index 29\n","max_index 349\n","max_index 809\n","max_index 109\n","max_index 349\n","max_index 59\n","max_index 349\n","max_index 239\n","max_index 159\n","max_index 59\n","max_index 189\n","max_index 169\n","max_index 59\n","max_index 149\n","max_index 169\n","max_index 109\n","max_index 99\n","max_index 89\n","max_index 99\n","max_index 369\n","92\n","neuron 138\n","max_index 7\n","max_index 7\n","max_index 7\n","max_index 7\n","max_index 8\n","max_index 10\n","max_index 8\n","max_index 29\n","max_index 29\n","max_index 7\n","max_index 13\n","max_index 8\n","max_index 7\n","max_index 18\n","max_index 15\n","max_index 29\n","max_index 29\n","max_index 7\n","max_index 29\n","max_index 7\n","93\n","neuron 783\n","max_index 16\n","max_index 989\n","max_index 29\n","max_index 49\n","max_index 29\n","max_index 18\n","max_index 39\n","max_index 29\n","max_index 6\n","max_index 13\n","max_index 69\n","max_index 39\n","max_index 5\n","max_index 8\n","max_index 13\n","max_index 29\n","max_index 17\n","max_index 39\n","max_index 10\n","max_index 14\n","94\n","neuron 211\n","max_index 269\n","max_index 14\n","max_index 39\n","max_index 8\n","max_index 49\n","max_index 29\n","max_index 11\n","max_index 49\n","max_index 39\n","max_index 139\n","max_index 39\n","max_index 99\n","max_index 89\n","max_index 11\n","max_index 6\n","max_index 11\n","max_index 99\n","max_index 6\n","max_index 49\n","max_index 109\n","95\n","neuron 800\n","max_index 39\n","max_index 16\n","max_index 69\n","max_index 12\n","max_index 39\n","max_index 17\n","max_index 13\n","max_index 29\n","max_index 39\n","max_index 11\n","max_index 16\n","max_index 29\n","max_index 12\n","max_index 10\n","max_index 69\n","max_index 29\n","max_index 12\n","max_index 12\n","max_index 10\n","max_index 9\n","96\n","neuron 793\n","max_index 139\n","max_index 528\n","max_index 29\n","max_index 199\n","max_index 29\n","max_index 29\n","max_index 199\n","max_index 59\n","max_index 159\n","max_index 29\n","max_index 29\n","max_index 309\n","max_index 139\n","max_index 29\n","max_index 109\n","max_index 59\n","max_index 199\n","max_index 89\n","max_index 39\n","max_index 19\n","97\n","neuron 508\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 3\n","max_index 4\n","max_index 7\n","max_index 3\n","max_index 9\n","max_index 3\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 3\n","max_index 4\n","max_index 3\n","max_index 4\n","max_index 3\n","max_index 4\n","max_index 3\n","98\n","neuron 583\n","max_index 9\n","max_index 11\n","max_index 8\n","max_index 9\n","max_index 16\n","max_index 17\n","max_index 4\n","max_index 5\n","max_index 9\n","max_index 10\n","max_index 4\n","max_index 14\n","max_index 6\n","max_index 8\n","max_index 9\n","max_index 16\n","max_index 9\n","max_index 6\n","max_index 3\n","max_index 9\n","99\n","neuron 785\n","max_index 18\n","max_index 12\n","max_index 14\n","max_index 39\n","max_index 29\n","max_index 29\n","max_index 39\n","max_index 29\n","max_index 39\n","max_index 99\n","max_index 129\n","max_index 69\n","max_index 99\n","max_index 129\n","max_index 89\n","max_index 39\n","max_index 109\n","max_index 89\n","max_index 89\n","max_index 29\n","100\n","neuron 712\n","max_index 29\n","max_index 7\n","max_index 39\n","max_index 139\n","max_index 99\n","max_index 139\n","max_index 12\n","max_index 129\n","max_index 79\n","max_index 129\n","max_index 129\n","max_index 11\n","max_index 129\n","max_index 129\n","max_index 29\n","max_index 129\n","max_index 199\n","max_index 59\n","max_index 29\n","max_index 129\n","101\n","neuron 218\n","max_index 29\n","max_index 29\n","max_index 7\n","max_index 13\n","max_index 29\n","max_index 29\n","max_index 4\n","max_index 16\n","max_index 12\n","max_index 39\n","max_index 29\n","max_index 15\n","max_index 13\n","max_index 7\n","max_index 9\n","max_index 29\n","max_index 14\n","max_index 7\n","max_index 7\n","max_index 12\n","102\n","neuron 240\n","max_index 9\n","max_index 11\n","max_index 8\n","max_index 5\n","max_index 11\n","max_index 9\n","max_index 6\n","max_index 9\n","max_index 11\n","max_index 5\n","max_index 4\n","max_index 8\n","max_index 11\n","max_index 7\n","max_index 9\n","max_index 10\n","max_index 9\n","max_index 9\n","max_index 4\n","max_index 5\n","103\n","neuron 996\n","max_index 16\n","max_index 2\n","max_index 3\n","max_index 2\n","max_index 13\n","max_index 29\n","max_index 29\n","max_index 2\n","max_index 2\n","max_index 4\n","max_index 2\n","max_index 4\n","max_index 9\n","max_index 2\n","max_index 2\n","max_index 3\n","max_index 2\n","max_index 2\n","max_index 3\n","max_index 9\n","104\n","neuron 135\n","max_index 16\n","max_index 39\n","max_index 59\n","max_index 59\n","max_index 69\n","max_index 69\n","max_index 59\n","max_index 79\n","max_index 10\n","max_index 69\n","max_index 8\n","max_index 69\n","max_index 69\n","max_index 79\n","max_index 3\n","max_index 16\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 59\n","105\n","neuron 835\n","max_index 3\n","max_index 3\n","max_index 4\n","max_index 2\n","max_index 3\n","max_index 2\n","max_index 2\n","max_index 39\n","max_index 2\n","max_index 2\n","max_index 3\n","max_index 2\n","max_index 10\n","max_index 29\n","max_index 2\n","max_index 69\n","max_index 2\n","max_index 3\n","max_index 3\n","max_index 2\n","106\n","neuron 956\n","max_index 29\n","max_index 39\n","max_index 15\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 13\n","max_index 9\n","max_index 39\n","max_index 39\n","max_index 18\n","107\n","neuron 778\n","max_index 89\n","max_index 69\n","max_index 99\n","max_index 99\n","max_index 99\n","max_index 99\n","max_index 89\n","max_index 99\n","max_index 11\n","max_index 11\n","max_index 11\n","max_index 11\n","max_index 11\n","max_index 11\n","max_index 11\n","max_index 11\n","max_index 11\n","max_index 11\n","max_index 11\n","max_index 11\n","108\n","neuron 980\n","max_index 11\n","max_index 15\n","max_index 15\n","max_index 15\n","max_index 13\n","max_index 14\n","max_index 15\n","max_index 15\n","max_index 13\n","max_index 15\n","max_index 15\n","max_index 16\n","max_index 19\n","max_index 15\n","max_index 15\n","max_index 13\n","max_index 13\n","max_index 16\n","max_index 19\n","max_index 15\n","109\n","neuron 361\n","max_index 4\n","max_index 29\n","max_index 29\n","max_index 3\n","max_index 18\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 19\n","max_index 19\n","max_index 3\n","max_index 29\n","max_index 19\n","max_index 49\n","max_index 337\n","110\n","neuron 623\n","max_index 29\n","max_index 11\n","max_index 12\n","max_index 5\n","max_index 49\n","max_index 10\n","max_index 11\n","max_index 9\n","max_index 10\n","max_index 15\n","max_index 19\n","max_index 19\n","max_index 12\n","max_index 19\n","max_index 12\n","max_index 29\n","max_index 19\n","max_index 18\n","max_index 13\n","max_index 12\n","111\n","neuron 605\n","max_index 7\n","max_index 8\n","max_index 3\n","max_index 5\n","max_index 6\n","max_index 5\n","max_index 6\n","max_index 2\n","max_index 14\n","max_index 11\n","max_index 2\n","max_index 11\n","max_index 7\n","max_index 3\n","max_index 9\n","max_index 6\n","max_index 8\n","max_index 29\n","max_index 2\n","max_index 3\n","112\n","neuron 919\n","max_index 14\n","max_index 11\n","max_index 11\n","max_index 11\n","max_index 18\n","max_index 59\n","max_index 59\n","max_index 18\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 18\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 39\n","max_index 29\n","max_index 18\n","max_index 59\n","113\n","neuron 644\n","max_index 369\n","max_index 639\n","max_index 349\n","max_index 489\n","max_index 39\n","max_index 11\n","max_index 599\n","max_index 259\n","max_index 16\n","max_index 19\n","max_index 139\n","max_index 189\n","max_index 59\n","max_index 169\n","max_index 779\n","max_index 29\n","max_index 369\n","max_index 449\n","max_index 49\n","max_index 739\n","114\n","neuron 510\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 7\n","max_index 29\n","max_index 7\n","max_index 4\n","max_index 29\n","max_index 5\n","max_index 4\n","max_index 7\n","max_index 6\n","max_index 6\n","max_index 4\n","max_index 29\n","max_index 7\n","max_index 4\n","max_index 4\n","115\n","neuron 110\n","max_index 13\n","max_index 39\n","max_index 99\n","max_index 49\n","max_index 109\n","max_index 69\n","max_index 15\n","max_index 79\n","max_index 49\n","max_index 49\n","max_index 49\n","max_index 209\n","max_index 119\n","max_index 39\n","max_index 79\n","max_index 15\n","max_index 109\n","max_index 49\n","max_index 39\n","max_index 109\n","116\n","neuron 630\n","max_index 199\n","max_index 119\n","max_index 59\n","max_index 179\n","max_index 149\n","max_index 59\n","max_index 169\n","max_index 149\n","max_index 109\n","max_index 139\n","max_index 119\n","max_index 169\n","max_index 179\n","max_index 49\n","max_index 69\n","max_index 139\n","max_index 159\n","max_index 49\n","max_index 79\n","max_index 69\n","117\n","neuron 853\n","max_index 9\n","max_index 39\n","max_index 10\n","max_index 39\n","max_index 11\n","max_index 29\n","max_index 9\n","max_index 10\n","max_index 10\n","max_index 9\n","max_index 9\n","max_index 29\n","max_index 10\n","max_index 12\n","max_index 10\n","max_index 29\n","max_index 9\n","max_index 29\n","max_index 10\n","max_index 49\n","118\n","neuron 26\n","max_index 159\n","max_index 159\n","max_index 179\n","max_index 169\n","max_index 149\n","max_index 159\n","max_index 99\n","max_index 349\n","max_index 149\n","max_index 159\n","max_index 199\n","max_index 149\n","max_index 149\n","max_index 119\n","max_index 79\n","max_index 119\n","max_index 349\n","max_index 229\n","max_index 59\n","max_index 349\n","119\n","neuron 539\n","max_index 329\n","max_index 329\n","max_index 329\n","max_index 189\n","max_index 189\n","max_index 199\n","max_index 309\n","max_index 119\n","max_index 309\n","max_index 189\n","max_index 17\n","max_index 119\n","max_index 59\n","max_index 119\n","max_index 199\n","max_index 49\n","max_index 10\n","max_index 119\n","max_index 6\n","max_index 199\n","120\n","neuron 610\n","max_index 119\n","max_index 599\n","max_index 79\n","max_index 69\n","max_index 169\n","max_index 89\n","max_index 429\n","max_index 279\n","max_index 389\n","max_index 149\n","max_index 129\n","max_index 129\n","max_index 59\n","max_index 259\n","max_index 59\n","max_index 119\n","max_index 39\n","max_index 159\n","max_index 269\n","max_index 159\n","121\n","neuron 974\n","max_index 119\n","max_index 199\n","max_index 99\n","max_index 99\n","max_index 69\n","max_index 99\n","max_index 99\n","max_index 349\n","max_index 309\n","max_index 69\n","max_index 29\n","max_index 29\n","max_index 179\n","max_index 9\n","max_index 59\n","max_index 16\n","max_index 49\n","max_index 11\n","max_index 12\n","max_index 29\n","122\n","neuron 500\n","max_index 10\n","max_index 79\n","max_index 10\n","max_index 79\n","max_index 69\n","max_index 79\n","max_index 10\n","max_index 10\n","max_index 5\n","max_index 16\n","max_index 3\n","max_index 4\n","max_index 10\n","max_index 29\n","max_index 18\n","max_index 19\n","max_index 10\n","max_index 10\n","max_index 2\n","max_index 29\n","123\n","neuron 466\n","max_index 3\n","max_index 3\n","max_index 5\n","max_index 4\n","max_index 15\n","max_index 5\n","max_index 3\n","max_index 4\n","max_index 5\n","max_index 3\n","max_index 4\n","max_index 39\n","max_index 3\n","max_index 4\n","max_index 5\n","max_index 5\n","max_index 29\n","max_index 3\n","max_index 4\n","max_index 3\n","124\n","neuron 316\n","max_index 16\n","max_index 16\n","max_index 19\n","max_index 16\n","max_index 16\n","max_index 16\n","max_index 11\n","max_index 16\n","max_index 16\n","max_index 15\n","max_index 11\n","max_index 4\n","max_index 11\n","max_index 16\n","max_index 16\n","max_index 16\n","max_index 16\n","max_index 11\n","max_index 16\n","max_index 16\n","125\n","neuron 12\n","max_index 39\n","max_index 39\n","max_index 29\n","max_index 29\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 29\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 12\n","max_index 39\n","max_index 39\n","max_index 29\n","max_index 29\n","max_index 15\n","max_index 10\n","126\n","neuron 225\n","max_index 18\n","max_index 16\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 11\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 7\n","max_index 10\n","max_index 4\n","max_index 39\n","max_index 13\n","max_index 8\n","max_index 39\n","max_index 39\n","max_index 4\n","max_index 39\n","127\n","neuron 568\n","max_index 8\n","max_index 59\n","max_index 59\n","max_index 5\n","max_index 59\n","max_index 69\n","max_index 69\n","max_index 59\n","max_index 59\n","max_index 69\n","max_index 59\n","max_index 59\n","max_index 59\n","max_index 59\n","max_index 59\n","max_index 59\n","max_index 59\n","max_index 59\n","max_index 5\n","max_index 59\n","128\n","neuron 668\n","max_index 69\n","max_index 69\n","max_index 99\n","max_index 109\n","max_index 109\n","max_index 39\n","max_index 79\n","max_index 109\n","max_index 39\n","max_index 129\n","max_index 109\n","max_index 129\n","max_index 109\n","max_index 129\n","max_index 39\n","max_index 79\n","max_index 59\n","max_index 129\n","max_index 39\n","max_index 129\n","129\n","neuron 166\n","max_index 49\n","max_index 59\n","max_index 49\n","max_index 79\n","max_index 109\n","max_index 39\n","max_index 49\n","max_index 89\n","max_index 49\n","max_index 39\n","max_index 39\n","max_index 59\n","max_index 79\n","max_index 89\n","max_index 49\n","max_index 49\n","max_index 49\n","max_index 59\n","max_index 59\n","max_index 59\n","130\n","neuron 968\n","max_index 14\n","max_index 9\n","max_index 9\n","max_index 9\n","max_index 4\n","max_index 10\n","max_index 4\n","max_index 12\n","max_index 2\n","max_index 4\n","max_index 18\n","max_index 5\n","max_index 8\n","max_index 4\n","max_index 7\n","max_index 10\n","max_index 4\n","max_index 10\n","max_index 11\n","max_index 29\n","131\n","neuron 506\n","max_index 169\n","max_index 99\n","max_index 79\n","max_index 39\n","max_index 109\n","max_index 249\n","max_index 69\n","max_index 139\n","max_index 39\n","max_index 29\n","max_index 89\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 15\n","max_index 109\n","max_index 89\n","max_index 19\n","max_index 59\n","132\n","neuron 828\n","max_index 9\n","max_index 6\n","max_index 7\n","max_index 12\n","max_index 9\n","max_index 11\n","max_index 14\n","max_index 6\n","max_index 7\n","max_index 9\n","max_index 9\n","max_index 15\n","max_index 7\n","max_index 17\n","max_index 10\n","max_index 4\n","max_index 11\n","max_index 9\n","max_index 7\n","max_index 6\n","133\n","neuron 755\n","max_index 39\n","max_index 6\n","max_index 69\n","max_index 14\n","max_index 59\n","max_index 8\n","max_index 139\n","max_index 5\n","max_index 299\n","max_index 17\n","max_index 9\n","max_index 159\n","max_index 16\n","max_index 15\n","max_index 15\n","max_index 15\n","max_index 15\n","max_index 15\n","max_index 8\n","max_index 7\n","134\n","neuron 492\n","max_index 59\n","max_index 59\n","max_index 59\n","max_index 59\n","max_index 59\n","max_index 59\n","max_index 29\n","max_index 18\n","max_index 59\n","max_index 289\n","max_index 16\n","max_index 49\n","max_index 289\n","max_index 39\n","max_index 29\n","max_index 29\n","max_index 39\n","max_index 59\n","max_index 49\n","max_index 29\n","135\n","neuron 969\n","max_index 79\n","max_index 59\n","max_index 49\n","max_index 49\n","max_index 79\n","max_index 49\n","max_index 59\n","max_index 59\n","max_index 49\n","max_index 49\n","max_index 149\n","max_index 59\n","max_index 39\n","max_index 69\n","max_index 49\n","max_index 49\n","max_index 69\n","max_index 59\n","max_index 29\n","max_index 49\n","136\n","neuron 321\n","max_index 310\n","max_index 135\n","max_index 498\n","max_index 215\n","max_index 65\n","max_index 200\n","max_index 576\n","max_index 235\n","max_index 695\n","max_index 173\n","max_index 955\n","max_index 485\n","max_index 59\n","max_index 188\n","max_index 765\n","max_index 49\n","max_index 57\n","max_index 843\n","max_index 628\n","max_index 578\n","137\n","neuron 721\n","max_index 69\n","max_index 59\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 79\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 89\n","max_index 69\n","138\n","neuron 868\n","max_index 17\n","max_index 15\n","max_index 15\n","max_index 17\n","max_index 17\n","max_index 17\n","max_index 15\n","max_index 16\n","max_index 15\n","max_index 15\n","max_index 15\n","max_index 17\n","max_index 17\n","max_index 17\n","max_index 14\n","max_index 15\n","max_index 15\n","max_index 14\n","max_index 15\n","max_index 15\n","139\n","neuron 80\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 39\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","140\n","neuron 265\n","max_index 3\n","max_index 15\n","max_index 3\n","max_index 4\n","max_index 3\n","max_index 10\n","max_index 3\n","max_index 4\n","max_index 5\n","max_index 8\n","max_index 13\n","max_index 3\n","max_index 10\n","max_index 8\n","max_index 7\n","max_index 6\n","max_index 3\n","max_index 3\n","max_index 4\n","max_index 2\n","141\n","neuron 949\n","max_index 15\n","max_index 11\n","max_index 10\n","max_index 7\n","max_index 39\n","max_index 29\n","max_index 12\n","max_index 3\n","max_index 11\n","max_index 7\n","max_index 7\n","max_index 6\n","max_index 11\n","max_index 39\n","max_index 49\n","max_index 14\n","max_index 39\n","max_index 3\n","max_index 3\n","max_index 4\n","142\n","neuron 618\n","max_index 11\n","max_index 11\n","max_index 29\n","max_index 11\n","max_index 14\n","max_index 11\n","max_index 17\n","max_index 17\n","max_index 11\n","max_index 10\n","max_index 10\n","max_index 10\n","max_index 10\n","max_index 10\n","max_index 10\n","max_index 17\n","max_index 17\n","max_index 17\n","max_index 29\n","max_index 10\n","143\n","neuron 411\n","max_index 6\n","max_index 11\n","max_index 15\n","max_index 6\n","max_index 8\n","max_index 6\n","max_index 6\n","max_index 8\n","max_index 7\n","max_index 6\n","max_index 7\n","max_index 2\n","max_index 6\n","max_index 6\n","max_index 6\n","max_index 9\n","max_index 4\n","max_index 6\n","max_index 6\n","max_index 5\n","144\n","neuron 970\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","145\n","neuron 195\n","max_index 59\n","max_index 59\n","max_index 29\n","max_index 11\n","max_index 49\n","max_index 29\n","max_index 129\n","max_index 69\n","max_index 89\n","max_index 11\n","max_index 8\n","max_index 11\n","max_index 19\n","max_index 18\n","max_index 6\n","max_index 29\n","max_index 13\n","max_index 8\n","max_index 7\n","max_index 10\n","146\n","neuron 841\n","max_index 79\n","max_index 79\n","max_index 79\n","max_index 8\n","max_index 14\n","max_index 79\n","max_index 39\n","max_index 49\n","max_index 49\n","max_index 14\n","max_index 14\n","max_index 79\n","max_index 69\n","max_index 39\n","max_index 14\n","max_index 13\n","max_index 13\n","max_index 49\n","max_index 79\n","max_index 13\n","147\n","neuron 324\n","max_index 39\n","max_index 39\n","max_index 11\n","max_index 11\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 11\n","max_index 39\n","max_index 18\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 29\n","max_index 39\n","max_index 16\n","max_index 39\n","max_index 11\n","max_index 29\n","max_index 11\n","148\n","neuron 804\n","max_index 79\n","max_index 49\n","max_index 59\n","max_index 39\n","max_index 29\n","max_index 29\n","max_index 69\n","max_index 49\n","max_index 79\n","max_index 69\n","max_index 59\n","max_index 49\n","max_index 79\n","max_index 69\n","max_index 59\n","max_index 69\n","max_index 89\n","max_index 39\n","max_index 89\n","max_index 59\n","149\n","neuron 298\n","max_index 6\n","max_index 5\n","max_index 5\n","max_index 5\n","max_index 5\n","max_index 5\n","max_index 5\n","max_index 5\n","max_index 5\n","max_index 5\n","max_index 5\n","max_index 10\n","max_index 69\n","max_index 5\n","max_index 6\n","max_index 5\n","max_index 5\n","max_index 5\n","max_index 5\n","max_index 5\n","150\n","neuron 915\n","max_index 39\n","max_index 3\n","max_index 5\n","max_index 39\n","max_index 3\n","max_index 10\n","max_index 2\n","max_index 39\n","max_index 169\n","max_index 4\n","max_index 5\n","max_index 2\n","max_index 4\n","max_index 10\n","max_index 159\n","max_index 5\n","max_index 5\n","max_index 49\n","max_index 4\n","max_index 3\n","151\n","neuron 60\n","max_index 3\n","max_index 29\n","max_index 29\n","max_index 3\n","max_index 12\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 7\n","max_index 29\n","max_index 6\n","max_index 4\n","max_index 5\n","max_index 10\n","max_index 6\n","max_index 3\n","152\n","neuron 213\n","max_index 19\n","max_index 14\n","max_index 19\n","max_index 29\n","max_index 19\n","max_index 29\n","max_index 29\n","max_index 49\n","max_index 9\n","max_index 49\n","max_index 69\n","max_index 17\n","max_index 8\n","max_index 39\n","max_index 139\n","max_index 49\n","max_index 15\n","max_index 49\n","max_index 39\n","max_index 39\n","153\n","neuron 39\n","max_index 29\n","max_index 18\n","max_index 29\n","max_index 29\n","max_index 59\n","max_index 29\n","max_index 29\n","max_index 19\n","max_index 18\n","max_index 18\n","max_index 29\n","max_index 18\n","max_index 18\n","max_index 39\n","max_index 18\n","max_index 17\n","max_index 4\n","max_index 3\n","max_index 8\n","max_index 17\n","154\n","neuron 322\n","max_index 15\n","max_index 8\n","max_index 5\n","max_index 8\n","max_index 17\n","max_index 7\n","max_index 38\n","max_index 49\n","max_index 15\n","max_index 9\n","max_index 10\n","max_index 5\n","max_index 2\n","max_index 9\n","max_index 11\n","max_index 6\n","max_index 49\n","max_index 29\n","max_index 16\n","max_index 13\n","155\n","neuron 743\n","max_index 39\n","max_index 15\n","max_index 59\n","max_index 17\n","max_index 14\n","max_index 14\n","max_index 16\n","max_index 14\n","max_index 10\n","max_index 16\n","max_index 15\n","max_index 18\n","max_index 17\n","max_index 14\n","max_index 18\n","max_index 17\n","max_index 39\n","max_index 17\n","max_index 14\n","max_index 39\n","156\n","neuron 765\n","max_index 59\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 139\n","max_index 89\n","max_index 59\n","max_index 29\n","max_index 29\n","max_index 11\n","max_index 59\n","max_index 17\n","max_index 49\n","max_index 59\n","max_index 29\n","max_index 59\n","max_index 59\n","max_index 59\n","157\n","neuron 255\n","max_index 266\n","max_index 4\n","max_index 2\n","max_index 99\n","max_index 11\n","max_index 5\n","max_index 69\n","max_index 8\n","max_index 14\n","max_index 13\n","max_index 11\n","max_index 8\n","max_index 13\n","max_index 59\n","max_index 5\n","max_index 11\n","max_index 74\n","max_index 4\n","max_index 8\n","max_index 4\n","158\n","neuron 351\n","max_index 6\n","max_index 6\n","max_index 7\n","max_index 89\n","max_index 5\n","max_index 9\n","max_index 9\n","max_index 7\n","max_index 9\n","max_index 6\n","max_index 7\n","max_index 8\n","max_index 9\n","max_index 11\n","max_index 6\n","max_index 10\n","max_index 5\n","max_index 39\n","max_index 3\n","max_index 6\n","159\n","neuron 451\n","max_index 29\n","max_index 29\n","max_index 39\n","max_index 29\n","max_index 11\n","max_index 13\n","max_index 10\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 39\n","max_index 99\n","max_index 18\n","max_index 18\n","max_index 6\n","max_index 8\n","max_index 39\n","max_index 15\n","max_index 49\n","max_index 8\n","160\n","neuron 684\n","max_index 149\n","max_index 209\n","max_index 159\n","max_index 159\n","max_index 59\n","max_index 289\n","max_index 339\n","max_index 489\n","max_index 149\n","max_index 369\n","max_index 69\n","max_index 129\n","max_index 59\n","max_index 109\n","max_index 89\n","max_index 69\n","max_index 139\n","max_index 339\n","max_index 149\n","max_index 99\n","161\n","neuron 885\n","max_index 8\n","max_index 7\n","max_index 12\n","max_index 9\n","max_index 14\n","max_index 19\n","max_index 8\n","max_index 13\n","max_index 10\n","max_index 4\n","max_index 6\n","max_index 4\n","max_index 6\n","max_index 6\n","max_index 4\n","max_index 9\n","max_index 6\n","max_index 29\n","max_index 4\n","max_index 4\n","162\n","neuron 989\n","max_index 69\n","max_index 9\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 4\n","max_index 11\n","max_index 4\n","max_index 79\n","max_index 39\n","max_index 39\n","max_index 59\n","max_index 59\n","max_index 3\n","max_index 5\n","max_index 89\n","max_index 39\n","max_index 3\n","max_index 59\n","163\n","neuron 673\n","max_index 49\n","max_index 29\n","max_index 49\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 39\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","164\n","neuron 231\n","max_index 14\n","max_index 6\n","max_index 8\n","max_index 16\n","max_index 5\n","max_index 17\n","max_index 14\n","max_index 6\n","max_index 6\n","max_index 19\n","max_index 4\n","max_index 7\n","max_index 18\n","max_index 18\n","max_index 11\n","max_index 18\n","max_index 5\n","max_index 6\n","max_index 14\n","max_index 12\n","165\n","neuron 266\n","max_index 8\n","max_index 10\n","max_index 13\n","max_index 39\n","max_index 13\n","max_index 16\n","max_index 49\n","max_index 39\n","max_index 17\n","max_index 59\n","max_index 29\n","max_index 16\n","max_index 39\n","max_index 29\n","max_index 18\n","max_index 10\n","max_index 29\n","max_index 14\n","max_index 11\n","max_index 29\n","166\n","neuron 352\n","max_index 16\n","max_index 10\n","max_index 8\n","max_index 29\n","max_index 39\n","max_index 7\n","max_index 15\n","max_index 29\n","max_index 9\n","max_index 39\n","max_index 109\n","max_index 15\n","max_index 14\n","max_index 7\n","max_index 13\n","max_index 39\n","max_index 29\n","max_index 29\n","max_index 14\n","max_index 29\n","167\n","neuron 687\n","max_index 309\n","max_index 89\n","max_index 109\n","max_index 5\n","max_index 3\n","max_index 39\n","max_index 229\n","max_index 4\n","max_index 3\n","max_index 3\n","max_index 3\n","max_index 5\n","max_index 3\n","max_index 5\n","max_index 4\n","max_index 12\n","max_index 99\n","max_index 49\n","max_index 239\n","max_index 59\n","168\n","neuron 894\n","max_index 159\n","max_index 149\n","max_index 99\n","max_index 179\n","max_index 149\n","max_index 149\n","max_index 159\n","max_index 149\n","max_index 149\n","max_index 149\n","max_index 29\n","max_index 49\n","max_index 209\n","max_index 49\n","max_index 49\n","max_index 49\n","max_index 49\n","max_index 49\n","max_index 49\n","max_index 49\n","169\n","neuron 312\n","max_index 989\n","max_index 169\n","max_index 29\n","max_index 299\n","max_index 179\n","max_index 139\n","max_index 299\n","max_index 239\n","max_index 329\n","max_index 329\n","max_index 329\n","max_index 279\n","max_index 329\n","max_index 129\n","max_index 49\n","max_index 259\n","max_index 79\n","max_index 29\n","max_index 129\n","max_index 49\n","170\n","neuron 17\n","max_index 13\n","max_index 119\n","max_index 13\n","max_index 13\n","max_index 119\n","max_index 279\n","max_index 13\n","max_index 199\n","max_index 13\n","max_index 13\n","max_index 39\n","max_index 13\n","max_index 29\n","max_index 49\n","max_index 159\n","max_index 13\n","max_index 13\n","max_index 149\n","max_index 29\n","max_index 7\n","171\n","neuron 364\n","max_index 10\n","max_index 5\n","max_index 10\n","max_index 6\n","max_index 11\n","max_index 5\n","max_index 7\n","max_index 5\n","max_index 6\n","max_index 7\n","max_index 6\n","max_index 6\n","max_index 8\n","max_index 6\n","max_index 10\n","max_index 6\n","max_index 6\n","max_index 6\n","max_index 12\n","max_index 9\n","172\n","neuron 587\n","max_index 39\n","max_index 4\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 6\n","max_index 4\n","max_index 29\n","max_index 6\n","max_index 39\n","max_index 6\n","max_index 6\n","max_index 19\n","max_index 17\n","max_index 29\n","max_index 12\n","max_index 49\n","max_index 6\n","max_index 6\n","173\n","neuron 552\n","max_index 15\n","max_index 16\n","max_index 13\n","max_index 29\n","max_index 13\n","max_index 16\n","max_index 13\n","max_index 19\n","max_index 13\n","max_index 15\n","max_index 13\n","max_index 29\n","max_index 13\n","max_index 13\n","max_index 29\n","max_index 29\n","max_index 13\n","max_index 13\n","max_index 13\n","max_index 13\n","174\n","neuron 59\n","max_index 16\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 29\n","max_index 39\n","max_index 3\n","max_index 29\n","max_index 3\n","max_index 29\n","max_index 39\n","max_index 16\n","max_index 29\n","max_index 16\n","max_index 29\n","max_index 6\n","max_index 3\n","max_index 2\n","max_index 14\n","175\n","neuron 749\n","max_index 29\n","max_index 49\n","max_index 59\n","max_index 79\n","max_index 49\n","max_index 39\n","max_index 29\n","max_index 16\n","max_index 178\n","max_index 10\n","max_index 39\n","max_index 39\n","max_index 548\n","max_index 39\n","max_index 3\n","max_index 89\n","max_index 5\n","max_index 39\n","max_index 39\n","max_index 49\n","176\n","neuron 645\n","max_index 39\n","max_index 14\n","max_index 39\n","max_index 8\n","max_index 159\n","max_index 39\n","max_index 13\n","max_index 5\n","max_index 29\n","max_index 9\n","max_index 69\n","max_index 6\n","max_index 5\n","max_index 79\n","max_index 5\n","max_index 11\n","max_index 5\n","max_index 119\n","max_index 5\n","max_index 5\n","177\n","neuron 154\n","max_index 4\n","max_index 7\n","max_index 4\n","max_index 7\n","max_index 5\n","max_index 4\n","max_index 29\n","max_index 7\n","max_index 8\n","max_index 8\n","max_index 4\n","max_index 7\n","max_index 3\n","max_index 7\n","max_index 4\n","max_index 6\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 9\n","178\n","neuron 914\n","max_index 12\n","max_index 12\n","max_index 12\n","max_index 12\n","max_index 12\n","max_index 11\n","max_index 16\n","max_index 11\n","max_index 11\n","max_index 10\n","max_index 11\n","max_index 10\n","max_index 11\n","max_index 10\n","max_index 11\n","max_index 10\n","max_index 10\n","max_index 11\n","max_index 11\n","max_index 10\n","179\n","neuron 22\n","max_index 29\n","max_index 5\n","max_index 18\n","max_index 11\n","max_index 10\n","max_index 29\n","max_index 7\n","max_index 59\n","max_index 6\n","max_index 13\n","max_index 3\n","max_index 109\n","max_index 29\n","max_index 17\n","max_index 29\n","max_index 3\n","max_index 29\n","max_index 15\n","max_index 3\n","max_index 39\n","180\n","neuron 502\n","max_index 69\n","max_index 49\n","max_index 49\n","max_index 29\n","max_index 7\n","max_index 69\n","max_index 17\n","max_index 189\n","max_index 17\n","max_index 11\n","max_index 139\n","max_index 79\n","max_index 49\n","max_index 39\n","max_index 12\n","max_index 13\n","max_index 89\n","max_index 79\n","max_index 69\n","max_index 14\n","181\n","neuron 642\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 10\n","max_index 19\n","max_index 10\n","max_index 10\n","max_index 10\n","max_index 69\n","max_index 49\n","max_index 10\n","max_index 10\n","max_index 69\n","max_index 12\n","max_index 10\n","max_index 12\n","max_index 10\n","182\n","neuron 62\n","max_index 139\n","max_index 59\n","max_index 12\n","max_index 10\n","max_index 10\n","max_index 12\n","max_index 279\n","max_index 349\n","max_index 6\n","max_index 79\n","max_index 79\n","max_index 279\n","max_index 10\n","max_index 459\n","max_index 119\n","max_index 17\n","max_index 29\n","max_index 10\n","max_index 11\n","max_index 39\n","183\n","neuron 940\n","max_index 409\n","max_index 309\n","max_index 329\n","max_index 910\n","max_index 89\n","max_index 169\n","max_index 49\n","max_index 39\n","max_index 279\n","max_index 99\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 39\n","max_index 18\n","max_index 17\n","max_index 16\n","max_index 4\n","max_index 479\n","max_index 39\n","184\n","neuron 247\n","max_index 14\n","max_index 4\n","max_index 12\n","max_index 5\n","max_index 6\n","max_index 16\n","max_index 13\n","max_index 15\n","max_index 3\n","max_index 9\n","max_index 2\n","max_index 6\n","max_index 3\n","max_index 8\n","max_index 5\n","max_index 12\n","max_index 4\n","max_index 4\n","max_index 4\n","max_index 8\n","185\n","neuron 46\n","max_index 79\n","max_index 8\n","max_index 39\n","max_index 59\n","max_index 29\n","max_index 16\n","max_index 29\n","max_index 29\n","max_index 10\n","max_index 14\n","max_index 59\n","max_index 12\n","max_index 59\n","max_index 139\n","max_index 109\n","max_index 79\n","max_index 9\n","max_index 6\n","max_index 10\n","max_index 17\n","186\n","neuron 898\n","max_index 69\n","max_index 89\n","max_index 79\n","max_index 89\n","max_index 199\n","max_index 99\n","max_index 69\n","max_index 69\n","max_index 19\n","max_index 59\n","max_index 29\n","max_index 119\n","max_index 99\n","max_index 79\n","max_index 129\n","max_index 99\n","max_index 69\n","max_index 69\n","max_index 79\n","max_index 89\n","187\n","neuron 859\n","max_index 11\n","max_index 39\n","max_index 11\n","max_index 17\n","max_index 11\n","max_index 10\n","max_index 7\n","max_index 17\n","max_index 29\n","max_index 11\n","max_index 49\n","max_index 11\n","max_index 17\n","max_index 11\n","max_index 16\n","max_index 49\n","max_index 7\n","max_index 169\n","max_index 49\n","max_index 199\n","188\n","neuron 669\n","max_index 59\n","max_index 59\n","max_index 79\n","max_index 59\n","max_index 59\n","max_index 89\n","max_index 59\n","max_index 59\n","max_index 59\n","max_index 59\n","max_index 49\n","max_index 69\n","max_index 69\n","max_index 79\n","max_index 69\n","max_index 79\n","max_index 59\n","max_index 501\n","max_index 69\n","max_index 89\n","189\n","neuron 334\n","max_index 29\n","max_index 159\n","max_index 39\n","max_index 17\n","max_index 809\n","max_index 429\n","max_index 149\n","max_index 199\n","max_index 49\n","max_index 149\n","max_index 229\n","max_index 199\n","max_index 29\n","max_index 79\n","max_index 149\n","max_index 29\n","max_index 229\n","max_index 349\n","max_index 17\n","max_index 329\n","190\n","neuron 68\n","max_index 89\n","max_index 49\n","max_index 69\n","max_index 4\n","max_index 99\n","max_index 10\n","max_index 8\n","max_index 89\n","max_index 14\n","max_index 13\n","max_index 14\n","max_index 169\n","max_index 209\n","max_index 3\n","max_index 12\n","max_index 49\n","max_index 6\n","max_index 79\n","max_index 17\n","max_index 7\n","191\n","neuron 63\n","max_index 6\n","max_index 9\n","max_index 6\n","max_index 14\n","max_index 16\n","max_index 9\n","max_index 6\n","max_index 6\n","max_index 8\n","max_index 7\n","max_index 11\n","max_index 7\n","max_index 5\n","max_index 5\n","max_index 19\n","max_index 5\n","max_index 11\n","max_index 29\n","max_index 8\n","max_index 17\n","192\n","neuron 353\n","max_index 49\n","max_index 4\n","max_index 29\n","max_index 14\n","max_index 6\n","max_index 3\n","max_index 6\n","max_index 4\n","max_index 2\n","max_index 59\n","max_index 7\n","max_index 14\n","max_index 10\n","max_index 4\n","max_index 29\n","max_index 10\n","max_index 11\n","max_index 7\n","max_index 8\n","max_index 5\n","193\n","neuron 679\n","max_index 89\n","max_index 39\n","max_index 99\n","max_index 9\n","max_index 39\n","max_index 139\n","max_index 429\n","max_index 99\n","max_index 119\n","max_index 39\n","max_index 479\n","max_index 9\n","max_index 119\n","max_index 359\n","max_index 139\n","max_index 69\n","max_index 19\n","max_index 109\n","max_index 49\n","max_index 189\n","194\n","neuron 432\n","max_index 29\n","max_index 12\n","max_index 8\n","max_index 6\n","max_index 7\n","max_index 6\n","max_index 11\n","max_index 7\n","max_index 6\n","max_index 9\n","max_index 4\n","max_index 13\n","max_index 8\n","max_index 6\n","max_index 7\n","max_index 13\n","max_index 6\n","max_index 29\n","max_index 4\n","max_index 6\n","195\n","neuron 139\n","max_index 4\n","max_index 7\n","max_index 3\n","max_index 7\n","max_index 4\n","max_index 10\n","max_index 4\n","max_index 6\n","max_index 9\n","max_index 16\n","max_index 6\n","max_index 3\n","max_index 4\n","max_index 3\n","max_index 3\n","max_index 5\n","max_index 3\n","max_index 5\n","max_index 8\n","max_index 6\n","196\n","neuron 221\n","max_index 14\n","max_index 14\n","max_index 14\n","max_index 18\n","max_index 14\n","max_index 14\n","max_index 16\n","max_index 14\n","max_index 14\n","max_index 14\n","max_index 14\n","max_index 15\n","max_index 14\n","max_index 18\n","max_index 14\n","max_index 249\n","max_index 14\n","max_index 11\n","max_index 11\n","max_index 14\n","197\n","neuron 459\n","max_index 5\n","max_index 8\n","max_index 8\n","max_index 29\n","max_index 29\n","max_index 14\n","max_index 7\n","max_index 3\n","max_index 13\n","max_index 109\n","max_index 10\n","max_index 5\n","max_index 6\n","max_index 13\n","max_index 12\n","max_index 89\n","max_index 209\n","max_index 8\n","max_index 39\n","max_index 129\n","198\n","neuron 445\n","max_index 16\n","max_index 16\n","max_index 16\n","max_index 16\n","max_index 16\n","max_index 16\n","max_index 11\n","max_index 16\n","max_index 49\n","max_index 16\n","max_index 11\n","max_index 4\n","max_index 11\n","max_index 11\n","max_index 11\n","max_index 11\n","max_index 11\n","max_index 15\n","max_index 11\n","max_index 11\n","199\n","neuron 145\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 69\n","max_index 59\n","CPU times: user 4h 11min 49s, sys: 32.7 s, total: 4h 12min 22s\n","Wall time: 4h 10min 56s\n"]}]},{"cell_type":"code","source":["if False:\n","  with open(os.path.join(base_path, \"data/pruned_snippets.json\"), \"w\") as ofh:\n","    json.dump(pruned_dicts, ofh, indent=2, ensure_ascii=False)"],"metadata":{"id":"_M-1ckfTh_x2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Statistics"],"metadata":{"id":"_fT5LbrMIPDi"}},{"cell_type":"code","source":["import json\n","\n","with open(os.path.join(base_path, \"data/pruned_snippets.json\")) as ifh:\n","  pruned_dicts = json.load(ifh)"],"metadata":{"id":"F1T621krIOqA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import statistics\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=[15, 10])\n","\n","threshold = 50\n","\n","layers = []\n","stats = []\n","for layer, pruned_dict in enumerate(pruned_dicts):\n","  layers.append(layer)\n","  stats.append([])\n","  for neuron, pruned_snippets in pruned_dict.items():\n","    # contexts = [index for _, index in pruned_snippets if threshold is None or index <= threshold]\n","    contexts = [index for _, index in pruned_snippets]\n","    if not contexts:\n","      continue\n","    avg_context = statistics.mean(contexts)\n","    if threshold is not None and avg_context > threshold:\n","      continue\n","    stats[layer].append(avg_context)\n","    # stats[layer].extend(contexts)\n","\n","  # plt.figure(figsize=[15, 10])\n","  plt.hist(stats[layer], bins=50, alpha=0.7)\n","\n","plt.legend(layers)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l01BtPGRIuvd","executionInfo":{"status":"ok","timestamp":1673285795315,"user_tz":0,"elapsed":561,"user":{"displayName":"Alex Foote","userId":"09524383492218707220"}},"outputId":"04adce57-ebe4-40cc-a51c-7bf0f9bcfda3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.legend.Legend at 0x7f9b5a267a30>"]},"metadata":{},"execution_count":19},{"output_type":"display_data","data":{"text/plain":["<Figure size 1080x720 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}